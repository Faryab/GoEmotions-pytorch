{"cells":[{"cell_type":"markdown","metadata":{"id":"9YksMAtTQ4Vr"},"source":["## Mount GDrive, Setup Repo"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16267,"status":"ok","timestamp":1639699201039,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"},"user_tz":300},"id":"xbX3KHegnsuz","outputId":"2fdae8ec-cf4d-43fa-f56b-26b00865220d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"hiFbaMp53eUI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639699184776,"user_tz":300,"elapsed":1513,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"}},"outputId":"11afbd7b-3641-4b4f-8193-38bb89e238ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'GoEmotions-pytorch'...\n","remote: Enumerating objects: 190, done.\u001b[K\n","remote: Counting objects: 100% (190/190), done.\u001b[K\n","remote: Compressing objects: 100% (122/122), done.\u001b[K\n","remote: Total 190 (delta 119), reused 136 (delta 65), pack-reused 0\u001b[K\n","Receiving objects: 100% (190/190), 2.42 MiB | 12.80 MiB/s, done.\n","Resolving deltas: 100% (119/119), done.\n"]}],"source":["!rm -rf GoEmotions-pytorch\n","!git clone https://github.com/Faryab/GoEmotions-pytorch"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":171,"status":"ok","timestamp":1639699201205,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"},"user_tz":300},"id":"RV7L7U_sdJK4"},"outputs":[],"source":["!rm -rf config data LICENSE multilabel_pipeline.py  run_goemotions.py sample_data utils.py requirements.txt\tmodel.py\tdata_loader.py\n","!cp -r /content/GoEmotions-pytorch/* ./\t"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":136,"status":"ok","timestamp":1639699201338,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"},"user_tz":300},"id":"-NNkJMHp3wgz","outputId":"f2d4a0c7-0626-4e8e-f5cb-948a3e8e1992"},"outputs":[{"output_type":"stream","name":"stdout","text":["config\t\tLICENSE\t\t\tREADME.md\t   utils.py\n","data\t\tmodel.py\t\trequirements.txt\n","data_loader.py\tmultilabel_pipeline.py\trun_goemotions.py\n"]}],"source":["!ls /content/GoEmotions-pytorch/"]},{"cell_type":"code","source":["!cat config/original-roberta.json"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lWbmtmme3j9a","executionInfo":{"status":"ok","timestamp":1639699201555,"user_tz":300,"elapsed":219,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"}},"outputId":"1016ba40-308c-4223-e0d8-9dead2696507"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"task\": \"goemotions\",\n","  \"data_dir\": \"data/original\",\n","  \"ckpt_dir\": \"drive/MyDrive/EECS595 Final Project/roberta\",\n","  \"output_dir\": \"ckpt/\",\n","  \"train_file\": \"train.tsv\",\n","  \"dev_file\": \"dev.tsv\",\n","  \"test_file\": \"test.tsv\",\n","  \"label_file\": \"labels.txt\",\n","  \"evaluate_test_during_training\": false,\n","  \"eval_all_checkpoints\": true,\n","  \"save_optimizer\": false,\n","  \"do_lower_case\": false,\n","  \"do_train\": false,\n","  \"do_eval\": true,\n","  \"max_seq_len\": 50,\n","  \"num_train_epochs\": 10,\n","  \"weight_decay\": 0.0,\n","  \"gradient_accumulation_steps\": 1,\n","  \"adam_epsilon\": 1e-8,\n","  \"warmup_proportion\": 0.1,\n","  \"max_steps\": -1,\n","  \"max_grad_norm\": 1.0,\n","  \"no_cuda\": false,\n","  \"model_type\": \"bert\",\n","  \"model_name_or_path\": \"/content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-2000/\",\n","  \"tokenizer_name_or_path\": \"/content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-2000/e\",\n","  \"seed\": 42,\n","  \"train_batch_size\": 64,\n","  \"eval_batch_size\": 32,\n","  \"logging_steps\": 1000,\n","  \"save_steps\": 1000,\n","  \"learning_rate\": 5e-5,\n","  \"threshold\": 0.3\n","}\n"]}]},{"cell_type":"markdown","metadata":{"id":"2JamJmr3ScS0"},"source":["### Pip"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":179391,"status":"ok","timestamp":1639699380944,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"},"user_tz":300},"id":"VqqnU3O2dOVc","outputId":"9978cd04-9b74-4ef5-ac07-39e36925a87d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==1.4.0\n","  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n","\u001b[K     |████████████████████████████████| 753.4 MB 6.8 kB/s \n","\u001b[?25hCollecting transformers==2.11.0\n","  Downloading transformers-2.11.0-py3-none-any.whl (674 kB)\n","\u001b[K     |████████████████████████████████| 674 kB 42.6 MB/s \n","\u001b[?25hCollecting attrdict==2.0.1\n","  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0->-r /content/GoEmotions-pytorch/requirements.txt (line 2)) (1.19.5)\n","Collecting tokenizers==0.7.0\n","  Downloading tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n","\u001b[K     |████████████████████████████████| 5.6 MB 24.8 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0->-r /content/GoEmotions-pytorch/requirements.txt (line 2)) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0->-r /content/GoEmotions-pytorch/requirements.txt (line 2)) (2.23.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 37.6 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0->-r /content/GoEmotions-pytorch/requirements.txt (line 2)) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0->-r /content/GoEmotions-pytorch/requirements.txt (line 2)) (3.4.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 48.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.11.0->-r /content/GoEmotions-pytorch/requirements.txt (line 2)) (4.62.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from attrdict==2.0.1->-r /content/GoEmotions-pytorch/requirements.txt (line 3)) (1.15.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==2.11.0->-r /content/GoEmotions-pytorch/requirements.txt (line 2)) (3.0.6)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0->-r /content/GoEmotions-pytorch/requirements.txt (line 2)) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0->-r /content/GoEmotions-pytorch/requirements.txt (line 2)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0->-r /content/GoEmotions-pytorch/requirements.txt (line 2)) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.11.0->-r /content/GoEmotions-pytorch/requirements.txt (line 2)) (1.24.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.11.0->-r /content/GoEmotions-pytorch/requirements.txt (line 2)) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.11.0->-r /content/GoEmotions-pytorch/requirements.txt (line 2)) (7.1.2)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers, torch, attrdict\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\n","torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n","Successfully installed attrdict-2.0.1 sacremoses-0.0.46 sentencepiece-0.1.96 tokenizers-0.7.0 torch-1.4.0 transformers-2.11.0\n"]}],"source":["!pip install -r /content/GoEmotions-pytorch/requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1639626110688,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"},"user_tz":300},"id":"CNjU3dnX4WAm","outputId":"1e0df559-b96c-465a-af64-17e8e9fa3b02"},"outputs":[{"output_type":"stream","name":"stdout","text":["ekman.json  original.json\t   original-xlnet.json\n","group.json  original-roberta.json\n"]}],"source":["!ls config"]},{"cell_type":"markdown","metadata":{"id":"QPX7peAaRCM5"},"source":["## Run the Original Model Training "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qZ5B1i8qi9DM","outputId":"40836f34-9bcd-4bdb-c0fb-b76a51cbfca4"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","           3.5469e-01, -1.4702e-01],\n","         [ 9.3428e-02,  7.3529e-02,  1.2098e-01,  ..., -3.6620e-01,\n","           3.7040e-01,  9.7400e-04],\n","         [ 2.3537e-01,  7.4738e-02,  7.2659e-02,  ..., -1.0605e-01,\n","           1.5178e-01,  4.6043e-02]],\n","\n","        [[ 3.4254e-01,  1.5826e-01, -2.2965e-01,  ..., -7.0952e-02,\n","           3.9559e-02,  1.2392e-01],\n","         [-7.7794e-02, -4.9016e-01,  4.9758e-01,  ...,  5.5451e-01,\n","           2.5332e-01,  4.1348e-01],\n","         [ 1.3857e-03, -7.0521e-02,  5.1880e-02,  ..., -8.7652e-02,\n","           5.1707e-01, -1.8775e-02],\n","         ...,\n","         [ 8.5866e-02,  2.7964e-01, -2.1547e-01,  ...,  2.9735e-01,\n","          -2.2409e-01, -5.6442e-03],\n","         [ 2.2393e-03,  4.5364e-01, -1.7164e-02,  ...,  3.5918e-01,\n","          -2.8445e-01, -1.5690e-01],\n","         [-1.1666e-01,  3.2119e-01,  3.3919e-02,  ...,  4.6939e-01,\n","          -3.2872e-01, -4.2343e-02]],\n","\n","        [[ 3.4388e-01,  2.0019e-01,  1.8384e-01,  ..., -3.5088e-01,\n","           5.0003e-01, -5.2551e-02],\n","         [ 1.7414e-01, -4.7937e-01,  4.9609e-01,  ...,  4.1938e-01,\n","           2.9359e-01,  3.8781e-01],\n","         [ 3.5009e-01,  2.0679e-01,  1.1221e-01,  ...,  5.5320e-01,\n","           1.0191e+00, -2.3906e-01],\n","         ...,\n","         [ 9.5129e-02, -5.5175e-03,  2.1182e-01,  ...,  4.4234e-02,\n","           5.7117e-01, -4.3055e-01],\n","         [ 6.9363e-02, -2.0709e-01, -1.3828e-01,  ..., -5.2804e-03,\n","           4.4299e-01,  1.1600e-01],\n","         [-1.2752e-02, -4.3543e-02, -1.0304e-01,  ...,  7.1142e-02,\n","           5.8772e-01, -2.5388e-02]],\n","\n","        ...,\n","\n","        [[ 3.5255e-01,  2.4570e-01, -2.7950e-02,  ..., -1.7990e-01,\n","           8.9905e-02,  2.2027e-01],\n","         [ 5.0229e-01, -2.8001e-01,  4.3268e-01,  ..., -3.1976e-01,\n","           7.5126e-02,  3.0262e-01],\n","         [ 2.6362e-01, -8.8194e-02,  3.5794e-01,  ...,  5.8471e-01,\n","          -1.0791e-01,  2.5023e-01],\n","         ...,\n","         [-2.3557e-02,  2.2774e-01, -1.5984e-01,  ...,  2.4265e-01,\n","          -2.0277e-01, -1.3645e-01],\n","         [ 1.7669e-01, -9.7271e-02, -1.5821e-01,  ..., -4.5231e-02,\n","           1.6464e-01,  3.8642e-01],\n","         [ 2.5946e-01, -9.9221e-02, -2.0305e-01,  ...,  5.8412e-02,\n","          -3.0498e-01,  2.7968e-01]],\n","\n","        [[ 3.1060e-01,  1.8983e-01,  1.5960e-01,  ..., -1.9658e-01,\n","           3.7157e-01,  1.1485e-01],\n","         [ 5.4041e-01, -6.0609e-01,  6.3711e-01,  ..., -7.7275e-02,\n","           6.1914e-03,  4.1709e-01],\n","         [ 3.5798e-01, -8.3718e-02,  5.1835e-01,  ...,  5.4766e-01,\n","          -5.0405e-01,  1.7277e-01],\n","         ...,\n","         [ 3.0492e-01,  3.6125e-02,  2.7437e-01,  ...,  1.0348e-01,\n","           5.4737e-01,  7.1510e-02],\n","         [ 2.0505e-01,  1.5781e-01,  2.4610e-01,  ...,  2.3393e-01,\n","           5.6313e-01, -4.5092e-02],\n","         [ 1.2652e-01, -6.1535e-02,  7.3902e-02,  ..., -6.8867e-02,\n","           3.8842e-01,  3.1464e-01]],\n","\n","        [[ 1.9744e-01,  2.1266e-01,  1.1265e-01,  ..., -2.9217e-01,\n","           1.1728e-01, -2.9637e-01],\n","         [ 4.4724e-01, -1.7627e-01,  5.2296e-01,  ..., -5.2096e-02,\n","           2.6010e-01, -4.5732e-02],\n","         [-2.9592e-01,  2.9465e-01, -3.1533e-02,  ..., -2.8234e-01,\n","           2.1720e-01, -5.1167e-01],\n","         ...,\n","         [-1.9385e-01,  1.8220e-01, -8.0951e-02,  ...,  5.1924e-02,\n","           2.5688e-01, -3.6876e-01],\n","         [-2.1622e-01,  4.2488e-02,  1.5286e-01,  ..., -1.7901e-01,\n","           2.1079e-01, -2.0877e-01],\n","         [-1.5815e-01,  5.0533e-02, -2.1108e-02,  ..., -1.2299e-01,\n","           1.6966e-01, -2.2417e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward>), tensor([[-0.6503,  0.5203,  0.9997,  ...,  0.9999, -0.8346,  0.9853],\n","        [-0.7062,  0.4831,  0.9998,  ...,  1.0000, -0.7622,  0.9898],\n","        [-0.7134,  0.4112,  0.9998,  ...,  1.0000, -0.7169,  0.9965],\n","        ...,\n","        [-0.6843,  0.3494,  0.9996,  ...,  0.9999, -0.7264,  0.9863],\n","        [-0.7826,  0.4343,  0.9999,  ...,  1.0000, -0.2396,  0.9943],\n","        [-0.5278,  0.3607,  0.9995,  ...,  0.9999, -0.8759,  0.9922]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.6503,  0.5203,  0.9997,  ...,  0.9999, -0.8346,  0.9853],\n","        [-0.7062,  0.4831,  0.9998,  ...,  1.0000, -0.7622,  0.9898],\n","        [-0.7134,  0.4112,  0.9998,  ...,  1.0000, -0.7169,  0.9965],\n","        ...,\n","        [-0.6843,  0.3494,  0.9996,  ...,  0.9999, -0.7264,  0.9863],\n","        [-0.7826,  0.4343,  0.9999,  ...,  1.0000, -0.2396,  0.9943],\n","        [-0.5278,  0.3607,  0.9995,  ...,  0.9999, -0.8759,  0.9922]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-9.4791e-01, -5.0791e-01,  1.6015e-01, -3.8817e-01,  1.3854e-01,\n","          7.9401e-01, -1.0094e+00,  9.5556e-01, -3.3974e-01, -3.9312e-01,\n","          1.9293e-01,  1.0355e+00, -1.6380e-01,  4.9936e-01,  1.5919e-01,\n","          4.8371e-01, -2.9992e-01,  9.1040e-01,  6.9646e-03, -7.5167e-01,\n","         -1.5463e+00,  4.7828e-01,  1.5797e-01, -2.3692e-01,  3.3535e-01,\n","          9.8652e-01,  2.9182e-01,  3.6976e-01],\n","        [-7.1935e-01, -6.2138e-01,  3.0037e-01, -9.1466e-02,  4.7354e-01,\n","          6.9573e-01, -8.4825e-01,  8.9847e-01, -3.2311e-01, -5.2140e-01,\n","         -1.4917e-01,  7.6268e-01, -3.5265e-01,  4.0395e-01, -2.1290e-01,\n","          1.5918e-01,  1.0975e-01,  1.0261e+00,  1.8866e-02, -9.6169e-01,\n","         -1.4301e+00,  2.4246e-01,  3.6696e-01, -2.5852e-01,  4.2984e-01,\n","          1.1127e+00,  3.9082e-01,  1.0188e-01],\n","        [-8.9626e-01, -4.4666e-01,  2.2796e-01, -2.9704e-01,  4.6203e-01,\n","          2.9061e-01, -1.1077e+00,  7.4044e-01, -3.0948e-01, -7.8890e-01,\n","          2.0807e-02,  5.4010e-01, -1.3598e-01,  3.9809e-01, -1.1387e-01,\n","          4.8328e-01, -2.4890e-02,  8.2457e-01,  4.3616e-02, -5.9642e-01,\n","         -1.3631e+00,  1.4809e-01,  2.9208e-01, -2.6752e-01,  2.5182e-01,\n","          9.7772e-01,  1.5654e-01,  3.5443e-01],\n","        [-9.1172e-01, -5.1047e-01, -1.3530e-01, -3.0778e-01,  5.6236e-01,\n","          5.3519e-01, -8.7028e-01,  8.0214e-01, -3.7283e-01, -6.3659e-01,\n","         -8.7833e-02,  7.1984e-01, -3.9322e-01,  7.6165e-01, -1.8045e-01,\n","          2.4689e-01, -2.7965e-01,  8.7203e-01, -2.9134e-01, -7.9136e-01,\n","         -1.3840e+00,  1.4788e-01,  1.1687e-01,  2.6267e-01,  4.9815e-01,\n","          1.1699e+00,  2.9064e-01,  5.0163e-01],\n","        [-4.6288e-01, -9.1127e-01,  2.5323e-01, -1.9316e-01,  4.1070e-01,\n","          6.8390e-01, -9.3883e-01,  7.6098e-01, -1.1508e-01, -4.2547e-01,\n","          2.1164e-01,  7.6574e-01, -1.5641e-01,  3.5177e-01, -5.3941e-02,\n","          1.8185e-01, -2.0241e-01,  8.3502e-01,  1.6263e-01, -6.5907e-01,\n","         -1.5010e+00,  1.1792e-01,  5.7214e-01, -1.6417e-01,  2.9807e-01,\n","          7.9258e-01,  1.5248e-01,  3.3199e-01],\n","        [-9.1847e-01, -6.2306e-01,  2.6322e-01, -3.9526e-01,  2.5877e-01,\n","          3.1598e-01, -9.3884e-01,  8.1934e-01, -1.3941e-01, -7.2069e-01,\n","         -3.5368e-01,  5.8719e-01, -1.2991e-01,  4.0125e-01, -6.9201e-02,\n","          5.5886e-01, -7.7697e-02,  7.5182e-01, -1.2182e-01, -6.0010e-01,\n","         -1.1631e+00,  1.4728e-01,  2.6171e-01, -1.5628e-01,  4.1127e-01,\n","          7.8877e-01, -1.2805e-02,  4.1924e-01],\n","        [-8.3905e-01, -4.9645e-01,  1.5184e-01, -2.7758e-01,  5.1871e-01,\n","          8.2953e-01, -8.3173e-01,  7.9192e-01, -3.7308e-01, -4.3884e-01,\n","         -1.8696e-02,  7.4937e-01,  9.1964e-02,  6.8013e-01,  1.5094e-01,\n","          3.8212e-01, -1.7149e-01,  1.1121e+00,  5.7172e-02, -6.4181e-01,\n","         -1.4854e+00,  4.3338e-01,  2.5108e-01, -3.6005e-01,  2.9097e-01,\n","          8.3953e-01,  3.7041e-01,  6.4047e-01],\n","        [-9.8047e-01, -7.8439e-01,  3.7938e-01, -1.5229e-02,  2.3131e-01,\n","          7.6779e-01, -1.0790e+00,  7.7578e-01,  3.6999e-02, -1.8929e-01,\n","         -3.7367e-02,  4.9343e-01, -3.2963e-01,  6.3443e-01,  1.2593e-01,\n","          4.6273e-01,  1.0983e-01,  6.9871e-01,  2.3328e-01, -1.0197e+00,\n","         -1.1867e+00, -1.3694e-01,  4.3150e-01, -6.3916e-02,  3.4709e-01,\n","          7.8019e-01, -1.2266e-01,  5.6513e-01],\n","        [-4.8917e-01, -3.5375e-01, -6.6612e-02, -2.2018e-01,  4.9880e-01,\n","          4.3779e-01, -7.1681e-01,  8.9260e-01, -3.4530e-01, -3.1654e-01,\n","          7.7764e-03,  6.5904e-01, -5.8181e-01,  5.7876e-01,  3.6863e-02,\n","          2.6939e-01,  8.7294e-02,  8.8029e-01,  4.8475e-02, -7.1593e-01,\n","         -1.7890e+00,  2.2541e-01,  3.0315e-02, -3.2473e-01,  1.1528e-01,\n","          7.3129e-01, -1.2309e-01,  5.4350e-01],\n","        [-8.4725e-01, -7.5331e-01,  3.5185e-01, -2.4003e-01,  4.4520e-01,\n","          4.2512e-01, -6.9999e-01,  8.5813e-01, -3.7483e-01, -5.6629e-01,\n","          1.0308e-02,  6.6323e-01, -2.9307e-01,  2.2091e-01, -3.0604e-02,\n","          1.7449e-01, -2.2047e-01,  8.8713e-01, -8.0193e-02, -1.0334e+00,\n","         -1.5803e+00,  6.6208e-02,  2.1062e-01, -2.5777e-01,  1.8821e-01,\n","          1.3154e+00,  1.0031e-01,  1.6963e-01],\n","        [-6.7140e-01, -6.2012e-01,  4.2042e-02, -1.3159e-01,  7.8117e-01,\n","          5.8364e-01, -8.8717e-01,  6.8119e-01,  2.0153e-03, -8.4848e-01,\n","         -2.1147e-01,  8.1186e-01, -1.1313e-01,  3.5769e-01,  7.4066e-02,\n","          4.8613e-01, -8.2840e-02,  6.1464e-01, -2.4480e-01, -1.0563e+00,\n","         -1.6485e+00,  3.7447e-01,  4.4085e-01, -4.5270e-01,  2.4702e-01,\n","          7.4221e-01,  2.0168e-01,  3.6784e-01],\n","        [-7.0787e-01, -7.1114e-01,  7.9121e-02, -1.6856e-01,  4.1603e-01,\n","          3.7074e-01, -9.9135e-01,  8.7446e-01, -1.3705e-01, -3.2462e-01,\n","          1.7818e-01,  7.1318e-01, -3.7597e-01,  7.0357e-01,  1.2188e-01,\n","          2.5265e-02, -1.8163e-01,  8.1405e-01,  1.2802e-01, -6.5972e-01,\n","         -1.8334e+00,  1.4678e-01,  2.9370e-01, -3.7990e-01,  2.8628e-01,\n","          1.2145e+00,  7.1951e-02,  6.3681e-01],\n","        [-9.3335e-01, -5.5502e-01,  1.4720e-01, -2.5375e-01,  3.3303e-01,\n","          3.5842e-01, -8.0609e-01,  6.2227e-01, -2.7602e-01, -3.5165e-01,\n","          7.3192e-03,  3.5686e-01, -1.6429e-01,  6.4807e-01, -9.5632e-02,\n","          1.2741e-01, -2.0681e-01,  7.8682e-01, -7.3992e-02, -6.6913e-01,\n","         -1.5555e+00,  5.9895e-01,  4.5029e-01,  1.6819e-01,  1.8158e-01,\n","          9.2092e-01,  3.9041e-01,  3.7820e-01],\n","        [-7.0363e-01, -5.2917e-01,  1.1047e-01, -3.0683e-01,  3.6608e-01,\n","          5.5223e-01, -9.1238e-01,  6.1640e-01, -2.2746e-01, -5.4005e-01,\n","         -5.5460e-04,  7.4277e-01, -8.8921e-02,  6.1250e-01,  7.8635e-02,\n","          4.3873e-01, -1.9535e-01,  1.1766e+00, -1.8988e-01, -7.5498e-01,\n","         -1.1433e+00,  1.3911e-01,  2.7706e-01, -3.6226e-01,  1.6079e-01,\n","          7.6322e-01,  2.7855e-01,  3.9802e-01],\n","        [-8.9278e-01, -8.8518e-01,  4.8292e-01,  3.7593e-02,  1.6920e-01,\n","          4.9376e-01, -7.9841e-01,  8.8226e-01, -4.0367e-01, -4.9656e-01,\n","          2.1393e-02,  6.8592e-01, -3.0776e-01,  2.0690e-01,  1.4775e-01,\n","         -4.0486e-02,  3.8588e-01,  5.1254e-01, -7.6919e-02, -7.3712e-01,\n","         -1.6187e+00,  2.7516e-03,  1.1886e-01, -2.0255e-01, -7.1698e-02,\n","          7.0002e-01, -9.7162e-02,  7.4311e-02],\n","        [-8.8164e-01, -5.7186e-01,  4.1579e-01, -3.9272e-01,  6.2210e-01,\n","          5.1782e-01, -1.1747e+00,  7.4140e-01, -3.2406e-01, -4.1335e-01,\n","          2.5579e-02,  6.2518e-01, -2.6288e-02,  5.0404e-01, -1.9387e-01,\n","          4.0209e-01, -1.5911e-01,  8.4186e-01, -3.4403e-01, -7.8183e-01,\n","         -1.4028e+00,  2.4966e-01,  5.6069e-02, -1.3218e-01,  1.7257e-01,\n","          1.0795e+00,  4.8778e-01,  5.6531e-01]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   1% 29/2714 [00:11<17:11,  2.60it/s]\u001b[Aoutputs:\n","(tensor([[[ 0.5597,  0.3323,  0.1124,  ..., -0.2766,  0.0341, -0.0464],\n","         [-0.0123,  0.6793, -0.0451,  ..., -0.0073, -0.0860,  0.0875],\n","         [-0.2039, -0.1181,  0.3650,  ...,  0.1451, -0.0603,  0.4077],\n","         ...,\n","         [ 0.0959,  0.1614,  0.1590,  ...,  0.1322,  0.3429, -0.2613],\n","         [ 0.0516,  0.4233,  0.0376,  ...,  0.0155,  0.0909, -0.2236],\n","         [ 0.2099,  0.4674,  0.0280,  ...,  0.0675,  0.0408, -0.3468]],\n","\n","        [[ 0.3530,  0.1142,  0.1124,  ...,  0.0078,  0.3429,  0.1186],\n","         [ 0.2369, -0.4208,  0.4952,  ..., -0.1844,  0.4916,  0.2161],\n","         [ 0.5320, -0.1229,  0.0261,  ...,  0.3672,  0.5301,  0.3653],\n","         ...,\n","         [ 0.1759,  0.5277,  0.1474,  ...,  0.0419,  0.0325,  0.0522],\n","         [ 0.1275,  0.4343,  0.0709,  ...,  0.0201,  0.0946,  0.0871],\n","         [ 0.1685,  0.6273,  0.0584,  ..., -0.0502,  0.0782, -0.0212]],\n","\n","        [[ 0.4053, -0.0504,  0.0671,  ..., -0.0577,  0.4690,  0.3441],\n","         [ 0.4856, -0.6902,  0.5752,  ..., -0.1614,  0.2888, -0.0755],\n","         [ 0.4251, -0.2199,  0.3744,  ...,  0.2607,  0.7331, -0.6562],\n","         ...,\n","         [-0.1381,  0.1697,  0.0671,  ..., -0.0359,  0.1946, -0.4391],\n","         [-0.0100,  0.1385,  0.1181,  ..., -0.1633,  0.2052, -0.4285],\n","         [-0.2024, -0.0096, -0.1993,  ..., -0.0014,  0.0042, -0.3560]],\n","\n","        ...,\n","\n","        [[ 0.3999,  0.3168, -0.2775,  ..., -0.3356,  0.2606, -0.1595],\n","         [ 0.4404, -0.5011,  0.0577,  ..., -0.2484, -0.1862, -0.3035],\n","         [ 0.4293,  0.5364, -0.1678,  ..., -0.0678,  0.3405, -0.2421],\n","         ...,\n","         [ 0.0911, -0.0230, -0.0116,  ...,  0.0120,  0.0450,  0.0543],\n","         [ 0.0396,  0.1070, -0.2033,  ..., -0.0958, -0.0545, -0.3013],\n","         [-0.0456,  0.2166, -0.1407,  ..., -0.2656,  0.1512, -0.1989]],\n","\n","        [[ 0.7698, -0.0962, -0.0197,  ..., -0.1878,  0.2013, -0.0032],\n","         [ 0.4373, -0.1955,  0.1778,  ...,  0.0196,  0.1219, -0.0622],\n","         [ 0.4038, -0.0873, -0.3654,  ...,  0.0747,  0.6132,  0.1207],\n","         ...,\n","         [-0.1193,  0.3032,  0.0785,  ...,  0.1354,  0.4533,  0.2111],\n","         [ 0.1040,  0.0559, -0.2264,  ...,  0.3657,  0.0754,  0.0131],\n","         [ 0.0331,  0.3527, -0.1069,  ...,  0.4195,  0.2695, -0.0498]],\n","\n","        [[ 0.4649,  0.3008,  0.1768,  ..., -0.3441,  0.3406,  0.3364],\n","         [ 0.7833, -0.2591,  0.8451,  ..., -0.3846,  0.1920,  0.2943],\n","         [ 0.3569, -0.2784,  0.1873,  ..., -0.1543,  0.0384,  0.8805],\n","         ...,\n","         [-0.0891, -0.0090,  0.2373,  ...,  0.1638,  0.3296,  0.5158],\n","         [-0.0767,  0.0684,  0.3604,  ..., -0.0606,  0.4686,  0.3524],\n","         [-0.1836,  0.4223, -0.0998,  ...,  0.0517,  0.0649,  0.0106]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward>), tensor([[-0.6455,  0.4751,  0.9998,  ...,  1.0000, -0.9156,  0.9951],\n","        [-0.7463,  0.4806,  0.9999,  ...,  1.0000, -0.7932,  0.9957],\n","        [-0.7516,  0.3076,  0.9997,  ...,  0.9999, -0.6911,  0.9877],\n","        ...,\n","        [-0.6102,  0.4231,  0.9998,  ...,  1.0000, -0.7855,  0.9942],\n","        [-0.6044,  0.4318,  0.9994,  ...,  0.9998, -0.7203,  0.9754],\n","        [-0.8041,  0.4943,  0.9998,  ...,  0.9999, -0.6003,  0.9845]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.6455,  0.4751,  0.9998,  ...,  1.0000, -0.9156,  0.9951],\n","        [-0.7463,  0.4806,  0.9999,  ...,  1.0000, -0.7932,  0.9957],\n","        [-0.7516,  0.3076,  0.9997,  ...,  0.9999, -0.6911,  0.9877],\n","        ...,\n","        [-0.6102,  0.4231,  0.9998,  ...,  1.0000, -0.7855,  0.9942],\n","        [-0.6044,  0.4318,  0.9994,  ...,  0.9998, -0.7203,  0.9754],\n","        [-0.8041,  0.4943,  0.9998,  ...,  0.9999, -0.6003,  0.9845]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-1.0323, -0.3479,  0.2197, -0.1457,  0.4600,  0.4271, -1.1624,  0.8851,\n","         -0.3569, -0.3941,  0.1801,  0.8398,  0.0366,  0.7060, -0.0139, -0.0900,\n","         -0.3682,  0.9421,  0.0533, -0.4641, -1.3398,  0.1629, -0.0626, -0.0108,\n","          0.1610,  1.0661, -0.0632,  0.4050],\n","        [-0.8297, -0.7212,  0.2498, -0.1840,  0.3845,  0.6540, -1.1071,  1.0848,\n","         -0.2484, -0.2631, -0.1207,  0.4944,  0.0388,  0.6412, -0.2105,  0.0926,\n","         -0.2490,  0.8975,  0.2275, -0.6846, -1.6090,  0.1498,  0.2325,  0.0579,\n","          0.0522,  1.0296,  0.0778,  0.4308],\n","        [-0.7871, -0.3638,  0.2181, -0.4311,  0.4857,  0.7548, -0.7999,  0.7197,\n","         -0.6086, -0.6131, -0.0111,  0.5866, -0.3906,  0.4369,  0.0907,  0.2064,\n","         -0.0673,  0.9911, -0.1654, -0.9553, -1.2112, -0.0130,  0.4654, -0.0595,\n","          0.4394,  0.8423,  0.1228,  0.3088],\n","        [-0.7086, -0.5297,  0.2798, -0.0786,  0.3759,  0.2109, -1.0424,  0.9501,\n","         -0.1319, -0.4516, -0.3494,  0.3900, -0.2219,  0.3707,  0.1716,  0.3913,\n","         -0.4273,  0.9276, -0.2950, -0.8135, -1.3485,  0.5727,  0.1681,  0.0583,\n","          0.3186,  0.7101,  0.2060,  0.4644],\n","        [-0.8840, -0.6670, -0.0703, -0.2192,  0.4215,  0.6597, -1.2921,  0.7765,\n","         -0.3385, -0.5557, -0.0894,  0.8636,  0.0964,  0.3860,  0.2117,  0.3227,\n","         -0.2986,  0.7472, -0.1391, -0.3824, -1.2627,  0.5322,  0.3787, -0.0949,\n","          0.3951,  0.7343,  0.2170,  0.6499],\n","        [-0.7428, -0.6215,  0.1394,  0.1826,  0.7078,  0.2953, -0.9405,  0.6761,\n","         -0.2621, -0.3478, -0.0387,  0.9925,  0.1301,  0.5444,  0.0848,  0.1275,\n","         -0.0400,  0.9294, -0.2308, -0.6839, -1.3525,  0.1946,  0.3169, -0.2290,\n","          0.1981,  0.7829,  0.1347,  0.4716],\n","        [-0.8006, -0.3439,  0.0913, -0.1594,  0.3736,  0.7574, -1.0673,  0.6289,\n","         -0.3745, -0.4870, -0.1360,  0.6719,  0.2497,  0.3468, -0.0677,  0.1327,\n","          0.0102,  1.0394, -0.2443, -0.7378, -1.5083,  0.3564,  0.2187, -0.2119,\n","          0.1921,  0.7863,  0.2414,  0.4954],\n","        [-0.8073, -0.9662,  0.5004, -0.0843,  0.2219,  0.4339, -0.8362,  0.8945,\n","         -0.3234, -0.3522,  0.0504,  0.5864,  0.2060,  0.2798,  0.0589,  0.3148,\n","         -0.0948,  0.6406,  0.0306, -0.9994, -1.4689,  0.1901,  0.2445, -0.1391,\n","          0.1974,  0.8348,  0.1142,  0.3193],\n","        [-0.5452, -0.4162, -0.0545, -0.3485,  0.4857,  0.3675, -0.9556,  0.6135,\n","         -0.2840, -0.4657, -0.2634,  0.7561, -0.2288,  0.4359,  0.0722,  0.2099,\n","         -0.2066,  1.1494, -0.2950, -0.4234, -1.3029,  0.1080,  0.3528, -0.0334,\n","          0.3611,  0.7997,  0.0997,  0.5131],\n","        [-0.7691, -0.6535,  0.3677, -0.0559,  0.2332,  0.7289, -1.0711,  0.9195,\n","         -0.0450, -0.3037, -0.0360,  0.7326, -0.3052,  0.5403, -0.1316,  0.1128,\n","         -0.2838,  0.7950, -0.1174, -0.9433, -1.5686,  0.2662,  0.6349, -0.1229,\n","          0.4939,  1.0623,  0.2470,  0.4995],\n","        [-0.7073, -0.9484,  0.5951, -0.4802,  0.6797,  0.6651, -1.1628,  0.9327,\n","         -0.1806, -0.8313,  0.0075,  0.6405,  0.1003,  0.4052, -0.0340,  0.6496,\n","         -0.2086,  0.7224, -0.2288, -0.9083, -1.1397,  0.2020,  0.4233,  0.1014,\n","          0.3432,  0.6778,  0.1677,  0.4195],\n","        [-1.0790, -0.3249,  0.1355, -0.4405,  0.4833,  0.5678, -0.7169,  0.6484,\n","         -0.3557, -0.2762, -0.1801,  0.6381, -0.0650,  0.6135, -0.0023,  0.4431,\n","         -0.0677,  0.8969, -0.1334, -0.6647, -1.4626,  0.3046,  0.4395, -0.0050,\n","          0.3945,  0.6937,  0.3506,  0.6258],\n","        [-0.8850, -0.6063,  0.3966, -0.4267,  0.2299,  0.2886, -0.8252,  0.8375,\n","         -0.2842, -0.5694,  0.0062,  0.9293, -0.1301,  0.6120,  0.1134,  0.3138,\n","         -0.0792,  0.8867, -0.0230, -0.5955, -1.0581,  0.0132,  0.1754, -0.3419,\n","          0.4049,  1.0189,  0.2794,  0.4604],\n","        [-0.7261, -0.6307,  0.0288, -0.4202,  0.4915,  0.6323, -0.7914,  0.6802,\n","         -0.3514, -0.5153,  0.1193,  0.6501,  0.2367,  0.5464, -0.1277,  0.3100,\n","         -0.1625,  0.9067, -0.1337, -0.5099, -1.0920,  0.2703,  0.2116, -0.2807,\n","          0.3641,  0.7754,  0.3701,  0.5831],\n","        [-0.7479, -0.5859,  0.2515, -0.3461,  0.3728,  0.6651, -1.0212,  0.8085,\n","         -0.3470, -0.6764,  0.1631,  0.5824, -0.1693,  0.5221,  0.1144,  0.3031,\n","         -0.3826,  1.0014, -0.1116, -0.7057, -1.4193,  0.1688,  0.5307, -0.3091,\n","          0.2143,  0.8006,  0.2015,  0.3016],\n","        [-0.8661, -0.6295,  0.3359, -0.1782,  0.2165,  0.5656, -0.8995,  0.9946,\n","         -0.2873, -0.6218, -0.0463,  0.4265, -0.4908,  0.7170,  0.0159,  0.3063,\n","         -0.1535,  1.0224,  0.0279, -0.6390, -1.6845,  0.0945,  0.3688, -0.1055,\n","          0.1003,  0.9499,  0.0440,  0.1330]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   1% 30/2714 [00:11<17:10,  2.60it/s]\u001b[Aoutputs:\n","(tensor([[[ 0.3420,  0.2089, -0.1602,  ..., -0.0757,  0.3073, -0.0441],\n","         [ 0.5563, -0.3078,  0.2839,  ...,  0.0426,  0.0476,  0.1094],\n","         [ 0.5734,  0.3384, -0.3487,  ...,  0.5624,  0.5168, -0.1053],\n","         ...,\n","         [ 0.1641,  0.1432, -0.1198,  ...,  0.0911,  0.5564, -0.2450],\n","         [ 0.3340,  0.1320, -0.2318,  ...,  0.0552,  0.7000, -0.0643],\n","         [ 0.1069,  0.2553, -0.3555,  ...,  0.1973,  0.0986, -0.0708]],\n","\n","        [[ 0.4767,  0.3704,  0.0225,  ..., -0.6418,  0.0857,  0.0453],\n","         [ 0.3834, -0.0656,  0.7246,  ..., -0.3197, -0.2117,  0.0837],\n","         [ 0.2810,  0.0335,  0.2704,  ..., -0.3106,  0.1332,  0.0711],\n","         ...,\n","         [ 0.2609,  0.2431,  0.0591,  ..., -0.2241,  0.2390, -0.3272],\n","         [ 0.5529,  0.1881, -0.3128,  ..., -0.1792,  0.2763,  0.3619],\n","         [-0.3442,  0.4235, -0.0498,  ...,  0.2429,  0.1397, -0.2978]],\n","\n","        [[ 0.3348,  0.2269,  0.1849,  ..., -0.1078,  0.2533,  0.0586],\n","         [-0.4125, -0.3819, -1.1758,  ...,  0.5701,  0.9036,  0.4867],\n","         [-0.5177, -0.6147,  0.1254,  ..., -0.0793, -0.3752,  0.3952],\n","         ...,\n","         [ 0.3403,  0.3556,  0.2801,  ..., -0.0085,  0.3945, -0.1229],\n","         [ 0.0110,  0.1225, -0.2634,  ...,  0.2630,  0.6504,  0.0403],\n","         [-0.0839,  0.0313, -0.0647,  ...,  0.3656,  0.6890,  0.1753]],\n","\n","        ...,\n","\n","        [[ 0.4432,  0.2474, -0.1913,  ..., -0.0354,  0.4515,  0.2435],\n","         [ 0.5576, -0.3027,  0.4528,  ..., -0.1782,  0.0905,  0.2903],\n","         [ 0.4271,  0.5326, -0.5378,  ...,  0.2425,  0.3345, -0.1282],\n","         ...,\n","         [-0.4284,  0.4684, -0.2309,  ...,  0.2777,  0.2760, -0.3036],\n","         [ 0.0199,  0.0949, -0.3253,  ...,  0.1060,  0.3110,  0.2721],\n","         [ 0.1158,  0.4933, -0.3565,  ...,  0.3140, -0.0718,  0.1560]],\n","\n","        [[ 0.3409,  0.1541, -0.2285,  ..., -0.0915,  0.1761, -0.1846],\n","         [ 0.6160, -0.3735,  0.3444,  ..., -0.3230,  0.3606, -0.0876],\n","         [ 0.6166,  0.0783,  0.2838,  ...,  0.1831,  0.3109,  0.1021],\n","         ...,\n","         [-0.2146,  0.3163, -0.3799,  ...,  0.0053,  0.7003, -0.3542],\n","         [-0.1042,  0.3946, -0.2238,  ...,  0.0028,  0.6376, -0.3025],\n","         [-0.0540,  0.2082, -0.0658,  ...,  0.1282,  0.5035, -0.0693]],\n","\n","        [[ 0.3503, -0.0062, -0.0171,  ..., -0.2810,  0.2320, -0.2100],\n","         [ 0.1280, -0.5077,  0.5931,  ..., -0.3552, -0.1099,  0.2367],\n","         [-0.1312,  0.2389, -0.0648,  ...,  0.3640,  0.1216,  0.0683],\n","         ...,\n","         [-0.1870,  0.0521,  0.0035,  ..., -0.2076, -0.0877, -0.2738],\n","         [-0.2210,  0.0636, -0.0900,  ..., -0.2853, -0.2555, -0.0731],\n","         [-0.1086,  0.0285,  0.0189,  ..., -0.2543, -0.1140, -0.3686]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward>), tensor([[-0.7614,  0.4627,  0.9999,  ...,  1.0000, -0.7707,  0.9926],\n","        [-0.6875,  0.3243,  0.9999,  ...,  1.0000, -0.7807,  0.9978],\n","        [-0.5514,  0.4093,  0.9999,  ...,  1.0000, -0.7694,  0.9948],\n","        ...,\n","        [-0.8108,  0.4769,  0.9998,  ...,  1.0000, -0.7151,  0.9914],\n","        [-0.6139,  0.3740,  0.9996,  ...,  0.9999, -0.7322,  0.9786],\n","        [-0.5242,  0.4982,  0.9998,  ...,  1.0000, -0.7618,  0.9899]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.7614,  0.4627,  0.9999,  ...,  1.0000, -0.7707,  0.9926],\n","        [-0.6875,  0.3243,  0.9999,  ...,  1.0000, -0.7807,  0.9978],\n","        [-0.5514,  0.4093,  0.9999,  ...,  1.0000, -0.7694,  0.9948],\n","        ...,\n","        [-0.8108,  0.4769,  0.9998,  ...,  1.0000, -0.7151,  0.9914],\n","        [-0.6139,  0.3740,  0.9996,  ...,  0.9999, -0.7322,  0.9786],\n","        [-0.5242,  0.4982,  0.9998,  ...,  1.0000, -0.7618,  0.9899]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-0.7473, -0.7162, -0.0444, -0.2795,  0.3560,  0.2918, -0.7571,  0.6829,\n","         -0.2455, -0.5285, -0.0621,  0.7824,  0.1242,  0.4970,  0.0514,  0.0724,\n","          0.0675,  0.7903, -0.1377, -0.7960, -1.4733,  0.3285,  0.4661, -0.0850,\n","          0.3227,  0.8058, -0.0087,  0.2618],\n","        [-0.8843, -0.6179,  0.3180, -0.1095,  0.6086,  0.5488, -1.1809,  0.6446,\n","         -0.2655, -0.6667, -0.4041,  0.6846, -0.1465,  0.5515, -0.0091,  0.1863,\n","         -0.2723,  1.1433, -0.3588, -0.8295, -1.2881,  0.2624,  0.4678, -0.0618,\n","          0.7664,  0.8566,  0.5319,  0.3365],\n","        [-0.9295, -0.8484,  0.3268, -0.4014,  0.4451,  0.7458, -1.1350,  0.7356,\n","         -0.2985, -0.5748, -0.1445,  0.0994, -0.2094,  0.5832,  0.1243, -0.0803,\n","         -0.2119,  1.1351, -0.1080, -0.9212, -1.2527, -0.1126,  0.2892, -0.1301,\n","          0.2631,  1.1490, -0.1100,  0.7350],\n","        [-0.9889, -0.7233,  0.2694, -0.5341,  0.5579,  0.6768, -1.2200,  0.6739,\n","         -0.0427, -0.7132, -0.4196,  0.4440,  0.0991,  0.6693, -0.2624,  0.7049,\n","         -0.2830,  0.5831,  0.1411, -0.6299, -1.4137,  0.2911,  0.2091, -0.1000,\n","          0.2317,  0.9355,  0.0308,  0.5900],\n","        [-1.1473, -0.6190,  0.3160, -0.3112,  0.4822,  0.7449, -1.1284,  0.8201,\n","         -0.2583, -0.5253, -0.0130,  0.6941, -0.1220,  0.4879, -0.0545,  0.2963,\n","         -0.1637,  0.4423, -0.0693, -0.5792, -1.5829,  0.3126,  0.3733, -0.2896,\n","         -0.2052,  0.9801,  0.2617,  0.5320],\n","        [-0.8312, -0.5374, -0.1165, -0.1191,  0.2852,  0.5567, -0.7108,  1.1102,\n","         -0.2340, -0.4399,  0.1799,  0.6819,  0.0671,  0.5879, -0.1380,  0.0387,\n","         -0.1859,  0.9195,  0.0633, -0.6513, -1.5045,  0.0294,  0.2663, -0.4103,\n","          0.1873,  0.9884,  0.2544,  0.4927],\n","        [-0.8889, -0.4350,  0.3520, -0.0789,  0.3068,  0.2324, -0.7769,  0.6906,\n","         -0.1190, -0.4018, -0.2075,  0.6452,  0.0139,  0.3152,  0.2151,  0.2880,\n","         -0.2324,  0.9161, -0.0366, -0.8172, -1.3458,  0.1884,  0.1048, -0.3162,\n","          0.3471,  0.9096,  0.3982,  0.3754],\n","        [-0.7698, -0.5547,  0.0037, -0.0765,  0.5954,  0.1512, -0.5355,  1.0463,\n","         -0.2943, -0.6111, -0.0909,  0.8696, -0.1097,  0.4002,  0.1372,  0.0619,\n","         -0.1059,  0.8830, -0.0558, -0.6214, -1.4780,  0.3392,  0.1621, -0.3439,\n","          0.2419,  1.1098, -0.0316,  0.3166],\n","        [-0.9605, -0.6015,  0.2843, -0.2178,  0.3190,  0.7042, -1.1729,  0.7626,\n","         -0.1723, -0.1814,  0.0391,  0.6875, -0.0149,  0.3464, -0.1040,  0.1819,\n","         -0.0098,  0.7571,  0.0451, -0.9075, -1.5427,  0.3374,  0.3040, -0.2105,\n","          0.1043,  0.8985,  0.2943,  0.5796],\n","        [-0.4318, -0.6356,  0.2977,  0.1479,  0.3121,  0.5384, -0.8238,  0.7104,\n","         -0.0510, -0.6235,  0.3113,  0.4506, -0.1675,  0.2757,  0.2561,  0.0982,\n","         -0.4002,  0.6292,  0.2690, -0.8032, -1.7644,  0.4990,  0.3978, -0.1451,\n","          0.2990,  0.7379, -0.0901,  0.8264],\n","        [-0.8256, -0.7755,  0.1509, -0.4072,  0.3711,  0.5483, -1.0237,  0.9457,\n","         -0.3876, -0.3682,  0.1759,  0.2615, -0.1599,  0.6658,  0.1943,  0.2565,\n","          0.0855,  0.7990,  0.0227, -0.6206, -1.4862,  0.2262,  0.5049,  0.0134,\n","          0.1697,  0.7211,  0.2963,  0.7228],\n","        [-0.7276, -0.6056,  0.2039, -0.2228,  0.4035,  0.3986, -0.8864,  0.7170,\n","         -0.3325, -0.4233,  0.1359,  0.5369, -0.2412,  0.5231,  0.0576, -0.0676,\n","         -0.3933,  0.8975,  0.2188, -0.6671, -1.3554,  0.2327,  0.1664,  0.1654,\n","          0.2137,  1.0698,  0.2082,  0.5501],\n","        [-0.8848, -0.7036,  0.3163, -0.3501,  0.2787,  0.4485, -0.9852,  0.5724,\n","         -0.5726, -0.6084, -0.1457,  0.5319,  0.0148,  0.5913, -0.2518,  0.2272,\n","         -0.3170,  0.6585,  0.0591, -0.8762, -1.7111,  0.3118,  0.4278, -0.2671,\n","          0.2277,  0.8269,  0.2245,  0.6249],\n","        [-1.1104, -0.5606,  0.1305, -0.2544,  0.5521,  0.5102, -1.0907,  0.4294,\n","         -0.3295, -0.6823, -0.2523,  0.8656, -0.3877,  0.3841, -0.1470, -0.2806,\n","         -0.2834,  0.8496,  0.0467, -0.6724, -1.2761,  0.2115,  0.3536, -0.1581,\n","          0.4382,  0.8448,  0.3007,  0.3860],\n","        [-0.7770, -0.6725,  0.2970, -0.1197,  0.2418,  0.2479, -0.8949,  0.5782,\n","         -0.2715, -0.1100,  0.0520,  0.7392, -0.0061,  0.2303,  0.0395,  0.1904,\n","          0.0134,  0.7080,  0.2369, -0.4825, -1.3288,  0.2783,  0.0074, -0.0818,\n","          0.4194,  0.8162,  0.0793,  0.5381],\n","        [-0.7857, -0.8536,  0.0721, -0.5248,  0.3795,  0.6525, -0.6494,  0.6271,\n","         -0.1397, -0.4404,  0.0879,  0.5921,  0.1485,  0.6779,  0.0750,  0.2267,\n","         -0.2675,  1.0589, -0.2701, -0.8647, -1.3384,  0.5433,  0.3666, -0.0055,\n","          0.4440,  0.9345,  0.0590,  0.7569]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   1% 31/2714 [00:12<17:02,  2.62it/s]\u001b[Aoutputs:\n","(tensor([[[ 0.4603,  0.0751, -0.2423,  ..., -0.0931,  0.2299,  0.2009],\n","         [ 0.6525, -0.5730,  0.5116,  ...,  0.2605, -0.1246,  0.4648],\n","         [ 0.4648, -0.1687,  0.0177,  ...,  0.4084, -0.1188,  0.3823],\n","         ...,\n","         [ 0.2818,  0.2314,  0.0946,  ...,  0.3266, -0.3764,  0.4609],\n","         [ 0.4054,  0.2400,  0.3693,  ...,  0.5744, -0.1884,  0.3148],\n","         [ 0.2644,  0.2624,  0.2985,  ...,  0.4512, -0.2121,  0.1379]],\n","\n","        [[ 0.5614,  0.2067, -0.0717,  ..., -0.3685,  0.0254, -0.1562],\n","         [-0.7903, -0.6078,  0.2941,  ..., -0.1920,  0.8507, -0.0821],\n","         [ 0.3425,  0.2331,  0.2455,  ...,  0.0094,  0.1596,  0.1622],\n","         ...,\n","         [-0.0840, -0.0700, -0.2492,  ...,  0.1172,  0.9194, -0.0489],\n","         [ 0.1621,  0.2456,  0.0387,  ..., -0.1207,  0.5360, -0.1896],\n","         [-0.1184, -0.1024, -0.3609,  ...,  0.1277,  0.7082,  0.0470]],\n","\n","        [[ 0.0689,  0.6030,  0.0884,  ..., -0.1883,  0.4985, -0.1551],\n","         [-0.0595,  0.4016,  0.2104,  ..., -0.1055, -0.2210, -0.2146],\n","         [ 0.2435, -0.5377, -0.1729,  ..., -0.2516, -0.1640, -0.0022],\n","         ...,\n","         [ 0.0906,  0.5264, -0.2124,  ...,  0.2694, -0.0823, -0.3875],\n","         [ 0.3393,  0.2140, -0.3547,  ..., -0.0863,  0.4150, -0.5448],\n","         [-0.0804,  0.4461, -0.0301,  ..., -0.4732, -0.0570, -0.0906]],\n","\n","        ...,\n","\n","        [[ 0.1058,  0.2404,  0.1831,  ...,  0.0130,  0.4088,  0.1291],\n","         [ 0.4689, -0.3590,  0.6571,  ...,  0.1395,  0.2114,  0.2322],\n","         [ 0.1589,  0.1531,  0.0112,  ...,  0.9193,  0.1090, -0.5430],\n","         ...,\n","         [-0.1774,  0.0455,  0.1059,  ...,  0.2782,  0.2624, -0.0997],\n","         [-0.0684,  0.0482,  0.0538,  ...,  0.2324,  0.4832, -0.0499],\n","         [-0.0568,  0.4373,  0.1339,  ...,  0.0562,  0.0972, -0.3394]],\n","\n","        [[ 0.3938,  0.3188,  0.1842,  ..., -0.0576,  0.4223, -0.3582],\n","         [ 0.8569, -0.2639,  0.7857,  ..., -0.1581,  0.0967,  0.2038],\n","         [ 0.0712,  0.3845, -0.3518,  ...,  0.0652, -0.4349,  0.4633],\n","         ...,\n","         [ 0.1202,  0.1835,  0.3237,  ..., -0.3450,  0.5152, -0.4133],\n","         [-0.0027, -0.0605, -0.0214,  ...,  0.0774,  0.2455,  0.1553],\n","         [ 0.4503, -0.1412,  0.0266,  ...,  0.2346, -0.1396, -0.0329]],\n","\n","        [[ 0.5914,  0.1896,  0.0183,  ..., -0.1185,  0.4417,  0.0805],\n","         [ 0.6813, -0.2216,  0.4256,  ..., -0.1054,  0.0033,  0.0948],\n","         [ 0.4513, -0.2909, -0.3388,  ...,  0.4882, -0.4367,  0.4487],\n","         ...,\n","         [ 0.0034,  0.1237,  0.2001,  ...,  0.3583,  0.0655, -0.0736],\n","         [ 0.2642, -0.0188,  0.0553,  ...,  0.0384,  0.3047, -0.1295],\n","         [ 0.2927, -0.0388,  0.4050,  ...,  0.2715, -0.2706, -0.0430]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward>), tensor([[-0.8061,  0.5148,  0.9999,  ...,  1.0000, -0.3515,  0.9923],\n","        [-0.5498,  0.4255,  0.9999,  ...,  1.0000, -0.8782,  0.9938],\n","        [-0.6717,  0.5155,  0.9999,  ...,  1.0000, -0.8147,  0.9967],\n","        ...,\n","        [-0.6637,  0.5344,  0.9999,  ...,  0.9999, -0.7679,  0.9891],\n","        [-0.5615,  0.4955,  0.9999,  ...,  1.0000, -0.8047,  0.9956],\n","        [-0.8150,  0.4849,  0.9999,  ...,  1.0000, -0.7840,  0.9979]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.8061,  0.5148,  0.9999,  ...,  1.0000, -0.3515,  0.9923],\n","        [-0.5498,  0.4255,  0.9999,  ...,  1.0000, -0.8782,  0.9938],\n","        [-0.6717,  0.5155,  0.9999,  ...,  1.0000, -0.8147,  0.9967],\n","        ...,\n","        [-0.6637,  0.5344,  0.9999,  ...,  0.9999, -0.7679,  0.9891],\n","        [-0.5615,  0.4955,  0.9999,  ...,  1.0000, -0.8047,  0.9956],\n","        [-0.8150,  0.4849,  0.9999,  ...,  1.0000, -0.7840,  0.9979]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-6.1896e-01, -8.1122e-01,  6.0491e-01,  9.1521e-02,  1.7916e-01,\n","          4.7276e-01, -9.5215e-01,  6.3624e-01, -3.5852e-01, -4.2286e-01,\n","         -1.5633e-01,  6.4164e-01, -4.6258e-01,  2.0680e-01,  1.2714e-01,\n","          1.6078e-02, -2.0882e-02,  7.3730e-01,  1.9252e-01, -6.7887e-01,\n","         -1.7561e+00,  1.7176e-01,  2.5333e-01, -6.3548e-02, -4.3528e-02,\n","          8.4904e-01, -1.6844e-01,  8.1553e-02],\n","        [-1.0304e+00, -8.9181e-01, -6.1463e-02, -1.0704e-01,  7.1982e-01,\n","          7.6796e-01, -1.0371e+00,  8.8460e-01, -4.2175e-01, -6.4976e-01,\n","         -4.1770e-01,  6.7351e-01, -3.0936e-01,  6.5882e-01,  7.1889e-02,\n","          5.1196e-01, -3.0379e-01,  8.3699e-01,  7.9750e-02, -7.1453e-01,\n","         -1.5664e+00,  2.4029e-01,  4.7822e-01, -3.0073e-01,  5.0226e-02,\n","          9.0399e-01,  4.1613e-01,  5.6394e-01],\n","        [-8.1372e-01, -7.7992e-01,  1.0090e-01, -5.1596e-01,  3.8911e-01,\n","          6.6565e-01, -1.0985e+00,  1.0125e+00, -3.6216e-01, -6.9821e-01,\n","          1.5908e-01,  8.4644e-01, -8.7776e-02,  7.8063e-01,  3.5309e-02,\n","          3.1689e-01, -3.7187e-01,  1.0220e+00,  6.1411e-02, -6.9518e-01,\n","         -1.6776e+00,  2.6213e-01,  6.8387e-01, -2.8566e-01,  2.8248e-01,\n","          9.2113e-01,  1.1534e-01,  6.1791e-01],\n","        [-9.0825e-01, -4.8256e-01,  2.5024e-01, -6.8125e-02,  2.9277e-01,\n","          3.3498e-01, -1.0605e+00,  9.6988e-01, -4.5024e-02, -5.6002e-01,\n","          1.1603e-01,  6.0263e-01, -3.0926e-01,  3.5430e-01,  2.6554e-02,\n","          1.5641e-01, -3.5471e-02,  6.4893e-01, -1.8665e-01, -8.4951e-01,\n","         -1.6924e+00,  4.1353e-01,  3.4205e-01, -2.5646e-01,  3.2113e-01,\n","          1.0037e+00,  1.0344e-01,  5.9883e-01],\n","        [-7.1448e-01, -6.5319e-01,  2.9420e-01,  1.6913e-01,  2.8449e-01,\n","          3.7050e-01, -1.0002e+00,  6.7710e-01, -8.9953e-02, -3.5691e-01,\n","         -4.8715e-02,  6.5599e-01, -3.5549e-01,  2.0866e-01,  4.9671e-02,\n","          8.7939e-02, -6.8597e-03,  6.8338e-01,  9.0837e-02, -6.6432e-01,\n","         -1.4852e+00, -2.7528e-01,  1.7186e-01, -3.2097e-01,  3.2550e-01,\n","          9.8700e-01,  1.4702e-01,  3.4347e-01],\n","        [-9.9392e-01, -1.0969e+00,  2.2267e-01,  2.3215e-01,  2.2867e-01,\n","          6.4121e-01, -9.3150e-01,  5.6129e-01, -5.9230e-02, -4.5085e-01,\n","          7.7859e-02,  9.7358e-01, -2.7249e-01,  2.0222e-01, -1.1594e-01,\n","          1.6234e-01, -1.9106e-01,  5.8240e-01,  1.4102e-01, -7.1412e-01,\n","         -1.5797e+00,  2.3506e-01,  2.8520e-01,  7.7071e-02, -2.3773e-01,\n","          6.5690e-01,  3.2412e-01,  3.1825e-01],\n","        [-9.5522e-01, -6.9169e-01,  1.0262e-01, -1.1469e-01,  5.5341e-01,\n","          8.7463e-01, -8.6555e-01,  7.4105e-01, -3.8735e-01, -7.5136e-01,\n","          5.7248e-03,  5.9825e-01, -1.8680e-01,  3.9180e-01,  1.2362e-01,\n","          2.9007e-01,  6.4082e-02,  9.1451e-01,  1.9370e-01, -8.5250e-01,\n","         -1.7829e+00,  4.6767e-02,  1.8560e-01, -1.0417e-01,  2.2410e-01,\n","          7.9202e-01,  1.1663e-01,  4.6665e-01],\n","        [-9.0674e-01, -7.4883e-01,  1.7498e-01, -4.2168e-01,  7.5684e-01,\n","          7.0068e-01, -9.8677e-01,  8.7573e-01, -1.1245e-01, -3.0501e-01,\n","         -3.9776e-01,  5.5248e-01, -9.6859e-02,  6.6622e-01, -4.6164e-02,\n","          3.5957e-01, -2.4656e-01,  1.0342e+00, -6.2165e-02, -8.3542e-01,\n","         -1.4573e+00,  2.4983e-01,  5.0661e-01, -6.7495e-02,  3.8546e-01,\n","          5.8033e-01,  4.7436e-01,  7.5513e-01],\n","        [-8.3629e-01, -5.5458e-01,  3.2730e-01, -1.8944e-01,  6.5170e-01,\n","          6.6172e-01, -1.0063e+00,  5.2337e-01, -5.2421e-01, -7.5470e-01,\n","          3.6194e-04,  7.1409e-01, -2.8685e-01,  5.3746e-01,  2.6561e-02,\n","         -5.1008e-03, -7.1311e-02,  9.5244e-01, -2.7677e-01, -9.0726e-01,\n","         -1.2436e+00,  1.7449e-01,  3.7235e-01, -1.2324e-01,  3.3558e-01,\n","          1.0189e+00,  5.6042e-01,  3.4392e-01],\n","        [-6.2257e-01, -4.3513e-01,  3.4329e-01,  1.4879e-02,  3.2851e-01,\n","          4.9936e-01, -1.1995e+00,  7.2362e-01, -4.3450e-01, -4.8966e-01,\n","         -4.1550e-02,  4.1020e-01,  2.0258e-01,  6.5763e-01,  7.2537e-02,\n","          4.6313e-01, -2.7347e-01,  8.8316e-01, -2.4427e-02, -6.3697e-01,\n","         -1.1350e+00,  2.6704e-01,  9.0352e-02, -6.0027e-02,  5.0766e-01,\n","          8.2046e-01,  3.5760e-01,  6.0901e-01],\n","        [-9.7551e-01, -8.0249e-01,  6.5767e-01, -1.7772e-01,  4.6795e-01,\n","          5.5382e-01, -1.1352e+00,  6.7110e-01, -1.2182e-01, -4.1696e-01,\n","          1.2791e-01,  3.5643e-01, -1.6464e-01,  5.5219e-01,  1.2294e-01,\n","         -4.6684e-02,  6.4408e-02,  9.6068e-01, -2.9368e-02, -9.4937e-01,\n","         -1.6301e+00, -1.1062e-01,  2.4924e-01, -3.7739e-01,  2.8369e-01,\n","          6.1743e-01,  2.4460e-01,  5.7703e-01],\n","        [-9.1104e-01, -6.7056e-01,  3.3193e-01,  1.2476e-01,  3.5922e-01,\n","          2.7025e-01, -1.0285e+00,  6.9109e-01, -1.7684e-01, -4.2043e-01,\n","         -7.8393e-02,  3.2047e-01, -9.2009e-02,  5.1533e-01,  7.8809e-02,\n","          2.9676e-01, -2.5155e-01,  9.1437e-01,  1.2002e-01, -8.0662e-01,\n","         -1.6904e+00,  2.1152e-01,  4.7689e-01, -3.2998e-01,  1.1185e-01,\n","          8.2048e-01,  1.4787e-01,  4.1609e-01],\n","        [-9.3184e-01, -8.9000e-01,  1.4875e-01, -6.0422e-01,  1.8736e-01,\n","          3.9379e-01, -1.1382e+00,  2.7435e-01, -3.8644e-01, -5.4595e-01,\n","         -3.3798e-02,  1.0099e+00, -1.7186e-02,  2.9358e-01, -5.8428e-02,\n","         -4.2722e-02, -3.0625e-01,  8.7695e-01, -2.4201e-01, -8.6892e-01,\n","         -1.3967e+00,  5.4427e-02,  3.2749e-01, -2.0450e-01,  3.6970e-01,\n","          9.1635e-01,  4.5772e-01,  6.1461e-01],\n","        [-8.6664e-01, -7.4274e-01,  2.0066e-03, -2.7826e-01,  4.5070e-02,\n","          4.9722e-01, -8.6005e-01,  8.0562e-01, -3.2217e-01, -4.2170e-01,\n","         -1.5098e-03,  5.5900e-01, -3.7168e-01,  6.9746e-01,  4.0626e-02,\n","          2.6501e-01, -9.4983e-02,  7.3859e-01, -8.7340e-02, -7.6051e-01,\n","         -1.6139e+00,  2.4713e-03,  3.7493e-01, -1.3748e-01,  1.0993e-01,\n","          8.0494e-01, -1.3288e-01,  4.9518e-01],\n","        [-9.6410e-01, -6.0919e-01,  3.0764e-01, -4.8463e-01,  4.0012e-01,\n","          4.5495e-01, -1.0353e+00,  8.1397e-01, -6.3032e-01, -5.4143e-01,\n","          2.3686e-02,  8.9139e-01,  5.5168e-02,  4.3246e-01,  1.0532e-01,\n","          2.7128e-01, -1.5951e-01,  9.0762e-01, -3.0540e-02, -6.1030e-01,\n","         -1.3287e+00,  4.2483e-01,  1.9940e-01,  9.3014e-03,  3.6036e-01,\n","          1.1437e+00,  2.3752e-01,  6.4966e-01],\n","        [-9.3151e-01, -7.1129e-01,  2.0582e-01, -1.3593e-01,  3.9719e-01,\n","          6.9489e-01, -9.0513e-01,  7.6896e-01, -5.1094e-02, -5.7097e-01,\n","         -1.2925e-01,  3.4891e-01, -3.0621e-01,  1.0016e+00, -9.8314e-02,\n","          2.0757e-01, -1.8842e-01,  7.9151e-01, -2.0372e-01, -7.7207e-01,\n","         -1.6470e+00,  4.4768e-01,  6.1901e-01, -3.3934e-01,  1.4215e-02,\n","          7.5144e-01,  3.5709e-01,  3.8426e-01]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   1% 32/2714 [00:12<17:01,  2.63it/s]\u001b[Aoutputs:\n","(tensor([[[ 0.2329,  0.4086, -0.3902,  ..., -0.1451,  0.4724,  0.0804],\n","         [ 0.4576, -0.1683,  0.1266,  ..., -0.2809,  0.3466, -0.0355],\n","         [-0.0257, -0.0853, -0.6256,  ...,  0.3392, -0.3013, -0.0931],\n","         ...,\n","         [ 0.1747,  0.5613, -0.2965,  ..., -0.4865, -0.0682, -0.0912],\n","         [-0.0045,  0.5699, -0.3103,  ..., -0.2844,  0.0221, -0.0409],\n","         [ 0.1948,  0.5609, -0.3353,  ..., -0.3841,  0.1794,  0.0692]],\n","\n","        [[ 0.7246,  0.2138,  0.0666,  ..., -0.1090,  0.1215, -0.2602],\n","         [ 0.6318, -0.3818,  0.4259,  ...,  0.0476,  0.1293,  0.0360],\n","         [ 0.4954,  0.7192,  0.0412,  ...,  0.1273,  0.1260, -0.6186],\n","         ...,\n","         [ 0.3223,  0.4535, -0.0558,  ...,  0.3456,  0.1259,  0.0226],\n","         [ 0.5031,  0.1249, -0.0429,  ...,  0.2213,  0.0102,  0.1239],\n","         [ 0.1023,  0.2489,  0.0784,  ...,  0.2555, -0.3005,  0.0555]],\n","\n","        [[ 0.6876,  0.2836,  0.2616,  ..., -0.3744,  0.4563, -0.2918],\n","         [ 0.7192, -0.1792,  0.6411,  ...,  0.1692, -0.0891,  0.1494],\n","         [ 0.6217, -0.2961,  0.0864,  ...,  0.9166, -0.3072, -0.1118],\n","         ...,\n","         [ 0.1712,  0.1538, -0.1232,  ...,  0.1395,  0.2760, -0.2657],\n","         [ 0.1891,  0.3245, -0.2490,  ...,  0.2795,  0.4398, -0.3104],\n","         [ 0.1168,  0.2692, -0.2563,  ...,  0.0157,  0.1420, -0.3498]],\n","\n","        ...,\n","\n","        [[ 0.6020,  0.4444,  0.2149,  ..., -0.3351,  0.7813, -0.0459],\n","         [ 0.1996,  0.4667,  0.2287,  ...,  0.2822,  0.9467, -0.0176],\n","         [ 0.2613,  0.2126,  0.1774,  ...,  0.0866,  0.2265,  0.1222],\n","         ...,\n","         [ 0.4505,  0.5210,  0.1175,  ...,  0.0069,  0.2846, -0.1451],\n","         [ 0.3410,  0.4114,  0.1094,  ..., -0.2102,  0.5559, -0.4359],\n","         [ 0.3371,  0.4323,  0.1036,  ...,  0.0985,  0.4611, -0.3721]],\n","\n","        [[ 0.2268,  0.2540, -0.0208,  ..., -0.0894,  0.2226, -0.0738],\n","         [ 0.3103, -0.6015,  0.7533,  ..., -0.1402,  0.1034,  0.3942],\n","         [-0.0967,  0.0192, -0.1011,  ..., -0.0864, -0.1827, -0.0896],\n","         ...,\n","         [-0.0263, -0.0416, -0.1686,  ...,  0.0656, -0.1808, -0.2959],\n","         [-0.0990,  0.0420, -0.1616,  ..., -0.0830,  0.2983,  0.1817],\n","         [-0.0209, -0.0057, -0.0604,  ...,  0.0762, -0.0897,  0.1590]],\n","\n","        [[ 0.2630,  0.3225, -0.1054,  ..., -0.2334,  0.1535, -0.1105],\n","         [-0.1553, -0.2133,  0.2918,  ..., -0.3084,  0.2788, -0.2384],\n","         [-0.4504,  0.7344, -0.5002,  ..., -0.5040,  0.0748, -0.4262],\n","         ...,\n","         [-0.0587,  0.2812,  0.0447,  ...,  0.0189, -0.2365, -0.3589],\n","         [-0.0887,  0.4955,  0.2109,  ...,  0.0629,  0.1656, -0.1167],\n","         [-0.1510,  0.5182,  0.0816,  ...,  0.0314,  0.0551, -0.1265]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward>), tensor([[-0.8237,  0.5273,  1.0000,  ...,  1.0000, -0.6248,  0.9930],\n","        [-0.5837,  0.3929,  0.9998,  ...,  1.0000, -0.8116,  0.9902],\n","        [-0.7363,  0.5442,  1.0000,  ...,  1.0000, -0.6322,  0.9976],\n","        ...,\n","        [-0.7781,  0.4812,  1.0000,  ...,  1.0000, -0.5234,  0.9983],\n","        [-0.6447,  0.3589,  0.9991,  ...,  0.9998, -0.6563,  0.9748],\n","        [-0.5941,  0.4366,  0.9998,  ...,  1.0000, -0.8742,  0.9947]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.8237,  0.5273,  1.0000,  ...,  1.0000, -0.6248,  0.9930],\n","        [-0.5837,  0.3929,  0.9998,  ...,  1.0000, -0.8116,  0.9902],\n","        [-0.7363,  0.5442,  1.0000,  ...,  1.0000, -0.6322,  0.9976],\n","        ...,\n","        [-0.7781,  0.4812,  1.0000,  ...,  1.0000, -0.5234,  0.9983],\n","        [-0.6447,  0.3589,  0.9991,  ...,  0.9998, -0.6563,  0.9748],\n","        [-0.5941,  0.4366,  0.9998,  ...,  1.0000, -0.8742,  0.9947]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-9.5008e-01, -7.8075e-01,  4.1326e-01,  1.5042e-01,  3.3336e-01,\n","          6.4044e-01, -1.0683e+00,  5.8534e-01, -1.2811e-01, -5.4167e-01,\n","          9.3802e-02,  5.2040e-01, -3.1834e-01, -6.1427e-02,  4.1659e-01,\n","          1.0326e-01, -2.5908e-02,  6.5675e-01, -2.0513e-01, -7.7730e-01,\n","         -1.8010e+00,  3.2851e-01,  4.6540e-01, -3.4464e-01, -1.0367e-01,\n","          7.0674e-01, -3.2675e-02,  4.9796e-01],\n","        [-6.7533e-01, -7.5123e-01,  1.9682e-01, -5.0503e-02,  7.0140e-01,\n","          1.4069e-01, -8.7293e-01,  8.4922e-01, -1.4397e-01, -5.7480e-01,\n","         -3.4021e-02,  5.8006e-01, -2.9494e-03,  5.0243e-01, -8.6147e-02,\n","          1.2344e-01, -3.1318e-01,  8.9162e-01,  2.2212e-01, -8.3943e-01,\n","         -1.5626e+00,  2.6505e-01,  3.1159e-01, -3.6613e-01,  2.3091e-01,\n","          7.4597e-01,  2.5003e-01,  2.2258e-01],\n","        [-7.6198e-01, -6.8564e-01,  3.8509e-01, -2.6688e-01,  6.2660e-01,\n","          4.5721e-01, -9.7711e-01,  9.7441e-01, -4.0360e-01, -3.1418e-01,\n","          2.1187e-01,  8.3517e-01, -1.5996e-01,  4.8499e-01,  1.8413e-01,\n","         -4.8201e-02,  3.1815e-02,  1.0427e+00,  6.1314e-02, -6.1336e-01,\n","         -1.8504e+00,  1.5182e-01,  3.0085e-01, -2.0295e-01,  2.8416e-01,\n","          9.6935e-01,  2.3084e-01,  3.0345e-01],\n","        [-7.0178e-01, -8.7865e-01, -1.0476e-01, -4.4628e-01,  3.7514e-01,\n","          7.3553e-01, -1.0375e+00,  8.3409e-01, -5.4259e-02, -7.4066e-01,\n","          1.3407e-01,  7.4055e-01,  1.0064e-01,  3.7405e-01,  6.2791e-02,\n","          5.5438e-01,  4.6524e-02,  9.1036e-01, -2.8208e-01, -8.3476e-01,\n","         -1.5932e+00,  2.6890e-01,  3.3287e-01, -5.2725e-01,  2.9714e-01,\n","          8.2063e-01,  3.4279e-01,  4.2369e-01],\n","        [-6.1825e-01, -6.7317e-01,  1.2894e-01, -3.1902e-01,  3.4668e-01,\n","          4.9810e-01, -9.8253e-01,  5.2706e-01, -5.6029e-01, -6.3601e-01,\n","         -2.6922e-02,  8.6968e-01, -1.1753e-01,  2.6039e-01,  7.4492e-02,\n","          1.5749e-01, -3.3590e-01,  6.3875e-01,  1.0928e-01, -5.7983e-01,\n","         -1.3385e+00,  8.2154e-02,  2.7691e-01, -3.5044e-02,  3.5404e-01,\n","          9.5447e-01,  1.6571e-01,  4.9881e-01],\n","        [-6.7246e-01, -4.5199e-01, -1.1976e-02, -2.4675e-01,  1.6780e-01,\n","          5.2373e-01, -9.6729e-01,  9.7397e-01, -3.7469e-01, -5.0905e-01,\n","          3.0508e-01,  2.7556e-01,  4.6445e-02,  4.4987e-01, -1.2450e-01,\n","          3.2002e-01, -2.1186e-01,  8.2797e-01, -1.8559e-01, -6.9144e-01,\n","         -1.4404e+00,  3.4548e-01,  5.9403e-01, -2.1177e-01,  6.2350e-02,\n","          7.8399e-01,  1.2607e-01,  4.6156e-01],\n","        [-7.4378e-01, -8.9663e-01,  4.3614e-01, -1.4327e-01,  3.1104e-01,\n","          5.7711e-01, -7.3528e-01,  6.5379e-01, -3.2248e-01, -5.4255e-01,\n","         -2.0091e-01,  8.4304e-01, -5.7981e-02,  3.8204e-01, -7.9990e-02,\n","          7.9954e-02,  1.6154e-02,  7.9996e-01,  1.2336e-01, -9.1245e-01,\n","         -1.3564e+00,  1.6665e-01,  2.7546e-01, -1.6537e-01,  1.7062e-01,\n","          7.2406e-01,  2.2075e-01,  4.4309e-01],\n","        [-7.7094e-01, -5.9462e-01,  1.9683e-01, -3.7112e-01,  1.4485e-01,\n","          4.4558e-01, -9.8356e-01,  6.2403e-01, -3.8038e-01, -8.4816e-01,\n","         -5.8232e-02,  7.6025e-01, -4.4527e-03,  4.6122e-01,  7.5963e-02,\n","          2.4329e-01, -1.5821e-03,  8.7266e-01,  2.3592e-01, -7.7564e-01,\n","         -1.4599e+00,  1.9511e-01,  1.7976e-01, -2.8067e-01,  9.3783e-02,\n","          8.4599e-01,  2.1097e-01,  3.4057e-01],\n","        [-1.0326e+00, -8.8092e-01,  4.5057e-01, -2.6323e-01,  5.6315e-01,\n","          5.9775e-01, -8.5728e-01,  8.9569e-01, -2.9529e-01, -5.9841e-01,\n","         -6.1698e-02,  7.5435e-01, -1.5910e-01,  1.6265e-01,  8.2373e-02,\n","          3.4611e-01, -4.6608e-01,  8.6004e-01,  6.3234e-02, -5.4490e-01,\n","         -1.5626e+00,  5.1177e-01,  2.7846e-01,  7.6036e-02,  6.9725e-02,\n","          1.1108e+00,  2.2388e-01,  5.2067e-01],\n","        [-7.6462e-01, -7.6644e-01,  1.6175e-01, -3.6442e-01,  2.5403e-01,\n","          6.3150e-01, -9.2687e-01,  6.9207e-01, -2.6073e-01, -1.3653e-01,\n","          1.7417e-01,  2.9381e-01,  1.4966e-01,  4.6172e-01, -2.5478e-01,\n","          1.0731e-01, -1.3623e-01,  9.1068e-01,  7.0653e-02, -5.4139e-01,\n","         -1.4366e+00,  1.5855e-01,  2.4507e-01, -1.0588e-01,  1.0932e-01,\n","          7.6360e-01,  1.5461e-01,  5.9613e-01],\n","        [-5.2869e-01, -8.3818e-01,  3.0216e-01, -7.2903e-02,  2.3897e-01,\n","          6.2765e-01, -8.4260e-01,  7.1656e-01, -2.2429e-01, -5.0705e-01,\n","          2.2528e-01,  4.7594e-01, -1.1099e-01,  3.3025e-01,  4.8107e-02,\n","          2.5175e-01, -3.5738e-02,  7.9877e-01,  1.7737e-01, -8.8229e-01,\n","         -1.3358e+00, -5.2805e-03,  2.1382e-01, -2.2031e-01,  1.6909e-01,\n","          7.2283e-01,  5.0766e-02,  2.9242e-01],\n","        [-6.4095e-01, -9.0141e-01,  4.7643e-01, -6.6434e-02,  3.7766e-01,\n","          2.3798e-01, -8.8080e-01,  5.1893e-01, -3.4935e-02, -4.0417e-01,\n","          7.5444e-02,  7.4185e-01, -4.0083e-01,  1.5187e-01,  1.7668e-01,\n","          1.6436e-01,  1.5505e-01,  6.7276e-01,  2.2177e-01, -6.5495e-01,\n","         -1.7443e+00,  1.2566e-01,  5.1657e-01, -5.4115e-01,  4.0191e-02,\n","          6.6758e-01,  1.9831e-02,  2.3938e-01],\n","        [-8.4407e-01, -9.4133e-01,  1.4985e-01, -4.2845e-01,  4.5130e-01,\n","          5.5879e-01, -1.0775e+00,  6.6516e-01, -1.4891e-01, -5.5448e-01,\n","         -1.7231e-01,  4.1347e-01, -3.8429e-01,  2.7357e-01, -2.2347e-01,\n","          9.1516e-02, -2.9882e-01,  9.9918e-01, -1.4184e-01, -5.9909e-01,\n","         -1.6207e+00,  7.2559e-02,  4.4724e-01, -5.9166e-02,  8.7157e-02,\n","          9.3426e-01,  1.8629e-01,  2.7173e-01],\n","        [-7.7229e-01, -1.0119e+00,  5.0632e-01, -1.6640e-01,  5.1126e-01,\n","          6.0154e-01, -9.8725e-01,  6.2071e-01, -3.0032e-01, -5.0978e-01,\n","          3.6624e-02,  4.0603e-01, -2.2338e-01,  5.0755e-01, -2.5929e-01,\n","          2.3521e-01, -1.4827e-01,  6.8629e-01,  1.5891e-01, -7.3983e-01,\n","         -1.5780e+00,  1.3776e-01,  6.3376e-01, -1.2794e-01,  8.1418e-02,\n","          7.1054e-01, -4.7307e-02,  1.3215e-01],\n","        [-8.2502e-01, -9.7890e-01,  3.4088e-01,  8.5839e-02,  5.7072e-01,\n","          7.1578e-01, -1.2625e+00,  4.8957e-01, -2.8744e-01, -4.9121e-01,\n","          2.4645e-01,  8.3893e-01, -2.3586e-01,  5.8378e-01,  3.4956e-01,\n","          3.2145e-01,  1.2623e-01,  9.1379e-01,  1.0939e-02, -5.7976e-01,\n","         -1.4053e+00,  1.4346e-01,  3.7753e-01, -4.7713e-01, -2.4169e-01,\n","          1.0547e+00,  3.7831e-02,  3.7106e-01],\n","        [-1.0234e+00, -4.4235e-01,  3.0828e-01, -2.8334e-01,  3.2767e-01,\n","          4.1747e-01, -1.1432e+00,  7.3718e-01, -3.4263e-01, -6.5397e-01,\n","         -1.0929e-01,  4.5848e-01, -5.9996e-02,  6.2968e-01,  6.2835e-03,\n","          4.4362e-01, -3.6187e-01,  1.1240e+00,  3.2473e-02, -8.3279e-01,\n","         -1.4174e+00,  3.0887e-01,  1.7733e-01, -1.9924e-01,  3.6880e-01,\n","          8.0434e-01,  6.5716e-02,  3.9067e-01]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   1% 33/2714 [00:12<17:02,  2.62it/s]\u001b[Aoutputs:\n","(tensor([[[ 0.1902,  0.2950,  0.1114,  ..., -0.2363,  0.4023, -0.2109],\n","         [ 0.4124, -0.1150,  0.5684,  ..., -0.0532,  0.3048,  0.2073],\n","         [-0.0098,  0.3161, -0.1497,  ...,  0.1592,  0.4094, -0.0443],\n","         ...,\n","         [-0.0349,  0.1845, -0.1460,  ...,  0.2292,  0.3457, -0.1304],\n","         [-0.0905,  0.2723, -0.0772,  ...,  0.0087,  0.7936, -0.1531],\n","         [-0.0931,  0.4115,  0.1811,  ...,  0.0382,  0.2465, -0.1282]],\n","\n","        [[ 0.5969, -0.0097, -0.0559,  ..., -0.1463,  0.1086,  0.0161],\n","         [ 0.4729, -0.5490,  0.1652,  ..., -0.1209,  0.0976, -0.1672],\n","         [ 0.7429,  0.1662,  0.0860,  ...,  0.0862, -0.1517,  0.2794],\n","         ...,\n","         [ 0.2092, -0.2375,  0.3371,  ..., -0.1892, -0.1034, -0.0826],\n","         [ 0.2906,  0.1671,  0.1909,  ..., -0.3173,  0.3312, -0.2945],\n","         [ 0.3277,  0.2219, -0.3224,  ..., -0.1377, -0.0355, -0.0493]],\n","\n","        [[ 0.5532,  0.0361,  0.0033,  ..., -0.2283,  0.2316,  0.0534],\n","         [ 0.3143, -0.3722,  0.4623,  ..., -0.1634,  0.1246, -0.0509],\n","         [-0.8873,  0.1867,  0.7995,  ...,  0.5447, -0.2047, -0.3733],\n","         ...,\n","         [ 0.0199, -0.0853,  0.2987,  ...,  0.0577,  0.1037, -0.3060],\n","         [ 0.1169,  0.0784,  0.0620,  ..., -0.0530,  0.0493,  0.1610],\n","         [ 0.0039,  0.1918, -0.0442,  ..., -0.2167, -0.1392, -0.0009]],\n","\n","        ...,\n","\n","        [[ 0.6170,  0.2482, -0.0161,  ..., -0.4762,  0.4915, -0.0984],\n","         [ 0.4696, -0.4442,  0.6051,  ..., -0.4866,  0.3549,  0.2664],\n","         [ 0.4138,  0.0826,  0.4899,  ..., -0.2202, -0.0455,  0.2310],\n","         ...,\n","         [ 0.3822,  0.0169,  0.5785,  ..., -0.2581,  0.0696,  0.0958],\n","         [ 0.3664, -0.0996,  0.2307,  ..., -0.5606,  0.1870, -0.0800],\n","         [ 0.3479,  0.1462,  0.2141,  ..., -0.1342, -0.0637,  0.1497]],\n","\n","        [[ 0.4724,  0.1776,  0.1412,  ..., -0.0961,  0.3203, -0.1802],\n","         [-0.2466,  0.2642,  0.4168,  ..., -0.1712,  0.1759, -0.3435],\n","         [ 0.6492,  0.1759,  0.6846,  ...,  0.5202,  0.1217, -0.2988],\n","         ...,\n","         [-0.0344,  0.1300,  0.3568,  ...,  0.0311, -0.3157, -0.2924],\n","         [-0.2369,  0.1242,  0.2512,  ..., -0.1377,  0.2843, -0.1331],\n","         [-0.1540,  0.1824,  0.2590,  ...,  0.1155,  0.3505, -0.1976]],\n","\n","        [[ 0.6335,  0.4861, -0.0462,  ..., -0.3532,  0.5155,  0.1556],\n","         [ 0.0834, -0.4140,  0.6573,  ..., -0.3086, -0.0068, -0.0281],\n","         [ 0.4026,  0.6944,  0.8650,  ..., -0.5744,  0.1764, -0.5848],\n","         ...,\n","         [ 0.0325,  0.4290,  0.3251,  ..., -0.1099,  0.0511,  0.2462],\n","         [ 0.5330,  0.2850,  0.4273,  ..., -0.5315,  0.0358,  0.0115],\n","         [-0.0989, -0.3589, -0.0862,  ...,  0.0762, -0.3738,  0.3133]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward>), tensor([[-0.6089,  0.4009,  0.9999,  ...,  1.0000, -0.8720,  0.9966],\n","        [-0.6332,  0.4121,  0.9998,  ...,  0.9999, -0.7075,  0.9898],\n","        [-0.7038,  0.4581,  0.9999,  ...,  1.0000, -0.7882,  0.9926],\n","        ...,\n","        [-0.7301,  0.4512,  0.9999,  ...,  1.0000, -0.6086,  0.9967],\n","        [-0.6920,  0.4885,  0.9999,  ...,  1.0000, -0.8779,  0.9959],\n","        [-0.7601,  0.5335,  1.0000,  ...,  1.0000, -0.8064,  0.9957]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.6089,  0.4009,  0.9999,  ...,  1.0000, -0.8720,  0.9966],\n","        [-0.6332,  0.4121,  0.9998,  ...,  0.9999, -0.7075,  0.9898],\n","        [-0.7038,  0.4581,  0.9999,  ...,  1.0000, -0.7882,  0.9926],\n","        ...,\n","        [-0.7301,  0.4512,  0.9999,  ...,  1.0000, -0.6086,  0.9967],\n","        [-0.6920,  0.4885,  0.9999,  ...,  1.0000, -0.8779,  0.9959],\n","        [-0.7601,  0.5335,  1.0000,  ...,  1.0000, -0.8064,  0.9957]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-1.0225e+00, -6.6185e-01,  2.9272e-01, -6.8404e-02,  3.5564e-01,\n","          4.1737e-01, -1.1273e+00,  8.6257e-01, -2.7449e-01, -5.1703e-01,\n","          7.5789e-02,  5.3907e-01, -2.0274e-01,  4.9860e-01,  1.5309e-01,\n","          3.4421e-01, -2.8289e-01,  7.5708e-01,  4.8235e-02, -7.7929e-01,\n","         -1.6516e+00,  8.2920e-02,  5.6443e-01, -1.0509e-01,  3.2516e-01,\n","          1.0172e+00,  1.3294e-01,  3.9099e-01],\n","        [-6.9333e-01, -7.4262e-01,  3.3843e-02, -3.8077e-01,  1.1024e-01,\n","          3.5873e-01, -7.8034e-01,  9.6657e-01, -4.0163e-02, -6.0253e-01,\n","          1.3292e-02,  5.2548e-01, -3.7153e-01,  5.3510e-01, -1.3978e-01,\n","          2.5202e-01, -1.5770e-01,  8.0781e-01, -2.0334e-01, -4.7911e-01,\n","         -1.3923e+00,  5.2956e-02,  8.2500e-02, -4.6785e-02,  6.7724e-02,\n","          8.8385e-01,  2.6758e-01,  3.2802e-01],\n","        [-7.4128e-01, -3.5034e-01, -5.3430e-02, -1.2453e-01,  3.0367e-01,\n","          6.2290e-01, -8.5951e-01,  7.2047e-01, -3.2581e-01, -5.9869e-01,\n","         -2.5850e-03,  4.1403e-01, -1.1015e-01,  6.3636e-01,  1.0097e-01,\n","          6.2804e-02, -2.0659e-01,  7.7240e-01, -3.6284e-02, -7.8736e-01,\n","         -1.2931e+00, -1.0103e-01,  2.5627e-01, -5.6888e-02,  5.2399e-01,\n","          9.4602e-01,  1.3056e-01,  4.7754e-01],\n","        [-8.7134e-01, -6.5320e-01,  2.7914e-01,  1.4506e-01,  3.0097e-01,\n","          6.2034e-01, -8.7423e-01,  6.7210e-01, -3.9725e-01, -8.3895e-01,\n","         -5.3337e-02,  7.4114e-01, -5.7882e-01,  3.8907e-01, -1.1682e-01,\n","          1.6627e-01, -7.8608e-02,  9.4726e-01,  1.7236e-01, -8.5681e-01,\n","         -1.4374e+00,  2.1841e-01,  1.9828e-01, -3.5278e-01,  3.1286e-01,\n","          1.0306e+00,  1.8736e-01,  4.2597e-01],\n","        [-4.5848e-01, -7.3883e-01,  1.7487e-01, -1.6953e-01,  4.2190e-01,\n","          2.5670e-01, -9.0777e-01,  7.5136e-01, -3.4343e-01, -8.3094e-01,\n","         -5.6884e-02,  6.2125e-01, -4.0485e-02,  6.7058e-01,  1.0044e-01,\n","          7.3828e-03, -7.7129e-03,  9.6393e-01, -1.9099e-01, -1.2149e+00,\n","         -1.4784e+00,  2.7912e-01,  5.3764e-01, -1.6523e-01,  4.1997e-01,\n","          8.4162e-01, -8.8782e-02,  5.2040e-01],\n","        [-8.9203e-01, -5.9740e-01,  1.0691e-01, -2.6123e-01,  3.7447e-01,\n","          5.7874e-01, -1.0175e+00,  6.6785e-01, -2.1290e-01, -4.6670e-01,\n","          1.1565e-01,  5.7687e-01, -3.3784e-01,  7.6878e-01,  2.1238e-01,\n","          1.5838e-01,  8.0060e-02,  7.5522e-01,  2.4157e-02, -5.9224e-01,\n","         -1.6569e+00,  3.1573e-01,  4.8513e-01, -1.8221e-01, -1.1524e-02,\n","          8.0813e-01,  2.0879e-01,  4.9077e-01],\n","        [-7.7551e-01, -3.9441e-01, -2.2441e-01, -1.3288e-01,  2.1651e-01,\n","          3.2171e-01, -8.0067e-01,  7.2199e-01, -2.1290e-01, -6.6466e-01,\n","         -2.3249e-01,  5.8305e-01,  6.5206e-03,  6.0254e-01,  1.3689e-02,\n","          4.5214e-01, -4.4255e-02,  9.2700e-01, -3.6432e-01, -6.9668e-01,\n","         -1.6353e+00,  5.6682e-01,  1.5525e-01, -1.9197e-01,  4.6997e-01,\n","          7.7912e-01,  2.8652e-02,  5.7506e-01],\n","        [-7.4625e-01, -6.7846e-01,  5.2591e-01, -1.3235e-01,  7.5386e-01,\n","          3.7746e-01, -1.0780e+00,  5.9613e-01, -4.7683e-01, -8.2955e-01,\n","         -1.3938e-01,  4.1100e-01, -3.1777e-01,  4.3194e-01, -1.0858e-01,\n","          3.8193e-01, -1.5380e-01,  4.8277e-01, -1.5841e-01, -8.1209e-01,\n","         -1.2210e+00,  1.4477e-01,  1.0848e-01, -6.9622e-02, -5.2419e-02,\n","          9.3397e-01,  2.1674e-01,  4.5079e-01],\n","        [-6.3821e-01, -5.7474e-01,  3.0889e-01,  1.1330e-01,  3.2671e-01,\n","          4.8424e-01, -1.1455e+00,  6.6333e-01, -4.4136e-01, -3.3868e-01,\n","          1.1155e-01,  6.2748e-01, -3.1303e-01,  2.3477e-01, -2.2951e-01,\n","          8.3202e-02, -2.1704e-03,  8.1817e-01,  1.0073e-01, -8.4444e-01,\n","         -1.5553e+00,  1.2956e-01,  5.7273e-01, -4.3592e-01,  3.3389e-01,\n","          9.9593e-01,  3.5928e-01,  3.9848e-01],\n","        [-7.7306e-01, -4.8596e-01,  9.7527e-02, -2.4989e-01,  5.5579e-01,\n","          4.9850e-01, -7.1697e-01,  4.6984e-01, -3.3844e-01, -9.1897e-01,\n","          7.9908e-02,  9.5553e-01, -3.8489e-01,  3.7450e-01,  7.1773e-02,\n","          2.0409e-01,  1.7578e-01,  8.5773e-01,  2.2413e-01, -8.8815e-01,\n","         -1.2050e+00,  1.0177e-02,  5.0037e-01, -4.9374e-01,  4.5581e-01,\n","          9.1092e-01,  2.2694e-01,  3.4739e-01],\n","        [-8.5962e-01, -7.5941e-01,  5.3682e-01, -1.5203e-01,  4.8056e-01,\n","          2.9473e-01, -8.7035e-01,  9.2928e-01, -2.0016e-01, -7.2584e-01,\n","         -5.5937e-02,  7.6446e-01,  9.5860e-02,  1.9909e-01,  1.9852e-02,\n","          3.0132e-01, -1.3832e-01,  8.1741e-01,  4.3809e-02, -1.0586e+00,\n","         -1.5052e+00,  4.3982e-01,  1.6776e-01,  1.9422e-02,  1.9882e-01,\n","          1.1007e+00,  2.3514e-01,  6.1668e-01],\n","        [-1.0117e+00, -6.7521e-01,  4.0537e-01, -2.6637e-01,  4.0515e-01,\n","          5.5951e-01, -9.5502e-01,  8.6673e-01, -3.6795e-01, -5.1035e-01,\n","          1.6037e-01,  9.2824e-01, -9.2083e-03,  3.9792e-01, -9.6353e-02,\n","          1.3330e-01, -1.9793e-01,  1.0068e+00,  2.3332e-01, -5.4297e-01,\n","         -1.4569e+00,  1.3855e-01,  3.9916e-01, -2.0971e-01,  5.2318e-01,\n","          1.0524e+00,  3.2798e-01,  3.1120e-01],\n","        [-7.1528e-01, -6.8939e-01,  4.3693e-01, -3.3874e-01,  4.0508e-01,\n","          4.9517e-01, -7.7535e-01,  2.6659e-01, -2.0575e-01, -6.5603e-01,\n","          7.9382e-02,  6.2754e-01,  2.5752e-01,  1.9923e-01,  2.0917e-01,\n","         -1.1288e-01,  2.2170e-01,  8.0666e-01,  1.2696e-01, -1.0087e+00,\n","         -1.5518e+00,  1.0051e-02,  4.7650e-01, -2.7855e-01,  1.1258e-01,\n","          6.6223e-01,  2.0086e-02,  3.1280e-01],\n","        [-9.2051e-01, -6.9125e-01,  2.0609e-01, -9.8606e-02,  2.6397e-01,\n","          5.8460e-01, -8.5600e-01,  7.7640e-01, -3.3518e-01, -4.8292e-01,\n","         -4.3105e-01,  6.4871e-01,  3.9501e-02,  3.3505e-01, -2.0706e-01,\n","          3.0224e-01, -1.0527e-01,  9.5403e-01, -1.1039e-01, -2.3862e-01,\n","         -1.5350e+00,  8.5333e-02,  5.3219e-01, -4.8758e-01,  3.4121e-01,\n","          9.6990e-01,  3.7166e-01,  3.2176e-01],\n","        [-9.1326e-01, -4.9103e-01,  2.0397e-01, -3.8144e-01,  6.6915e-01,\n","          2.4013e-01, -6.5958e-01,  8.7482e-01, -9.6132e-02, -7.7690e-01,\n","         -3.6564e-01,  3.7237e-01, -3.5695e-01,  5.9846e-01,  1.3324e-01,\n","          3.1965e-01,  2.0322e-01,  1.0839e+00,  1.2256e-01, -9.1029e-01,\n","         -1.2406e+00,  3.7095e-01,  2.6475e-01, -1.5592e-01,  1.3702e-01,\n","          8.8977e-01,  1.6645e-01,  3.2899e-01],\n","        [-4.9611e-01, -7.2641e-01, -6.4454e-04, -5.5759e-01,  5.2726e-01,\n","          6.6939e-01, -1.1201e+00,  9.0232e-01, -9.6595e-02, -3.5392e-01,\n","         -2.1225e-02,  3.4209e-01, -3.5902e-01,  1.8423e-01,  1.6371e-01,\n","         -4.5731e-02, -2.0443e-01,  9.9035e-01,  1.8870e-01, -6.4671e-01,\n","         -1.6025e+00,  3.8848e-01,  4.2485e-01, -3.1698e-01,  3.3068e-01,\n","          1.2350e+00,  2.9409e-01,  7.2315e-01]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   1% 34/2714 [00:13<17:04,  2.62it/s]\u001b[Aoutputs:\n","(tensor([[[ 0.2986,  0.1209, -0.0561,  ..., -0.2502,  0.3737,  0.1669],\n","         [ 0.4586, -0.3055,  0.3685,  ...,  0.0593,  0.1045,  0.3540],\n","         [ 0.7663,  0.3434, -0.2487,  ..., -0.1033, -0.0401,  0.7808],\n","         ...,\n","         [-0.2176,  0.1714, -0.3164,  ...,  0.1858,  0.1249, -0.4659],\n","         [ 0.1456,  0.2492, -0.1692,  ...,  0.0134,  0.5351,  0.0969],\n","         [-0.3421, -0.1908, -0.3477,  ...,  0.0358,  0.4232,  0.0166]],\n","\n","        [[ 0.1069, -0.0145,  0.0422,  ...,  0.0726,  0.6600,  0.1138],\n","         [-0.1225, -0.0512,  0.4939,  ...,  0.1721,  0.4883,  0.3153],\n","         [-0.1920,  0.0989,  0.6641,  ..., -0.1423,  0.4612,  0.1028],\n","         ...,\n","         [ 0.0219,  0.2554,  0.2294,  ...,  0.1269,  0.7075,  0.2654],\n","         [ 0.1152, -0.0469,  0.0983,  ..., -0.0299,  0.4574,  0.2813],\n","         [ 0.2869,  0.0487,  0.2351,  ...,  0.1293,  0.3160,  0.1151]],\n","\n","        [[ 0.5023,  0.3115, -0.1653,  ..., -0.4543,  0.4117,  0.2026],\n","         [ 0.3616, -0.2295,  0.2482,  ..., -0.3282,  0.0827,  0.2671],\n","         [ 0.3244,  0.4916, -0.2656,  ..., -0.0656,  0.3495,  0.5544],\n","         ...,\n","         [-0.1061,  0.0804,  0.0063,  ...,  0.0362,  0.3206,  0.1931],\n","         [ 0.2540,  0.4136, -0.0286,  ...,  0.3008, -0.4480,  0.0616],\n","         [-0.0636,  0.2220, -0.2861,  ...,  0.2282,  0.0876,  0.3439]],\n","\n","        ...,\n","\n","        [[ 0.1818,  0.1050,  0.0754,  ...,  0.1970,  0.2256,  0.0731],\n","         [ 0.3098, -0.3834,  0.3807,  ...,  0.0282,  0.1796,  0.1252],\n","         [-0.0409,  0.4360,  0.2064,  ...,  0.1707,  0.3000,  0.2606],\n","         ...,\n","         [-0.1365,  0.1836,  0.0947,  ...,  0.2932,  0.2612,  0.1557],\n","         [-0.2454,  0.1760,  0.1389,  ...,  0.1878,  0.5159,  0.1682],\n","         [-0.0241,  0.2779, -0.0765,  ...,  0.3285,  0.3603,  0.3391]],\n","\n","        [[ 0.4617, -0.0709, -0.4025,  ..., -0.0068,  0.1285,  0.1087],\n","         [ 0.1142, -0.3500, -0.1885,  ...,  0.4132,  0.3985,  0.2329],\n","         [-0.0703, -0.0924, -0.4732,  ...,  0.2483,  0.2328,  0.5698],\n","         ...,\n","         [ 0.1347,  0.0413, -0.1286,  ...,  0.3403,  0.1717,  0.2114],\n","         [ 0.4253,  0.0589, -0.4457,  ...,  0.3948,  0.2696,  0.1218],\n","         [ 0.2100, -0.1399, -0.0020,  ...,  0.3035,  0.1238,  0.2341]],\n","\n","        [[ 0.3917,  0.3809, -0.0144,  ..., -0.1493,  0.2000,  0.0861],\n","         [ 0.3641, -0.3103,  0.5531,  ..., -0.0570,  0.4300, -0.1180],\n","         [ 0.1558,  0.1638, -0.2027,  ..., -0.1463,  0.5729,  0.0175],\n","         ...,\n","         [-0.2869,  0.1427,  0.2320,  ...,  0.3120,  0.3634, -0.0328],\n","         [ 0.1921,  0.3800,  0.2590,  ...,  0.2315,  0.7162, -0.2972],\n","         [ 0.1506,  0.1560,  0.4194,  ...,  0.0792,  0.2702, -0.1678]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward>), tensor([[-0.7525,  0.3899,  0.9999,  ...,  1.0000, -0.7835,  0.9977],\n","        [-0.7326,  0.5275,  1.0000,  ...,  1.0000, -0.3463,  0.9965],\n","        [-0.7574,  0.5011,  0.9999,  ...,  1.0000, -0.7954,  0.9915],\n","        ...,\n","        [-0.6404,  0.4000,  0.9994,  ...,  0.9999, -0.8386,  0.9853],\n","        [-0.7598,  0.4630,  1.0000,  ...,  1.0000, -0.4176,  0.9921],\n","        [-0.7195,  0.3991,  0.9999,  ...,  1.0000, -0.8981,  0.9932]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.7525,  0.3899,  0.9999,  ...,  1.0000, -0.7835,  0.9977],\n","        [-0.7326,  0.5275,  1.0000,  ...,  1.0000, -0.3463,  0.9965],\n","        [-0.7574,  0.5011,  0.9999,  ...,  1.0000, -0.7954,  0.9915],\n","        ...,\n","        [-0.6404,  0.4000,  0.9994,  ...,  0.9999, -0.8386,  0.9853],\n","        [-0.7598,  0.4630,  1.0000,  ...,  1.0000, -0.4176,  0.9921],\n","        [-0.7195,  0.3991,  0.9999,  ...,  1.0000, -0.8981,  0.9932]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-3.3852e-01, -6.4607e-01,  2.3292e-01, -8.3683e-02,  6.5414e-01,\n","          5.7853e-01, -9.0238e-01,  8.4153e-01, -4.1185e-01, -4.2661e-01,\n","         -8.2914e-02,  6.3142e-01, -5.0468e-01,  3.4713e-01, -6.1436e-02,\n","          2.4601e-01, -1.6334e-01,  7.3610e-01,  1.9341e-02, -7.9110e-01,\n","         -1.4810e+00,  1.3855e-01, -1.2386e-01, -4.5374e-02,  2.1340e-01,\n","          7.4160e-01,  3.0776e-01,  5.3852e-01],\n","        [-8.1374e-01, -9.6797e-01,  4.6348e-01,  1.2712e-01,  3.7146e-01,\n","          3.7231e-01, -8.8420e-01,  6.8113e-01, -1.1297e-01, -6.4609e-01,\n","          1.0700e-01,  7.2572e-01, -3.7734e-01,  1.6458e-01, -6.9700e-02,\n","          2.7794e-01, -7.2742e-03,  6.5751e-01,  1.5606e-01, -5.9382e-01,\n","         -1.5630e+00, -2.4392e-01,  3.2710e-01, -3.2071e-01, -1.8419e-01,\n","          8.8815e-01, -3.2488e-02,  2.0733e-01],\n","        [-7.2642e-01, -5.1467e-01,  3.0813e-01, -1.3696e-01,  2.5474e-01,\n","          7.5976e-01, -1.1660e+00,  6.6143e-01, -3.1731e-01, -6.3464e-01,\n","          4.0905e-03,  6.1331e-01, -2.0124e-01,  3.9596e-01,  1.5234e-01,\n","          1.9236e-01, -4.0523e-02,  9.4541e-01,  1.3581e-02, -7.9294e-01,\n","         -1.2812e+00,  3.5296e-01,  2.4516e-01, -1.1407e-01,  4.5466e-01,\n","          7.9202e-01,  4.5091e-01,  3.6416e-01],\n","        [-9.0214e-01, -6.5181e-01,  2.0405e-01, -5.2117e-01,  4.7937e-01,\n","          4.2204e-01, -8.9241e-01,  6.7865e-01, -5.2195e-02, -6.8017e-01,\n","         -1.2636e-01,  5.5149e-01, -1.5255e-01,  5.7616e-01,  2.1014e-01,\n","          4.1379e-01, -3.6306e-01,  8.4312e-01,  1.5241e-01, -8.0226e-01,\n","         -1.2880e+00,  5.1511e-01,  3.2636e-01, -9.9900e-02,  5.9941e-01,\n","          9.6870e-01,  1.7972e-01,  3.8552e-01],\n","        [-7.9467e-01, -5.4293e-01,  4.0676e-02, -3.8481e-01,  4.0410e-01,\n","          2.7179e-01, -1.0797e+00,  6.4995e-01, -3.2259e-01, -6.8747e-01,\n","         -7.2575e-02,  5.9319e-01, -5.9487e-02,  5.7793e-01,  1.3858e-01,\n","          1.9985e-01, -6.0836e-02,  1.1441e+00, -4.3469e-01, -6.6860e-01,\n","         -1.2149e+00,  2.2264e-01,  1.8927e-01,  7.4433e-02,  2.2863e-01,\n","          7.1800e-01,  8.4202e-02,  4.9434e-01],\n","        [-9.0764e-01, -6.3451e-01,  1.8401e-01, -1.3329e-01,  5.9110e-01,\n","          6.9879e-01, -1.1756e+00,  6.3659e-01, -2.2331e-01, -5.8338e-01,\n","         -1.7483e-01,  8.4356e-01, -2.4393e-01,  3.5266e-01,  2.2073e-01,\n","          3.6464e-01,  6.8712e-02,  1.1106e+00,  1.9859e-01, -2.0414e-01,\n","         -1.2313e+00,  4.5201e-01,  3.4003e-01,  7.3146e-02,  5.5235e-01,\n","          7.4654e-01,  3.3689e-02,  7.1275e-01],\n","        [-1.0143e+00, -6.7999e-01,  3.6621e-01, -2.1249e-01,  4.8295e-01,\n","          4.8675e-01, -9.6146e-01,  5.3730e-01,  1.6472e-02, -7.1739e-01,\n","         -2.2621e-01,  6.7098e-01, -9.6549e-02,  4.0526e-01, -3.3248e-01,\n","          3.1238e-01, -2.4147e-01,  6.6269e-01, -1.5547e-01, -9.4053e-01,\n","         -1.5235e+00,  2.4307e-01,  4.2859e-01, -2.6556e-01,  2.3448e-01,\n","          9.4962e-01,  5.0142e-02,  6.1623e-01],\n","        [-8.2287e-01, -5.0480e-01, -3.2596e-02, -3.4093e-01,  2.6032e-01,\n","          2.4630e-01, -9.0926e-01,  8.5634e-01, -2.5630e-01, -6.3583e-01,\n","         -1.6826e-03,  8.6636e-01, -1.5714e-01,  4.4016e-01, -1.1144e-01,\n","          4.0757e-01, -2.2257e-01,  6.1868e-01, -3.0190e-01, -8.2518e-01,\n","         -1.3576e+00,  3.2542e-01,  4.0238e-01,  1.1394e-01, -5.3896e-02,\n","          9.9749e-01,  2.4554e-01,  2.7172e-01],\n","        [-9.0679e-01, -6.2952e-01,  4.3450e-01, -5.7205e-01,  2.3794e-01,\n","          2.5885e-01, -1.0289e+00,  6.7665e-01, -4.7538e-02, -5.1430e-01,\n","         -3.0254e-01,  4.3097e-01, -7.4979e-02,  7.0925e-01, -8.7401e-02,\n","          5.9220e-01, -1.9452e-01,  9.6436e-01, -1.3583e-01, -9.0272e-01,\n","         -1.4509e+00,  4.1372e-01,  1.8844e-01, -1.3650e-01,  4.0109e-01,\n","          8.9165e-01,  1.5089e-01,  4.6699e-01],\n","        [-7.0065e-01, -7.7419e-01,  2.8116e-01, -7.3284e-01,  5.2140e-01,\n","          5.7326e-01, -8.6302e-01,  6.9727e-01, -2.0740e-02, -9.0825e-01,\n","         -4.2510e-02,  6.3371e-01,  1.4998e-01,  5.1645e-01, -1.0516e-01,\n","          5.0458e-01, -3.3123e-01,  9.8657e-01, -2.8503e-01, -9.3305e-01,\n","         -1.5355e+00,  2.5783e-01,  3.5175e-01, -3.8035e-02,  3.9728e-01,\n","          8.6980e-01,  5.1130e-01,  2.8849e-01],\n","        [-8.1500e-01, -6.1963e-01, -2.2487e-01, -2.1277e-01,  2.3225e-01,\n","          5.4282e-01, -1.0419e+00,  9.0646e-01, -6.3763e-01, -3.9158e-01,\n","          3.5846e-02,  7.2388e-01,  1.6062e-01,  3.2291e-01,  7.2023e-01,\n","          1.3616e-01, -1.5110e-01,  8.9899e-01, -1.3086e-01, -9.2745e-01,\n","         -1.4764e+00,  3.7023e-01,  5.0092e-01, -1.3336e-02,  4.0941e-01,\n","          8.4827e-01,  2.5182e-01,  6.6177e-01],\n","        [-9.0716e-01, -4.9303e-01,  4.8000e-01,  2.5491e-01,  1.8762e-01,\n","          2.7223e-01, -1.0983e+00,  8.2344e-01, -9.1284e-02, -5.3483e-01,\n","          2.4426e-01,  5.9220e-01, -1.0576e-01,  6.1369e-01,  1.2297e-01,\n","          2.6219e-01, -2.5526e-02,  9.5208e-01,  6.4785e-02, -4.9925e-01,\n","         -1.5349e+00,  3.9279e-01, -7.3664e-02, -2.6723e-01,  3.9683e-01,\n","          9.4642e-01,  1.2947e-01,  5.7973e-01],\n","        [-8.6286e-01, -6.3249e-01,  3.4048e-01, -1.5917e-01,  6.1433e-02,\n","          7.3216e-01, -1.0162e+00,  8.5523e-01,  5.1399e-02, -4.0817e-01,\n","         -1.1186e-01,  5.5652e-01,  6.7655e-02,  4.2645e-01, -1.1257e-01,\n","          3.3877e-01, -1.2646e-01,  7.6490e-01,  4.2155e-02, -5.3410e-01,\n","         -1.5858e+00,  2.2357e-01,  2.9222e-01, -1.6948e-01,  2.2325e-01,\n","          7.0024e-01,  1.1582e-01,  5.4284e-01],\n","        [-8.1050e-01, -5.5858e-01,  1.7691e-01, -2.1682e-01,  2.8242e-02,\n","          2.5209e-01, -9.9034e-01,  8.4133e-01, -9.0705e-02, -4.0542e-01,\n","         -1.2317e-01,  4.5672e-01, -3.4261e-01,  4.7565e-01,  5.6010e-02,\n","          1.7550e-01, -3.8127e-01,  7.0744e-01, -1.1905e-01, -6.4199e-01,\n","         -1.5960e+00,  4.2755e-01,  2.3743e-01, -1.2405e-01,  1.6329e-02,\n","          9.8954e-01,  1.1916e-02,  6.9762e-01],\n","        [-6.6981e-01, -6.5511e-01,  3.0207e-01,  1.0399e-01,  4.3791e-01,\n","          3.5759e-01, -9.3864e-01,  8.7604e-01, -2.8750e-01, -5.6120e-01,\n","         -3.0717e-01,  6.4022e-01, -2.1683e-01,  1.2742e-01, -9.8392e-02,\n","          1.5547e-01,  2.9222e-02,  7.3434e-01,  2.0550e-01, -6.3823e-01,\n","         -1.7435e+00,  8.9340e-04,  3.7284e-01, -3.1954e-01,  1.0708e-01,\n","          8.4724e-01,  1.8082e-01,  5.2742e-01],\n","        [-7.9370e-01, -6.4363e-01,  1.1985e-01, -2.3390e-01,  2.6200e-01,\n","          3.3015e-01, -8.7360e-01,  9.3605e-01, -4.4131e-01, -7.5462e-01,\n","          1.3119e-01,  6.3730e-01, -2.4897e-01,  8.1379e-01, -1.8222e-01,\n","          6.6855e-01, -3.6407e-01,  1.0085e+00, -1.5697e-01, -6.2604e-01,\n","         -1.3384e+00,  1.9559e-01,  4.8849e-01, -2.5758e-01,  1.3732e-01,\n","          5.9236e-01,  2.4512e-01,  3.1764e-01]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   1% 35/2714 [00:13<17:10,  2.60it/s]\u001b[Aoutputs:\n","(tensor([[[ 0.4193,  0.2725, -0.2958,  ..., -0.1222,  0.2054, -0.0426],\n","         [ 0.2779, -0.1854,  0.2192,  ..., -0.0603,  0.1099,  0.4284],\n","         [-0.0146,  0.1999, -0.1809,  ...,  0.2174, -0.3914,  0.0042],\n","         ...,\n","         [-0.0040,  0.0144, -0.3125,  ...,  0.5499,  0.0844,  0.2173],\n","         [-0.0129,  0.2341, -0.0333,  ...,  0.4504,  0.0354,  0.0577],\n","         [ 0.0847, -0.0408,  0.1155,  ...,  0.1697,  0.2325, -0.2302]],\n","\n","        [[ 0.3997, -0.0832,  0.0279,  ..., -0.0635,  0.1720,  0.0451],\n","         [ 0.3491, -0.1182,  0.2614,  ...,  0.8598,  0.8247,  0.2948],\n","         [ 0.8916, -0.4332, -0.0932,  ..., -0.0021,  0.2575,  1.0450],\n","         ...,\n","         [-0.1501,  0.1574,  0.2112,  ...,  0.1200,  0.2541,  0.0677],\n","         [-0.1482, -0.0557,  0.2907,  ...,  0.2986,  0.1381,  0.4055],\n","         [ 0.1894,  0.0636,  0.3356,  ...,  0.3151, -0.2705,  0.3831]],\n","\n","        [[ 0.8708,  0.3269,  0.0326,  ..., -0.1421,  0.3191,  0.4066],\n","         [ 0.8445, -0.7929,  0.7193,  ..., -0.2481,  0.0367, -0.3256],\n","         [ 0.6385, -0.6471, -0.5236,  ...,  0.8628, -0.3849,  0.1821],\n","         ...,\n","         [ 0.1511,  0.1671,  0.1914,  ..., -0.0776, -0.0688, -0.0830],\n","         [ 0.4718,  0.3971,  0.2510,  ..., -0.1118,  0.0252, -0.2567],\n","         [ 0.4350,  0.3688,  0.0497,  ..., -0.1816, -0.0578, -0.2041]],\n","\n","        ...,\n","\n","        [[ 0.3996,  0.1370,  0.0117,  ..., -0.2222,  0.3514,  0.0719],\n","         [ 0.3226,  0.0364,  0.6411,  ..., -0.3643,  0.2717,  0.2008],\n","         [ 0.4915,  0.3015,  0.0440,  ..., -0.1898,  0.2366,  0.3444],\n","         ...,\n","         [ 0.0868,  0.3606,  0.1573,  ...,  0.1485,  0.3988,  0.0897],\n","         [ 0.0775,  0.2009, -0.0286,  ...,  0.0987,  0.2278,  0.4599],\n","         [-0.0295,  0.2285, -0.0227,  ...,  0.3469,  0.2390,  0.2816]],\n","\n","        [[ 0.3509,  0.0792, -0.0449,  ..., -0.2825,  0.5565,  0.1254],\n","         [ 0.3016, -0.3700,  0.2827,  ...,  0.1516, -0.0458,  0.0966],\n","         [ 0.1450,  0.7650, -0.1160,  ...,  0.1581,  0.5333, -0.6277],\n","         ...,\n","         [-0.1729,  0.4673,  0.0031,  ...,  0.8007, -0.0724, -0.2507],\n","         [ 0.1252,  0.4052, -0.0258,  ...,  0.1892,  0.0977, -0.0761],\n","         [ 0.0654,  0.1456,  0.1079,  ..., -0.0179, -0.0184, -0.1155]],\n","\n","        [[ 0.2232,  0.1739, -0.1579,  ..., -0.3144,  0.2683, -0.0830],\n","         [ 0.5349, -0.5840,  0.3411,  ..., -0.2867,  0.0428, -0.4382],\n","         [-0.0646,  0.0607, -0.6602,  ...,  0.5809,  0.1107, -0.0402],\n","         ...,\n","         [ 0.0951,  0.1891,  0.1202,  ..., -0.0447,  0.0425, -0.2072],\n","         [-0.0244,  0.0371,  0.1149,  ..., -0.4193,  0.0522, -0.2699],\n","         [-0.0811, -0.0333,  0.1231,  ...,  0.0042,  0.1697, -0.0340]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward>), tensor([[-0.6385,  0.3330,  0.9997,  ...,  0.9999, -0.8243,  0.9864],\n","        [-0.6148,  0.3877,  0.9997,  ...,  0.9999, -0.6655,  0.9832],\n","        [-0.6618,  0.4047,  0.9999,  ...,  1.0000, -0.5393,  0.9945],\n","        ...,\n","        [-0.6892,  0.4484,  0.9998,  ...,  0.9999, -0.6158,  0.9896],\n","        [-0.7349,  0.4964,  0.9999,  ...,  1.0000, -0.4632,  0.9927],\n","        [-0.6367,  0.4632,  0.9999,  ...,  1.0000, -0.5925,  0.9976]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.6385,  0.3330,  0.9997,  ...,  0.9999, -0.8243,  0.9864],\n","        [-0.6148,  0.3877,  0.9997,  ...,  0.9999, -0.6655,  0.9832],\n","        [-0.6618,  0.4047,  0.9999,  ...,  1.0000, -0.5393,  0.9945],\n","        ...,\n","        [-0.6892,  0.4484,  0.9998,  ...,  0.9999, -0.6158,  0.9896],\n","        [-0.7349,  0.4964,  0.9999,  ...,  1.0000, -0.4632,  0.9927],\n","        [-0.6367,  0.4632,  0.9999,  ...,  1.0000, -0.5925,  0.9976]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-8.1630e-01, -5.7596e-01,  2.0992e-01, -4.5388e-01,  2.7988e-01,\n","          4.7409e-01, -9.1860e-01,  5.3514e-01, -3.6688e-01, -7.7577e-01,\n","         -1.7778e-01,  5.8124e-01, -1.6577e-01,  3.3776e-01,  1.6052e-01,\n","          4.0427e-01, -1.6049e-01,  1.0528e+00, -1.8409e-01, -9.6039e-01,\n","         -1.4244e+00,  4.0295e-01,  3.9008e-01,  3.5177e-02,  3.6381e-01,\n","          8.9332e-01,  7.5497e-02,  2.6017e-01],\n","        [-5.3619e-01, -7.6574e-01,  1.6766e-01,  1.0391e-01,  5.0795e-01,\n","          2.7797e-01, -1.0159e+00,  7.0086e-01, -2.0197e-01, -8.0388e-01,\n","         -1.0729e-02,  9.1820e-01, -4.5084e-01,  5.0438e-01,  5.7677e-02,\n","          2.1710e-01, -7.5502e-02,  9.5061e-01, -9.4930e-02, -9.1020e-01,\n","         -1.2365e+00,  2.3678e-01,  2.8960e-01, -2.1023e-01,  3.1449e-01,\n","          9.2756e-01,  1.1955e-01,  2.4288e-01],\n","        [-5.7507e-01, -7.9389e-01,  2.0982e-01, -6.1135e-02,  4.7149e-01,\n","          6.8900e-01, -9.3718e-01,  7.2513e-01, -8.9143e-02, -6.5815e-01,\n","         -1.4385e-01,  5.2779e-01, -2.7562e-01,  2.3540e-01, -2.2340e-01,\n","          1.4565e-02,  2.8181e-02,  9.3014e-01,  1.6158e-01, -7.4828e-01,\n","         -1.5449e+00,  3.1607e-02,  2.9108e-01, -2.7565e-01, -1.4411e-02,\n","          1.0353e+00,  2.3416e-01,  3.7790e-01],\n","        [-8.1842e-01, -7.2827e-01, -1.8590e-03, -1.8303e-01,  3.6284e-01,\n","          5.8775e-01, -8.1668e-01,  8.8858e-01, -6.1869e-01, -6.5145e-01,\n","         -1.3382e-01,  7.4768e-01, -1.6690e-01,  4.5964e-01, -1.5262e-01,\n","          1.2631e-01,  2.6506e-01,  8.0049e-01, -8.4800e-02, -6.5799e-01,\n","         -1.3961e+00, -3.2664e-02,  6.3153e-01, -4.4563e-01,  5.9872e-02,\n","          8.7400e-01, -1.2160e-02,  4.1692e-01],\n","        [-4.4840e-01, -5.1630e-01,  2.4864e-01, -7.3410e-02,  2.6380e-01,\n","          6.5086e-01, -1.0348e+00,  5.1464e-01, -3.9153e-01, -6.3648e-01,\n","         -1.2331e-02,  7.7723e-01, -2.1444e-01,  4.7980e-01, -2.3339e-01,\n","          1.1298e-01, -2.4291e-01,  9.0584e-01,  1.6195e-02, -1.0354e+00,\n","         -1.3762e+00,  3.0515e-01,  2.3345e-01,  9.9690e-03,  2.8510e-01,\n","          6.0917e-01,  2.6764e-01,  4.6352e-01],\n","        [-9.6229e-01, -6.2883e-01,  2.2149e-01, -3.3412e-01,  2.0894e-01,\n","          4.8130e-01, -1.3252e+00,  7.8065e-01, -3.0732e-01, -4.9667e-01,\n","         -1.8856e-01,  4.8666e-01, -2.9024e-01,  4.0981e-01, -1.3206e-01,\n","          3.6282e-01, -3.1452e-02,  1.1613e+00, -1.4988e-02, -7.4241e-01,\n","         -1.7279e+00,  1.1158e-01,  2.7765e-01, -4.1040e-01,  1.8833e-01,\n","          1.0412e+00, -1.4528e-02,  1.5839e-01],\n","        [-8.7877e-01, -7.6899e-01,  1.4278e-01, -1.8094e-01,  5.7208e-01,\n","          5.7125e-01, -9.7409e-01,  8.0395e-01, -5.3408e-01, -3.6269e-01,\n","         -1.0632e-01,  5.4517e-01, -1.2025e-01,  6.8333e-01, -4.5701e-02,\n","          1.5664e-01, -2.1607e-01,  6.9510e-01, -6.6496e-02, -6.4674e-01,\n","         -1.4679e+00,  3.0678e-02,  1.5293e-01, -1.4377e-01,  4.5861e-02,\n","          8.5070e-01, -1.7970e-01,  2.1943e-01],\n","        [-8.8988e-01, -7.9441e-01,  2.1569e-01, -2.0281e-01,  5.5229e-01,\n","          3.5748e-01, -9.4169e-01,  6.3194e-01,  4.8871e-02, -4.7118e-01,\n","         -8.2882e-02,  6.4955e-01, -1.8020e-01,  3.8220e-01,  6.4977e-02,\n","          3.4103e-01, -1.2056e-02,  9.8906e-01,  8.5300e-02, -7.3454e-01,\n","         -1.5823e+00,  9.6533e-02,  4.9759e-01, -1.7861e-01,  4.0982e-01,\n","          9.1044e-01,  3.2557e-01,  4.3011e-01],\n","        [-6.9451e-01, -6.9214e-01,  3.2136e-01, -4.6256e-04,  2.8453e-01,\n","          3.8525e-01, -9.8475e-01,  8.4384e-01, -4.5907e-02, -5.1505e-01,\n","          1.4305e-02,  4.5977e-01, -4.0858e-01,  3.7541e-01, -4.6682e-02,\n","          6.6438e-02, -3.5592e-01,  6.6933e-01,  7.0587e-02, -6.5964e-01,\n","         -1.5346e+00,  1.2727e-01,  4.8749e-01, -3.9948e-01,  3.0164e-01,\n","          8.7064e-01,  3.3721e-01,  1.2131e-01],\n","        [-7.3285e-01, -7.4660e-01,  2.4202e-01,  7.9674e-02,  9.1645e-02,\n","          1.1481e-01, -9.5111e-01,  8.5798e-01, -2.5206e-01, -5.5702e-01,\n","         -3.7914e-02,  8.0733e-01, -3.1289e-01,  6.0334e-01,  1.0389e-02,\n","          2.7039e-01, -1.6971e-01,  6.5699e-01, -1.2183e-01, -9.2655e-01,\n","         -1.2641e+00,  4.3620e-01,  3.5517e-01,  7.7970e-02,  2.9615e-01,\n","          7.9549e-01,  2.3203e-01,  4.8855e-01],\n","        [-8.3722e-01, -6.2723e-01,  2.8851e-01, -2.5055e-01,  6.8680e-01,\n","          6.3374e-01, -9.3847e-01,  6.2286e-01, -4.2578e-01, -6.3714e-01,\n","          1.7277e-01,  5.9161e-01, -1.8442e-01,  3.6496e-01, -3.4082e-02,\n","          4.9539e-01, -1.8046e-02,  9.8207e-01, -2.5883e-01, -9.7352e-01,\n","         -1.6731e+00,  3.2599e-01,  5.3710e-01, -4.3415e-01,  3.8942e-01,\n","          9.6703e-01,  2.2010e-01,  8.0210e-01],\n","        [-5.8247e-01, -9.8549e-01,  5.4955e-01,  7.7073e-02,  2.8016e-01,\n","          3.7973e-01, -7.8032e-01,  7.3240e-01, -2.6235e-01, -4.1559e-01,\n","         -9.3970e-02,  5.1686e-01, -3.6707e-01,  4.1023e-01,  1.1295e-01,\n","          3.1050e-01, -2.2208e-01,  6.7644e-01,  1.3193e-01, -8.4302e-01,\n","         -1.8842e+00,  2.9232e-01,  5.3926e-01, -5.1763e-01,  7.1359e-02,\n","          9.2338e-01,  2.0699e-01,  4.3505e-01],\n","        [-6.6945e-01, -4.9170e-01,  4.8632e-02,  1.2994e-01,  8.4546e-02,\n","          4.5544e-01, -8.3077e-01,  7.1248e-01, -4.9744e-01, -4.6783e-01,\n","         -1.7807e-01,  7.2318e-01, -4.9033e-01,  3.3599e-01,  4.8123e-02,\n","          9.1306e-03, -9.2782e-02,  3.3780e-01,  7.8897e-02, -6.0018e-01,\n","         -1.3224e+00,  1.6101e-01,  3.9140e-01, -3.2646e-01, -8.8366e-02,\n","          7.4803e-01,  1.2524e-01,  3.2677e-01],\n","        [-9.9702e-01, -6.0108e-01,  2.3369e-01, -1.7452e-01,  3.6138e-01,\n","          4.1092e-01, -8.3131e-01,  7.8865e-01, -5.8675e-01, -4.2061e-01,\n","          2.4082e-02,  5.4555e-01, -2.9306e-01,  4.5836e-01,  1.2308e-02,\n","          3.1518e-01, -1.4760e-02,  8.7601e-01, -8.1332e-03, -9.8363e-01,\n","         -1.6860e+00,  1.0924e-01,  2.7717e-01, -7.0132e-02,  2.0212e-01,\n","          9.5868e-01, -1.1173e-01,  2.8049e-01],\n","        [-4.3688e-01, -7.2985e-01,  1.5864e-01, -1.1018e-01,  3.3215e-01,\n","          6.0231e-01, -7.3024e-01,  8.0924e-01, -4.8972e-01, -4.3913e-01,\n","          2.2627e-01,  4.4726e-01, -3.3964e-01,  2.8249e-01, -4.9497e-02,\n","          1.5467e-01,  1.8795e-02,  5.2151e-01, -1.0005e-01, -7.3936e-01,\n","         -1.6915e+00,  8.4347e-02,  4.0349e-01,  1.3113e-01,  3.8968e-01,\n","          9.8687e-01,  2.7667e-01,  1.8507e-01],\n","        [-6.7042e-01, -8.1715e-01,  2.7584e-01, -3.5390e-01,  3.0272e-01,\n","          6.1361e-01, -7.5165e-01,  7.9240e-01, -2.9405e-01, -6.5673e-01,\n","         -1.3217e-01,  6.0642e-01, -3.5705e-01,  5.6144e-01,  7.8461e-02,\n","          1.4718e-01, -5.8224e-02,  6.5860e-01, -7.9110e-02, -5.6670e-01,\n","         -1.3913e+00,  1.8601e-01,  4.0613e-01, -3.2651e-01,  2.7226e-01,\n","          7.3892e-01,  9.1307e-02,  4.3089e-01]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   1% 36/2714 [00:13<17:07,  2.61it/s]\u001b[Aoutputs:\n","(tensor([[[ 2.2589e-01,  4.5053e-01, -3.2232e-01,  ..., -3.5205e-01,\n","           1.1934e-01,  1.1259e-01],\n","         [ 8.4161e-01, -5.8937e-01,  2.9112e-01,  ...,  1.9525e-01,\n","          -1.3075e-01,  2.8746e-01],\n","         [ 3.4755e-01,  7.8725e-01, -4.0817e-02,  ...,  5.9796e-01,\n","           2.3428e-01,  3.0896e-01],\n","         ...,\n","         [-1.8151e-01,  4.5798e-01, -7.3347e-02,  ..., -1.3231e-01,\n","          -4.8256e-02,  7.5399e-02],\n","         [-3.2143e-01,  2.6300e-01,  4.0365e-02,  ..., -2.8842e-01,\n","          -1.3436e-01,  1.6893e-01],\n","         [-1.7245e-01,  3.2815e-01,  4.4674e-02,  ..., -1.8668e-01,\n","          -8.4558e-02,  6.0299e-02]],\n","\n","        [[ 2.3365e-01,  2.2796e-01, -3.5969e-01,  ..., -8.0929e-02,\n","          -3.2429e-02,  3.1600e-02],\n","         [ 3.7923e-01, -2.6642e-01,  2.7965e-01,  ...,  2.1702e-01,\n","          -2.3938e-01,  2.0657e-01],\n","         [-1.9806e-01,  2.4742e-01, -6.7952e-01,  ...,  7.2353e-01,\n","          -6.4281e-01,  9.4719e-02],\n","         ...,\n","         [-1.8007e-01,  2.4305e-01, -1.3108e-01,  ...,  2.2070e-03,\n","          -1.2886e-01,  1.2662e-02],\n","         [ 3.2507e-02,  1.8572e-01, -1.7642e-01,  ..., -1.3914e-01,\n","           1.3780e-02,  6.9074e-02],\n","         [-2.5210e-01,  6.6482e-02,  1.1772e-02,  ..., -9.3520e-02,\n","           3.3082e-03,  1.8707e-02]],\n","\n","        [[ 6.1832e-01,  1.7046e-01, -1.0954e-01,  ..., -3.0113e-01,\n","          -5.4671e-02, -3.6278e-02],\n","         [ 4.3514e-01, -1.6985e-01,  2.0609e-01,  ..., -1.5866e-01,\n","          -9.7943e-02,  3.9396e-01],\n","         [ 2.3481e-01,  5.4654e-01, -4.0315e-01,  ..., -1.2678e-01,\n","          -1.6599e-01,  2.9399e-01],\n","         ...,\n","         [-2.7833e-02, -7.3928e-02,  2.2269e-02,  ..., -2.8683e-01,\n","          -7.9080e-02, -6.4725e-02],\n","         [ 1.2017e-01,  1.1286e-01, -3.4101e-02,  ..., -1.3303e-01,\n","          -2.0443e-01,  4.0568e-02],\n","         [ 1.7610e-01,  8.5807e-02, -3.5883e-02,  ..., -2.4533e-01,\n","           4.4695e-02,  2.1608e-01]],\n","\n","        ...,\n","\n","        [[ 5.3001e-01,  5.0530e-01,  2.9955e-01,  ..., -2.1828e-01,\n","           2.2588e-01, -1.7862e-01],\n","         [ 3.1854e-02, -4.1537e-01,  7.4021e-01,  ..., -3.7678e-01,\n","           4.4973e-01,  2.8766e-02],\n","         [ 4.0099e-01,  3.0974e-01,  6.8986e-01,  ...,  6.3755e-02,\n","          -5.1311e-01, -6.7500e-01],\n","         ...,\n","         [-3.6873e-02,  1.0346e-02,  4.6627e-01,  ...,  1.4170e-01,\n","           5.6724e-01,  2.8102e-01],\n","         [-1.2991e-01,  5.3291e-02,  1.0454e-01,  ...,  1.5693e-01,\n","           3.5350e-01, -1.7442e-02],\n","         [-2.2162e-01,  2.2474e-01,  3.8237e-01,  ...,  6.5021e-02,\n","          -1.6623e-01,  4.9026e-02]],\n","\n","        [[ 5.4802e-01,  5.7007e-02, -1.1859e-01,  ..., -3.2445e-01,\n","          -1.1619e-01, -8.0550e-04],\n","         [-4.5943e-02, -3.5930e-01,  1.7746e-01,  ..., -7.4883e-02,\n","          -3.3588e-01,  5.8170e-01],\n","         [ 2.9090e-02,  8.7819e-01, -4.9376e-01,  ..., -3.2046e-01,\n","          -2.6892e-01,  1.7322e-01],\n","         ...,\n","         [ 1.0351e-01,  1.1861e-01, -1.7526e-01,  ..., -3.5312e-02,\n","          -1.4695e-01, -1.9819e-01],\n","         [-4.0655e-03, -1.4276e-02, -1.3504e-01,  ..., -1.0217e-01,\n","          -1.4308e-01, -2.3481e-02],\n","         [ 1.9431e-01,  4.4349e-02, -2.3502e-01,  ...,  6.7831e-02,\n","          -4.6694e-01,  1.3736e-01]],\n","\n","        [[ 1.6064e-01,  1.6249e-01, -2.5140e-01,  ..., -1.2899e-01,\n","           3.0583e-02, -5.4001e-03],\n","         [ 5.2130e-01, -4.7443e-01,  3.2678e-01,  ..., -3.5952e-01,\n","           6.1398e-01,  5.2328e-02],\n","         [-1.5989e-01, -1.6764e-01,  2.0024e-01,  ...,  4.1498e-01,\n","           2.0459e-02, -1.5663e-02],\n","         ...,\n","         [ 1.4730e-01,  1.5019e-01, -1.6073e-01,  ..., -1.8560e-01,\n","          -1.9967e-01, -2.8491e-01],\n","         [-1.8574e-01, -2.9932e-01, -4.6606e-01,  ..., -3.9998e-01,\n","           4.7975e-02,  1.8245e-01],\n","         [-2.1355e-01,  3.1291e-02, -9.5497e-02,  ...,  8.9138e-02,\n","           9.8863e-02, -1.0372e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward>), tensor([[-0.6275,  0.3567,  0.9998,  ...,  1.0000, -0.8336,  0.9900],\n","        [-0.6345,  0.3807,  0.9996,  ...,  0.9999, -0.7998,  0.9875],\n","        [-0.4574,  0.5302,  1.0000,  ...,  1.0000, -0.8902,  0.9981],\n","        ...,\n","        [-0.6641,  0.3896,  0.9999,  ...,  1.0000, -0.8360,  0.9973],\n","        [-0.5926,  0.4014,  0.9997,  ...,  0.9999, -0.9136,  0.9945],\n","        [-0.5578,  0.4702,  0.9997,  ...,  0.9999, -0.6635,  0.9833]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.6275,  0.3567,  0.9998,  ...,  1.0000, -0.8336,  0.9900],\n","        [-0.6345,  0.3807,  0.9996,  ...,  0.9999, -0.7998,  0.9875],\n","        [-0.4574,  0.5302,  1.0000,  ...,  1.0000, -0.8902,  0.9981],\n","        ...,\n","        [-0.6641,  0.3896,  0.9999,  ...,  1.0000, -0.8360,  0.9973],\n","        [-0.5926,  0.4014,  0.9997,  ...,  0.9999, -0.9136,  0.9945],\n","        [-0.5578,  0.4702,  0.9997,  ...,  0.9999, -0.6635,  0.9833]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-0.9103, -0.6876,  0.3463, -0.3927,  0.4111,  0.4295, -0.9242,  0.5217,\n","         -0.2449, -0.4231, -0.1639,  0.7396, -0.1348,  0.3650, -0.2142,  0.1919,\n","         -0.1664,  0.8645,  0.0460, -0.6667, -1.2021,  0.4259,  0.3979,  0.0082,\n","          0.1771,  0.9024,  0.3335,  0.3409],\n","        [-0.6276, -0.6504,  0.2523,  0.1396,  0.3943,  0.3522, -1.0505,  0.5036,\n","         -0.3737, -0.7537, -0.0572,  0.6122, -0.3110,  0.5450,  0.1048,  0.3284,\n","         -0.1920,  1.0324, -0.0270, -0.7770, -1.4706,  0.2864, -0.1152, -0.1181,\n","          0.3912,  0.8364,  0.1157,  0.4225],\n","        [-0.3710, -0.7097,  0.0165, -0.2464,  0.6095,  0.5160, -0.9700,  0.8368,\n","         -0.4996, -0.4452,  0.0340,  0.7733, -0.2707,  0.5508,  0.0506,  0.1979,\n","         -0.3316,  1.0243,  0.0312, -0.9884, -1.4680,  0.4535,  0.5928, -0.7325,\n","          0.2511,  1.1942,  0.4236,  0.3544],\n","        [-0.5733, -0.8721,  0.2920, -0.0922,  0.1790,  0.6111, -1.1762,  0.7969,\n","         -0.4744, -0.5231,  0.1545,  1.0176, -0.1147,  0.4990,  0.0492, -0.0290,\n","         -0.2545,  0.5990, -0.1712, -0.6711, -1.4146,  0.2544,  0.3048, -0.3223,\n","         -0.2208,  0.6974,  0.4185,  0.3885],\n","        [-0.9282, -0.7484,  0.0242, -0.1304,  0.1367,  0.2309, -0.9974,  0.6618,\n","         -0.2067, -0.3125, -0.2080,  0.6754, -0.3826, -0.0064,  0.1144,  0.3565,\n","         -0.2119,  0.7145,  0.0530, -0.9488, -1.2852,  0.1591,  0.5428, -0.2816,\n","          0.1700,  0.8107,  0.2280,  0.3614],\n","        [-0.5723, -0.5941,  0.2248, -0.0755,  0.3848,  0.6824, -0.8345,  0.6288,\n","         -0.0894, -0.6144,  0.2470,  0.8564, -0.2920,  0.3244,  0.1869,  0.1072,\n","         -0.2248,  0.9300,  0.0960, -0.7225, -1.3480,  0.0844,  0.1832, -0.1180,\n","          0.3950,  0.7998,  0.1093,  0.3687],\n","        [-0.6155, -0.4858,  0.4766, -0.5235,  0.5750,  0.2879, -0.9770,  0.7919,\n","         -0.2531, -0.5031,  0.1276,  0.6667, -0.2492,  0.6605,  0.2282,  0.2354,\n","          0.0090,  1.1445,  0.2739, -0.8796, -1.5652,  0.5169,  0.1715, -0.4449,\n","          0.1398,  0.8553,  0.0789,  0.4903],\n","        [-0.9785, -0.4652,  0.2549, -0.0615,  0.4598,  0.5524, -1.1951,  0.5453,\n","         -0.1615, -0.6103, -0.1788,  0.7345, -0.2709,  0.5715, -0.1381,  0.1421,\n","         -0.1392,  0.8579, -0.1039, -0.8101, -1.4495,  0.3646,  0.4034,  0.0803,\n","          0.3427,  0.5686,  0.3965,  0.7308],\n","        [-0.9816, -0.5378,  0.1713,  0.0111,  0.5123,  0.3685, -1.1277,  0.5309,\n","         -0.3836, -0.6491, -0.2256,  0.3170, -0.0940,  0.5564,  0.2452,  0.1194,\n","         -0.0318,  0.9124,  0.1779, -0.7546, -1.6705,  0.2788,  0.3015, -0.2492,\n","          0.1534,  0.8665,  0.3399,  0.5239],\n","        [-0.8302, -0.6952,  0.3917, -0.2585,  0.4699,  0.5176, -0.9397,  0.7287,\n","         -0.4702, -0.4422, -0.0131,  0.7167, -0.3909,  0.4380, -0.0924,  0.2998,\n","         -0.0801,  0.7264, -0.0763, -0.9761, -1.5835,  0.0896,  0.3944,  0.0498,\n","          0.0047,  0.7119,  0.0471,  0.5146],\n","        [-0.5846, -0.6912,  0.4130, -0.2601,  0.4231,  0.4601, -0.8821,  0.6416,\n","         -0.1224, -0.6813, -0.1709,  0.6379, -0.4351,  0.3885, -0.0797,  0.1055,\n","          0.1626,  0.8655,  0.4235, -0.8869, -1.5268, -0.0069,  0.0613, -0.4416,\n","          0.1031,  0.6564,  0.2825,  0.0494],\n","        [-0.7939, -0.7539,  0.2475, -0.5479,  0.2683,  0.5114, -0.9647,  0.8516,\n","         -0.3032, -0.7366,  0.0653,  0.7931,  0.0195,  0.4391, -0.2113,  0.0035,\n","         -0.1514,  1.0698, -0.1470, -0.7682, -1.5904,  0.3193,  0.3136, -0.2141,\n","          0.5188,  0.9749,  0.3259,  0.3622],\n","        [-0.6763, -0.4900, -0.0377, -0.2858,  0.3700,  0.4740, -0.7782,  0.8098,\n","         -0.5629, -0.9836,  0.0990,  0.9492,  0.1005,  0.2738,  0.1871,  0.0276,\n","          0.0609,  0.7545, -0.1941, -1.0420, -1.5699,  0.3689,  0.2381, -0.0874,\n","         -0.0346,  0.6996,  0.3721,  0.7016],\n","        [-0.8129, -0.5472,  0.1930, -0.1592,  0.8032,  0.4853, -0.9234,  0.8580,\n","         -0.4736, -0.5508, -0.2958,  0.6650,  0.0547,  0.4208, -0.0698,  0.2278,\n","         -0.0478,  1.0785, -0.1518, -0.9667, -1.3734,  0.5788,  0.1949, -0.1663,\n","         -0.0102,  0.8841,  0.4292,  0.4331],\n","        [-1.1496, -0.5523, -0.0020, -0.2873,  0.5725,  0.3479, -1.0136,  0.9514,\n","         -0.2919, -0.7321, -0.1861,  0.3450, -0.0235,  0.4123, -0.0267,  0.7620,\n","         -0.1588,  1.0137, -0.2609, -0.8235, -1.3623,  0.1949,  0.4506, -0.1802,\n","          0.2753,  0.9028,  0.0887,  0.7334],\n","        [-1.0214, -0.5621, -0.0110, -0.2118,  0.5361,  0.7771, -1.2330,  0.7870,\n","         -0.1999, -0.3905, -0.2524,  0.6267, -0.0961,  0.2038,  0.3191,  0.2508,\n","         -0.1634,  1.0930,  0.1010, -0.6405, -1.5220,  0.1106,  0.1703, -0.1769,\n","          0.2773,  0.8777, -0.0973,  0.3903]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   1% 37/2714 [00:14<17:08,  2.60it/s]\u001b[Aoutputs:\n","(tensor([[[ 0.4318,  0.4666, -0.0009,  ..., -0.3256,  0.2119, -0.0864],\n","         [ 0.4073, -0.3967,  0.5385,  ..., -0.4667,  0.3535,  0.0247],\n","         [-0.1114,  0.1399,  0.3314,  ...,  0.0516,  0.1068,  0.2923],\n","         ...,\n","         [-0.1070,  0.7366,  0.2089,  ...,  0.0099, -0.2593, -0.3469],\n","         [-0.2948,  0.6339,  0.0906,  ..., -0.0741, -0.0101, -0.1984],\n","         [ 0.0242,  0.2885,  0.1274,  ..., -0.0105,  0.4038, -0.1469]],\n","\n","        [[ 0.5955, -0.1896, -0.0476,  ..., -0.1612,  0.2132,  0.2048],\n","         [ 0.5829, -0.0720,  0.4537,  ...,  0.0336, -0.0388,  0.2300],\n","         [ 0.1054,  0.1719, -0.0356,  ...,  0.5404, -0.3801,  0.4290],\n","         ...,\n","         [-0.0425,  0.4003,  0.1978,  ...,  0.3409, -0.3973, -0.0234],\n","         [ 0.1359,  0.1056,  0.1571,  ...,  0.0735,  0.4395,  0.0828],\n","         [ 0.1160,  0.3837,  0.0563,  ...,  0.4086, -0.0874,  0.1011]],\n","\n","        [[ 0.2604,  0.1643,  0.0581,  ..., -0.2513,  0.3193,  0.1795],\n","         [ 0.1917, -0.0839,  0.3476,  ..., -0.1883,  0.1711,  0.0706],\n","         [ 0.2939,  0.6634, -0.3133,  ...,  0.0753, -0.1959,  0.5851],\n","         ...,\n","         [-0.4241,  0.6750,  0.0784,  ...,  0.3617, -0.4191,  0.5376],\n","         [ 0.2321,  0.2935, -0.0191,  ..., -0.0289,  0.1086, -0.2248],\n","         [ 0.2391,  0.4216, -0.2390,  ...,  0.3865,  0.2406, -0.0868]],\n","\n","        ...,\n","\n","        [[ 0.4475,  0.1100, -0.1304,  ..., -0.1686,  0.1162,  0.0679],\n","         [ 0.1719, -0.3406,  0.2538,  ...,  0.0879, -0.0296,  0.3394],\n","         [ 0.2826, -0.2885,  0.3417,  ...,  0.3783,  0.0519,  0.2310],\n","         ...,\n","         [ 0.2936, -0.0069,  0.0898,  ..., -0.0929,  0.4812,  0.0879],\n","         [ 0.3455, -0.0647,  0.3143,  ..., -0.2451,  0.5642,  0.0544],\n","         [ 0.0777,  0.0925, -0.0267,  ..., -0.1789,  0.2004, -0.1092]],\n","\n","        [[ 0.5857,  0.2889, -0.2238,  ...,  0.1821,  0.3546,  0.0413],\n","         [ 0.7177, -0.2942,  0.6242,  ...,  0.1144, -0.1259,  0.3645],\n","         [ 0.6041, -0.2112,  0.1124,  ...,  0.4592, -0.8833, -0.1693],\n","         ...,\n","         [-0.0768,  0.0738, -0.1610,  ..., -0.0026,  0.1523,  0.3221],\n","         [ 0.2633,  0.1719, -0.3058,  ...,  0.1104,  0.3925,  0.2916],\n","         [ 0.1080,  0.1251, -0.1571,  ...,  0.0923,  0.5474,  0.3390]],\n","\n","        [[ 0.3995,  0.5475,  0.0895,  ..., -0.1946,  0.1965, -0.2993],\n","         [-0.0817,  0.1291, -0.1679,  ...,  0.0491,  0.0774, -0.0713],\n","         [ 0.1328,  0.0841, -0.0939,  ...,  0.0505, -0.0074, -0.1516],\n","         ...,\n","         [-0.1155,  0.4169,  0.1191,  ...,  0.0123,  0.2660, -0.3053],\n","         [-0.3957,  0.2499,  0.0838,  ..., -0.0049,  0.2436, -0.4553],\n","         [-0.1414,  0.2289,  0.0850,  ..., -0.0025,  0.1473, -0.1963]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward>), tensor([[-0.6646,  0.4539,  0.9999,  ...,  1.0000, -0.8195,  0.9957],\n","        [-0.8135,  0.4011,  0.9999,  ...,  1.0000, -0.8051,  0.9898],\n","        [-0.6391,  0.4341,  0.9999,  ...,  1.0000, -0.2101,  0.9964],\n","        ...,\n","        [-0.5945,  0.3400,  0.9984,  ...,  0.9995, -0.8324,  0.9416],\n","        [-0.7445,  0.4644,  0.9999,  ...,  1.0000, -0.4905,  0.9902],\n","        [-0.6418,  0.4346,  0.9999,  ...,  0.9999, -0.7229,  0.9894]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.6646,  0.4539,  0.9999,  ...,  1.0000, -0.8195,  0.9957],\n","        [-0.8135,  0.4011,  0.9999,  ...,  1.0000, -0.8051,  0.9898],\n","        [-0.6391,  0.4341,  0.9999,  ...,  1.0000, -0.2101,  0.9964],\n","        ...,\n","        [-0.5945,  0.3400,  0.9984,  ...,  0.9995, -0.8324,  0.9416],\n","        [-0.7445,  0.4644,  0.9999,  ...,  1.0000, -0.4905,  0.9902],\n","        [-0.6418,  0.4346,  0.9999,  ...,  0.9999, -0.7229,  0.9894]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-0.7523, -0.5307, -0.0267, -0.2049,  0.2929,  0.3615, -1.0411,  0.8689,\n","         -0.2397, -0.3869, -0.0977,  0.6524, -0.2457,  0.4539, -0.1162,  0.1927,\n","         -0.0237,  0.7319, -0.1882, -1.0109, -1.3683,  0.3307,  0.1870, -0.1933,\n","         -0.1257,  0.5713,  0.1360,  0.7469],\n","        [-0.7489, -0.7028,  0.0573, -0.1363,  0.5361,  0.5900, -0.7780,  0.7784,\n","         -0.2242, -0.6886, -0.1347,  0.7207, -0.2609,  0.1839,  0.0627,  0.0390,\n","         -0.1570,  0.8048, -0.0503, -0.6291, -1.5435,  0.2561,  0.4244, -0.2918,\n","          0.1101,  0.7430,  0.2007,  0.4967],\n","        [-0.8988, -0.8265,  0.4668, -0.0566,  0.3448,  0.2670, -0.7857,  0.8048,\n","         -0.2572, -0.6247,  0.3122,  0.6931, -0.6095,  0.4162,  0.2797, -0.0919,\n","          0.0224,  0.4890,  0.3418, -0.7515, -1.5303,  0.2237,  0.4082, -0.1948,\n","          0.1960,  0.9724,  0.2172,  0.4162],\n","        [-0.8507, -0.7084,  0.1572, -0.2800,  0.2157,  0.2112, -1.1633,  0.6756,\n","         -0.4398, -0.2218, -0.1672,  0.6534, -0.3879,  0.3398,  0.1295, -0.0030,\n","         -0.2921,  0.6478, -0.0198, -0.7623, -1.4679,  0.1068,  0.5304, -0.1704,\n","          0.3565,  1.0672,  0.2556,  0.3182],\n","        [-0.8711, -0.7816,  0.1034, -0.2841,  0.3863,  0.7091, -0.9981,  0.7369,\n","         -0.1521, -0.5134,  0.1928,  0.8162, -0.3105,  0.5039,  0.1128, -0.0872,\n","         -0.1387,  0.7906, -0.2067, -0.8546, -1.4040,  0.1626,  0.4715, -0.1257,\n","          0.2163,  0.9364,  0.2480,  0.4143],\n","        [-0.8699, -0.6234,  0.0576, -0.4016,  0.4276,  0.7004, -0.7901,  0.7145,\n","         -0.3949, -0.4613,  0.0073,  0.8720,  0.0546,  0.4799,  0.1308,  0.3341,\n","         -0.1397,  1.0827, -0.2173, -0.6635, -1.6675,  0.3119,  0.1921, -0.4059,\n","          0.3136,  1.0030,  0.2154,  0.4678],\n","        [-1.0013, -0.8402, -0.0148, -0.4097,  0.4825,  0.4921, -1.1756,  0.5991,\n","         -0.4519, -0.5521, -0.1040,  0.9294,  0.0983,  0.5996, -0.1156,  0.3569,\n","         -0.2932,  0.6577,  0.1332, -0.7569, -1.2725,  0.5206,  0.2463,  0.0771,\n","          0.1984,  0.9249, -0.0481,  0.5663],\n","        [-0.6772, -0.9300,  0.4579, -0.5281,  0.3040,  0.5108, -0.7025,  0.7564,\n","         -0.1618, -0.7399,  0.2025,  0.3746, -0.0130,  0.3436,  0.1694,  0.1512,\n","         -0.2274,  0.7776,  0.0751, -0.5714, -1.5187,  0.2670,  0.2557, -0.2627,\n","          0.3755,  0.7773,  0.1304,  0.3510],\n","        [-1.0045, -0.5269,  0.0350, -0.2110,  0.1924,  0.3091, -1.1645,  0.6598,\n","         -0.5759, -0.7110, -0.3250,  0.8079, -0.2076,  0.5940, -0.0273,  0.1632,\n","         -0.2639,  0.8185, -0.0369, -0.8089, -1.3850,  0.2630,  0.1058, -0.1675,\n","         -0.0144,  0.9192,  0.1288,  0.4201],\n","        [-0.6229, -0.8200,  0.6125, -0.0857, -0.0315,  0.5653, -0.8113,  0.6691,\n","         -0.3709, -0.5404,  0.1512,  0.4316, -0.2334,  0.2941,  0.0351,  0.1863,\n","         -0.2002,  0.6897,  0.1424, -0.6855, -1.4539,  0.1715,  0.2828, -0.6289,\n","          0.1195,  0.7838,  0.1401,  0.2600],\n","        [-0.3940, -0.5597,  0.3964, -0.0962,  0.2522,  0.5437, -1.0753,  0.7345,\n","         -0.3388, -0.7324,  0.2053,  0.8046, -0.1325,  0.2753,  0.3247, -0.1680,\n","         -0.3995,  1.0278, -0.0386, -0.7055, -1.5020,  0.1793,  0.2877, -0.3642,\n","          0.1962,  0.9076,  0.3277,  0.3591],\n","        [-0.6648, -0.6356,  0.4526,  0.0108,  0.3537,  0.6051, -1.0585,  0.3108,\n","         -0.0581, -0.5308, -0.0089,  0.5417, -0.2017,  0.6079,  0.0455,  0.0959,\n","         -0.1609,  1.2495,  0.0773, -0.5994, -1.3104, -0.0564,  0.4187,  0.0482,\n","          0.1540,  0.7348,  0.2700,  0.2656],\n","        [-0.8176, -0.6415,  0.1767, -0.2727,  0.0232,  0.4501, -0.8872,  0.6098,\n","         -0.3845, -0.5957,  0.0798,  0.8707, -0.0328,  0.4231,  0.0594,  0.2460,\n","          0.0327,  0.7812, -0.0101, -0.9127, -1.5700, -0.0444,  0.3368, -0.1153,\n","          0.1378,  0.7378,  0.2438,  0.3997],\n","        [-0.9211, -0.8344,  0.2338, -0.5687,  0.3336,  0.0594, -1.0128,  0.3575,\n","         -0.3767, -0.4086, -0.1972,  0.7982, -0.3311,  0.7495, -0.1473,  0.3280,\n","         -0.2091,  0.7363, -0.0249, -0.7286, -1.6110,  0.4864,  0.1531, -0.2446,\n","          0.0901,  0.9089,  0.3897,  0.3755],\n","        [-0.8556, -0.7014,  0.3246, -0.1305,  0.3395,  0.1552, -1.1077,  0.6104,\n","         -0.1760, -0.5379, -0.0538,  0.6327, -0.1228,  0.2636, -0.2111,  0.1423,\n","         -0.0856,  0.7046, -0.1066, -0.7498, -1.4968,  0.2226,  0.4579, -0.1308,\n","          0.1145,  0.9273,  0.3172,  0.3700],\n","        [-0.5945, -0.8342,  0.2606, -0.3607,  0.6489,  0.3348, -0.9594,  0.6041,\n","         -0.2729, -0.6676, -0.0821,  0.9009, -0.2886,  0.4594, -0.1626,  0.1957,\n","         -0.0305,  0.7134,  0.0894, -0.9264, -1.5477,  0.2572,  0.2338, -0.0570,\n","          0.3547,  0.7252,  0.1509,  0.2992]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   1% 38/2714 [00:14<16:58,  2.63it/s]\u001b[Aoutputs:\n","(tensor([[[ 2.8828e-01, -1.2809e-01,  4.7090e-03,  ..., -4.3001e-02,\n","           2.3534e-01,  2.0441e-01],\n","         [ 1.2335e-01, -1.6453e-01, -2.0296e-02,  ...,  3.8851e-01,\n","          -1.4392e-01, -9.8501e-02],\n","         [-7.8744e-02, -1.0960e-01, -4.7590e-01,  ...,  3.8142e-01,\n","           3.5200e-01, -8.3184e-02],\n","         ...,\n","         [-5.2927e-03,  7.2154e-02, -7.7043e-02,  ...,  3.2692e-01,\n","           3.1210e-02, -6.7990e-03],\n","         [-1.2329e-01,  3.2249e-02, -1.2313e-01,  ...,  4.2143e-01,\n","           6.4165e-02,  2.5824e-01],\n","         [-1.3981e-01, -7.1905e-02, -4.0509e-01,  ...,  4.7062e-01,\n","          -5.9750e-02, -7.7055e-02]],\n","\n","        [[ 5.1258e-01,  3.7563e-01, -2.3921e-02,  ..., -7.9129e-03,\n","           6.0796e-01,  1.0012e-01],\n","         [-2.4180e-01,  4.2428e-01,  2.2668e-01,  ...,  5.0459e-01,\n","           4.0086e-01,  4.3825e-02],\n","         [-4.6192e-01,  5.3759e-02, -1.1527e-01,  ...,  1.2643e+00,\n","           2.6431e-01,  3.5220e-01],\n","         ...,\n","         [ 1.9281e-01,  3.1227e-01, -3.5482e-02,  ...,  5.1419e-01,\n","           5.9223e-01,  1.3086e-01],\n","         [ 1.7378e-01,  1.5546e-01, -6.1619e-02,  ...,  5.7990e-01,\n","           6.0443e-01,  1.3980e-01],\n","         [ 2.7237e-01,  4.3891e-01, -5.3960e-02,  ...,  5.2377e-01,\n","           4.9737e-01,  1.7040e-01]],\n","\n","        [[ 5.2634e-01, -4.4903e-02, -7.8162e-02,  ..., -1.6647e-01,\n","           3.9658e-01,  3.1200e-02],\n","         [ 7.6302e-01, -4.5273e-01,  9.0254e-01,  ...,  1.8165e-01,\n","           2.0203e-02,  1.4599e-01],\n","         [ 3.7377e-01,  3.1418e-01,  1.2590e-02,  ..., -9.3463e-02,\n","           6.2212e-01, -3.9392e-01],\n","         ...,\n","         [-2.5155e-02, -2.4786e-02,  1.2884e-01,  ..., -1.0164e-01,\n","           9.6968e-02, -9.7108e-03],\n","         [ 1.8842e-01,  3.9235e-02,  1.3032e-01,  ...,  3.3798e-02,\n","           4.3658e-01, -1.9864e-02],\n","         [ 6.6342e-01,  2.4493e-01, -1.5119e-01,  ..., -1.5641e-01,\n","           3.6249e-01, -5.3199e-01]],\n","\n","        ...,\n","\n","        [[ 5.6107e-01,  1.2317e-01, -2.3908e-01,  ..., -3.0804e-02,\n","           1.1692e-01,  1.6575e-02],\n","         [ 5.7493e-01, -3.5591e-01,  8.3546e-02,  ...,  1.2535e-01,\n","           3.9531e-01, -1.0139e-01],\n","         [ 6.5653e-01, -4.7925e-01, -2.5949e-01,  ...,  5.0773e-01,\n","           4.4174e-01,  3.8768e-01],\n","         ...,\n","         [ 4.7139e-02,  2.8158e-01,  1.4793e-01,  ...,  2.6421e-01,\n","          -1.9112e-01, -1.8909e-01],\n","         [ 7.4382e-02,  1.9939e-01,  9.7950e-02,  ...,  1.3375e-01,\n","           2.4762e-01,  6.7557e-02],\n","         [-7.3829e-02, -2.6030e-01, -6.6391e-02,  ...,  6.9026e-01,\n","           2.0191e-01,  2.8908e-01]],\n","\n","        [[ 5.7536e-01,  2.9878e-01,  1.6152e-01,  ..., -2.0190e-01,\n","           2.8947e-01,  2.3744e-01],\n","         [-7.2439e-02, -2.9668e-02,  4.5451e-02,  ..., -2.9003e-01,\n","           7.7099e-02,  2.2989e-01],\n","         [ 2.1529e-01,  5.0591e-01,  4.8876e-02,  ...,  1.0579e-01,\n","           2.8054e-01, -1.2901e-02],\n","         ...,\n","         [ 8.3035e-02,  1.0799e-01, -1.8864e-01,  ...,  2.4518e-02,\n","           4.0184e-01, -1.4763e-01],\n","         [ 1.5916e-01,  6.3358e-02, -1.6893e-01,  ...,  1.9744e-01,\n","           3.7600e-01,  1.2531e-02],\n","         [ 5.4322e-02,  1.2409e-01, -1.2812e-01,  ..., -2.8257e-01,\n","           1.0679e-01, -1.8562e-01]],\n","\n","        [[ 1.2387e-01, -6.4526e-04, -2.1083e-01,  ..., -6.4809e-02,\n","           1.8028e-01,  1.7448e-01],\n","         [ 4.5712e-01, -3.5279e-01,  2.2434e-01,  ...,  3.3770e-01,\n","           4.9766e-02,  1.3508e-01],\n","         [-6.0635e-01,  1.9943e-01, -4.4695e-02,  ...,  5.3296e-01,\n","          -2.6437e-01,  2.8591e-01],\n","         ...,\n","         [ 1.6610e-01, -1.2783e-01, -5.1277e-02,  ...,  2.2822e-01,\n","           1.2882e-01, -2.7564e-01],\n","         [ 7.2040e-03, -1.8335e-01, -2.2448e-01,  ...,  1.0340e-01,\n","           2.3596e-01,  5.8360e-03],\n","         [-2.1292e-01,  7.3273e-02, -3.0513e-01,  ...,  2.6284e-01,\n","           3.6703e-01,  1.9742e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward>), tensor([[-0.7007,  0.4855,  0.9999,  ...,  0.9999, -0.4329,  0.9818],\n","        [-0.8183,  0.6152,  1.0000,  ...,  1.0000, -0.5379,  0.9948],\n","        [-0.6779,  0.4931,  0.9999,  ...,  1.0000, -0.3907,  0.9895],\n","        ...,\n","        [-0.6646,  0.4803,  0.9997,  ...,  0.9999, -0.7342,  0.9857],\n","        [-0.7259,  0.5040,  1.0000,  ...,  1.0000, -0.6919,  0.9966],\n","        [-0.5911,  0.4554,  0.9995,  ...,  0.9999, -0.6835,  0.9801]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.7007,  0.4855,  0.9999,  ...,  0.9999, -0.4329,  0.9818],\n","        [-0.8183,  0.6152,  1.0000,  ...,  1.0000, -0.5379,  0.9948],\n","        [-0.6779,  0.4931,  0.9999,  ...,  1.0000, -0.3907,  0.9895],\n","        ...,\n","        [-0.6646,  0.4803,  0.9997,  ...,  0.9999, -0.7342,  0.9857],\n","        [-0.7259,  0.5040,  1.0000,  ...,  1.0000, -0.6919,  0.9966],\n","        [-0.5911,  0.4554,  0.9995,  ...,  0.9999, -0.6835,  0.9801]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-5.3997e-01, -5.1018e-01,  3.5724e-01,  2.2639e-01,  3.8414e-01,\n","          1.2508e-01, -8.4606e-01,  4.5383e-01, -3.4215e-01, -6.3002e-01,\n","          7.1022e-02,  6.9952e-01, -1.7451e-01,  4.7274e-01,  3.3116e-01,\n","         -1.5521e-02,  1.1051e-01,  5.8935e-01, -1.5602e-02, -8.0619e-01,\n","         -1.4944e+00, -8.3185e-02,  4.0426e-01, -7.5616e-01, -1.7988e-02,\n","          7.8738e-01,  7.2683e-02,  3.0098e-01],\n","        [-7.0636e-01, -6.1474e-01,  7.3018e-01, -2.4172e-01,  3.3903e-01,\n","          2.7448e-01, -8.2883e-01,  7.7812e-01, -5.2380e-01, -4.0235e-01,\n","          2.6621e-03,  4.3980e-01, -1.1753e-01,  2.0689e-01,  2.8636e-02,\n","          3.8651e-01,  6.5457e-02,  6.1033e-01,  1.5147e-01, -6.4257e-01,\n","         -1.6201e+00,  6.7496e-02,  4.0419e-01, -3.6109e-01,  1.6552e-01,\n","          6.2687e-01,  2.2203e-01,  2.2278e-01],\n","        [-7.7230e-01, -6.3128e-01,  4.2777e-01, -2.6011e-02,  4.1862e-01,\n","          5.0021e-01, -7.8000e-01,  6.0805e-01, -3.0796e-02, -5.8047e-01,\n","          4.5614e-02,  7.1537e-01, -3.2806e-01,  3.2179e-01, -2.6106e-01,\n","          1.2455e-01, -1.1350e-01,  5.3255e-01, -6.8841e-02, -6.5451e-01,\n","         -1.5323e+00,  8.5666e-03,  1.5108e-01, -1.0771e-01,  3.0559e-01,\n","          9.1334e-01,  3.0550e-01,  3.0603e-01],\n","        [-6.5176e-01, -7.6253e-01,  1.9616e-01,  1.2506e-01,  4.4003e-01,\n","          7.1198e-01, -9.9801e-01,  4.9137e-01, -3.0368e-01, -6.3121e-01,\n","         -2.9287e-01,  9.6685e-01, -4.2194e-01,  1.7163e-02,  9.5709e-02,\n","         -4.3122e-02,  1.5585e-01,  6.5519e-01,  8.7928e-02, -8.3132e-01,\n","         -1.7152e+00, -1.3430e-01,  3.1392e-01, -2.4517e-01, -1.1735e-02,\n","          4.8432e-01,  4.3226e-02,  3.7426e-01],\n","        [-6.4413e-01, -6.6067e-01,  5.5767e-01, -5.4893e-02,  9.1173e-02,\n","          6.4646e-01, -8.7891e-01,  4.7584e-01,  2.2335e-01, -4.1572e-01,\n","         -2.8440e-02,  7.5186e-01, -2.8114e-01,  4.3532e-02,  9.8945e-02,\n","          2.1967e-01,  8.8332e-02,  2.3711e-01, -4.3228e-02, -5.3295e-01,\n","         -1.5393e+00,  1.4872e-01,  3.8137e-01, -2.4741e-01,  7.3524e-02,\n","          6.6402e-01,  2.9742e-01,  2.9045e-01],\n","        [-8.9049e-01, -7.2485e-01,  3.7081e-01, -1.3889e-01,  2.2611e-01,\n","          3.6086e-01, -7.7228e-01,  7.4091e-01, -3.0199e-01, -3.6845e-01,\n","          5.7345e-02,  5.3006e-01, -1.9670e-01,  3.7130e-01,  6.0105e-02,\n","          3.7128e-01,  5.9194e-02,  8.1415e-01,  2.6385e-01, -7.1082e-01,\n","         -1.4651e+00,  2.7745e-01,  4.2381e-01, -5.0143e-01,  6.2499e-02,\n","          9.1430e-01,  2.0587e-01,  1.7120e-02],\n","        [-9.7709e-01, -5.2351e-01,  3.1694e-01,  5.7459e-02,  3.6195e-01,\n","          6.4296e-01, -1.0019e+00,  7.5659e-01, -8.6179e-02, -4.9263e-01,\n","          1.2370e-01,  8.7952e-01, -2.0325e-01,  3.9426e-01,  4.2338e-02,\n","          3.1763e-01, -3.0232e-01,  7.2560e-01, -2.3362e-01, -8.2020e-01,\n","         -1.3865e+00,  4.9969e-01,  4.3701e-01, -7.3849e-02,  4.0961e-02,\n","          6.2177e-01,  3.2341e-01,  4.4839e-01],\n","        [-5.0394e-01, -7.2738e-01,  2.9429e-01, -4.2627e-01,  3.3075e-01,\n","          8.5961e-01, -1.0938e+00,  6.2872e-01, -2.9718e-01, -4.6580e-01,\n","         -8.5596e-02,  7.7198e-01, -1.9754e-01,  6.7305e-02,  1.0333e-02,\n","          5.2550e-02,  7.0990e-02,  5.8570e-01, -2.6703e-03, -8.3218e-01,\n","         -1.4354e+00,  3.3811e-01,  5.0107e-01, -2.7606e-01,  1.2402e-01,\n","          8.6373e-01, -2.1257e-01, -9.2478e-04],\n","        [-7.3141e-01, -6.5531e-01,  5.2635e-01,  1.6314e-02,  2.1131e-01,\n","          3.8872e-01, -5.3615e-01,  6.1179e-01, -1.8505e-01, -7.4123e-01,\n","          2.1727e-01,  8.0134e-01, -2.0562e-01,  3.4599e-01,  5.3110e-02,\n","          2.2111e-01,  4.9109e-01,  7.2793e-01,  2.0974e-01, -7.5756e-01,\n","         -1.4144e+00, -1.0159e-01,  2.7314e-01, -9.2465e-02,  3.4945e-02,\n","          7.0600e-01, -2.0612e-01,  1.7710e-01],\n","        [-7.7221e-01, -8.3608e-01, -5.1423e-02, -3.0446e-01,  3.5307e-01,\n","          6.0512e-01, -1.0847e+00,  8.3118e-01, -1.9528e-01, -6.1023e-01,\n","         -1.2497e-01,  3.3228e-01, -3.8408e-02,  8.0061e-01,  1.6639e-02,\n","          3.2187e-01, -1.9604e-01,  9.2547e-01, -3.4129e-02, -8.6509e-01,\n","         -1.5095e+00,  1.4718e-01,  4.6288e-01, -5.0968e-02,  1.5593e-01,\n","          6.9540e-01,  3.8787e-02,  5.3245e-01],\n","        [-7.6894e-01, -4.9824e-01,  1.7213e-01, -3.4119e-01,  5.9906e-01,\n","          5.9836e-01, -1.3186e+00,  8.4911e-01, -3.5245e-01, -6.7790e-01,\n","          3.0054e-01,  4.7915e-01,  2.2340e-01,  5.7367e-01,  3.0776e-01,\n","          8.1229e-02, -3.1376e-01,  8.6682e-01,  2.7118e-01, -8.6458e-01,\n","         -1.4279e+00,  2.6570e-01,  2.7994e-01,  3.7743e-02,  2.5979e-01,\n","          1.0964e+00, -6.6415e-03,  6.7022e-01],\n","        [-7.0859e-01, -6.2773e-01, -6.0416e-02, -1.7730e-01,  5.0496e-01,\n","          6.6712e-01, -8.7294e-01,  9.7223e-01, -3.9030e-02, -4.9932e-01,\n","         -2.8238e-02,  5.3987e-01, -4.6806e-01,  6.1467e-01,  3.4033e-02,\n","          2.1405e-01, -3.9160e-02,  9.9914e-01,  2.9324e-02, -6.8030e-01,\n","         -1.5039e+00,  4.4693e-01,  3.4064e-01, -4.3695e-01,  2.8855e-01,\n","          8.0223e-01, -4.9760e-03,  4.4684e-01],\n","        [-4.9428e-01, -8.6380e-01,  1.4947e-01, -3.4699e-01,  2.1384e-01,\n","          7.0130e-01, -8.8117e-01,  7.9830e-01, -1.0105e-01, -5.9645e-01,\n","          3.4068e-03,  6.8695e-01, -4.8327e-01,  3.4806e-01, -1.0185e-01,\n","          2.9206e-01, -3.4591e-01,  8.4145e-01,  3.2758e-01, -5.1743e-01,\n","         -1.6196e+00,  4.4560e-03,  2.0095e-01, -2.4218e-01,  1.5587e-01,\n","          5.7456e-01,  5.5450e-02,  2.1950e-01],\n","        [-9.0622e-01, -5.6159e-01,  1.4463e-02, -2.7344e-01,  2.0924e-01,\n","          4.8117e-01, -1.0598e+00,  7.7078e-01, -3.5630e-01, -6.9043e-01,\n","         -1.3644e-01,  7.4384e-01, -1.7341e-01,  2.3575e-01, -4.5762e-02,\n","          3.6657e-01, -5.8466e-01,  8.4401e-01,  1.6788e-01, -9.6701e-01,\n","         -1.5021e+00,  2.0224e-01,  1.1693e-01, -8.6854e-02, -1.2954e-01,\n","          9.2427e-01,  2.4853e-02,  3.9511e-01],\n","        [-7.9042e-01, -5.3716e-01,  1.5350e-01, -5.3441e-01,  2.9846e-01,\n","          5.9186e-01, -8.2333e-01,  8.5437e-01, -1.5755e-01, -5.5966e-01,\n","          4.9711e-02,  5.8613e-01, -2.5419e-01,  5.4495e-01,  2.5130e-01,\n","          8.2445e-02,  2.0921e-01,  5.2250e-01,  2.6156e-02, -4.7652e-01,\n","         -1.3895e+00,  8.3883e-02,  9.0564e-02, -1.0767e-01,  1.0974e-01,\n","          8.1070e-01,  4.2575e-01,  4.2147e-01],\n","        [-8.4083e-01, -6.0916e-01,  2.5508e-01, -1.1152e-01,  1.2335e-01,\n","          3.3286e-01, -5.8977e-01,  6.0052e-01, -6.2539e-02, -3.6154e-01,\n","          7.6253e-02,  7.6792e-01, -2.6138e-01,  1.5253e-01,  2.0516e-01,\n","          2.0512e-01,  2.3945e-01,  5.7245e-01,  2.7626e-01, -5.8812e-01,\n","         -1.5861e+00, -3.1292e-02,  2.7948e-01, -6.2502e-02,  4.3803e-01,\n","          8.2068e-01, -8.4096e-02,  5.4387e-01]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   1% 39/2714 [00:15<17:11,  2.59it/s]\u001b[Aoutputs:\n","(tensor([[[ 3.1189e-01,  9.9445e-02,  1.1106e-01,  ..., -2.4730e-01,\n","           5.7490e-01,  8.0594e-02],\n","         [ 7.8125e-01, -3.6453e-01,  4.7070e-02,  ..., -2.7587e-02,\n","           6.5075e-02,  3.4059e-01],\n","         [ 5.7593e-01,  1.6582e-01, -1.4361e-01,  ..., -1.9832e-01,\n","          -9.7503e-02,  2.4534e-01],\n","         ...,\n","         [ 2.6463e-01,  3.5723e-01, -2.4914e-01,  ...,  1.0461e-01,\n","           4.6761e-01,  2.9797e-01],\n","         [ 3.8242e-01,  1.0543e-01, -1.6561e-01,  ...,  3.3986e-01,\n","           2.9926e-01,  4.3303e-01],\n","         [ 2.2702e-01,  3.4235e-01, -5.1179e-02,  ...,  1.9062e-01,\n","           3.5392e-01,  3.7591e-01]],\n","\n","        [[ 4.3297e-01,  3.7564e-01, -7.3426e-02,  ..., -5.5580e-01,\n","           3.4426e-01, -3.3264e-02],\n","         [ 6.1556e-01, -2.1655e-01,  3.6310e-01,  ..., -1.5451e-01,\n","           3.2367e-01,  1.6937e-01],\n","         [ 4.0627e-01,  8.7953e-02, -1.9645e-01,  ..., -1.1024e-01,\n","           7.7551e-01, -5.9456e-02],\n","         ...,\n","         [ 6.4360e-02,  1.0824e-01, -4.0313e-02,  ..., -2.5024e-01,\n","           4.8700e-01, -2.0723e-01],\n","         [ 1.3964e-01,  3.2955e-01,  3.5650e-02,  ..., -1.9448e-01,\n","           5.0046e-01, -2.4267e-01],\n","         [ 1.4256e-01,  3.6233e-01, -9.4741e-02,  ..., -1.0902e-01,\n","           6.3239e-01, -3.2728e-04]],\n","\n","        [[ 5.7870e-01, -2.8300e-02, -7.4357e-02,  ...,  1.6509e-02,\n","           2.5423e-01, -5.0268e-02],\n","         [ 2.7375e-01, -3.6699e-02,  3.0485e-01,  ...,  2.5330e-01,\n","           1.1123e-01,  1.7371e-01],\n","         [ 4.6577e-01, -3.4465e-01, -9.5539e-02,  ...,  5.5253e-01,\n","          -3.9637e-01, -3.8448e-02],\n","         ...,\n","         [ 3.2820e-01,  3.7725e-01, -1.1887e-01,  ..., -1.4453e-01,\n","          -8.9163e-02, -9.6148e-02],\n","         [ 1.2024e-01, -1.7134e-02,  8.0173e-02,  ...,  1.1457e-01,\n","           2.9004e-01, -3.2716e-02],\n","         [-9.5531e-02,  1.7551e-01,  2.7409e-02,  ...,  1.7314e-01,\n","           1.0837e-01, -7.0302e-02]],\n","\n","        ...,\n","\n","        [[ 5.8318e-01,  2.0113e-01, -1.7368e-01,  ..., -3.9551e-01,\n","           2.3060e-01,  2.3664e-01],\n","         [ 3.8018e-01, -4.8801e-01,  5.0672e-02,  ...,  4.5174e-02,\n","          -4.3789e-02,  5.6200e-01],\n","         [-1.0760e-01, -1.7944e-01, -3.4964e-01,  ...,  7.2649e-01,\n","          -7.1794e-01,  2.1125e-01],\n","         ...,\n","         [ 2.2792e-01,  3.5069e-01,  1.9073e-01,  ...,  1.7254e-02,\n","          -1.9846e-02,  1.4263e-01],\n","         [-2.2784e-01, -4.5251e-02, -1.2767e-01,  ..., -1.2518e-01,\n","           4.1410e-02,  2.7894e-01],\n","         [-1.4254e-01,  4.0392e-02,  2.6385e-01,  ...,  6.3213e-02,\n","           9.6906e-02,  6.6631e-03]],\n","\n","        [[ 2.8712e-01, -2.3412e-01,  1.3284e-01,  ...,  3.6486e-02,\n","           5.2671e-01,  4.1857e-01],\n","         [ 2.8960e-01, -3.2566e-01, -1.3895e-01,  ...,  5.0695e-01,\n","           4.1715e-01,  1.1586e+00],\n","         [ 1.5205e-01, -2.6187e-01,  3.1927e-01,  ...,  4.8437e-01,\n","          -1.3238e-02,  9.1279e-01],\n","         ...,\n","         [ 2.3830e-01, -4.0514e-01, -2.9496e-02,  ...,  3.8234e-01,\n","           2.8762e-01,  4.8044e-01],\n","         [ 1.6355e-01, -1.9243e-01, -7.0024e-02,  ...,  3.2832e-01,\n","           4.6686e-01,  5.6918e-01],\n","         [ 1.8888e-01, -2.9305e-01, -2.6088e-01,  ...,  1.3198e-01,\n","           3.9829e-01,  4.9173e-01]],\n","\n","        [[ 5.5218e-01,  5.1351e-01,  1.5799e-02,  ..., -2.4130e-01,\n","           4.9174e-01,  7.4727e-02],\n","         [ 2.5269e-01, -2.7555e-01,  3.8067e-01,  ..., -2.1924e-01,\n","           1.8898e-01, -5.1564e-01],\n","         [-1.8252e-01,  8.0713e-02,  4.8398e-01,  ...,  4.3313e-01,\n","           1.7549e-01, -3.7258e-01],\n","         ...,\n","         [-8.3821e-02,  2.2176e-01, -3.7693e-02,  ...,  2.3210e-01,\n","           2.2946e-01,  9.4744e-03],\n","         [-5.1750e-02,  2.5574e-01, -4.6373e-02,  ...,  2.0798e-01,\n","           5.0587e-02, -2.9924e-02],\n","         [-3.2871e-03,  2.8654e-01,  1.1552e-01,  ...,  3.5626e-02,\n","           1.3798e-01,  1.4891e-04]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward>), tensor([[-0.7873,  0.6074,  0.9999,  ...,  0.9999, -0.5691,  0.9749],\n","        [-0.6663,  0.4553,  0.9999,  ...,  1.0000, -0.6424,  0.9974],\n","        [-0.5621,  0.3371,  0.9994,  ...,  0.9999, -0.7848,  0.9881],\n","        ...,\n","        [-0.7512,  0.4838,  0.9999,  ...,  1.0000, -0.2729,  0.9861],\n","        [-0.6864,  0.3957,  0.9999,  ...,  1.0000, -0.3103,  0.9906],\n","        [-0.7604,  0.5249,  1.0000,  ...,  1.0000, -0.5539,  0.9970]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.7873,  0.6074,  0.9999,  ...,  0.9999, -0.5691,  0.9749],\n","        [-0.6663,  0.4553,  0.9999,  ...,  1.0000, -0.6424,  0.9974],\n","        [-0.5621,  0.3371,  0.9994,  ...,  0.9999, -0.7848,  0.9881],\n","        ...,\n","        [-0.7512,  0.4838,  0.9999,  ...,  1.0000, -0.2729,  0.9861],\n","        [-0.6864,  0.3957,  0.9999,  ...,  1.0000, -0.3103,  0.9906],\n","        [-0.7604,  0.5249,  1.0000,  ...,  1.0000, -0.5539,  0.9970]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-7.4038e-01, -6.5121e-01,  2.8385e-01, -8.7913e-02,  8.4799e-02,\n","          6.9996e-01, -9.1198e-01,  6.9588e-01, -4.0861e-01, -5.5738e-01,\n","          2.0989e-01,  4.5185e-01, -7.4127e-02,  5.5730e-01,  4.2007e-02,\n","          2.4214e-01, -5.7677e-02,  8.3959e-01,  8.8553e-02, -1.1227e+00,\n","         -1.4744e+00,  3.2162e-01,  4.7131e-01, -2.8495e-01,  2.5494e-01,\n","          7.6694e-01,  3.9745e-01,  5.0180e-01],\n","        [-6.8151e-01, -4.4375e-01,  2.3481e-01, -3.3582e-01,  3.7884e-01,\n","          5.7625e-01, -9.7139e-01,  5.7866e-01, -3.2897e-01, -5.8245e-01,\n","          3.8715e-01,  5.9561e-01,  3.5521e-02,  3.6938e-01, -1.8727e-02,\n","         -1.4285e-02, -2.1991e-01,  7.6782e-01,  4.8851e-02, -6.4253e-01,\n","         -1.5006e+00,  1.9124e-01,  3.2948e-01, -1.7431e-01,  2.7708e-01,\n","          2.8039e-01,  2.6650e-01,  5.5216e-01],\n","        [-6.5344e-01, -5.7031e-01,  1.3235e-01, -2.9173e-01,  4.5704e-01,\n","          3.8906e-01, -8.6773e-01,  6.7443e-01, -3.7709e-01, -5.8446e-01,\n","         -6.7190e-02,  6.2715e-01,  8.3735e-02,  6.4835e-01, -3.3532e-01,\n","          2.3635e-01, -2.2971e-01,  8.5343e-01, -1.3946e-01, -6.0003e-01,\n","         -1.0069e+00,  1.6885e-01,  2.0675e-01, -1.9338e-01,  2.1473e-01,\n","          6.9113e-01, -9.1784e-02,  3.1768e-01],\n","        [-8.2157e-01, -8.7215e-01,  3.9681e-01, -2.1160e-02,  2.9484e-01,\n","          5.0845e-01, -9.4594e-01,  7.4620e-01, -1.0183e-01, -4.0638e-01,\n","          1.6468e-01,  6.5780e-01, -1.5023e-01,  1.8644e-01, -1.3446e-01,\n","          1.1562e-01, -2.0888e-01,  9.4040e-01,  2.3587e-01, -6.1552e-01,\n","         -1.4832e+00,  1.4289e-01,  3.1734e-01, -3.0728e-01,  1.0504e-01,\n","          8.2993e-01,  1.3809e-01,  4.4674e-01],\n","        [-6.7929e-01, -5.6459e-01,  2.5383e-01, -5.8762e-02,  2.7109e-01,\n","          2.6692e-01, -6.9634e-01,  5.6659e-01, -6.3462e-02, -6.6905e-01,\n","         -1.4980e-01,  6.3425e-01, -2.8209e-01,  4.3524e-01,  2.1970e-01,\n","         -1.7573e-02, -2.5765e-01,  1.2651e+00, -2.3764e-01, -6.9709e-01,\n","         -1.5934e+00,  2.5070e-01,  1.0553e-01, -5.0194e-01,  3.4753e-01,\n","          8.0398e-01,  7.4732e-02,  6.4102e-01],\n","        [-9.5497e-01, -9.4778e-01,  1.5982e-01, -7.7097e-02,  3.5486e-01,\n","          4.4178e-01, -8.8844e-01,  6.8787e-01, -2.8199e-01, -5.9182e-01,\n","         -1.2372e-01,  7.5569e-01, -5.7754e-02,  5.5856e-01,  2.4579e-01,\n","          3.7950e-01, -3.4740e-02,  9.7654e-01,  2.0046e-01, -7.6988e-01,\n","         -1.5828e+00, -8.1901e-02,  5.4985e-01, -2.4999e-01,  2.9813e-01,\n","          8.5870e-01, -3.3814e-02,  3.9625e-01],\n","        [-7.8394e-01, -8.4810e-01,  3.7787e-01, -1.5593e-01,  6.4348e-01,\n","          5.6723e-01, -1.2108e+00,  6.9862e-01, -4.0898e-01, -4.4319e-01,\n","          8.5983e-02,  4.6921e-01, -2.4563e-01,  4.4356e-01, -6.0124e-02,\n","          2.9178e-01, -6.5586e-02,  7.7611e-01, -1.8896e-02, -7.0462e-01,\n","         -1.4195e+00,  5.4859e-02,  2.3510e-01, -8.7233e-05,  2.5794e-01,\n","          8.8647e-01,  4.7365e-02,  3.4609e-01],\n","        [-6.4677e-01, -8.1034e-01,  2.7542e-01,  1.6625e-01,  3.2487e-01,\n","          3.5585e-01, -8.7693e-01,  6.1708e-01, -2.9465e-01, -4.6235e-01,\n","          4.2002e-02,  5.6687e-01, -2.9150e-01,  1.9050e-01, -4.9063e-02,\n","          7.2363e-02, -2.0212e-02,  4.7755e-01, -1.0403e-01, -6.0993e-01,\n","         -1.9986e+00, -9.0322e-02,  3.1881e-01, -2.1120e-01,  1.1050e-01,\n","          8.6274e-01, -3.0442e-02,  1.7847e-01],\n","        [-1.1015e+00, -1.2363e+00,  2.5752e-01, -2.6679e-01,  3.4077e-01,\n","          3.8835e-01, -7.4999e-01,  9.7249e-01, -2.9225e-01, -7.6380e-01,\n","         -1.7745e-01,  6.1301e-01, -2.6061e-01,  4.7453e-01,  2.0410e-01,\n","          4.4915e-01, -1.4372e-02,  7.8487e-01, -2.7452e-02, -5.9835e-01,\n","         -1.6262e+00,  3.2949e-01,  6.1219e-01, -1.9886e-01,  1.1188e-01,\n","          9.3755e-01,  9.5018e-02,  3.3759e-01],\n","        [-1.0834e+00, -6.8962e-01,  1.1397e-01, -4.3317e-02,  3.6572e-01,\n","          5.5696e-01, -9.4674e-01,  6.6715e-01, -3.7855e-01, -5.9039e-01,\n","         -1.2857e-01,  5.9937e-01, -2.3666e-01,  6.1765e-01, -1.2055e-01,\n","          2.5929e-01, -5.0562e-02,  8.7047e-01, -9.5026e-02, -6.8627e-01,\n","         -1.3529e+00,  1.3391e-01,  3.2789e-01, -6.5594e-02,  3.5308e-01,\n","          9.4003e-01,  1.7960e-01,  3.9344e-01],\n","        [-5.5981e-01, -4.9262e-01,  7.4814e-03, -3.2605e-01,  3.8243e-01,\n","          4.3827e-01, -8.9433e-01,  6.5402e-01, -3.7047e-01, -5.7699e-01,\n","          1.5059e-01,  6.7037e-01, -2.6327e-01,  4.6123e-01,  8.9979e-02,\n","          5.2277e-02, -7.9518e-03,  8.3655e-01,  1.0239e-01, -7.6859e-01,\n","         -1.4936e+00,  4.0584e-01,  3.1661e-01, -3.8154e-01,  1.8854e-01,\n","          9.2746e-01,  2.1138e-01,  6.3948e-01],\n","        [-6.5476e-01, -9.4989e-01,  3.8252e-01, -8.0043e-02,  2.0470e-01,\n","          4.2520e-01, -8.4191e-01,  5.1965e-01, -2.2172e-01, -2.7297e-01,\n","          1.2035e-01,  4.8765e-01, -4.3896e-01,  2.4549e-01, -1.6787e-01,\n","          3.0649e-01, -5.0095e-02,  4.6519e-01, -1.2317e-01, -6.3708e-01,\n","         -1.4744e+00,  5.6970e-02,  2.5938e-01, -2.8091e-01,  6.4238e-02,\n","          7.2233e-01,  3.7595e-01,  3.5523e-01],\n","        [-8.0832e-01, -6.0239e-01,  4.3552e-01, -2.8327e-01,  2.2738e-01,\n","          3.8513e-01, -1.1159e+00,  6.1469e-01, -2.0858e-01, -7.1751e-01,\n","         -1.0133e-01,  7.7135e-01, -4.0581e-01,  3.6267e-01, -1.2637e-01,\n","         -8.0478e-02,  4.2435e-02,  7.5266e-01,  3.6514e-03, -7.9024e-01,\n","         -1.6307e+00,  4.0352e-01,  2.8375e-01, -4.4567e-01,  1.0723e-01,\n","          1.0616e+00,  4.2731e-01,  2.0600e-01],\n","        [-6.2452e-01, -6.9490e-01,  3.0411e-01, -2.4087e-01,  1.9860e-01,\n","          1.9192e-01, -9.7403e-01,  4.9531e-01, -2.2490e-01, -3.6972e-01,\n","         -1.8568e-01,  5.0424e-01, -1.7316e-01,  7.1327e-02, -1.0058e-01,\n","          1.6742e-01,  2.5494e-01,  6.0639e-01, -4.2181e-02, -8.8321e-01,\n","         -1.3524e+00, -3.5711e-02,  4.4369e-01,  9.6081e-02,  2.4447e-01,\n","          7.6743e-01,  3.0612e-01,  3.8927e-01],\n","        [-7.8841e-01, -5.3126e-01,  6.2216e-01, -1.6572e-01,  1.9798e-01,\n","          3.8828e-01, -7.9517e-01,  7.9041e-01, -4.6568e-01, -5.0142e-01,\n","          6.7718e-02,  7.2660e-01, -2.5420e-01,  1.6557e-01,  1.5697e-01,\n","          5.3055e-02, -2.5677e-01,  5.4942e-01,  5.4260e-02, -7.8569e-01,\n","         -1.6523e+00,  8.0656e-02,  2.4240e-01, -8.6273e-02, -7.0005e-02,\n","          7.0459e-01,  4.0153e-01,  3.5237e-01],\n","        [-8.5815e-01, -6.7737e-01,  2.3303e-01, -2.7281e-01,  3.6099e-01,\n","          6.9120e-01, -8.0688e-01,  6.4280e-01, -4.0393e-02, -4.4470e-01,\n","         -4.7907e-02,  5.2223e-01, -3.5852e-01,  4.6348e-01, -3.1645e-02,\n","          3.8327e-01,  2.9141e-02,  5.0253e-01, -1.7468e-03, -8.3533e-01,\n","         -1.7112e+00,  2.4519e-01,  4.0014e-01, -4.2096e-01,  9.1157e-02,\n","          7.2772e-01,  1.6103e-01,  4.7661e-01]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   1% 40/2714 [00:15<17:22,  2.56it/s]\u001b[Aoutputs:\n","(tensor([[[ 2.1092e-02,  1.4329e-01,  7.5964e-02,  ..., -3.5547e-01,\n","           3.0198e-01,  1.7546e-01],\n","         [-5.9807e-02,  4.8566e-01,  1.7558e-01,  ...,  4.5380e-01,\n","          -1.8866e-01,  2.4945e-01],\n","         [-3.0586e-01,  5.5521e-02, -2.0295e-01,  ..., -2.0350e-02,\n","          -4.0802e-01,  1.6672e-01],\n","         ...,\n","         [-3.0195e-01,  3.3112e-01, -3.1696e-02,  ..., -1.6171e-01,\n","           2.0108e-01,  1.1799e-01],\n","         [-1.8693e-01,  2.8457e-01,  8.4213e-02,  ...,  2.5187e-02,\n","           1.0810e-01,  2.8274e-01],\n","         [ 3.3227e-01,  1.4894e-01, -1.0125e-01,  ..., -3.4994e-04,\n","          -4.8574e-01,  6.6477e-01]],\n","\n","        [[ 3.4003e-01,  3.1130e-02, -3.8498e-01,  ..., -4.8446e-02,\n","           3.5450e-01,  2.9224e-01],\n","         [ 1.2408e-01, -1.7227e-01, -2.2121e-01,  ..., -2.2505e-02,\n","           7.4048e-02,  5.5253e-01],\n","         [ 1.5399e-01,  5.1448e-01,  7.6983e-02,  ..., -6.1787e-02,\n","           2.5258e-01,  6.0804e-01],\n","         ...,\n","         [ 3.0118e-02,  3.5541e-01,  2.9206e-02,  ..., -3.0458e-01,\n","          -1.5392e-01,  1.8045e-01],\n","         [ 1.4451e-01,  1.9463e-01,  2.2294e-01,  ..., -3.1247e-01,\n","          -1.7117e-02, -2.7732e-03],\n","         [-7.1135e-03,  1.7287e-01, -1.1317e-01,  ..., -6.0305e-02,\n","           1.0636e-01, -5.8722e-02]],\n","\n","        [[ 3.2066e-01,  1.9261e-01, -2.6911e-01,  ..., -1.3871e-01,\n","           2.2023e-01,  4.7914e-02],\n","         [ 7.4167e-02, -4.8465e-01,  4.1189e-01,  ..., -3.2449e-01,\n","           1.0682e-01,  3.7070e-01],\n","         [ 1.7166e-01, -4.9027e-01, -1.6158e-01,  ...,  1.4642e-01,\n","           4.0515e-01,  1.0026e-01],\n","         ...,\n","         [ 3.4234e-02,  3.1723e-01,  8.6143e-02,  ..., -8.6042e-02,\n","           4.7289e-02,  2.2165e-01],\n","         [-1.2126e-01,  2.9980e-01, -1.8220e-01,  ..., -6.0462e-02,\n","          -1.1557e-01, -1.3230e-01],\n","         [ 1.0266e-01,  2.9495e-01, -5.3271e-01,  ...,  8.0722e-02,\n","           6.5621e-02, -2.2303e-01]],\n","\n","        ...,\n","\n","        [[ 2.1679e-01,  2.2402e-01, -1.9836e-01,  ...,  7.8530e-03,\n","           1.0342e-02,  9.8460e-02],\n","         [ 2.5605e-01, -1.5094e-01,  7.5992e-01,  ..., -1.9630e-01,\n","          -5.4509e-02,  2.1105e-01],\n","         [-5.5302e-02,  4.1403e-02, -6.9965e-02,  ...,  2.3420e-01,\n","          -5.3087e-01, -1.1569e-01],\n","         ...,\n","         [ 2.4719e-01,  9.8612e-02,  5.4522e-01,  ...,  2.7955e-01,\n","           2.6937e-01,  2.4442e-01],\n","         [ 2.5355e-01,  1.0663e-01,  9.0476e-01,  ...,  1.3711e-01,\n","           3.9089e-02,  4.7314e-01],\n","         [ 3.2264e-01,  2.8268e-01,  3.6703e-01,  ..., -4.2836e-02,\n","          -2.7617e-02, -4.8159e-02]],\n","\n","        [[ 4.2455e-01,  3.0812e-01,  7.4499e-03,  ..., -3.1824e-01,\n","           3.4216e-01, -5.4542e-02],\n","         [ 1.0190e-01,  2.4970e-01,  1.7295e-01,  ...,  3.9412e-01,\n","          -2.9790e-04,  2.4700e-01],\n","         [ 2.9468e-01,  3.2876e-01, -2.5233e-01,  ...,  6.9337e-02,\n","          -2.5057e-01,  3.9125e-02],\n","         ...,\n","         [ 1.5377e-01, -1.2002e-01, -8.7344e-02,  ...,  7.6552e-02,\n","           4.7351e-01,  1.0978e-01],\n","         [ 2.2137e-01, -2.2380e-01, -1.8520e-02,  ...,  2.6439e-01,\n","           2.8563e-01,  1.3241e-01],\n","         [ 4.6554e-01,  9.0819e-02,  6.8587e-02,  ...,  1.3568e-01,\n","           1.1150e-01, -1.0548e-01]],\n","\n","        [[ 3.3754e-01, -7.9753e-03,  1.7780e-01,  ..., -1.2443e-01,\n","           4.1691e-01,  1.1189e-01],\n","         [ 6.8240e-01, -3.5284e-01,  8.7385e-01,  ...,  7.1840e-02,\n","           3.6733e-01,  2.7052e-01],\n","         [-5.0991e-02,  2.3428e-02, -1.2809e-01,  ...,  4.7827e-02,\n","           2.7118e-01, -9.1570e-02],\n","         ...,\n","         [-1.1064e-01,  3.2133e-03, -4.6781e-02,  ...,  1.0662e-01,\n","           3.2355e-01,  5.8656e-02],\n","         [-6.7373e-03, -1.8068e-01, -3.8975e-03,  ...,  1.4910e-01,\n","           3.3648e-01,  9.0967e-02],\n","         [ 3.0412e-01, -1.0020e-01,  1.6546e-01,  ...,  1.5892e-01,\n","          -5.0959e-01,  1.1199e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward>), tensor([[-0.8461,  0.5252,  0.9999,  ...,  1.0000,  0.0408,  0.9912],\n","        [-0.7729,  0.4446,  0.9998,  ...,  1.0000, -0.6385,  0.9906],\n","        [-0.6850,  0.5402,  0.9999,  ...,  1.0000, -0.5906,  0.9907],\n","        ...,\n","        [-0.5861,  0.3812,  0.9992,  ...,  0.9997, -0.7607,  0.9632],\n","        [-0.5538,  0.4086,  0.9999,  ...,  0.9999, -0.7386,  0.9895],\n","        [-0.7429,  0.5153,  0.9999,  ...,  1.0000, -0.4566,  0.9919]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.8461,  0.5252,  0.9999,  ...,  1.0000,  0.0408,  0.9912],\n","        [-0.7729,  0.4446,  0.9998,  ...,  1.0000, -0.6385,  0.9906],\n","        [-0.6850,  0.5402,  0.9999,  ...,  1.0000, -0.5906,  0.9907],\n","        ...,\n","        [-0.5861,  0.3812,  0.9992,  ...,  0.9997, -0.7607,  0.9632],\n","        [-0.5538,  0.4086,  0.9999,  ...,  0.9999, -0.7386,  0.9895],\n","        [-0.7429,  0.5153,  0.9999,  ...,  1.0000, -0.4566,  0.9919]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-0.4093, -0.6870,  0.4885, -0.0860,  0.1509,  0.3669, -0.6494,  0.5717,\n","         -0.0674, -0.3695, -0.0266,  0.4791, -0.3447,  0.1567, -0.0606,  0.0531,\n","          0.3160,  0.3405,  0.2176, -0.5638, -1.7241,  0.1761,  0.5296, -0.3048,\n","          0.2382,  0.8130,  0.1247,  0.1254],\n","        [-0.6623, -0.6037,  0.2111, -0.3121,  0.1776,  0.7546, -0.9804,  0.6263,\n","         -0.2536, -0.6536, -0.1296,  0.4139, -0.2211,  0.2301,  0.0236,  0.2838,\n","          0.1944,  0.7544,  0.0058, -0.4783, -1.3852, -0.1758,  0.3867, -0.3985,\n","          0.4434,  0.9178,  0.1653,  0.5944],\n","        [-0.5199, -0.7668,  0.6289, -0.1965,  0.4880,  0.5759, -0.9861,  0.9075,\n","         -0.2393, -0.6128,  0.1169,  0.3814, -0.2824,  0.3203,  0.3104,  0.0379,\n","          0.0732,  0.8108, -0.0736, -0.9340, -1.6060,  0.0809, -0.0125, -0.2271,\n","          0.3484,  0.7247,  0.1176,  0.2705],\n","        [-0.7934, -0.8679,  0.4685, -0.4835,  0.4465,  0.7111, -1.1838,  0.5132,\n","         -0.2029, -0.7426, -0.1598,  0.6306, -0.4309,  0.3772,  0.1509,  0.3036,\n","         -0.1942,  0.7609, -0.1125, -0.7276, -1.6388,  0.2818,  0.4023, -0.1142,\n","          0.3582,  0.7976,  0.2995,  0.2274],\n","        [-0.6421, -0.8019,  0.5646,  0.0541,  0.4923,  0.3856, -0.8083,  0.8466,\n","         -0.0967, -0.5363, -0.1403,  0.4509, -0.1862,  0.4627,  0.0395,  0.2392,\n","         -0.0088,  0.9058,  0.2708, -0.9409, -1.6666,  0.2701,  0.5709, -0.4716,\n","          0.0570,  0.8166,  0.2000,  0.1626],\n","        [-0.5522, -0.6956,  0.3049, -0.5317,  0.2861,  0.6163, -0.9205,  0.7086,\n","         -0.3141, -0.5223,  0.1410,  0.5213, -0.4732,  0.5058,  0.0447,  0.1935,\n","         -0.0635,  0.6358,  0.2382, -0.7244, -1.7586,  0.1135,  0.4725, -0.1539,\n","          0.1710,  0.5634,  0.0306,  0.3342],\n","        [-0.6787, -0.7591,  0.4568, -0.1068,  0.4687,  0.5955, -0.6988,  0.6698,\n","         -0.2063, -0.3778,  0.0032,  0.6175,  0.1334,  0.5815,  0.0371,  0.3342,\n","         -0.1367,  0.8333,  0.2473, -0.6415, -1.3582,  0.0922,  0.3464, -0.0586,\n","          0.7025,  0.6494,  0.1708,  0.4545],\n","        [-0.7621, -0.7689,  0.3008, -0.0487,  0.2785,  0.6311, -0.9361,  0.8498,\n","         -0.5917, -0.4415,  0.0904,  0.5860, -0.3966,  0.1866, -0.1865,  0.1178,\n","         -0.4640,  0.5029, -0.1200, -0.6930, -1.2117,  0.0289,  0.2500, -0.1007,\n","          0.3261,  1.0991,  0.1045,  0.2195],\n","        [-0.8426, -0.8133,  0.3586, -0.3079,  0.4204,  0.5431, -0.8396,  0.6960,\n","         -0.1875, -0.7023, -0.2847,  0.7507, -0.4238,  0.4004,  0.0499,  0.0883,\n","         -0.0260,  0.8903, -0.1575, -0.8115, -1.7529,  0.0835,  0.1320, -0.1486,\n","          0.1582,  0.9863,  0.0982,  0.5860],\n","        [-0.7234, -0.7653,  0.0425, -0.0746,  0.3302,  0.3438, -0.7354,  0.4750,\n","         -0.2552, -0.3669, -0.0356,  0.4278, -0.3320,  0.5193,  0.1574,  0.0859,\n","          0.0044,  0.7254,  0.0692, -0.8682, -1.6432,  0.2054,  0.2643, -0.1861,\n","          0.5537,  0.6319,  0.2823,  0.3631],\n","        [-0.6236, -0.9362,  0.1890, -0.5119,  0.6501,  0.3091, -0.8963,  1.0743,\n","         -0.2685, -0.4228, -0.0986,  0.6397, -0.3066,  0.2386, -0.1011,  0.2029,\n","         -0.0875,  0.3772, -0.0243, -0.5971, -1.5769,  0.2495,  0.5866,  0.0928,\n","          0.4125,  0.9661,  0.0777,  0.4954],\n","        [-0.8299, -0.5600,  0.2694, -0.2888,  0.2688,  0.5631, -0.8702,  0.8225,\n","         -0.0422, -0.6010,  0.3706,  0.7632, -0.5538,  0.4044, -0.3727,  0.0219,\n","          0.1355,  0.5095,  0.1369, -0.6469, -1.7824,  0.1390,  0.2701, -0.3026,\n","         -0.1123,  1.1809, -0.0177,  0.1423],\n","        [-0.7156, -0.8858,  0.4863, -0.0733,  0.4320,  0.5442, -0.8934,  0.5839,\n","          0.0794, -0.7584, -0.1431,  0.3032, -0.1157,  0.4625,  0.0891,  0.3059,\n","          0.0771,  0.5860, -0.2803, -0.6720, -1.3138,  0.2260,  0.5393,  0.2319,\n","          0.2142,  0.8180,  0.1925,  0.4173],\n","        [-0.5763, -0.7422,  0.4813, -0.3741,  0.2708,  0.4833, -1.0693,  0.4191,\n","         -0.2185, -0.4595, -0.0977,  0.5547, -0.4608,  0.1615,  0.2220,  0.3760,\n","         -0.0698,  0.6814, -0.0685, -1.1223, -1.4629,  0.3666,  0.2004, -0.1743,\n","          0.3057,  0.7558,  0.2727,  0.2404],\n","        [-0.8972, -0.7078,  0.2905, -0.1487,  0.4014,  0.3688, -0.9851,  0.6855,\n","         -0.1820, -0.5016, -0.1659,  0.6167, -0.1190,  0.3066, -0.0771,  0.4522,\n","         -0.1038,  0.9828, -0.1109, -0.9563, -1.7828,  0.1005,  0.3451, -0.1599,\n","          0.2835,  0.8160,  0.2948,  0.5863],\n","        [-0.5779, -0.7428,  0.5193, -0.3218,  0.2664,  0.2326, -0.9861,  0.8446,\n","          0.0107, -0.5966,  0.2896,  0.4996, -0.3997,  0.2274,  0.0766, -0.1151,\n","         -0.4200,  1.1293,  0.0092, -0.7439, -1.6517,  0.0490,  0.2332, -0.3545,\n","          0.0192,  0.7018, -0.0887,  0.3669]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   2% 41/2714 [00:15<17:20,  2.57it/s]\u001b[Aoutputs:\n","(tensor([[[ 0.1565,  0.2956,  0.2459,  ...,  0.1600,  0.3178,  0.1854],\n","         [ 0.2513, -0.2843,  0.5313,  ..., -0.2759,  0.2586,  0.3497],\n","         [ 0.0398,  0.2184,  0.5337,  ..., -0.0651,  0.1574,  1.1629],\n","         ...,\n","         [-0.1998,  0.1584,  0.2965,  ...,  0.3999,  0.2744,  0.3977],\n","         [-0.1373,  0.2662,  0.2200,  ...,  0.3172,  0.4253,  0.4887],\n","         [-0.1022,  0.0305,  0.3893,  ...,  0.3591,  0.2720,  0.4193]],\n","\n","        [[ 0.2935,  0.1438, -0.1135,  ..., -0.2100,  0.0911, -0.0777],\n","         [ 0.3148, -0.0027,  0.2013,  ...,  0.5217, -0.0219,  0.2332],\n","         [-0.5243,  0.7671, -0.6873,  ..., -0.4473, -0.2730,  0.2054],\n","         ...,\n","         [ 0.0944,  0.1700, -0.1990,  ..., -0.1354, -0.2815, -0.2155],\n","         [ 0.3552,  0.4395,  0.1493,  ..., -0.1170, -0.1638, -0.2157],\n","         [ 0.2734,  0.3893,  0.0445,  ..., -0.0196, -0.2365, -0.1863]],\n","\n","        [[ 0.5248,  0.2063, -0.3391,  ..., -0.2869, -0.0575, -0.1050],\n","         [ 0.2980, -0.4013,  0.1568,  ..., -0.3495, -0.1830,  0.0135],\n","         [ 0.5999,  0.3294, -0.4038,  ..., -0.0743,  0.0065, -0.1499],\n","         ...,\n","         [ 0.1216, -0.2154,  0.0741,  ..., -0.0442, -0.3876, -0.2235],\n","         [ 0.6475, -0.0504,  0.0664,  ..., -0.4516,  0.1044, -0.3695],\n","         [ 0.3809, -0.0606,  0.0217,  ..., -0.0956,  0.0029, -0.0615]],\n","\n","        ...,\n","\n","        [[ 0.4660,  0.3455,  0.1163,  ..., -0.4813,  0.1632, -0.2596],\n","         [ 0.3609, -0.2372,  0.4459,  ..., -0.3944,  0.2528,  0.0098],\n","         [ 0.1346, -0.1451,  0.1553,  ..., -0.1719,  0.2782,  0.0592],\n","         ...,\n","         [ 0.2574,  0.4281, -0.0768,  ..., -0.0978,  0.2935, -0.4355],\n","         [ 0.0762,  0.2366, -0.5009,  ..., -0.1391,  0.0022, -0.4897],\n","         [ 0.4138,  0.4080, -0.1306,  ..., -0.1591,  0.0418, -0.4788]],\n","\n","        [[ 0.2929,  0.3446,  0.1108,  ..., -0.2230,  0.3298,  0.1901],\n","         [ 0.6780, -0.3439,  0.6395,  ..., -0.1169,  0.1389,  0.0691],\n","         [ 0.1250,  0.0338,  0.5968,  ...,  0.3999,  0.0577, -0.1736],\n","         ...,\n","         [-0.2098,  0.0442,  0.3869,  ..., -0.1249, -0.0195,  0.0288],\n","         [-0.2140,  0.1244,  0.4205,  ...,  0.0155,  0.0039,  0.0215],\n","         [-0.0726, -0.0407,  0.2780,  ..., -0.1828,  0.4801,  0.1395]],\n","\n","        [[ 0.4561,  0.2855,  0.0880,  ..., -0.0791,  0.3934, -0.2285],\n","         [ 0.6569, -0.1063,  0.1914,  ..., -0.0298,  0.3789,  0.2105],\n","         [ 0.3847,  0.0214, -0.3128,  ...,  0.5942,  0.2058,  0.3274],\n","         ...,\n","         [ 0.1101,  0.3771, -0.0680,  ...,  0.4010,  0.5981, -0.1218],\n","         [ 0.0365, -0.0583, -0.2408,  ...,  0.3531,  1.1007, -0.0517],\n","         [ 0.3169,  0.5194, -0.0823,  ...,  0.3172,  0.2056, -0.0894]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward>), tensor([[-0.8228,  0.5911,  1.0000,  ...,  1.0000, -0.6352,  0.9956],\n","        [-0.5691,  0.4909,  0.9997,  ...,  0.9999, -0.6991,  0.9863],\n","        [-0.6763,  0.3592,  0.9998,  ...,  1.0000, -0.6598,  0.9908],\n","        ...,\n","        [-0.6607,  0.3740,  0.9996,  ...,  0.9999, -0.9010,  0.9943],\n","        [-0.7440,  0.3494,  0.9996,  ...,  0.9999, -0.7805,  0.9911],\n","        [-0.7360,  0.4565,  0.9999,  ...,  1.0000, -0.7951,  0.9931]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.8228,  0.5911,  1.0000,  ...,  1.0000, -0.6352,  0.9956],\n","        [-0.5691,  0.4909,  0.9997,  ...,  0.9999, -0.6991,  0.9863],\n","        [-0.6763,  0.3592,  0.9998,  ...,  1.0000, -0.6598,  0.9908],\n","        ...,\n","        [-0.6607,  0.3740,  0.9996,  ...,  0.9999, -0.9010,  0.9943],\n","        [-0.7440,  0.3494,  0.9996,  ...,  0.9999, -0.7805,  0.9911],\n","        [-0.7360,  0.4565,  0.9999,  ...,  1.0000, -0.7951,  0.9931]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-0.7422, -0.4699,  0.3274, -0.0893,  0.6471,  0.6761, -0.8979,  0.6215,\n","         -0.2888, -0.3388,  0.0400,  0.5234, -0.3642,  0.2291,  0.0672,  0.0588,\n","          0.0436,  0.7321,  0.1546, -0.7213, -1.5203,  0.4242,  0.3601, -0.4827,\n","          0.0445,  0.8784,  0.1517,  0.0677],\n","        [-0.7797, -0.8672,  0.0950,  0.0167,  0.5983,  0.5297, -0.8330,  0.8333,\n","         -0.3161, -0.7088,  0.0071,  0.4962, -0.1570,  0.1313,  0.0874,  0.2064,\n","         -0.4682,  0.5939, -0.1704, -0.7607, -1.6511,  0.2716,  0.4549, -0.2208,\n","          0.0584,  0.9054,  0.2685,  0.4288],\n","        [-0.8144, -0.6181, -0.0385, -0.2746,  0.5019,  0.5430, -0.9539,  0.5980,\n","         -0.2016, -0.7043,  0.0522,  0.8740,  0.1183,  0.3789, -0.1717,  0.4560,\n","         -0.0809,  0.8264, -0.0505, -0.8091, -1.2563,  0.2103,  0.0038, -0.2161,\n","          0.1303,  0.7037,  0.1266,  0.1308],\n","        [-0.8280, -0.9770,  0.9286,  0.1407,  0.3427,  0.5652, -1.1695,  0.8534,\n","         -0.2088, -0.3391,  0.1864,  0.6150, -0.2163,  0.0876,  0.0889, -0.0366,\n","          0.1790,  0.7362,  0.3749, -0.6843, -1.6110, -0.0601,  0.6201, -0.6309,\n","         -0.0082,  0.9048,  0.0101,  0.0449],\n","        [-0.5757, -0.7117,  0.4010, -0.1457,  0.6502,  0.3722, -0.8054,  0.6558,\n","         -0.1736, -0.4795,  0.0070,  0.6181, -0.4145,  0.1529,  0.1897,  0.0084,\n","          0.4079,  0.6724,  0.2670, -0.4901, -1.4684,  0.1441,  0.3315, -0.2519,\n","         -0.1104,  0.6893,  0.2018,  0.1644],\n","        [-0.6953, -0.7011,  0.0602, -0.2212,  0.6628,  0.4842, -0.6440,  0.8041,\n","         -0.2898, -0.4791,  0.0744,  0.6065, -0.3563,  0.2446,  0.0889,  0.3288,\n","         -0.2456,  0.9517, -0.1435, -0.5548, -1.5684,  0.1442,  0.2109, -0.1003,\n","          0.2546,  0.6453,  0.0415,  0.5714],\n","        [-0.7242, -0.7406,  0.5660,  0.2416,  0.3640,  0.3203, -0.9419,  0.7008,\n","         -0.1310, -0.5476, -0.0268,  0.5114, -0.2278,  0.2476, -0.2561,  0.2479,\n","         -0.0729,  0.5564,  0.0274, -0.7540, -1.7559, -0.0324,  0.3652, -0.2765,\n","          0.1676,  1.0534,  0.2359,  0.3055],\n","        [-0.7333, -0.9108,  0.2853,  0.0330,  0.4850,  0.6824, -0.9443,  0.7759,\n","         -0.4490, -0.8174,  0.0381,  0.3362, -0.3798,  0.4843,  0.0018,  0.3882,\n","          0.1028,  0.9832, -0.0566, -0.8671, -1.6362,  0.1699,  0.4352, -0.0581,\n","          0.2523,  0.7286, -0.1434,  0.7737],\n","        [-0.8002, -0.5735,  0.2297, -0.2226,  0.0417,  0.1435, -0.8923,  0.5802,\n","         -0.0975, -0.5627, -0.0963,  0.3926, -0.1539,  0.3140,  0.0150,  0.2624,\n","         -0.0924,  0.7101, -0.0537, -0.5030, -1.5145,  0.2947,  0.2532, -0.2874,\n","          0.1273,  0.6336,  0.2819,  0.3266],\n","        [-0.9799, -0.8636,  0.2729, -0.2107,  0.4735,  0.3469, -0.9143,  0.5489,\n","         -0.3590, -0.5894, -0.1583,  0.6481,  0.0717,  0.3082, -0.1454,  0.3158,\n","         -0.1753,  0.7270, -0.0485, -0.9505, -1.4277,  0.0439,  0.3503, -0.2103,\n","          0.2798,  0.9695,  0.2372,  0.6836],\n","        [-0.7005, -0.6185,  0.4800, -0.5593,  0.2585,  0.4552, -0.9840,  0.7245,\n","         -0.1784, -0.6574, -0.0186,  0.5152, -0.0184,  0.5248,  0.0187,  0.0095,\n","          0.1422,  0.7969,  0.2394, -0.8531, -1.6493,  0.0709,  0.4296, -0.3704,\n","          0.1840,  0.9862,  0.4284,  0.5125],\n","        [-0.6957, -0.4322,  0.2085, -0.0117,  0.2858,  0.6427, -1.0044,  0.6333,\n","          0.1280, -0.5429,  0.1848,  0.7401,  0.0407,  0.3091,  0.0953,  0.3273,\n","          0.1822,  0.7055, -0.0082, -0.8861, -1.6973,  0.2256,  0.1910,  0.1022,\n","          0.2506,  0.7872,  0.1279,  0.2890],\n","        [-0.5396, -0.6855,  0.3360, -0.1321,  0.3041,  0.7435, -1.1417,  0.8227,\n","         -0.1806, -0.3136,  0.0206,  0.3746, -0.4880,  0.2914, -0.0320, -0.1577,\n","         -0.2707,  0.9002, -0.0579, -0.6829, -1.4699,  0.0482,  0.5610, -0.4088,\n","          0.2212,  0.7728, -0.0639,  0.1728],\n","        [-0.7842, -0.3263,  0.1656, -0.5409,  0.6287,  0.6520, -1.1359,  0.8275,\n","         -0.1332, -0.8156, -0.4046,  0.7360, -0.1356,  0.5398, -0.0841,  0.7201,\n","         -0.1703,  0.9411,  0.0031, -0.9220, -1.2287,  0.5636,  0.3119, -0.0174,\n","          0.1634,  0.8617,  0.3757,  0.3867],\n","        [-0.7996, -0.5001,  0.2649, -0.3358,  0.4125,  0.2882, -1.1366,  0.6464,\n","         -0.2852, -0.7045, -0.1285,  0.5438, -0.0895,  0.5346, -0.0892,  0.2444,\n","         -0.3808,  0.7644, -0.0052, -0.9808, -1.4329,  0.3933,  0.2254, -0.1306,\n","          0.1136,  0.8470,  0.4095,  0.1729],\n","        [-0.6011, -0.5935,  0.1196, -0.4401,  0.3636,  0.5163, -0.6807,  0.7099,\n","         -0.2503, -0.7669,  0.1053,  1.0254, -0.1455,  0.4853,  0.2021,  0.4397,\n","          0.0311,  0.6737, -0.1393, -0.6580, -1.4153,  0.3857,  0.2126,  0.1613,\n","          0.2791,  0.5083, -0.0305,  0.4813]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   2% 42/2714 [00:16<17:16,  2.58it/s]\u001b[Aoutputs:\n","(tensor([[[ 0.4158,  0.1022,  0.1650,  ..., -0.0655,  0.2368,  0.0845],\n","         [ 0.3534,  0.1181,  0.3331,  ...,  0.2618, -0.1784,  0.5672],\n","         [ 1.1387,  0.1699, -0.2690,  ..., -0.4220,  0.4191, -0.7146],\n","         ...,\n","         [-0.0125,  0.0423, -0.0681,  ..., -0.1860, -0.2476,  0.0764],\n","         [ 0.2048,  0.2630,  0.1451,  ..., -0.0392,  0.2496, -0.0597],\n","         [ 0.1125,  0.1471, -0.1976,  ...,  0.0503, -0.5222,  0.2983]],\n","\n","        [[ 0.6390,  0.1101, -0.1398,  ..., -0.2119,  0.1090,  0.0963],\n","         [ 0.5406, -0.3035,  0.6382,  ..., -0.3789,  0.1213,  0.2490],\n","         [-0.2497, -0.1377,  0.8260,  ...,  0.4280, -0.0652, -0.1045],\n","         ...,\n","         [ 0.2599,  0.2100,  0.2459,  ..., -0.0130, -0.3117, -0.2647],\n","         [ 0.0476,  0.1402,  0.0690,  ...,  0.2370, -0.0391, -0.2814],\n","         [ 0.0849,  0.0713,  0.2225,  ...,  0.0993, -0.1005, -0.1875]],\n","\n","        [[ 0.2670,  0.2520, -0.0812,  ..., -0.2340,  0.3350, -0.1653],\n","         [-0.1063, -0.4561,  0.0518,  ..., -0.1504,  0.1947, -0.1960],\n","         [ 0.1617, -0.3457, -0.3180,  ...,  0.4073,  0.7256,  0.1741],\n","         ...,\n","         [ 0.2234,  0.2727, -0.4680,  ...,  0.1682,  0.0158, -0.3619],\n","         [ 0.1057,  0.0501, -0.1850,  ...,  0.1458,  0.2319, -0.1190],\n","         [ 0.0189, -0.1662, -0.0983,  ...,  0.2561,  0.2227,  0.1526]],\n","\n","        ...,\n","\n","        [[ 0.1993,  0.4241,  0.0639,  ..., -0.2035, -0.0377, -0.1084],\n","         [ 0.5882, -0.3078,  0.5571,  ..., -0.6779,  0.1443,  0.1345],\n","         [-0.1780,  0.3404,  0.2843,  ..., -0.3463,  0.0311,  0.2954],\n","         ...,\n","         [ 0.0375,  0.5330,  0.0733,  ...,  0.1954,  0.1354, -0.2368],\n","         [-0.1262,  0.3081,  0.2612,  ...,  0.2076,  0.1938, -0.1188],\n","         [ 0.1365,  0.3002,  0.3220,  ...,  0.1456,  0.0346,  0.0446]],\n","\n","        [[ 0.0381,  0.4305, -0.0231,  ..., -0.3900,  0.3992, -0.2381],\n","         [ 0.3862, -0.0217,  0.7616,  ...,  0.1894, -0.0419,  0.2957],\n","         [-0.2852,  0.2598, -0.1280,  ...,  0.0995,  0.1266,  0.0369],\n","         ...,\n","         [-0.0115,  0.5608,  0.1718,  ...,  0.0163, -0.0517,  0.1965],\n","         [-0.1243,  0.3393, -0.3836,  ...,  0.0218,  0.5849, -0.2279],\n","         [ 0.1628,  0.2867,  0.2831,  ...,  0.1053, -0.0461,  0.0497]],\n","\n","        [[ 0.2447,  0.1911, -0.0600,  ..., -0.1262,  0.1711, -0.1188],\n","         [ 0.4248, -0.1831,  0.4693,  ...,  0.0126,  0.3634, -0.0744],\n","         [ 0.2029, -0.4243, -0.3094,  ...,  0.0661, -0.2376, -0.0543],\n","         ...,\n","         [-0.0579,  0.1531,  0.1807,  ..., -0.4916,  0.1031, -0.3271],\n","         [-0.0977, -0.1175,  0.0529,  ...,  0.0354,  0.4724,  0.0092],\n","         [ 0.1412,  0.0263, -0.0817,  ..., -0.0648,  0.0454,  0.0163]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward>), tensor([[-0.5684,  0.4241,  0.9999,  ...,  1.0000, -0.7750,  0.9959],\n","        [-0.6461,  0.5475,  0.9999,  ...,  1.0000, -0.8473,  0.9920],\n","        [-0.6173,  0.3634,  0.9996,  ...,  0.9999, -0.7029,  0.9839],\n","        ...,\n","        [-0.4954,  0.3185,  0.9989,  ...,  0.9997, -0.6443,  0.9850],\n","        [-0.6306,  0.4991,  0.9999,  ...,  1.0000, -0.6408,  0.9936],\n","        [-0.5864,  0.4309,  0.9991,  ...,  0.9997, -0.7963,  0.9798]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.5684,  0.4241,  0.9999,  ...,  1.0000, -0.7750,  0.9959],\n","        [-0.6461,  0.5475,  0.9999,  ...,  1.0000, -0.8473,  0.9920],\n","        [-0.6173,  0.3634,  0.9996,  ...,  0.9999, -0.7029,  0.9839],\n","        ...,\n","        [-0.4954,  0.3185,  0.9989,  ...,  0.9997, -0.6443,  0.9850],\n","        [-0.6306,  0.4991,  0.9999,  ...,  1.0000, -0.6408,  0.9936],\n","        [-0.5864,  0.4309,  0.9991,  ...,  0.9997, -0.7963,  0.9798]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-7.0032e-01, -5.8386e-01,  1.3318e-01, -2.6132e-01,  6.4694e-01,\n","          5.8032e-01, -6.9667e-01,  9.2407e-01, -8.7834e-03, -6.3330e-01,\n","          1.9593e-03,  6.4475e-01, -3.2973e-02,  3.8004e-01,  7.1358e-02,\n","          2.4632e-01, -2.7522e-01,  8.9167e-01, -6.3943e-02, -1.0995e+00,\n","         -1.5847e+00,  3.9146e-01,  1.9685e-01, -1.6737e-01,  3.4981e-01,\n","          7.0394e-01,  9.8800e-03,  3.9086e-01],\n","        [-6.9692e-01, -5.6545e-01,  2.9190e-01, -5.7382e-02,  4.4039e-02,\n","          5.7384e-01, -9.1206e-01,  9.6882e-01, -8.5684e-02, -4.7243e-01,\n","         -1.4652e-01,  6.6188e-01,  1.3604e-03,  1.6784e-01,  5.2682e-02,\n","          2.3467e-01,  1.4234e-01,  6.7367e-01, -3.7616e-02, -8.0014e-01,\n","         -1.7388e+00,  3.4714e-01,  2.6758e-01, -4.2312e-01,  8.2461e-02,\n","          9.4273e-01,  5.0010e-01,  4.5326e-01],\n","        [-6.0315e-01, -9.7586e-01,  4.2147e-01, -4.2894e-01,  2.6445e-01,\n","          5.1268e-01, -1.1321e+00,  6.5887e-01, -1.2277e-01, -5.7688e-01,\n","          4.1080e-02,  3.7176e-01,  4.1317e-02,  5.5042e-01, -1.0909e-01,\n","          1.4262e-01, -2.7070e-02,  8.8709e-01, -2.8514e-02, -8.5715e-01,\n","         -1.3744e+00,  3.1188e-01,  3.4712e-01, -3.8027e-01,  2.9582e-01,\n","          1.0065e+00,  1.9134e-01,  4.2913e-01],\n","        [-9.0158e-01, -7.5004e-01,  3.3142e-01, -2.3599e-01,  3.6018e-01,\n","          5.8446e-01, -8.8488e-01,  7.7593e-01, -2.9416e-01, -7.4729e-01,\n","         -1.9122e-01,  5.1633e-01, -3.9432e-01,  4.6904e-01, -1.4299e-01,\n","          5.4808e-01, -5.6606e-02,  7.9747e-01,  2.9837e-01, -6.9057e-01,\n","         -1.6609e+00, -1.2730e-01,  5.1601e-02, -3.8116e-01,  2.1692e-01,\n","          6.6498e-01,  3.0222e-01,  2.2417e-01],\n","        [-9.0314e-01, -4.1216e-01,  1.0810e-01,  2.2481e-01,  2.0038e-01,\n","          2.7432e-01, -8.1311e-01,  6.7684e-01, -3.7806e-01, -5.1363e-01,\n","          2.1105e-01,  6.3231e-01, -2.3532e-01,  4.6289e-01, -3.6742e-01,\n","         -5.6543e-02, -8.2626e-02,  6.4388e-01, -3.8377e-01, -6.7656e-01,\n","         -1.2560e+00, -9.4184e-02,  3.3383e-01, -2.1183e-01,  1.3239e-01,\n","          8.5934e-01, -8.0460e-02,  5.1344e-01],\n","        [-9.2270e-01, -5.4122e-01,  2.2800e-03, -4.7391e-01,  6.6184e-01,\n","          4.7799e-01, -8.6194e-01,  9.2195e-01, -1.5177e-01, -5.4542e-01,\n","          1.0663e-01,  6.4980e-01, -3.3691e-01,  4.6520e-01, -1.9603e-03,\n","          1.4177e-01,  2.0680e-02,  5.0157e-01,  4.8075e-02, -6.8579e-01,\n","         -1.5859e+00,  1.4490e-01,  2.7661e-01,  5.9214e-02,  3.7493e-01,\n","          5.9713e-01,  2.2220e-01,  5.5111e-01],\n","        [-9.3584e-01, -6.6021e-01, -7.5678e-02, -3.5418e-01,  3.8738e-01,\n","          3.3270e-01, -1.0991e+00,  5.8762e-01, -3.3400e-01, -7.4733e-01,\n","         -1.5743e-01,  9.8976e-01,  2.6984e-02,  5.0321e-01,  2.8476e-01,\n","          3.4125e-01, -4.5518e-01,  8.1577e-01, -3.6000e-01, -6.6371e-01,\n","         -1.6054e+00,  1.6083e-01,  2.9856e-01,  2.0416e-02,  1.3077e-01,\n","          7.7647e-01,  5.9926e-01,  4.9209e-01],\n","        [-6.7493e-01, -7.2030e-01,  4.4969e-01, -8.1031e-02,  1.3101e-01,\n","          5.3416e-01, -9.8930e-01,  9.9947e-01, -4.3145e-01, -5.7648e-01,\n","         -3.4916e-01,  7.2236e-01, -6.6226e-02,  2.8271e-01,  3.7588e-02,\n","          1.3069e-02, -9.8511e-02,  6.5167e-01,  2.2524e-01, -8.6099e-01,\n","         -1.4453e+00,  1.4775e-01,  3.8533e-01, -3.2870e-01,  7.9965e-03,\n","          1.0764e+00,  2.8376e-01,  1.8407e-01],\n","        [-6.0072e-01, -7.4411e-01,  2.6512e-01, -1.7212e-01,  3.1698e-01,\n","          3.2102e-01, -8.4153e-01,  7.2556e-01, -2.0339e-01, -4.8995e-01,\n","         -1.1485e-01,  6.6869e-01, -3.1836e-01,  1.7389e-01, -4.8956e-02,\n","          2.2916e-01, -2.7719e-01,  6.4479e-01, -1.1446e-01, -7.3650e-01,\n","         -1.3397e+00, -8.8540e-02,  1.8410e-01, -2.7893e-01,  3.0321e-01,\n","          8.5536e-01,  4.2133e-02,  2.5230e-01],\n","        [-1.0042e+00, -5.3366e-01,  2.1363e-01, -2.1057e-01,  3.9712e-01,\n","          5.7220e-01, -9.3363e-01,  8.6837e-01, -1.9297e-02, -5.9421e-01,\n","          4.4510e-03,  6.6162e-01, -2.9752e-01,  2.4932e-01,  3.7815e-01,\n","         -2.8461e-01, -9.5192e-02,  8.2077e-01,  2.5398e-01, -7.4960e-01,\n","         -1.5940e+00,  1.7204e-01,  1.3682e-01, -2.9380e-01,  2.6293e-01,\n","          8.2471e-01,  1.6626e-01,  1.0327e-01],\n","        [-6.8502e-01, -6.1247e-01,  3.2845e-01,  2.2555e-01,  4.0712e-01,\n","          6.1565e-01, -8.9955e-01,  1.0406e+00, -3.2748e-01, -4.9346e-01,\n","         -5.4038e-02,  6.6649e-01, -3.8194e-01,  2.4055e-01,  3.7981e-01,\n","          3.1934e-01, -1.9176e-01,  5.0786e-01,  1.1792e-01, -6.2941e-01,\n","         -1.6318e+00,  2.0385e-01,  5.9472e-01, -4.0001e-01,  1.5393e-01,\n","          6.4867e-01,  2.2002e-01,  3.0110e-01],\n","        [-6.3815e-01, -3.6705e-01, -1.4946e-01, -4.4105e-01,  2.3339e-01,\n","          6.4053e-01, -9.2039e-01,  8.4429e-01, -1.5789e-01, -5.4223e-01,\n","          5.9682e-02,  5.2383e-01, -1.5334e-01,  1.8519e-01,  1.2226e-01,\n","         -5.0705e-02, -2.1436e-01,  9.7026e-01, -1.7375e-01, -9.6116e-01,\n","         -1.3591e+00,  2.0772e-01,  2.1960e-01, -2.7289e-01,  2.3168e-01,\n","          5.4970e-01,  8.8179e-02,  5.6675e-01],\n","        [-7.1935e-01, -9.4516e-01,  6.0889e-01, -3.1107e-01,  2.8868e-01,\n","          1.2360e-01, -1.1476e+00,  5.5248e-01, -2.8203e-01, -3.8812e-01,\n","          2.1782e-01,  6.2091e-01, -2.8431e-01,  2.6790e-01, -1.9555e-02,\n","          1.8781e-01,  2.3163e-02,  5.8071e-01,  1.6053e-01, -9.6220e-01,\n","         -1.3691e+00,  1.1859e-01,  7.4245e-04, -7.1935e-02, -9.9914e-02,\n","          5.5636e-01,  2.7364e-01,  4.6198e-01],\n","        [-6.5548e-01, -5.8802e-01,  5.1152e-01, -1.5790e-01,  1.5343e-01,\n","          2.8230e-01, -9.6193e-01,  5.5175e-01, -1.3465e-01, -5.4008e-01,\n","         -6.5385e-02,  5.8659e-01, -3.2618e-01,  4.3260e-01,  2.4272e-01,\n","          3.0203e-01, -2.5079e-01,  5.6451e-01,  4.8241e-02, -6.0138e-01,\n","         -1.6100e+00,  2.6026e-01,  1.5602e-01,  2.8186e-02,  1.4277e-01,\n","          7.2254e-01, -7.2930e-04,  3.5208e-01],\n","        [-7.6435e-01, -1.0058e+00,  3.0437e-01, -1.5438e-01,  3.5149e-01,\n","          4.4441e-01, -9.5135e-01,  1.0434e+00, -3.2151e-01, -5.3131e-01,\n","         -1.0167e-01,  7.7601e-01, -3.3084e-01,  3.5090e-01, -1.3992e-01,\n","          9.2677e-02, -1.9421e-01,  8.0566e-01, -1.6627e-02, -6.0607e-01,\n","         -1.5609e+00,  1.9699e-01,  2.6059e-01, -2.5001e-01,  8.8992e-02,\n","          9.9740e-01,  1.4042e-01,  3.6468e-01],\n","        [-6.5797e-01, -5.0704e-01,  8.3994e-02, -4.3120e-01,  3.3261e-01,\n","          4.3506e-01, -8.6621e-01,  6.9532e-01, -4.1187e-01, -5.4371e-01,\n","         -1.9217e-02,  6.3717e-01, -5.0603e-02,  4.1957e-01, -8.1464e-02,\n","          3.9986e-01, -1.5607e-01,  9.2133e-01, -8.0083e-02, -7.5347e-01,\n","         -1.5067e+00,  4.1583e-02,  4.6076e-01, -1.3721e-01,  3.9684e-01,\n","          9.0767e-01,  2.3472e-01,  2.3664e-01]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   2% 43/2714 [00:16<17:20,  2.57it/s]\u001b[Aoutputs:\n","(tensor([[[ 0.4776,  0.5668, -0.0258,  ..., -0.2256,  0.1056, -0.2233],\n","         [ 0.0251, -0.1513,  0.6856,  ...,  0.1756, -0.2797,  0.4188],\n","         [ 0.0371,  0.6935, -0.2581,  ...,  0.6898,  0.0491,  0.3805],\n","         ...,\n","         [-0.1368,  0.7427, -0.0283,  ..., -0.0452,  0.1494, -0.2930],\n","         [ 0.2377,  0.5610,  0.0365,  ...,  0.4640,  0.5096, -0.0701],\n","         [-0.0984,  0.5862,  0.2319,  ...,  0.1214,  0.1494,  0.0758]],\n","\n","        [[ 0.1476,  0.2058,  0.1058,  ..., -0.2183,  0.4176, -0.2654],\n","         [-0.2832, -0.0239,  0.2874,  ..., -0.0974,  0.4595,  0.0543],\n","         [ 0.2070,  0.4666,  0.3253,  ...,  0.1040,  0.2202, -0.0603],\n","         ...,\n","         [ 0.0630,  0.1388,  0.1925,  ...,  0.0027,  0.4149, -0.1451],\n","         [ 0.0733,  0.1771,  0.0471,  ..., -0.1827,  0.2370, -0.0990],\n","         [-0.0759,  0.0811,  0.1421,  ..., -0.2478,  0.1888, -0.0588]],\n","\n","        [[ 0.2854,  0.1587, -0.1224,  ..., -0.2763,  0.5140, -0.1781],\n","         [ 0.3983, -0.1205,  0.2476,  ..., -0.2801,  0.4131, -0.0601],\n","         [ 0.1961, -0.0747,  0.4115,  ...,  0.0375,  0.4207,  0.2416],\n","         ...,\n","         [ 0.1754, -0.0967,  0.0378,  ...,  0.1549,  0.2807, -0.3100],\n","         [ 0.1378, -0.1520,  0.0796,  ..., -0.1389,  0.3020, -0.1049],\n","         [ 0.1407,  0.1719,  0.0075,  ...,  0.2655,  0.2434, -0.3393]],\n","\n","        ...,\n","\n","        [[ 0.5246, -0.1322, -0.0339,  ..., -0.0182,  0.3009,  0.2896],\n","         [-0.0220,  0.1366,  0.3231,  ..., -0.1366,  0.0082,  0.5082],\n","         [ 0.6356,  0.1574, -0.4536,  ..., -0.1655,  0.2923,  0.1605],\n","         ...,\n","         [ 0.2282, -0.0234, -0.0470,  ...,  0.2401,  0.0234,  0.0239],\n","         [ 0.0231,  0.1969, -0.0701,  ...,  0.1117, -0.0355,  0.1376],\n","         [ 0.1462,  0.0843,  0.0084,  ...,  0.1447,  0.0207,  0.2623]],\n","\n","        [[ 0.5344,  0.0642, -0.0560,  ..., -0.0765,  0.2380, -0.0189],\n","         [ 0.2893, -0.2562,  0.4757,  ...,  0.0133,  0.3667,  0.3693],\n","         [ 0.0198,  0.1788,  0.3219,  ...,  0.1862,  0.5781, -0.0561],\n","         ...,\n","         [ 0.0461, -0.0448,  0.0490,  ...,  0.0079,  0.1619,  0.1903],\n","         [ 0.1794,  0.2252, -0.0795,  ..., -0.0306,  0.0633,  0.1479],\n","         [ 0.0814,  0.3221, -0.4304,  ..., -0.0716,  0.1184,  0.0903]],\n","\n","        [[ 0.2024,  0.4102, -0.2164,  ..., -0.1429, -0.0442, -0.3126],\n","         [ 0.3444, -0.7327,  0.5492,  ...,  0.0105, -0.1362, -0.5529],\n","         [-0.1969, -0.2811, -0.8562,  ...,  1.4059, -0.1514,  0.3778],\n","         ...,\n","         [ 0.2396,  0.0182, -0.2217,  ..., -0.2617,  0.1696, -0.3458],\n","         [ 0.1280,  0.4108, -0.2846,  ...,  0.0406,  0.0256, -0.5750],\n","         [ 0.0139,  0.3804, -0.5531,  ...,  0.0344, -0.0122, -0.4210]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward>), tensor([[-0.5699,  0.4347,  0.9999,  ...,  1.0000, -0.8870,  0.9963],\n","        [-0.6955,  0.5076,  0.9999,  ...,  1.0000, -0.5861,  0.9942],\n","        [-0.7387,  0.5157,  0.9999,  ...,  1.0000, -0.6076,  0.9935],\n","        ...,\n","        [-0.8725,  0.5233,  1.0000,  ...,  1.0000, -0.2842,  0.9930],\n","        [-0.6818,  0.4959,  0.9999,  ...,  1.0000, -0.4565,  0.9922],\n","        [-0.5651,  0.3801,  0.9995,  ...,  0.9999, -0.8150,  0.9888]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.5699,  0.4347,  0.9999,  ...,  1.0000, -0.8870,  0.9963],\n","        [-0.6955,  0.5076,  0.9999,  ...,  1.0000, -0.5861,  0.9942],\n","        [-0.7387,  0.5157,  0.9999,  ...,  1.0000, -0.6076,  0.9935],\n","        ...,\n","        [-0.8725,  0.5233,  1.0000,  ...,  1.0000, -0.2842,  0.9930],\n","        [-0.6818,  0.4959,  0.9999,  ...,  1.0000, -0.4565,  0.9922],\n","        [-0.5651,  0.3801,  0.9995,  ...,  0.9999, -0.8150,  0.9888]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-0.8542, -0.9845, -0.2282, -0.3117,  0.4687,  1.0389, -1.3155,  0.6291,\n","         -0.3204, -0.6478, -0.2326,  0.6887, -0.0938,  0.5955,  0.1796,  0.3401,\n","         -0.1745,  1.0834, -0.0639, -0.5799, -1.5891,  0.0232,  0.1142, -0.1092,\n","          0.3476,  0.9596, -0.0061,  0.3179],\n","        [-0.7569, -0.9386,  0.4301,  0.0954,  0.3778,  0.4046, -0.8767,  0.6184,\n","         -0.4050, -0.6819,  0.0184,  0.6288, -0.2890,  0.4135, -0.0104,  0.5138,\n","          0.0350,  0.8078,  0.2326, -0.9698, -1.5903,  0.1724,  0.3357, -0.3282,\n","          0.0741,  0.8836,  0.0039,  0.1555],\n","        [-0.7117, -0.8209,  0.1471, -0.1174,  0.2430,  0.5519, -0.8790,  0.8812,\n","         -0.5281, -0.3628,  0.1359,  0.6781, -0.2099,  0.5658, -0.2662,  0.2489,\n","         -0.1199,  0.5195, -0.1202, -0.7432, -1.6878,  0.0947,  0.4337, -0.0829,\n","          0.2772,  0.6649,  0.1957,  0.5809],\n","        [-0.8934, -0.8391, -0.0124, -0.3876,  0.4187,  0.5952, -0.9279,  0.6724,\n","         -0.4963, -0.9498, -0.0841,  0.4591, -0.2820,  0.6536,  0.0232,  0.3599,\n","          0.1173,  0.8997, -0.0644, -0.8055, -1.3165,  0.0788,  0.3426, -0.3746,\n","          0.2273,  0.9717,  0.0166,  0.4391],\n","        [-0.6654, -0.9409,  0.5005, -0.1534,  0.2361,  0.6200, -0.9540,  0.8378,\n","         -0.0334, -0.2735,  0.0786,  0.7104, -0.4427,  0.0437,  0.1743, -0.0719,\n","          0.1403,  0.2586,  0.3713, -0.7980, -1.8697,  0.1543,  0.5660, -0.4919,\n","         -0.0148,  0.5980,  0.1238, -0.1239],\n","        [-0.6972, -0.8063,  0.2782, -0.3155,  0.6715,  0.5179, -1.0179,  0.7307,\n","         -0.0335, -0.8028,  0.0181,  0.5828,  0.1451,  0.4309, -0.1391,  0.4193,\n","         -0.1968,  0.6011, -0.1895, -0.6669, -1.4243,  0.4316,  0.3708,  0.0241,\n","          0.0280,  0.7679,  0.0858,  0.5788],\n","        [-0.7526, -0.7394,  0.5137, -0.1918,  0.0936,  1.0827, -0.8693,  0.5820,\n","         -0.3495, -0.5740,  0.1608,  0.4140, -0.4837,  0.3873, -0.0780,  0.2333,\n","         -0.2244,  0.7503, -0.1237, -0.5155, -1.6297,  0.1155,  0.4223, -0.5183,\n","          0.4054,  0.9077,  0.1503,  0.1854],\n","        [-0.7522, -0.9159,  0.1535, -0.2251,  0.4772,  0.4760, -0.9765,  0.7174,\n","         -0.0764, -0.2917, -0.0527,  0.5714, -0.0403,  0.2247,  0.0681, -0.0913,\n","          0.1194,  0.5537,  0.2268, -0.5898, -1.7569,  0.1490,  0.3117, -0.0841,\n","          0.0988,  0.8484,  0.3137,  0.4567],\n","        [-0.5364, -0.6901,  0.5943, -0.1925,  0.1388,  0.3642, -1.1293,  0.4782,\n","         -0.2327, -0.5675, -0.0133,  0.4655, -0.4575,  0.4079,  0.0808,  0.1732,\n","          0.0222,  0.7212,  0.1346, -0.6459, -1.5407,  0.3896,  0.4806, -0.2650,\n","          0.1371,  0.5371,  0.3284,  0.0938],\n","        [-0.7998, -0.5180,  0.1740, -0.1702,  0.1322,  0.5967, -0.7376,  0.5525,\n","         -0.3684, -0.6372, -0.0472,  0.5100, -0.1532,  0.2003, -0.0097,  0.1214,\n","          0.0470,  0.7537, -0.0152, -0.6534, -1.3358,  0.1285,  0.3706, -0.1833,\n","          0.2400,  0.7629,  0.0985,  0.2340],\n","        [-1.0535, -0.6357, -0.0504, -0.4185,  0.5977,  0.3904, -0.9345,  0.6446,\n","         -0.5497, -0.7007,  0.0803,  1.0362, -0.4676,  0.4692,  0.0138,  0.0999,\n","         -0.2084,  1.2295, -0.2980, -1.1635, -1.5496,  0.3444,  0.5348, -0.5044,\n","          0.1286,  0.9844,  0.2445,  0.3833],\n","        [-0.5837, -0.9725,  0.6552,  0.0374,  0.2456,  0.5836, -0.8882,  0.7060,\n","         -0.3565, -0.4567,  0.0530,  0.5815, -0.2545,  0.1376,  0.1115,  0.2715,\n","         -0.2290,  0.4980,  0.1224, -1.0120, -1.9344, -0.0880,  0.5780, -0.3735,\n","          0.0054,  0.8280,  0.1610,  0.5280],\n","        [-0.7202, -0.9219,  0.5236, -0.0356,  0.0976,  0.5299, -1.0357,  0.6526,\n","         -0.1190, -0.4753,  0.1055,  0.4786, -0.3697,  0.3412,  0.1861,  0.1279,\n","          0.2660,  0.3233,  0.2293, -0.7165, -1.7339,  0.0763,  0.3977, -0.4386,\n","         -0.1209,  0.6859, -0.0979,  0.4282],\n","        [-0.7567, -0.9182,  0.5677,  0.0279,  0.5968,  0.4729, -1.0422,  0.6591,\n","         -0.0494, -0.5170,  0.1130,  0.6569, -0.2287,  0.2879,  0.0024,  0.0580,\n","         -0.0675,  0.6555,  0.0415, -0.8135, -1.7116, -0.1330,  0.5531, -0.1644,\n","          0.1583,  0.6696,  0.2282,  0.1100],\n","        [-0.6386, -0.5431,  0.3296, -0.4068,  0.2291,  0.7962, -0.7178,  0.7422,\n","         -0.3780, -0.6459,  0.0490,  0.8685, -0.4632,  0.5249,  0.1226,  0.3368,\n","          0.1183,  0.9584,  0.0730, -1.0574, -1.6248, -0.1025,  0.4276, -0.1578,\n","          0.2705,  0.6468,  0.3509,  0.2744],\n","        [-0.9847, -0.9328,  0.2236, -0.4231,  0.2018,  0.6600, -0.9390,  0.8786,\n","         -0.2730, -0.5103, -0.0623,  0.4038,  0.0801,  0.4848,  0.1855,  0.3654,\n","         -0.3365,  0.9768,  0.1160, -0.5488, -1.5882,  0.2930,  0.6172, -0.1382,\n","          0.3320,  0.8181,  0.2614,  0.3077]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   2% 44/2714 [00:17<17:24,  2.56it/s]\u001b[Aoutputs:\n","(tensor([[[ 0.5218, -0.1329,  0.1113,  ..., -0.1444,  0.4867,  0.1198],\n","         [ 0.0577, -0.1956,  0.4804,  ...,  0.4113,  0.4024, -0.0581],\n","         [-0.4170, -0.6031,  0.0346,  ..., -0.1357, -0.0396,  0.2516],\n","         ...,\n","         [ 0.2418,  0.2999,  0.2586,  ...,  0.3363, -0.1357, -0.1272],\n","         [-0.0094, -0.0394,  0.2888,  ...,  0.0242, -0.0197,  0.0762],\n","         [ 0.1224,  0.1071,  0.4632,  ...,  0.0641,  0.1276, -0.2600]],\n","\n","        [[ 0.1981,  0.2317,  0.2833,  ..., -0.4880,  0.4072, -0.1077],\n","         [ 0.2287, -0.0014,  0.1692,  ...,  0.2106,  0.3327, -0.3991],\n","         [ 0.4015,  0.5425,  0.0487,  ..., -0.0639,  0.4332, -0.4699],\n","         ...,\n","         [-0.0870,  0.0592,  0.2340,  ..., -0.0181,  0.1506, -0.4843],\n","         [ 0.0210,  0.2347, -0.1871,  ..., -0.1033,  0.4272, -0.3379],\n","         [-0.0748, -0.0395,  0.2079,  ..., -0.0038,  0.0864, -0.4212]],\n","\n","        [[ 0.3933,  0.4025, -0.0258,  ..., -0.2840,  0.1452, -0.0871],\n","         [ 0.2589, -0.3202,  0.2866,  ...,  0.0752,  0.2788,  0.2229],\n","         [ 0.5403,  0.8072, -0.2052,  ...,  0.1613,  0.6164,  0.1542],\n","         ...,\n","         [-0.0287,  0.6813, -0.5423,  ...,  0.0260,  0.2640, -0.4448],\n","         [-0.0355,  0.0817, -0.1486,  ..., -0.1594,  0.4156,  0.0459],\n","         [ 0.0769,  0.0289, -0.0466,  ..., -0.3013,  0.2445,  0.0705]],\n","\n","        ...,\n","\n","        [[ 0.2405,  0.0917,  0.1156,  ..., -0.0073,  0.3309,  0.2965],\n","         [-0.4221,  0.3436,  0.4162,  ...,  0.2034,  0.1313, -0.2278],\n","         [-0.2208,  0.4942,  0.3561,  ...,  0.0138,  0.5678,  0.3484],\n","         ...,\n","         [-0.3059,  0.1327,  0.2264,  ..., -0.1161,  0.0809,  0.3338],\n","         [-0.1890,  0.0989,  0.1156,  ...,  0.0111,  0.2227,  0.1995],\n","         [-0.1766,  0.1323,  0.2857,  ...,  0.0595,  0.1600,  0.1946]],\n","\n","        [[ 0.5084,  0.0997, -0.0524,  ..., -0.0652,  0.4156,  0.1569],\n","         [-0.3750, -0.2736,  0.3321,  ...,  0.4951, -0.7693,  0.5115],\n","         [ 0.9432,  0.3246,  0.3100,  ...,  0.3822,  0.1309,  0.9099],\n","         ...,\n","         [-0.1964,  0.1531,  0.1241,  ...,  0.2742,  0.0844, -0.4417],\n","         [ 0.4797, -0.1454, -0.1109,  ...,  0.2969,  0.4036,  0.2435],\n","         [-0.0256,  0.0370, -0.2024,  ...,  0.2747,  0.1868, -0.2050]],\n","\n","        [[ 0.2455,  0.2533,  0.1338,  ..., -0.3705,  0.1196,  0.1308],\n","         [ 0.3654, -0.3923,  0.0603,  ...,  0.0033,  0.1320, -0.1984],\n","         [ 0.7734, -0.1665, -0.4126,  ...,  0.8440, -0.3176, -0.7448],\n","         ...,\n","         [-0.1129,  0.1234, -0.0620,  ..., -0.4052, -0.5679, -0.0622],\n","         [-0.0546, -0.0184, -0.0640,  ..., -0.3066, -0.3800, -0.0727],\n","         [-0.0063, -0.0443,  0.1350,  ..., -0.2046, -0.3783,  0.0283]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward>), tensor([[-0.8353,  0.4439,  0.9999,  ...,  1.0000, -0.5137,  0.9916],\n","        [-0.6951,  0.5645,  0.9999,  ...,  1.0000, -0.7340,  0.9967],\n","        [-0.6361,  0.3835,  0.9998,  ...,  0.9999, -0.6293,  0.9882],\n","        ...,\n","        [-0.8324,  0.5738,  0.9999,  ...,  1.0000, -0.3931,  0.9887],\n","        [-0.7461,  0.5398,  1.0000,  ...,  1.0000, -0.6983,  0.9989],\n","        [-0.8135,  0.4491,  0.9999,  ...,  1.0000, -0.3745,  0.9920]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.8353,  0.4439,  0.9999,  ...,  1.0000, -0.5137,  0.9916],\n","        [-0.6951,  0.5645,  0.9999,  ...,  1.0000, -0.7340,  0.9967],\n","        [-0.6361,  0.3835,  0.9998,  ...,  0.9999, -0.6293,  0.9882],\n","        ...,\n","        [-0.8324,  0.5738,  0.9999,  ...,  1.0000, -0.3931,  0.9887],\n","        [-0.7461,  0.5398,  1.0000,  ...,  1.0000, -0.6983,  0.9989],\n","        [-0.8135,  0.4491,  0.9999,  ...,  1.0000, -0.3745,  0.9920]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-6.0483e-01, -8.5199e-01,  6.3205e-01,  1.6483e-01, -4.8527e-02,\n","          4.1232e-01, -9.5606e-01,  7.1371e-01, -2.5215e-01, -5.7288e-01,\n","          7.9999e-02,  5.1800e-01, -2.6134e-01, -3.1120e-02,  1.2486e-01,\n","          2.7029e-02, -4.4321e-02,  4.6559e-01,  2.1887e-01, -8.4489e-01,\n","         -1.4699e+00,  2.3482e-01,  3.3720e-01, -4.5791e-01,  9.9737e-02,\n","          7.3982e-01,  7.9062e-02,  4.8253e-01],\n","        [-8.1519e-01, -6.5550e-01,  1.9624e-01, -2.0531e-01,  2.9577e-01,\n","          6.5571e-01, -7.7689e-01,  8.2213e-01, -5.7416e-01, -5.4962e-01,\n","          1.4392e-04,  5.8539e-01, -1.9189e-01,  2.4296e-01,  1.5320e-01,\n","          1.7493e-01, -1.6582e-01,  6.9496e-01, -4.3522e-02, -9.4992e-01,\n","         -1.6389e+00,  1.2616e-01,  2.7684e-01, -3.9869e-01,  1.3618e-01,\n","          8.4699e-01,  2.4370e-01,  5.5599e-01],\n","        [-7.1727e-01, -6.2173e-01,  3.2216e-01, -5.2629e-01,  4.6671e-01,\n","          4.7457e-01, -5.8867e-01,  3.3352e-01, -1.6682e-01, -3.8250e-01,\n","          1.5690e-03,  6.5284e-01, -2.6683e-01,  3.0540e-01,  7.9810e-02,\n","          1.4002e-01, -3.5854e-01,  7.8634e-01, -2.4594e-01, -5.4754e-01,\n","         -1.2911e+00,  2.8163e-01,  1.9596e-01,  3.8210e-03,  2.1137e-01,\n","          5.9349e-01,  2.9311e-01,  2.9026e-01],\n","        [-9.8415e-01, -9.1477e-01,  1.9342e-01, -1.7568e-03,  2.6939e-01,\n","          9.1807e-01, -1.0184e+00,  7.0451e-01, -2.7533e-01, -3.5520e-01,\n","         -2.9004e-02,  7.1288e-01, -1.5921e-01,  3.3562e-01, -1.2403e-01,\n","          1.6426e-01,  1.8112e-01,  7.5555e-01,  2.7696e-01, -8.5129e-01,\n","         -1.5003e+00,  1.1107e-01,  4.1311e-01, -1.6250e-01,  2.4423e-01,\n","          7.2067e-01, -2.7733e-02,  2.9820e-01],\n","        [-7.0396e-01, -5.1473e-01,  8.2148e-02, -2.6433e-01,  4.8553e-01,\n","          7.2181e-01, -1.0206e+00,  4.4347e-01, -4.2649e-01, -4.4258e-01,\n","          1.5953e-02,  6.0475e-01, -1.5343e-01,  2.9843e-01, -2.4668e-01,\n","          1.2029e-01, -9.7983e-02,  7.9826e-01, -6.9567e-02, -3.8461e-01,\n","         -1.6228e+00,  2.6694e-01,  4.1132e-01, -3.0133e-01,  1.2681e-01,\n","          6.7766e-01,  4.7129e-01,  3.6159e-01],\n","        [-9.5404e-01, -5.8936e-01,  1.6748e-01,  2.1046e-02,  2.4417e-01,\n","          4.3084e-01, -9.0547e-01,  6.8134e-01, -1.6467e-01, -7.5971e-02,\n","          1.7493e-02,  8.4444e-01, -3.2283e-01,  4.6449e-01,  4.3628e-02,\n","          1.9485e-01, -1.1938e-01,  6.1564e-01,  4.9725e-02, -7.4941e-01,\n","         -1.4995e+00,  3.1574e-01,  4.2839e-01, -3.0926e-01,  5.5065e-03,\n","          7.7673e-01,  1.9606e-01,  3.3278e-01],\n","        [-8.6581e-01, -6.3384e-01,  1.4424e-01, -3.4957e-02,  4.1599e-01,\n","          8.1043e-01, -1.0516e+00,  1.1200e+00, -8.9265e-02, -5.1600e-01,\n","          9.8520e-02,  7.0221e-01,  2.5456e-01,  4.7645e-01,  8.6624e-02,\n","         -7.5105e-02, -1.0261e-02,  8.9102e-01,  1.7066e-01, -6.1800e-01,\n","         -1.6607e+00,  1.0520e-01,  1.8415e-01, -5.8561e-01,  3.7620e-01,\n","          9.6808e-01,  1.2937e-01,  4.6529e-01],\n","        [-4.0076e-01, -7.6614e-01,  5.3182e-01,  3.1063e-02,  4.6426e-01,\n","          5.1200e-01, -9.9731e-01,  6.5284e-01,  1.1466e-01, -3.1656e-01,\n","         -9.8920e-02,  5.2662e-01, -5.0947e-01,  1.6459e-01, -1.5641e-02,\n","          1.0711e-01,  1.0524e-01,  4.6126e-01,  2.0050e-01, -7.8768e-01,\n","         -1.6727e+00,  9.7617e-02,  3.4438e-01, -3.4646e-01, -3.9014e-02,\n","          7.1920e-01,  2.4641e-01,  4.7003e-02],\n","        [-7.0442e-01, -6.4014e-01,  2.1162e-01, -8.6276e-03,  3.2346e-02,\n","          5.9231e-01, -9.0304e-01,  7.3839e-01, -6.4017e-02, -5.8153e-01,\n","          4.7701e-04,  3.4204e-01, -6.5165e-01,  2.4394e-01, -3.7582e-01,\n","         -5.2843e-02, -2.4887e-01,  3.8056e-01,  2.6762e-01, -6.5645e-01,\n","         -1.7796e+00, -1.9376e-01,  4.6063e-01, -1.7591e-01,  1.0369e-01,\n","          7.4885e-01, -1.7222e-01,  2.4324e-01],\n","        [-8.6602e-01, -3.8387e-01,  8.8302e-02, -8.0363e-02,  5.3323e-01,\n","          3.9098e-01, -8.1139e-01,  8.6357e-01, -6.2931e-01, -4.6709e-01,\n","          9.0717e-02,  9.6984e-01, -2.8656e-01,  3.0784e-01,  2.1979e-01,\n","          2.6223e-01, -1.5231e-01,  1.0130e+00, -9.9196e-02, -8.0365e-01,\n","         -1.6532e+00,  2.1186e-01,  3.7370e-01, -4.5544e-01,  3.6705e-01,\n","          7.1266e-01,  1.7779e-01,  5.8090e-01],\n","        [-7.8885e-01, -6.4325e-01,  1.1949e-01, -6.3972e-02,  1.3255e-01,\n","          6.6250e-01, -8.7136e-01,  9.9331e-01, -2.4912e-01, -5.4413e-01,\n","         -2.4480e-01,  6.3657e-01, -3.0074e-01,  5.8214e-01, -1.8869e-01,\n","          1.7241e-01, -2.1201e-01,  8.8381e-01,  7.3823e-02, -7.9166e-01,\n","         -1.6687e+00,  3.3251e-01,  2.0873e-01, -4.2120e-02,  2.1747e-01,\n","          7.7347e-01,  3.1335e-01,  5.7500e-01],\n","        [-7.1587e-01, -7.4201e-01,  5.5218e-01, -5.0839e-02,  1.4710e-01,\n","          3.4417e-01, -7.1094e-01,  6.2086e-01, -9.3782e-02, -3.9313e-01,\n","         -1.4077e-02,  4.7712e-01, -2.1240e-01, -1.1193e-01,  8.3121e-02,\n","          2.2110e-01,  6.4433e-02,  5.1104e-01, -7.3009e-02, -7.5840e-01,\n","         -1.5252e+00,  4.5480e-02,  3.4266e-01, -3.8662e-01,  1.9400e-01,\n","          8.5408e-01,  7.7896e-03,  2.9197e-01],\n","        [-6.3313e-01, -7.3932e-01,  5.1683e-01,  1.5886e-01,  1.4395e-01,\n","          6.5235e-02, -8.0319e-01,  5.7468e-01,  2.2789e-02, -2.7439e-01,\n","          1.8583e-01,  5.1365e-01, -5.4724e-01,  2.2018e-01,  7.6532e-02,\n","         -2.1920e-02, -3.1282e-02,  7.3163e-01,  4.2875e-01, -5.9587e-01,\n","         -1.6648e+00, -3.3626e-01,  1.6906e-01, -2.3834e-01, -8.5703e-03,\n","          7.5582e-01,  5.7632e-02,  2.3078e-01],\n","        [-6.0394e-01, -8.6758e-01,  5.3428e-01,  2.1200e-01,  4.6288e-01,\n","          4.9636e-01, -6.8932e-01,  7.9196e-01, -3.8460e-01, -4.4943e-01,\n","         -1.9228e-02,  4.9805e-01, -4.0288e-01,  2.9201e-01,  6.5716e-02,\n","          1.1159e-01,  1.0488e-01,  5.3174e-01,  1.2895e-01, -8.7878e-01,\n","         -1.4435e+00, -1.1571e-01,  5.6427e-01, -5.4436e-01,  3.1569e-03,\n","          6.8138e-01,  1.3291e-01,  6.3900e-02],\n","        [-9.7806e-01, -6.5791e-01,  4.4357e-01, -1.5843e-02,  4.6345e-01,\n","          4.3361e-01, -1.1623e+00,  8.4423e-01, -1.0939e-01, -8.9958e-01,\n","         -3.5916e-02,  6.2768e-01, -3.0286e-01,  3.6759e-01,  8.9128e-02,\n","          1.3489e-01, -1.2197e-01,  8.3565e-01,  2.4756e-01, -8.7638e-01,\n","         -1.3950e+00,  2.1243e-01,  2.9524e-01, -4.6869e-01,  1.9817e-01,\n","          8.7999e-01,  2.8447e-01,  8.1608e-02],\n","        [-1.0723e+00, -5.5396e-01, -3.7493e-03, -1.9972e-01,  2.2111e-01,\n","          7.3269e-01, -8.0004e-01,  7.4122e-01, -2.1032e-01, -5.3677e-01,\n","         -1.0199e-01,  4.9725e-01, -3.0898e-01,  2.5331e-01, -8.9126e-02,\n","          3.0541e-01, -2.4771e-01,  5.1761e-01, -6.6158e-02, -7.6307e-01,\n","         -1.4751e+00,  3.2550e-01,  5.5307e-01,  6.7150e-02,  3.7149e-01,\n","          4.8856e-01,  3.1019e-03,  4.5795e-01]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   2% 45/2714 [00:17<17:18,  2.57it/s]\u001b[Aoutputs:\n","(tensor([[[ 0.0081,  0.1547, -0.1851,  ..., -0.2002,  0.1824,  0.1059],\n","         [-0.1074, -0.2423,  0.2922,  ...,  0.3754, -0.1513,  0.3761],\n","         [-0.4742,  0.2437, -0.2836,  ...,  0.2502, -0.3075, -0.0611],\n","         ...,\n","         [-0.1962,  0.2582,  0.1347,  ..., -0.0094,  0.1271,  0.0232],\n","         [-0.0959,  0.2805, -0.0355,  ...,  0.1208,  0.1892, -0.0195],\n","         [-0.1089,  0.1639,  0.0704,  ...,  0.2534,  0.2341,  0.2221]],\n","\n","        [[ 0.3096,  0.2734, -0.2462,  ..., -0.2527,  0.1261, -0.0008],\n","         [ 0.4546, -0.2175,  0.0251,  ..., -0.3032, -0.2757, -0.1138],\n","         [ 0.1812,  0.0902, -0.1365,  ...,  0.4978, -0.1170,  0.4988],\n","         ...,\n","         [-0.0059,  0.2489,  0.0455,  ..., -0.6929,  0.0297,  0.0538],\n","         [ 0.0717,  0.2500,  0.1071,  ..., -0.2012,  0.4503, -0.3477],\n","         [ 0.2502,  0.3537, -0.0908,  ..., -0.3347,  0.2691,  0.2945]],\n","\n","        [[ 0.6823, -0.1196,  0.1178,  ..., -0.1008,  0.2477,  0.2923],\n","         [ 0.1896,  0.0156,  0.0162,  ..., -0.0212, -0.3085,  0.2117],\n","         [ 0.3557, -0.4702, -0.4098,  ...,  0.2356, -0.0251,  0.3433],\n","         ...,\n","         [ 0.2484,  0.2516,  0.0996,  ...,  0.0440,  0.0624,  0.2436],\n","         [ 0.3456, -0.0318,  0.0808,  ..., -0.3237,  0.1143,  0.3496],\n","         [ 0.1765,  0.1423, -0.0815,  ...,  0.0291,  0.3446,  0.2881]],\n","\n","        ...,\n","\n","        [[ 0.5754,  0.1256, -0.3764,  ..., -0.1550,  0.3359,  0.3423],\n","         [ 0.5930, -0.3735,  0.1871,  ..., -0.2806,  0.2314, -0.0784],\n","         [ 0.5997, -0.4324, -0.0781,  ...,  0.0557, -0.2335,  0.2311],\n","         ...,\n","         [ 0.4542,  0.1595, -0.1261,  ...,  0.2665, -0.0386, -0.0412],\n","         [ 0.4090,  0.1419,  0.1340,  ...,  0.3045,  0.3343, -0.3988],\n","         [ 0.2133,  0.0236, -0.0376,  ...,  0.2116,  0.2071,  0.1651]],\n","\n","        [[ 0.3425,  0.1787, -0.1653,  ..., -0.1838,  0.3072, -0.0022],\n","         [ 0.4654, -0.2026,  0.6383,  ...,  0.0176,  0.1317, -0.1390],\n","         [ 0.0948,  0.2174,  0.2157,  ...,  0.1897,  0.6106, -0.1370],\n","         ...,\n","         [ 0.1955,  0.1308,  0.4714,  ...,  0.0009, -0.1236, -0.5963],\n","         [ 0.0321,  0.0712,  0.2464,  ...,  0.0451,  0.3714, -0.2932],\n","         [ 0.0660,  0.1151,  0.3365,  ...,  0.0060, -0.0161, -0.3017]],\n","\n","        [[ 0.0356,  0.4268, -0.0253,  ..., -0.2014,  0.3059,  0.0766],\n","         [-0.4135, -0.0498,  0.4267,  ...,  0.1259, -0.1946,  0.3408],\n","         [-0.3005,  0.1533,  0.2650,  ..., -0.1153,  0.4256,  0.2825],\n","         ...,\n","         [ 0.0889,  0.3469, -0.0679,  ..., -0.1093, -0.4208,  0.1250],\n","         [-0.2435,  0.2150, -0.0555,  ...,  0.1646,  0.2367,  0.1261],\n","         [-0.4075,  0.2731,  0.0727,  ...,  0.1160, -0.0065,  0.3823]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward>), tensor([[-0.6303,  0.4789,  0.9997,  ...,  0.9999, -0.6589,  0.9872],\n","        [-0.5061,  0.3649,  0.9995,  ...,  0.9998, -0.6668,  0.9715],\n","        [-0.8250,  0.5647,  0.9999,  ...,  1.0000, -0.5686,  0.9937],\n","        ...,\n","        [-0.7715,  0.4468,  0.9998,  ...,  0.9999, -0.1823,  0.9680],\n","        [-0.6741,  0.4739,  0.9999,  ...,  1.0000, -0.7524,  0.9950],\n","        [-0.7290,  0.4352,  0.9999,  ...,  1.0000, -0.7734,  0.9960]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.6303,  0.4789,  0.9997,  ...,  0.9999, -0.6589,  0.9872],\n","        [-0.5061,  0.3649,  0.9995,  ...,  0.9998, -0.6668,  0.9715],\n","        [-0.8250,  0.5647,  0.9999,  ...,  1.0000, -0.5686,  0.9937],\n","        ...,\n","        [-0.7715,  0.4468,  0.9998,  ...,  0.9999, -0.1823,  0.9680],\n","        [-0.6741,  0.4739,  0.9999,  ...,  1.0000, -0.7524,  0.9950],\n","        [-0.7290,  0.4352,  0.9999,  ...,  1.0000, -0.7734,  0.9960]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-0.7836, -0.9292,  0.3219, -0.2386,  0.2204,  0.6088, -0.9525,  0.9266,\n","         -0.3590, -0.3929, -0.2543,  0.6520, -0.2572,  0.3103,  0.1479,  0.1011,\n","         -0.0693,  0.6427,  0.1900, -0.7364, -1.5720,  0.5109,  0.3089, -0.3046,\n","          0.0042,  0.7460,  0.2099,  0.4054],\n","        [-0.6048, -0.2027, -0.1446, -0.5209,  0.1716,  0.4430, -0.8672,  0.7868,\n","         -0.1359, -0.5124,  0.1551,  0.7529, -0.1303,  0.1886,  0.0738,  0.2040,\n","          0.1647,  0.9416, -0.0094, -1.0885, -1.4025,  0.0748,  0.3525, -0.0731,\n","          0.4740,  0.6730,  0.1215,  0.5302],\n","        [-0.8756, -0.5167,  0.0455,  0.0436,  0.1329,  0.2919, -0.8356,  0.7918,\n","         -0.3820, -0.6064,  0.0309,  0.7547, -0.2632,  0.3356,  0.1370,  0.1368,\n","         -0.2267,  0.6975, -0.0558, -0.6869, -1.5818,  0.3489,  0.3770, -0.2983,\n","         -0.0858,  0.9338,  0.0314,  0.3321],\n","        [-0.3804, -0.5994,  0.5648, -0.0729,  0.1492,  0.3353, -0.6277,  0.7675,\n","         -0.5151, -0.4135,  0.0349,  0.5958, -0.2908,  0.3143,  0.1048,  0.3268,\n","         -0.1696,  0.3530, -0.0638, -0.7690, -1.6057, -0.1849,  0.3722, -0.1290,\n","          0.0674,  0.6011,  0.0730,  0.0678],\n","        [-0.6584, -0.6938,  0.4093, -0.0256,  0.1756,  0.7521, -1.0269,  0.6574,\n","         -0.2008, -0.3203,  0.1166,  0.4677, -0.0726,  0.1954,  0.0451,  0.3688,\n","         -0.3007,  0.8522,  0.3114, -0.8707, -1.3934, -0.2747,  0.3623, -0.2473,\n","          0.2082,  0.8031, -0.1458,  0.2484],\n","        [-0.8081, -0.6352,  0.3523, -0.3794,  0.4152,  0.4241, -1.0587,  0.8170,\n","         -0.1246, -0.3713,  0.0188,  0.6473, -0.0459,  0.4087, -0.2601,  0.1271,\n","         -0.2662,  0.7957, -0.2240, -0.4480, -1.3672,  0.1205,  0.1864, -0.2131,\n","          0.2102,  0.7512,  0.5892,  0.5248],\n","        [-0.8433, -0.6001,  0.2939,  0.0391,  0.4496,  0.5563, -0.9004,  0.6796,\n","         -0.2471, -0.4422, -0.1559,  0.4835, -0.1511, -0.0139, -0.0212,  0.1434,\n","         -0.0944,  0.6506,  0.0209, -0.7651, -1.5907,  0.1249,  0.4947, -0.1431,\n","          0.1007,  0.6328,  0.1347,  0.4090],\n","        [-0.6160, -0.6611,  0.4105, -0.0350,  0.2436,  0.2994, -0.9489,  0.4161,\n","         -0.1803, -0.4776, -0.1892,  0.7746, -0.4030,  0.1163, -0.0822,  0.0407,\n","          0.2330,  0.6036, -0.0173, -0.8581, -1.5520, -0.1645,  0.5695, -0.1252,\n","          0.2971,  0.6759, -0.0078,  0.3230],\n","        [-0.7134, -0.6311,  0.3824, -0.1684,  0.4212,  0.4515, -0.9059,  0.8640,\n","         -0.1291, -0.3276,  0.4445,  0.5974, -0.3122,  0.1542,  0.0290,  0.3529,\n","         -0.1617,  0.5201,  0.2327, -0.4727, -1.2946,  0.0520,  0.1287, -0.1529,\n","          0.2222,  0.7127, -0.2382,  0.5324],\n","        [-0.4710, -0.5222,  0.1702, -0.0839, -0.0241,  0.4176, -0.9724,  0.8596,\n","         -0.3809, -0.5488,  0.0394,  0.8368, -0.3421,  0.1734,  0.0954,  0.0031,\n","          0.0399,  0.7736,  0.3075, -0.7240, -1.5647,  0.2109,  0.4218, -0.4430,\n","          0.1233,  0.7846,  0.0547,  0.3975],\n","        [-0.6631, -0.7748,  0.2852,  0.0685,  0.4859,  0.3472, -1.0778,  0.7886,\n","         -0.0961, -0.5053,  0.0576,  0.3805, -0.4061,  0.5024, -0.0917,  0.0026,\n","         -0.1143,  0.8066, -0.2348, -0.8412, -1.8003,  0.3283,  0.4244, -0.2690,\n","          0.2311,  0.9164,  0.3856,  0.2897],\n","        [-0.7163, -0.6817,  0.1964, -0.0604,  0.4850,  0.4203, -0.8223,  0.8837,\n","         -0.4711, -0.4738, -0.1154,  0.7289, -0.3251,  0.4140, -0.1048,  0.0449,\n","         -0.2483,  0.8116, -0.0033, -0.8582, -1.3665,  0.1729,  0.4240, -0.4587,\n","          0.2857,  0.9931,  0.2624, -0.0773],\n","        [-0.7193, -0.6841,  0.2275,  0.0599,  0.4096,  0.4334, -0.7595,  0.9256,\n","         -0.1370, -0.5556, -0.0506,  0.7083, -0.1666,  0.7457,  0.2593,  0.1856,\n","         -0.3651,  0.8409, -0.1281, -0.8689, -1.3588,  0.2815,  0.2826, -0.2613,\n","          0.3714,  0.8300, -0.0605,  0.3628],\n","        [-0.7701, -0.6082,  0.1236, -0.0347,  0.1225,  0.4166, -0.9096,  0.5444,\n","         -0.0079, -0.4176,  0.0915,  0.5871, -0.4689,  0.0091, -0.0682,  0.1684,\n","         -0.3096,  0.5574,  0.1052, -0.6000, -1.5461,  0.1145,  0.2349, -0.1146,\n","          0.0694,  0.8519,  0.2837,  0.2127],\n","        [-0.8570, -0.5826,  0.1318, -0.1501,  0.6091,  0.6710, -0.8495,  0.5751,\n","         -0.3758, -0.6466, -0.0562,  0.7717, -0.3774,  0.5056,  0.2578,  0.3909,\n","         -0.0588,  0.7448, -0.0439, -0.7704, -1.6334,  0.0595,  0.4476, -0.1313,\n","          0.3822,  0.7017,  0.2453,  0.3761],\n","        [-0.7754, -0.6659,  0.4635, -0.1734,  0.3078,  0.8286, -1.0732,  0.8155,\n","         -0.4691, -0.3679,  0.1769,  0.5720, -0.1735,  0.2011,  0.0453,  0.0508,\n","         -0.2593,  0.8902, -0.0102, -0.7478, -1.2554,  0.2645,  0.4386, -0.2609,\n","          0.4351,  1.0485,  0.2315,  0.5471]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   2% 46/2714 [00:17<17:32,  2.54it/s]\u001b[Aoutputs:\n","(tensor([[[ 6.0737e-01,  1.8823e-01, -2.8504e-02,  ..., -3.4986e-01,\n","           3.2228e-01,  2.6296e-01],\n","         [ 3.7525e-01, -5.3472e-01,  5.7162e-01,  ..., -2.7737e-01,\n","           4.8333e-02,  2.3968e-01],\n","         [ 4.1988e-02,  1.6039e-01, -9.1006e-02,  ...,  4.0605e-01,\n","          -5.0985e-02, -2.2945e-01],\n","         ...,\n","         [-1.3707e-02, -8.6824e-02,  1.6656e-01,  ...,  9.9239e-03,\n","           2.9418e-01,  9.6014e-02],\n","         [-2.3873e-01,  3.2792e-02, -7.9707e-02,  ..., -3.3371e-01,\n","           1.7450e-01,  1.6772e-01],\n","         [-2.1939e-01,  9.6997e-02, -4.6597e-02,  ...,  1.4887e-01,\n","           3.5204e-01,  1.4651e-01]],\n","\n","        [[ 5.4313e-01,  3.5072e-01,  2.6324e-01,  ..., -3.8989e-01,\n","           5.0057e-01, -7.2108e-02],\n","         [ 7.9524e-01, -8.6470e-02,  4.1909e-02,  ..., -4.8982e-04,\n","           1.9359e-01,  6.1574e-02],\n","         [-2.8711e-01,  2.7677e-01,  3.3064e-01,  ..., -3.6700e-01,\n","          -2.4479e-01, -1.4152e-01],\n","         ...,\n","         [ 3.5460e-01, -1.7350e-01,  5.3033e-01,  ..., -1.3572e-01,\n","          -7.7404e-02, -1.3652e-01],\n","         [ 1.5550e-01, -2.2428e-01,  2.6354e-01,  ...,  2.5590e-02,\n","           4.3002e-01, -1.3193e-02],\n","         [-2.2035e-01, -8.1690e-02,  3.7889e-01,  ..., -9.0934e-02,\n","           2.0612e-01,  1.8731e-01]],\n","\n","        [[-3.6773e-02,  7.0135e-01,  4.9444e-01,  ..., -3.4458e-01,\n","           2.1036e-01,  3.0760e-01],\n","         [ 2.5247e-01, -1.9085e-01,  7.2477e-01,  ..., -6.7066e-02,\n","           1.4898e-01,  2.4273e-02],\n","         [-9.9237e-02, -7.3269e-02,  2.2469e-01,  ...,  3.9532e-01,\n","          -2.9601e-01,  2.9585e-01],\n","         ...,\n","         [-4.3402e-01,  7.3782e-01, -9.1964e-02,  ..., -9.5134e-02,\n","          -2.8555e-01,  2.8800e-01],\n","         [-3.5809e-01,  6.8013e-01, -8.0168e-02,  ..., -8.6502e-02,\n","          -2.9338e-01,  3.6932e-01],\n","         [-3.4487e-01,  7.6356e-01, -1.9825e-01,  ...,  1.8546e-02,\n","          -3.6723e-01,  3.5197e-01]],\n","\n","        ...,\n","\n","        [[ 4.5069e-01,  3.0486e-01, -7.5677e-02,  ..., -4.7029e-01,\n","           1.1217e-02,  7.2592e-02],\n","         [ 3.5508e-01, -1.1960e-01,  9.0770e-02,  ...,  1.4468e-01,\n","           5.0633e-02,  4.2580e-01],\n","         [-4.4793e-01, -5.1144e-01,  3.9583e-02,  ...,  4.7697e-01,\n","          -2.9978e-01,  3.4858e-01],\n","         ...,\n","         [ 5.0160e-02,  2.8076e-01, -4.9402e-01,  ..., -1.0978e-01,\n","           2.4938e-01, -4.2530e-02],\n","         [ 8.9244e-02,  2.1587e-01, -6.8695e-01,  ..., -1.0970e-01,\n","          -4.2512e-02,  5.0020e-02],\n","         [ 1.6215e-01,  1.7543e-01, -9.3519e-02,  ..., -7.1804e-02,\n","          -5.5164e-02, -8.6110e-04]],\n","\n","        [[ 5.5767e-01,  9.1976e-02, -1.1206e-01,  ..., -7.1167e-02,\n","           8.5222e-02, -8.1678e-02],\n","         [ 2.5253e-01, -5.8448e-01,  3.9874e-01,  ...,  2.1578e-01,\n","          -1.9769e-01,  2.7183e-03],\n","         [ 2.3067e-01, -3.6552e-01, -2.5247e-01,  ...,  3.1847e-01,\n","           1.9083e-01, -2.9125e-01],\n","         ...,\n","         [ 8.5650e-02, -1.0120e-01, -1.7509e-01,  ...,  5.6870e-02,\n","          -2.2115e-01, -8.8536e-02],\n","         [ 2.1703e-01,  4.7647e-02, -2.5921e-01,  ...,  1.3013e-01,\n","          -3.7018e-01, -9.7407e-02],\n","         [ 1.5936e-01,  1.4784e-01, -1.6139e-01,  ...,  8.3618e-02,\n","          -1.2637e-01,  1.0796e-01]],\n","\n","        [[ 2.5485e-02,  1.1885e-01, -3.0809e-02,  ...,  2.7487e-01,\n","           5.1049e-01,  5.7497e-02],\n","         [-3.1661e-01,  2.0526e-01,  1.9491e-01,  ...,  3.5174e-01,\n","           1.4734e-01,  3.6462e-01],\n","         [ 3.8849e-01,  1.7433e-01,  3.1874e-01,  ..., -1.7371e-01,\n","           6.9866e-01,  7.6912e-01],\n","         ...,\n","         [-1.0534e-01,  2.3246e-01, -3.6753e-02,  ...,  4.3981e-01,\n","           2.9748e-01,  1.3525e-03],\n","         [ 7.4791e-02,  3.5373e-01, -2.3823e-02,  ...,  4.8003e-01,\n","           3.8115e-01,  1.7877e-01],\n","         [-5.8244e-02,  1.8653e-01,  5.5047e-02,  ...,  2.4388e-01,\n","           3.1840e-01,  1.3055e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward>), tensor([[-0.7126,  0.4750,  1.0000,  ...,  1.0000, -0.7169,  0.9931],\n","        [-0.8577,  0.5349,  1.0000,  ...,  1.0000, -0.2911,  0.9975],\n","        [-0.7483,  0.4530,  0.9998,  ...,  1.0000, -0.5922,  0.9967],\n","        ...,\n","        [-0.6095,  0.4043,  0.9996,  ...,  0.9999, -0.6933,  0.9868],\n","        [-0.5706,  0.4880,  0.9997,  ...,  0.9999, -0.8628,  0.9906],\n","        [-0.6305,  0.4063,  0.9997,  ...,  0.9999, -0.4613,  0.9876]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.7126,  0.4750,  1.0000,  ...,  1.0000, -0.7169,  0.9931],\n","        [-0.8577,  0.5349,  1.0000,  ...,  1.0000, -0.2911,  0.9975],\n","        [-0.7483,  0.4530,  0.9998,  ...,  1.0000, -0.5922,  0.9967],\n","        ...,\n","        [-0.6095,  0.4043,  0.9996,  ...,  0.9999, -0.6933,  0.9868],\n","        [-0.5706,  0.4880,  0.9997,  ...,  0.9999, -0.8628,  0.9906],\n","        [-0.6305,  0.4063,  0.9997,  ...,  0.9999, -0.4613,  0.9876]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-0.7610, -0.6975,  0.1987, -0.1075,  0.4409,  0.7241, -1.0319,  0.7557,\n","         -0.2048, -0.5672,  0.1195,  0.6230, -0.4091,  0.2841,  0.0209,  0.3257,\n","         -0.0592,  0.9679,  0.1778, -0.8387, -1.3689,  0.1381,  0.5984, -0.3737,\n","          0.3079,  0.8288,  0.2873,  0.6806],\n","        [-0.8530, -0.5367,  0.4286,  0.1201,  0.2048,  0.5316, -0.9204,  0.5426,\n","         -0.2377, -0.1047,  0.1748,  0.7104, -0.2654,  0.1513,  0.0462,  0.3248,\n","          0.1603,  0.7293,  0.1114, -0.7258, -1.6548,  0.0729,  0.5626, -0.5412,\n","         -0.0208,  0.8673, -0.0982,  0.2819],\n","        [-0.6401, -0.6387,  0.2459, -0.1815,  0.3256,  0.5722, -0.6069,  0.6953,\n","         -0.1643, -0.7403,  0.0395,  0.4803, -0.0836,  0.4173,  0.0185,  0.1420,\n","          0.1014,  0.7427, -0.2761, -0.5593, -2.0028,  0.1533,  0.5217, -0.3025,\n","          0.0534,  0.8247, -0.0554,  0.5181],\n","        [-0.5920, -0.9174,  0.1771,  0.0765,  0.2187,  0.6566, -0.9403,  0.7801,\n","         -0.3991, -0.7840, -0.0200,  0.7996, -0.4215,  0.0731,  0.1740,  0.1576,\n","         -0.0368,  0.8939,  0.0419, -0.9118, -1.3436,  0.3064,  0.1412, -0.5170,\n","          0.1796,  0.8835,  0.1479,  0.5245],\n","        [-0.7326, -0.8187,  0.4100,  0.2505,  0.3875,  0.3566, -0.9796,  0.3581,\n","         -0.1752, -0.4973, -0.0749,  0.5895, -0.4223,  0.3146, -0.4311, -0.1029,\n","         -0.0852,  0.3220, -0.0050, -0.6123, -1.8155, -0.1761,  0.4945, -0.3355,\n","          0.0471,  0.6992,  0.2126,  0.1290],\n","        [-0.7686, -0.6636,  0.4088,  0.3580,  0.2474,  0.4119, -0.9886,  0.9180,\n","         -0.1030, -0.3575, -0.1271,  0.5436, -0.4152,  0.0485,  0.0775,  0.3606,\n","          0.0601,  0.6037,  0.3807, -0.4566, -1.8065, -0.0144,  0.3657, -0.2382,\n","          0.0935,  0.6776,  0.2331,  0.3097],\n","        [-0.7884, -0.7277,  0.7502,  0.0086, -0.1127,  0.5993, -0.9772,  0.6632,\n","          0.0769, -0.3018, -0.0576,  0.6421, -0.4185,  0.1586, -0.0263, -0.1542,\n","         -0.3179,  0.5619,  0.1098, -0.6944, -1.6531, -0.0211,  0.5806, -0.2295,\n","         -0.1348,  0.8347,  0.1848,  0.2483],\n","        [-0.6039, -0.7194, -0.1501, -0.1430,  0.1552,  0.6137, -0.5871,  0.7564,\n","         -0.0828, -0.1227,  0.2099,  0.5200, -0.1542,  0.0998,  0.1043,  0.0467,\n","         -0.0341,  0.8676, -0.0389, -0.5620, -1.7252,  0.3666,  0.2377, -0.2640,\n","          0.2085,  0.6157,  0.0811,  0.2817],\n","        [-0.8556, -0.5231,  0.0906, -0.0997,  0.3061,  0.1723, -0.8730,  0.7218,\n","         -0.1446, -0.6150, -0.0577,  0.8076, -0.5129,  0.4830,  0.0106,  0.2596,\n","          0.0535,  0.7181, -0.0750, -0.8317, -1.9418, -0.0790,  0.1845, -0.4938,\n","          0.2345,  0.9970,  0.4245,  0.0428],\n","        [-0.7988, -0.8341,  0.4101, -0.0889,  0.1819,  0.5196, -1.0058,  0.6897,\n","         -0.2128, -0.4352, -0.0303,  0.5726, -0.0907,  0.3869,  0.0557,  0.4615,\n","         -0.3688,  0.8113,  0.4175, -0.7444, -1.6364,  0.3061,  0.3238, -0.3977,\n","          0.4461,  0.6953, -0.0108,  0.3884],\n","        [-0.6126, -0.6771,  0.1445, -0.3542,  0.5647,  0.6091, -0.8336,  0.7663,\n","         -0.1632, -0.6830, -0.3520,  0.7167, -0.1450,  0.4680,  0.2498, -0.0387,\n","          0.1558,  0.6828, -0.0861, -0.6184, -1.1964,  0.0536,  0.3823, -0.0885,\n","          0.1809,  0.8322,  0.0501,  0.4369],\n","        [-0.8148, -0.9331,  0.2884, -0.0203,  0.3003,  0.4724, -0.8827,  0.7734,\n","         -0.2253, -0.8745, -0.1595,  0.8798, -0.2690,  0.4462, -0.0844, -0.0049,\n","         -0.1406,  1.0901, -0.1301, -0.7973, -1.5456,  0.1380,  0.2153, -0.4851,\n","          0.2125,  0.9196,  0.4581,  0.5620],\n","        [-0.8447, -0.6363,  0.1001, -0.1600,  0.3961,  0.2752, -0.9582,  0.8850,\n","         -0.0343, -0.6996, -0.1734,  0.6781, -0.1243,  0.5332, -0.0669,  0.3715,\n","         -0.2215,  1.0161,  0.2211, -0.7277, -1.6402,  0.1118,  0.0734, -0.2289,\n","         -0.0609,  0.6613,  0.2899,  0.5332],\n","        [-0.9227, -0.6362,  0.2357, -0.1612,  0.4188,  0.4958, -0.8441,  0.7407,\n","         -0.1016, -0.1754,  0.0818,  0.4528, -0.3133,  0.5512,  0.1881,  0.2657,\n","         -0.1070,  0.9013,  0.1225, -0.8912, -1.2116,  0.0729,  0.2821, -0.0928,\n","          0.3774,  1.0885,  0.3093,  0.2061],\n","        [-0.7155, -0.5969,  0.1702, -0.2938,  0.5090,  0.7562, -1.1632,  0.8047,\n","         -0.1215, -0.6496,  0.1076,  0.7443, -0.0690,  0.5931,  0.1134,  0.2817,\n","         -0.1866,  1.0280, -0.1435, -0.8668, -1.6492,  0.2428,  0.3081, -0.3284,\n","          0.1976,  0.7449,  0.3833,  0.5748],\n","        [-0.5115, -0.9013,  0.4358,  0.0718,  0.0348,  0.3503, -0.7019,  0.5402,\n","         -0.0394, -0.4125, -0.0547,  0.6004, -0.2831,  0.0734,  0.0411,  0.2469,\n","          0.0107,  0.5700,  0.3215, -0.7783, -1.4985, -0.0240,  0.2255, -0.2174,\n","         -0.0576,  0.7410, -0.2156,  0.2419]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   2% 47/2714 [00:18<17:30,  2.54it/s]\u001b[Aoutputs:\n","(tensor([[[ 4.8629e-01,  1.8645e-01, -8.0891e-02,  ..., -4.9047e-02,\n","           3.3823e-01,  1.1296e-02],\n","         [ 1.0707e-01, -1.9557e-01,  6.5900e-02,  ...,  2.1047e-01,\n","           2.1928e-01,  2.4142e-01],\n","         [ 9.3079e-02, -1.6766e-02, -1.3710e-02,  ...,  5.2213e-02,\n","           5.0636e-01,  2.1296e-01],\n","         ...,\n","         [ 1.2388e-01,  2.1662e-01, -3.0054e-01,  ...,  1.9087e-02,\n","           3.8520e-01,  3.1193e-01],\n","         [-4.0909e-02,  2.1189e-01, -5.3923e-02,  ...,  8.5166e-02,\n","           1.1956e-01,  2.2723e-01],\n","         [ 5.2014e-03,  2.5108e-01, -2.6744e-02,  ...,  3.0216e-01,\n","           2.5811e-01,  3.4721e-01]],\n","\n","        [[ 3.5197e-01,  1.6746e-01, -6.3477e-02,  ..., -4.0601e-01,\n","           3.9964e-02, -2.4755e-01],\n","         [ 4.4709e-01, -3.8639e-01,  3.7550e-01,  ..., -5.1280e-01,\n","           7.9046e-02, -1.5783e-01],\n","         [ 9.1984e-02,  3.5709e-01, -4.3587e-01,  ...,  4.2279e-01,\n","          -3.6735e-01, -4.9159e-01],\n","         ...,\n","         [ 3.2434e-01,  3.5146e-01, -1.9229e-01,  ..., -3.9846e-01,\n","           9.1124e-02, -3.1145e-01],\n","         [-1.2356e-02,  2.6247e-02, -9.2476e-02,  ..., -3.9843e-01,\n","          -6.0431e-02,  1.5153e-01],\n","         [ 1.6517e-01,  1.7892e-02, -3.6284e-01,  ..., -1.9013e-01,\n","           3.4244e-02, -1.0359e-01]],\n","\n","        [[ 6.2675e-01,  3.1857e-01, -4.8965e-01,  ..., -1.9949e-01,\n","           6.4496e-01,  1.9706e-01],\n","         [-4.0422e-01, -2.1568e-02,  4.8264e-01,  ...,  9.4875e-02,\n","           7.1345e-01,  6.0720e-01],\n","         [ 2.3041e-01,  2.9136e-01, -1.4198e-01,  ...,  2.1014e-01,\n","           6.6677e-01,  2.6224e-01],\n","         ...,\n","         [ 3.0891e-01, -1.2458e-01, -3.4958e-01,  ..., -4.2731e-02,\n","           2.0721e-01,  1.1745e-01],\n","         [ 3.1277e-01, -5.2610e-03, -2.6977e-01,  ...,  1.5576e-01,\n","           1.8781e-01,  2.2135e-02],\n","         [ 3.5619e-01, -1.1067e-01, -3.5418e-01,  ...,  2.9124e-01,\n","           1.5364e-01,  6.2598e-02]],\n","\n","        ...,\n","\n","        [[ 4.0669e-01,  3.2048e-01,  1.0731e-01,  ...,  7.7694e-04,\n","           5.9549e-01,  3.4953e-01],\n","         [ 3.7278e-01, -6.0228e-01,  4.3012e-01,  ...,  3.3999e-01,\n","           3.9065e-01,  2.6596e-01],\n","         [ 7.7327e-02,  8.3600e-02,  6.1235e-02,  ...,  7.4222e-01,\n","          -3.6221e-01, -5.7574e-01],\n","         ...,\n","         [-1.4914e-01,  2.5195e-01,  3.2624e-01,  ...,  1.7265e-01,\n","           4.5481e-01,  2.5498e-01],\n","         [-1.3778e-01,  2.3788e-01,  3.4601e-01,  ...,  2.6115e-01,\n","           6.0842e-01,  4.3967e-01],\n","         [ 4.4868e-01, -1.3066e-01, -9.3503e-02,  ...,  4.2796e-01,\n","           2.1414e-01,  4.3155e-02]],\n","\n","        [[ 7.0339e-01,  1.2261e-01,  4.0030e-02,  ..., -2.8408e-01,\n","           3.2680e-01,  2.9002e-01],\n","         [ 3.3688e-01, -3.5966e-01,  4.2988e-01,  ..., -1.4193e-01,\n","          -1.9094e-01,  4.2534e-01],\n","         [ 1.8274e-01,  1.9655e-01, -3.7543e-01,  ...,  4.8928e-01,\n","           3.4053e-01,  2.1792e-01],\n","         ...,\n","         [-1.6952e-01, -2.1574e-02,  2.8355e-01,  ...,  1.2150e-01,\n","           5.7759e-02,  2.6000e-01],\n","         [ 9.2923e-03,  3.1721e-01, -9.2396e-02,  ..., -5.4460e-02,\n","          -2.2861e-01,  4.9649e-01],\n","         [-1.2840e-01,  4.5793e-01, -2.4626e-01,  ...,  3.6508e-02,\n","          -7.0693e-02,  3.8335e-01]],\n","\n","        [[ 2.4842e-01,  3.0671e-01,  2.1590e-01,  ...,  1.5879e-01,\n","           5.9316e-01,  1.0515e-01],\n","         [ 1.3720e-01,  3.1105e-01,  4.7986e-02,  ...,  1.7399e-01,\n","           2.5168e-01,  3.1264e-01],\n","         [ 6.7707e-01,  1.0139e+00,  1.0460e+00,  ...,  1.0103e-01,\n","          -2.9983e-01,  4.8188e-01],\n","         ...,\n","         [ 3.0260e-02,  1.7787e-01, -6.8588e-02,  ...,  1.4554e-01,\n","           3.2818e-01,  2.0709e-01],\n","         [-2.9986e-03,  2.2588e-01,  1.0764e-01,  ...,  1.0998e-01,\n","           1.7216e-01, -1.3398e-01],\n","         [ 8.3654e-02,  3.3667e-01,  7.1496e-02,  ...,  3.2144e-01,\n","           3.5978e-02,  1.6268e-02]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward>), tensor([[-0.8100,  0.4940,  0.9999,  ...,  0.9999, -0.6371,  0.9858],\n","        [-0.4896,  0.4112,  0.9989,  ...,  0.9998, -0.8873,  0.9809],\n","        [-0.7492,  0.4925,  1.0000,  ...,  1.0000, -0.5927,  0.9977],\n","        ...,\n","        [-0.8245,  0.4957,  0.9999,  ...,  1.0000, -0.3843,  0.9928],\n","        [-0.8428,  0.5114,  0.9999,  ...,  1.0000, -0.4520,  0.9933],\n","        [-0.7570,  0.4690,  0.9999,  ...,  1.0000, -0.2110,  0.9957]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.8100,  0.4940,  0.9999,  ...,  0.9999, -0.6371,  0.9858],\n","        [-0.4896,  0.4112,  0.9989,  ...,  0.9998, -0.8873,  0.9809],\n","        [-0.7492,  0.4925,  1.0000,  ...,  1.0000, -0.5927,  0.9977],\n","        ...,\n","        [-0.8245,  0.4957,  0.9999,  ...,  1.0000, -0.3843,  0.9928],\n","        [-0.8428,  0.5114,  0.9999,  ...,  1.0000, -0.4520,  0.9933],\n","        [-0.7570,  0.4690,  0.9999,  ...,  1.0000, -0.2110,  0.9957]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-6.6168e-01, -7.7011e-01,  3.0222e-01, -2.8716e-02,  3.7322e-01,\n","          5.4036e-01, -8.2261e-01,  6.6530e-01, -3.0088e-01, -2.6783e-01,\n","         -1.1183e-01,  6.9320e-01, -1.7126e-01,  2.9414e-01, -2.4670e-02,\n","          3.2803e-02, -3.0056e-02,  5.6542e-01, -2.1312e-01, -8.7585e-01,\n","         -1.7120e+00, -4.6664e-02,  2.7902e-01, -3.0373e-01, -5.5151e-02,\n","          6.7456e-01,  1.8394e-02,  2.3470e-01],\n","        [-8.6629e-01, -6.9574e-01,  2.1677e-01, -2.2196e-01,  4.9753e-01,\n","          3.5146e-01, -1.0016e+00,  7.8492e-01, -4.9969e-01, -4.2783e-01,\n","         -1.8532e-02,  6.4823e-01, -1.7546e-02,  4.2280e-01, -6.9463e-02,\n","          4.0706e-01, -5.9867e-01,  1.0831e+00,  6.9670e-02, -7.5253e-01,\n","         -1.0059e+00,  3.0359e-01,  1.2087e-01,  2.7428e-02,  5.1611e-01,\n","          1.0185e+00,  2.1565e-01,  3.2414e-01],\n","        [-6.6861e-01, -8.1093e-01,  4.6366e-01, -7.6675e-02,  5.3062e-01,\n","          3.5866e-01, -7.9661e-01,  6.6258e-01, -1.2299e-01, -2.4070e-01,\n","         -7.6780e-02,  4.8297e-01, -1.7761e-02,  3.1060e-01,  4.3148e-02,\n","          3.5927e-01, -9.1625e-02,  7.4289e-01,  2.0475e-01, -1.0532e+00,\n","         -1.6207e+00,  8.7794e-02,  4.6208e-01, -4.5436e-02, -5.4105e-02,\n","          6.3602e-01,  1.3542e-01,  6.4403e-01],\n","        [-6.2863e-01, -5.6648e-01,  1.9396e-01, -1.8249e-01,  3.9337e-01,\n","          5.8288e-01, -9.4238e-01,  4.4655e-01, -3.4608e-02, -5.5167e-01,\n","          1.9158e-01,  7.4602e-01, -5.9533e-01,  5.8869e-01,  2.8194e-01,\n","          1.4644e-01,  6.7108e-03,  8.2623e-01,  1.9167e-01, -7.5908e-01,\n","         -1.6031e+00,  2.1592e-01,  8.2617e-02, -6.0372e-02,  2.5339e-01,\n","          7.2779e-01,  1.3636e-01,  3.2717e-01],\n","        [-6.5626e-01, -7.6350e-01, -6.9871e-02, -7.0695e-01,  6.9925e-01,\n","          3.1306e-01, -6.4722e-01,  8.5459e-01, -3.7825e-01, -6.1985e-01,\n","         -1.8331e-01,  5.7553e-01, -8.0767e-02,  3.3897e-01,  2.8372e-03,\n","          3.2829e-01, -2.9724e-01,  8.9666e-01, -1.6870e-01, -9.0335e-01,\n","         -1.7818e+00,  2.0329e-01,  3.3250e-01, -1.8032e-01,  6.8610e-01,\n","          7.2647e-01,  2.0680e-01,  5.2128e-01],\n","        [-8.1481e-01, -9.2019e-01,  2.8957e-01, -4.9188e-02,  2.3155e-01,\n","          5.5890e-01, -9.6651e-01,  8.2823e-01, -3.0200e-01, -3.3844e-01,\n","         -1.9746e-02,  6.3776e-01, -3.0692e-01,  4.3392e-01, -3.7543e-01,\n","          1.9882e-01, -2.4722e-01,  7.1727e-01,  1.9963e-01, -6.4031e-01,\n","         -1.7415e+00, -2.8769e-01,  4.3727e-01, -3.6326e-01, -1.8141e-01,\n","          1.0243e+00,  8.9341e-02,  2.3874e-01],\n","        [-8.2835e-01, -6.9919e-01,  2.0401e-01,  4.3857e-02,  4.0441e-01,\n","          6.5058e-01, -6.5603e-01,  6.8517e-01, -2.4259e-01, -3.4985e-01,\n","          1.7953e-01,  7.8037e-01, -3.4436e-01,  2.8956e-01, -2.2105e-02,\n","          3.6252e-01, -1.5996e-01,  6.3650e-01,  1.0269e-01, -4.8592e-01,\n","         -1.3613e+00, -2.3106e-01,  3.5983e-01, -3.4170e-01,  9.5380e-02,\n","          6.0020e-01,  1.4301e-01,  3.9987e-01],\n","        [-7.2936e-01, -5.3694e-01,  2.4198e-01, -1.8512e-01,  3.9596e-01,\n","          6.5138e-01, -9.9047e-01,  7.7952e-01, -3.7511e-01, -4.4420e-01,\n","         -9.8348e-02,  5.6522e-01, -2.3943e-01,  5.5835e-01,  1.7342e-01,\n","         -5.0976e-02, -1.6872e-01,  6.1857e-01,  5.0085e-02, -7.9201e-01,\n","         -1.5673e+00,  2.2870e-01,  6.5063e-01, -3.3910e-01,  5.3145e-02,\n","          6.5628e-01,  4.0292e-01,  1.2536e-01],\n","        [-6.3006e-01, -6.2322e-01,  4.7297e-01,  1.9830e-01,  3.3804e-01,\n","          4.9404e-01, -8.5893e-01,  5.1913e-01, -2.9424e-01, -5.7183e-01,\n","          2.7948e-01,  2.6392e-01, -3.2931e-01,  3.6293e-01,  2.5247e-01,\n","          4.7903e-02,  3.2803e-01,  6.8250e-01,  2.3594e-01, -7.9294e-01,\n","         -1.6330e+00, -1.2122e-01,  3.2220e-01, -2.2977e-01, -3.3199e-02,\n","          7.2248e-01, -6.2268e-02,  1.4102e-01],\n","        [-7.2077e-01, -7.9142e-01,  7.0302e-01,  3.3011e-01,  2.7857e-01,\n","          2.2427e-01, -1.0128e+00,  6.0069e-01, -1.2767e-01, -4.9404e-01,\n","          2.1153e-01,  4.5656e-01,  1.8964e-02,  3.3952e-01,  2.7507e-01,\n","          1.0188e-01,  1.0405e-01,  8.1933e-01,  1.6304e-01, -7.2339e-01,\n","         -1.5382e+00,  4.0290e-02,  2.1979e-01, -2.9874e-01,  1.1490e-01,\n","          7.3697e-01, -5.0819e-02,  2.1796e-01],\n","        [-6.9789e-01, -5.2223e-01,  3.3242e-01, -1.8240e-01,  4.8825e-01,\n","          4.7393e-01, -1.1508e+00,  8.5685e-01, -4.3755e-01, -7.1161e-01,\n","          1.3790e-01,  8.1900e-01, -1.8640e-01,  2.2324e-01,  1.6838e-01,\n","         -6.9231e-03, -1.9844e-01,  8.9778e-01,  1.3797e-01, -8.7764e-01,\n","         -1.6708e+00,  3.6092e-01,  2.1307e-01,  2.6516e-04,  4.1692e-01,\n","          7.8506e-01,  8.9944e-02,  7.0315e-01],\n","        [-6.1966e-01, -6.4122e-01,  5.5555e-01,  4.4682e-02,  2.0674e-01,\n","          9.7109e-02, -8.8535e-01,  4.5714e-01, -9.3832e-02, -4.4962e-01,\n","          2.4184e-01,  9.9017e-01, -2.6805e-01,  2.7215e-02,  2.9303e-01,\n","         -2.9605e-03,  3.0542e-01,  6.7850e-01,  2.2106e-01, -5.4384e-01,\n","         -1.8410e+00,  1.2632e-01,  3.1143e-01, -5.5826e-01,  6.2726e-03,\n","          8.2145e-01,  9.2694e-02,  1.3130e-02],\n","        [-4.9690e-01, -9.4494e-01,  5.3422e-01,  5.1324e-02,  2.2588e-01,\n","          4.7132e-01, -8.7559e-01,  5.8149e-01, -1.2750e-01, -3.3765e-01,\n","         -1.8193e-01,  6.1532e-01, -4.1649e-01, -6.5413e-03,  2.3570e-01,\n","          5.8746e-02,  3.1905e-02,  6.4575e-01,  1.4654e-01, -5.1374e-01,\n","         -1.7274e+00, -9.7755e-02,  1.3490e-01, -3.0574e-01,  1.7321e-01,\n","          6.8011e-01,  1.1725e-02,  3.0318e-01],\n","        [-5.0698e-01, -8.7752e-01,  3.4140e-01, -3.8796e-01,  3.8546e-01,\n","          5.4386e-01, -1.1335e+00,  6.3516e-01, -2.4631e-01, -5.3733e-01,\n","         -2.1828e-01,  6.5351e-01, -3.0649e-01,  3.3762e-01, -3.0829e-02,\n","          1.6941e-01, -1.4327e-02,  5.7407e-01,  2.6460e-01, -6.4740e-01,\n","         -1.5051e+00, -2.1421e-01,  3.5147e-01, -1.0811e-01,  1.1472e-02,\n","          4.8487e-01,  1.9385e-01,  4.1341e-01],\n","        [-9.5894e-01, -8.2964e-01,  3.7007e-01, -2.2670e-01,  2.3196e-01,\n","          4.1495e-01, -8.4003e-01,  7.6631e-01, -1.9111e-01, -7.6971e-01,\n","         -4.2385e-02,  6.8186e-01, -4.9315e-01,  6.0775e-01,  2.8735e-02,\n","          6.2738e-02, -3.6767e-01,  4.3656e-01, -1.8979e-01, -6.7338e-01,\n","         -1.5467e+00,  6.9190e-02,  1.9256e-01, -6.8386e-01,  1.3855e-01,\n","          8.7456e-01,  2.6164e-01,  2.6132e-01],\n","        [-4.1491e-01, -8.9485e-01,  6.1395e-01, -1.0940e-01,  2.1920e-01,\n","          3.1322e-01, -7.3929e-01,  9.2365e-01, -1.0843e-01, -4.6786e-01,\n","         -1.2489e-01,  8.1579e-01, -2.9432e-01,  2.8938e-01, -1.0627e-01,\n","          5.1530e-02, -2.3203e-01,  6.8761e-01,  2.2875e-01, -7.6352e-01,\n","         -1.7396e+00, -5.6989e-02,  4.9426e-01, -3.1772e-01, -8.8944e-04,\n","          8.3587e-01,  1.1738e-01,  4.9982e-02]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   2% 48/2714 [00:18<17:23,  2.55it/s]\u001b[Aoutputs:\n","(tensor([[[ 4.9842e-01,  2.9371e-01, -8.4287e-02,  ..., -5.4522e-02,\n","           3.4641e-01,  4.1374e-02],\n","         [ 2.4755e-02, -8.2670e-02, -1.0470e-01,  ...,  8.1004e-01,\n","           2.4135e-01,  6.7887e-02],\n","         [-1.5500e-01, -2.6880e-01,  2.3873e-01,  ...,  2.8209e-01,\n","           7.3809e-02, -5.4407e-01],\n","         ...,\n","         [-1.1623e-01,  5.4686e-01, -9.8913e-02,  ..., -8.2886e-02,\n","          -6.5423e-03, -8.7787e-02],\n","         [-9.2052e-02,  6.1250e-01,  1.7866e-01,  ...,  3.2416e-01,\n","           1.7788e-01, -2.1400e-01],\n","         [ 6.2447e-02,  9.1749e-02,  3.3810e-02,  ...,  3.3975e-02,\n","           3.3796e-01, -1.8287e-01]],\n","\n","        [[ 2.3410e-01,  1.3694e-01, -1.0380e-01,  ..., -3.4218e-01,\n","           4.3321e-01, -5.6142e-01],\n","         [-5.7314e-02, -2.1104e-01,  3.3499e-02,  ...,  1.1681e-02,\n","          -1.7756e-01,  5.7140e-01],\n","         [-2.0596e-02,  3.6272e-01, -7.3584e-01,  ...,  1.3852e-01,\n","           2.6138e-01, -5.5092e-01],\n","         ...,\n","         [-2.3137e-02,  6.5447e-02, -6.0087e-01,  ..., -4.1322e-02,\n","           1.1718e-01, -4.9354e-01],\n","         [-7.6252e-02, -3.7092e-01, -3.8620e-01,  ...,  1.7539e-01,\n","           1.1380e-01, -2.3971e-01],\n","         [ 2.3083e-02, -3.5400e-01, -4.0592e-01,  ...,  1.7530e-01,\n","          -7.3593e-03, -3.6002e-01]],\n","\n","        [[ 6.7994e-01,  4.4637e-01,  1.4183e-01,  ..., -5.5004e-01,\n","           3.6514e-01,  2.0368e-03],\n","         [-1.3173e-01,  1.7084e-01,  1.2368e-01,  ..., -8.0904e-01,\n","          -4.2170e-01,  5.1372e-01],\n","         [ 2.3211e-01,  9.5826e-02,  5.1081e-02,  ..., -6.6323e-02,\n","           3.1414e-01,  8.4508e-02],\n","         ...,\n","         [ 1.5593e-01,  5.5754e-01, -2.1293e-01,  ..., -4.1477e-01,\n","          -1.1162e-01,  1.2609e-02],\n","         [ 1.9106e-01,  2.2774e-01, -1.8197e-01,  ..., -3.7160e-01,\n","           4.4106e-02,  1.6195e-01],\n","         [ 3.8690e-01,  2.4281e-01, -1.5312e-01,  ..., -6.6611e-01,\n","          -6.4815e-03,  2.3267e-01]],\n","\n","        ...,\n","\n","        [[ 4.7693e-01,  2.2743e-01,  3.8656e-03,  ..., -2.5736e-01,\n","           2.8095e-01, -4.2637e-02],\n","         [ 2.0363e-01, -3.4474e-01,  3.5293e-01,  ..., -9.6663e-02,\n","           7.0942e-02, -7.9174e-04],\n","         [ 1.5252e-01,  1.1176e-02,  2.0927e-01,  ...,  1.0490e-01,\n","          -3.0992e-01,  7.7502e-02],\n","         ...,\n","         [-1.4998e-01,  8.4659e-02, -1.2210e-01,  ...,  3.1772e-02,\n","          -3.0371e-01,  3.0865e-01],\n","         [ 9.7635e-02, -3.1814e-02, -4.1302e-02,  ...,  1.2619e-01,\n","          -1.4557e-01, -1.6223e-01],\n","         [-9.7177e-02, -1.5542e-02,  1.3704e-01,  ...,  1.6951e-01,\n","           1.2469e-01, -1.5769e-01]],\n","\n","        [[ 6.9129e-01,  3.8970e-01, -6.4233e-02,  ..., -3.3829e-01,\n","           2.6045e-01,  1.4686e-01],\n","         [ 3.2661e-02, -3.5194e-01,  2.6932e-01,  ..., -4.6240e-01,\n","           2.3277e-02,  9.0371e-02],\n","         [ 4.0927e-02, -5.7500e-02,  1.5001e-01,  ..., -2.0853e-01,\n","           3.6167e-01, -4.8368e-01],\n","         ...,\n","         [ 1.0791e-01, -5.5034e-03, -8.8036e-02,  ..., -1.1583e-01,\n","           1.6908e-01,  7.5891e-02],\n","         [ 2.1652e-01,  2.9145e-01,  1.7889e-02,  ..., -2.0263e-01,\n","          -2.7278e-01, -1.6721e-01],\n","         [ 3.5404e-01,  5.8268e-02,  1.2040e-01,  ...,  6.4929e-02,\n","           2.2031e-02, -2.7360e-01]],\n","\n","        [[ 4.1186e-01,  4.5179e-01, -1.3983e-01,  ..., -4.0293e-01,\n","           4.0157e-01,  9.8521e-02],\n","         [ 4.7187e-01,  1.6977e-01,  5.1418e-01,  ..., -2.0298e-01,\n","           3.3619e-01,  1.0917e-02],\n","         [-1.6260e-01,  8.5297e-01, -1.1172e-01,  ...,  8.3688e-01,\n","           7.3661e-01,  2.0270e-01],\n","         ...,\n","         [ 4.0785e-02, -1.7334e-01, -4.9728e-01,  ..., -2.4961e-01,\n","          -2.3407e-01, -3.0341e-01],\n","         [ 1.4320e-01,  3.3008e-01, -2.2853e-01,  ..., -2.2053e-01,\n","           2.5518e-01, -8.3517e-02],\n","         [ 3.2178e-01,  1.8465e-01,  4.4095e-02,  ...,  1.0580e-01,\n","           5.3376e-01,  1.5845e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward>), tensor([[-0.7105,  0.4770,  0.9999,  ...,  1.0000, -0.6524,  0.9899],\n","        [-0.6471,  0.3305,  0.9995,  ...,  0.9999, -0.9116,  0.9941],\n","        [-0.8247,  0.6482,  1.0000,  ...,  1.0000, -0.1230,  0.9949],\n","        ...,\n","        [-0.7310,  0.4577,  0.9998,  ...,  0.9999, -0.6427,  0.9872],\n","        [-0.7612,  0.4563,  0.9999,  ...,  1.0000, -0.7934,  0.9966],\n","        [-0.6901,  0.4355,  0.9998,  ...,  0.9999, -0.7171,  0.9953]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.7105,  0.4770,  0.9999,  ...,  1.0000, -0.6524,  0.9899],\n","        [-0.6471,  0.3305,  0.9995,  ...,  0.9999, -0.9116,  0.9941],\n","        [-0.8247,  0.6482,  1.0000,  ...,  1.0000, -0.1230,  0.9949],\n","        ...,\n","        [-0.7310,  0.4577,  0.9998,  ...,  0.9999, -0.6427,  0.9872],\n","        [-0.7612,  0.4563,  0.9999,  ...,  1.0000, -0.7934,  0.9966],\n","        [-0.6901,  0.4355,  0.9998,  ...,  0.9999, -0.7171,  0.9953]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-0.7408, -0.8418,  0.0667, -0.4413,  0.4422,  0.4289, -0.7905,  0.6065,\n","         -0.1717, -0.7087,  0.0899,  0.4396, -0.3899,  0.5330,  0.2526,  0.0471,\n","          0.0382,  0.5724, -0.0227, -0.6243, -1.3788,  0.0505,  0.3855, -0.0770,\n","          0.2348,  0.8952,  0.0135,  0.5480],\n","        [-0.7822, -0.7192,  0.0205, -0.6990,  0.6106,  0.5881, -1.2120,  0.6735,\n","         -0.2984, -0.5199,  0.0356,  0.7377, -0.1570,  0.7191,  0.0796,  0.6845,\n","         -0.2405,  1.0107, -0.2558, -0.6594, -1.4342,  0.1822,  0.2791, -0.1774,\n","          0.3189,  0.9065,  0.1530,  0.8792],\n","        [-0.9308, -0.7475,  0.2722, -0.0045,  0.3776,  0.3280, -1.2054,  0.5425,\n","          0.0975, -0.5941, -0.0616,  0.5404, -0.3562,  0.1371, -0.2284,  0.2167,\n","          0.1109,  0.4397,  0.1344, -1.0923, -1.8313,  0.0668,  0.4519, -0.6262,\n","          0.0562,  0.6994,  0.1993,  0.1128],\n","        [-0.7048, -0.8549,  0.1750, -0.2364,  0.4985,  0.6174, -0.9259,  0.6671,\n","         -0.5532, -0.6053,  0.0635,  0.7556, -0.2062,  0.2343,  0.1074,  0.1871,\n","         -0.2522,  1.0011,  0.0135, -0.5972, -1.6462, -0.0650,  0.5583, -0.1201,\n","          0.0307,  0.8113,  0.4562,  0.3661],\n","        [-0.6641, -0.6732,  0.3022, -0.0945,  0.2853,  0.3155, -1.0467,  0.6263,\n","         -0.2444, -0.5012, -0.1081,  0.7031, -0.3650,  0.2222,  0.1402, -0.0112,\n","         -0.4254,  0.7743,  0.0595, -0.4586, -1.3512,  0.2284,  0.3004, -0.2105,\n","          0.1313,  0.6987,  0.1370,  0.5270],\n","        [-0.7181, -0.9319,  0.4373, -0.0175,  0.4276,  0.2990, -1.0356,  0.7304,\n","         -0.2750, -0.5975,  0.0302,  0.4781, -0.2474,  0.4021,  0.1549,  0.0617,\n","          0.2350,  0.4222,  0.1847, -0.5815, -1.6237, -0.2489,  0.3660, -0.0275,\n","         -0.0830,  0.6149, -0.0796,  0.2073],\n","        [-0.5683, -1.0708,  0.3831,  0.1239,  0.4330,  0.6879, -1.0614,  0.6333,\n","         -0.3150, -0.5512,  0.0429,  0.6201, -0.3052,  0.1630, -0.0197, -0.0429,\n","         -0.1648,  0.5865, -0.2180, -0.8603, -1.5778, -0.2943,  0.1791, -0.3239,\n","          0.0482,  0.6584,  0.1082,  0.3291],\n","        [-0.6976, -0.6675,  0.3108, -0.3317,  0.3003,  0.3958, -1.2751,  0.6320,\n","         -0.3312, -0.6196, -0.2149,  0.5870, -0.1905,  0.4312,  0.0676,  0.2415,\n","         -0.4009,  0.6739,  0.0396, -0.7052, -1.7685,  0.0455,  0.3156, -0.4627,\n","          0.2834,  0.8878,  0.1677,  0.2951],\n","        [-0.4268, -0.6250,  0.2777,  0.0752, -0.1323,  0.3089, -0.7562,  0.3853,\n","         -0.6378, -0.3081,  0.2059,  0.6018, -0.2743,  0.0548,  0.3538, -0.0894,\n","         -0.2206,  0.5468,  0.3424, -0.2896, -1.5064,  0.1519,  0.0710, -0.2332,\n","          0.1189,  0.7132,  0.4014,  0.3035],\n","        [-0.8514, -0.7538,  0.1633, -0.1211,  0.2465,  0.5571, -0.8951,  0.8599,\n","         -0.3425, -0.6511, -0.0895,  0.6949, -0.0331,  0.5521, -0.0205,  0.2734,\n","         -0.1548,  0.8110,  0.3436, -0.7918, -1.5028,  0.3750,  0.2866, -0.1269,\n","          0.1559,  0.9301,  0.1166,  0.5379],\n","        [-1.0491, -0.7983,  0.3296, -0.0078,  0.5705,  0.5412, -0.8161,  0.9494,\n","         -0.0348, -0.6482,  0.0246,  0.4246, -0.1121,  0.2636, -0.0857,  0.2305,\n","         -0.0835,  0.9600,  0.0274, -0.4980, -1.4270,  0.1421,  0.4874, -0.2332,\n","          0.5388,  0.9647, -0.0177,  0.4635],\n","        [-0.7794, -0.7058,  0.2762,  0.0051,  0.2021,  0.3830, -1.0437,  0.5300,\n","         -0.6159, -0.5072, -0.0861,  0.6732, -0.2824,  0.0925,  0.0321, -0.0115,\n","         -0.1410,  0.6468, -0.0657, -0.9580, -1.4352, -0.0706,  0.2691, -0.1996,\n","          0.1828,  0.9884,  0.1308,  0.1413],\n","        [-0.7066, -0.6314,  0.2843, -0.1481,  0.5030,  0.8347, -0.7341,  0.6323,\n","         -0.2496, -0.5409,  0.0536,  0.3516, -0.2048,  0.5506,  0.0675,  0.2465,\n","          0.0462,  0.7572, -0.0841, -1.2371, -1.5892,  0.3567,  0.0078, -0.4365,\n","         -0.0565,  0.8400,  0.4113,  0.5976],\n","        [-0.6934, -0.7484,  0.2298, -0.1436,  0.2134,  0.8230, -0.7552,  0.4078,\n","         -0.2552, -0.4219,  0.0055,  0.4572,  0.0560,  0.3509,  0.0592,  0.1424,\n","          0.0816,  0.5409, -0.1035, -0.6940, -1.5114,  0.2044,  0.2752, -0.1861,\n","          0.4209,  0.6783,  0.4346,  0.5173],\n","        [-0.9108, -0.7602,  0.3018,  0.0050,  0.3712,  0.7456, -1.0746,  0.7283,\n","         -0.4443, -0.5907, -0.1295,  0.5580, -0.3117,  0.6652, -0.0364,  0.0633,\n","          0.1251,  0.7117, -0.1302, -0.6176, -1.4372,  0.1815,  0.0762, -0.5258,\n","          0.2021,  0.7818,  0.0452,  0.0587],\n","        [-0.6248, -0.5505,  0.0818, -0.3196,  0.4528,  0.6540, -0.7436,  0.7921,\n","         -0.4817, -0.1277, -0.0809,  0.7538, -0.3497,  0.4256, -0.3138,  0.0360,\n","         -0.2526,  0.8757, -0.2374, -0.5469, -1.2576,  0.1515,  0.2693, -0.3541,\n","          0.1692,  0.8916, -0.0980,  0.3858]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   2% 49/2714 [00:19<17:13,  2.58it/s]\u001b[Aoutputs:\n","(tensor([[[ 5.2816e-01,  2.4508e-01, -2.8418e-01,  ..., -5.0458e-01,\n","           1.3663e-01, -1.7428e-02],\n","         [ 5.5916e-01, -5.8625e-01,  4.7542e-01,  ..., -3.2064e-01,\n","           1.2486e-01, -1.4915e-01],\n","         [ 3.7372e-01,  9.0630e-01,  1.7877e-01,  ...,  1.7009e-01,\n","           8.9403e-02,  1.5927e-01],\n","         ...,\n","         [ 1.4509e-01,  4.0102e-01, -3.8989e-02,  ..., -2.8920e-01,\n","          -1.3658e-02, -7.6520e-01],\n","         [ 4.7095e-01,  2.2635e-01, -3.4413e-01,  ..., -7.4973e-02,\n","           4.1612e-02, -6.4861e-03],\n","         [ 1.4743e-01,  1.8877e-01, -7.4535e-02,  ..., -9.7207e-02,\n","           1.3447e-01, -5.2402e-02]],\n","\n","        [[ 5.2340e-01,  1.3238e-01, -1.2433e-01,  ..., -1.8034e-01,\n","           3.4016e-01, -1.6158e-01],\n","         [ 4.8825e-01, -1.6518e-01,  4.9827e-02,  ..., -3.8737e-01,\n","           2.9260e-01, -4.5872e-01],\n","         [-1.3206e-01,  5.7508e-02, -4.2114e-01,  ...,  3.9837e-01,\n","           2.0352e-01, -4.4045e-01],\n","         ...,\n","         [ 5.6845e-02,  1.7844e-01, -1.6355e-01,  ..., -1.5825e-02,\n","           2.9455e-01, -2.9069e-01],\n","         [ 2.6396e-01, -3.3040e-04, -3.0200e-01,  ..., -1.4393e-01,\n","           3.6191e-01, -2.2209e-01],\n","         [ 1.1718e-01,  3.0675e-01, -2.3793e-01,  ..., -1.2560e-01,\n","           4.3201e-01, -2.6371e-01]],\n","\n","        [[ 8.0704e-01,  2.1933e-01, -6.9149e-02,  ..., -1.7289e-01,\n","           2.7522e-01,  1.8436e-01],\n","         [ 5.3982e-01, -2.1452e-01,  4.1747e-01,  ..., -2.4929e-01,\n","           9.1100e-02,  3.6464e-01],\n","         [ 7.6050e-01,  1.2335e-01, -3.4672e-01,  ...,  3.2383e-01,\n","           2.4170e-01, -2.4470e-03],\n","         ...,\n","         [-1.4706e-01,  3.3714e-01, -2.6559e-02,  ...,  1.5658e-01,\n","          -3.6255e-01,  1.6569e-01],\n","         [ 1.3564e-01,  3.0415e-01, -8.0647e-02,  ...,  1.5557e-01,\n","           4.9128e-03,  2.8696e-01],\n","         [-1.5826e-01,  2.4619e-01, -1.4109e-01,  ...,  3.4859e-01,\n","          -3.7682e-01,  3.8339e-01]],\n","\n","        ...,\n","\n","        [[ 5.9009e-01,  1.7421e-01,  8.7996e-02,  ..., -4.0014e-01,\n","           4.9295e-01,  2.1433e-01],\n","         [ 3.2699e-01, -1.5687e-01,  2.5566e-01,  ..., -2.8457e-01,\n","           2.5286e-01, -1.4950e-01],\n","         [ 3.1535e-01,  1.2772e+00,  1.6647e-01,  ...,  3.0969e-01,\n","          -5.1425e-01, -5.8727e-02],\n","         ...,\n","         [ 4.8849e-02,  7.0784e-01,  2.1102e-01,  ...,  1.0500e-01,\n","           1.1180e-01,  1.3143e-01],\n","         [ 5.5790e-01,  8.3809e-02,  5.6700e-03,  ...,  1.4936e-01,\n","           3.3404e-01,  1.5307e-01],\n","         [-6.0285e-02,  3.0279e-01,  5.2148e-01,  ..., -6.2174e-02,\n","           4.0768e-02,  1.4016e-01]],\n","\n","        [[ 4.5445e-01,  9.3909e-02, -1.8311e-01,  ..., -3.4133e-01,\n","          -8.6926e-02,  1.7493e-02],\n","         [ 7.1757e-01, -6.0861e-01,  2.4528e-01,  ..., -2.8542e-01,\n","           2.9149e-01, -8.8091e-02],\n","         [ 7.4099e-01, -1.2237e-01, -7.0543e-01,  ..., -2.7412e-01,\n","          -4.6043e-01, -9.6000e-01],\n","         ...,\n","         [ 6.0949e-02,  5.8659e-02, -2.9923e-01,  ...,  1.4031e-01,\n","           1.2448e-01, -3.3451e-01],\n","         [ 1.6762e-01,  1.8435e-01, -2.9066e-02,  ..., -2.3757e-01,\n","           1.9924e-01,  7.5562e-02],\n","         [ 2.3622e-01, -6.3377e-02, -6.7027e-02,  ...,  5.5629e-01,\n","           1.6838e-01, -3.5511e-01]],\n","\n","        [[ 1.9664e-01,  1.8950e-01, -1.0342e-01,  ..., -3.0987e-01,\n","           5.3041e-01,  4.6126e-02],\n","         [ 5.4843e-01, -4.1031e-01,  5.2050e-01,  ..., -3.0570e-01,\n","           3.4466e-01,  3.1165e-01],\n","         [ 1.9273e-01,  3.8947e-02, -7.1148e-01,  ...,  5.6268e-01,\n","          -6.8997e-03, -6.9123e-02],\n","         ...,\n","         [-2.1135e-01,  2.6961e-01, -2.0760e-01,  ..., -3.7619e-01,\n","           4.2941e-01, -9.7596e-02],\n","         [-4.5837e-01,  2.8072e-01, -1.5695e-01,  ..., -2.4386e-01,\n","           1.7773e-01,  1.9940e-01],\n","         [-8.6909e-02,  4.8218e-01,  4.8365e-02,  ..., -9.1958e-02,\n","           2.4072e-01,  4.9258e-02]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward>), tensor([[-0.5470,  0.5010,  0.9999,  ...,  1.0000, -0.7443,  0.9941],\n","        [-0.6720,  0.4479,  0.9999,  ...,  1.0000, -0.3034,  0.9896],\n","        [-0.7601,  0.4541,  0.9999,  ...,  1.0000, -0.5666,  0.9822],\n","        ...,\n","        [-0.7766,  0.4379,  0.9999,  ...,  1.0000, -0.5792,  0.9952],\n","        [-0.6828,  0.4150,  0.9995,  ...,  0.9999, -0.4391,  0.9723],\n","        [-0.7383,  0.5529,  0.9999,  ...,  1.0000, -0.5576,  0.9951]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.5470,  0.5010,  0.9999,  ...,  1.0000, -0.7443,  0.9941],\n","        [-0.6720,  0.4479,  0.9999,  ...,  1.0000, -0.3034,  0.9896],\n","        [-0.7601,  0.4541,  0.9999,  ...,  1.0000, -0.5666,  0.9822],\n","        ...,\n","        [-0.7766,  0.4379,  0.9999,  ...,  1.0000, -0.5792,  0.9952],\n","        [-0.6828,  0.4150,  0.9995,  ...,  0.9999, -0.4391,  0.9723],\n","        [-0.7383,  0.5529,  0.9999,  ...,  1.0000, -0.5576,  0.9951]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-6.9908e-01, -6.0068e-01,  1.0469e-01, -2.8844e-01,  5.2680e-01,\n","          4.2974e-01, -1.1491e+00,  5.9132e-01, -1.8243e-01, -5.7868e-01,\n","         -3.0083e-01,  5.1257e-01, -3.8755e-01,  2.5102e-01, -2.9333e-03,\n","          4.3421e-01, -1.4762e-01,  6.7890e-01,  1.3770e-01, -8.8328e-01,\n","         -1.2300e+00,  5.7440e-01,  4.3005e-01, -2.9617e-01,  5.1135e-01,\n","          6.6966e-01,  1.7214e-01,  5.0229e-01],\n","        [-6.0192e-01, -6.6046e-01,  3.7873e-01, -4.0042e-01,  4.5511e-01,\n","          6.1677e-01, -7.2003e-01,  5.1762e-01, -4.2092e-01, -5.9288e-01,\n","          1.3807e-01,  8.1075e-01, -5.1051e-01,  9.4030e-02,  8.8395e-03,\n","          6.8413e-02, -7.4099e-02,  7.5236e-01,  3.1981e-01, -8.9561e-01,\n","         -1.4379e+00,  2.0222e-01,  6.0887e-01, -3.5299e-01,  1.3923e-02,\n","          6.7126e-01,  1.7818e-01,  6.2982e-01],\n","        [-7.2650e-01, -5.9098e-01,  4.5298e-01, -4.6498e-02,  4.7934e-01,\n","          4.3994e-01, -1.0162e+00,  4.3895e-01, -8.5980e-02, -5.3793e-01,\n","          2.1604e-01,  7.7729e-01, -6.2249e-01,  4.3878e-01,  4.2149e-02,\n","          1.1874e-01, -1.0327e-02,  9.1315e-01, -1.6926e-01, -9.4606e-01,\n","         -1.4813e+00,  1.6849e-01,  6.5346e-01, -4.2711e-01, -1.2948e-01,\n","          7.5254e-01,  4.6803e-01,  3.3321e-01],\n","        [-4.2021e-01, -8.1202e-01,  3.0870e-01, -1.4448e-01,  1.8061e-01,\n","          2.0868e-01, -1.1258e+00,  7.1165e-01, -1.9588e-01, -3.0034e-01,\n","          5.3416e-02,  5.4741e-01, -4.6212e-01,  6.3092e-02,  8.5119e-02,\n","         -7.5546e-02,  9.7213e-02,  7.2528e-01, -1.0510e-01, -4.9879e-01,\n","         -1.4952e+00, -2.3757e-01,  1.5502e-01, -8.0322e-03, -2.2648e-03,\n","          7.9757e-01,  1.0987e-01,  3.8633e-01],\n","        [-8.4746e-01, -6.6495e-01,  2.3053e-02, -5.8641e-01,  5.9712e-01,\n","          9.7519e-01, -1.2778e+00,  6.1390e-01, -2.4817e-01, -4.1339e-01,\n","          4.8357e-02,  6.1614e-01, -2.9549e-01,  6.6671e-01,  1.8874e-01,\n","          1.4372e-01,  2.1891e-02,  1.0610e+00, -1.1018e-01, -9.4404e-01,\n","         -1.4816e+00,  4.3015e-01,  8.4580e-01, -2.5381e-01,  3.2805e-01,\n","          8.9749e-01, -5.6960e-02,  5.2766e-01],\n","        [-9.0799e-01, -5.7446e-01,  3.7948e-01,  9.9703e-02,  4.3998e-01,\n","          5.9390e-01, -7.0108e-01,  4.2375e-01, -1.9107e-03, -4.8439e-01,\n","         -9.3405e-02,  4.4973e-01, -2.2510e-01,  4.2840e-01,  2.2674e-01,\n","          4.0736e-01, -1.5106e-01,  8.5935e-01,  2.2057e-01, -1.0044e+00,\n","         -1.8000e+00,  1.4661e-01,  1.7157e-01, -4.4341e-01,  3.4087e-01,\n","          7.7644e-01,  2.0648e-01,  3.5976e-01],\n","        [-7.8089e-01, -6.2144e-01,  8.6186e-02, -1.6571e-01,  1.0090e-01,\n","          2.8891e-01, -1.0510e+00,  5.5655e-01, -4.8478e-01, -4.2988e-01,\n","         -3.9663e-02,  7.0935e-01, -3.1816e-01,  3.6495e-01,  1.0338e-01,\n","          2.5097e-01, -4.1382e-02,  5.8671e-01, -2.9292e-01, -9.8661e-01,\n","         -1.7300e+00,  5.3323e-01,  2.5690e-01, -2.2879e-01,  7.0565e-02,\n","          6.9366e-01, -1.4147e-02,  4.0829e-01],\n","        [-4.7566e-01, -7.8898e-01,  2.9039e-01, -2.1901e-01,  2.2406e-01,\n","          3.2081e-01, -1.0441e+00,  3.5920e-01, -4.8973e-01, -1.9675e-01,\n","          8.4676e-02,  6.1069e-01, -1.1345e-01,  3.2978e-01,  1.6428e-02,\n","          1.6214e-01,  4.7348e-02,  6.5988e-01,  5.6062e-02, -6.5640e-01,\n","         -1.2371e+00,  1.6565e-02,  5.1809e-01, -1.1972e-01,  1.3240e-01,\n","          6.5603e-01,  9.2613e-02,  1.8566e-01],\n","        [-7.8904e-01, -7.2895e-01,  2.5903e-01, -1.1210e-02,  1.2274e-01,\n","          2.9805e-01, -9.5526e-01,  5.0830e-01, -2.1262e-01, -3.7273e-01,\n","         -6.5969e-02,  4.6131e-01, -2.7923e-01,  2.6591e-01, -1.7898e-03,\n","          1.2409e-01,  1.3711e-01,  6.4818e-01,  1.2930e-01, -8.3043e-01,\n","         -1.6563e+00,  1.5627e-02,  4.4301e-01, -2.7910e-01,  1.7897e-01,\n","          5.6202e-01,  5.3524e-03,  2.0896e-01],\n","        [-8.8500e-01, -5.5265e-01,  3.2516e-01, -6.6516e-01,  2.7449e-01,\n","          3.7576e-01, -1.0640e+00,  8.2445e-01, -2.0560e-01, -7.2461e-01,\n","          8.4759e-02,  7.4379e-01,  2.2564e-01,  5.7154e-01, -4.3981e-02,\n","          2.0824e-01, -2.2405e-01,  7.7281e-01, -1.7278e-01, -6.2633e-01,\n","         -1.0489e+00,  3.8098e-01,  2.8028e-01, -9.1912e-02,  1.7045e-01,\n","          7.2396e-01,  2.9122e-01,  6.5650e-01],\n","        [-7.4481e-01, -6.3906e-01,  3.1476e-01, -2.7326e-01,  2.3962e-01,\n","          3.8877e-01, -8.3489e-01,  5.0246e-01, -2.5614e-01, -5.5085e-01,\n","         -2.0759e-01,  6.7025e-01, -2.4820e-01,  1.5292e-01, -1.0636e-01,\n","          3.2573e-01, -2.9926e-01,  6.9557e-01,  8.0434e-02, -8.5026e-01,\n","         -1.3044e+00, -2.0049e-02,  1.7414e-01, -5.9749e-02,  1.1376e-03,\n","          8.7458e-01,  3.4261e-01,  2.6185e-01],\n","        [-7.5504e-01, -7.2688e-01,  3.0917e-01, -2.5933e-01,  9.0877e-02,\n","          3.5392e-01, -9.4930e-01,  4.9864e-01, -4.5188e-01, -4.2299e-01,\n","         -6.6612e-02,  6.6203e-01, -5.9452e-01,  2.9698e-01, -5.2413e-02,\n","          1.3371e-01, -1.2700e-01,  4.9084e-01, -1.4305e-01, -6.0338e-01,\n","         -1.5665e+00,  2.7914e-01,  6.1188e-01, -2.0568e-01, -1.4010e-01,\n","          6.5738e-01,  6.3374e-02,  1.2663e-01],\n","        [-5.9154e-01, -8.5441e-01,  3.2290e-01,  1.0177e-01,  3.1255e-01,\n","          3.7745e-01, -1.1854e+00,  6.2903e-01, -2.3988e-01, -4.1172e-01,\n","          9.7621e-02,  6.5487e-01, -3.2571e-01,  1.5607e-01,  3.9873e-02,\n","          1.9845e-02,  2.3412e-01,  5.1148e-01,  9.0449e-02, -1.0118e+00,\n","         -1.2374e+00, -7.1205e-02,  4.5784e-01, -8.9316e-02, -3.2794e-02,\n","          6.9019e-01, -8.2804e-02,  3.5450e-01],\n","        [-8.5678e-01, -6.5251e-01,  3.1769e-01, -1.2921e-01,  2.6456e-01,\n","          6.0467e-01, -8.6264e-01,  5.9928e-01, -6.6228e-02, -5.2242e-01,\n","          8.2103e-02,  6.4841e-01, -4.9799e-01,  5.4889e-01,  2.0522e-01,\n","          2.5066e-01, -1.5648e-01,  1.0054e+00,  2.7164e-02, -8.9954e-01,\n","         -1.5231e+00,  2.7704e-01,  5.4142e-01, -4.6060e-01,  1.1299e-02,\n","          8.4900e-01,  9.5783e-02,  2.2819e-01],\n","        [-5.4227e-01, -6.8259e-01,  2.6909e-01, -2.1918e-01,  3.8706e-01,\n","          4.1674e-01, -9.2845e-01,  9.4154e-01, -1.3703e-01, -4.0367e-01,\n","         -2.4559e-01,  4.8063e-01, -1.1726e-01,  3.2854e-01,  9.0664e-02,\n","          1.5876e-01,  1.4125e-02,  6.8711e-01, -1.5232e-01, -8.4640e-01,\n","         -1.4747e+00,  1.7420e-01,  3.0309e-01, -1.3313e-01, -1.8957e-02,\n","          8.3612e-01,  3.0577e-01,  3.2461e-01],\n","        [-7.7258e-01, -7.9421e-01,  4.6780e-01, -2.4102e-01,  4.0751e-01,\n","          4.1277e-01, -1.3029e+00,  8.2089e-01, -2.8533e-01, -3.7990e-01,\n","          2.8572e-02,  6.8807e-01, -4.5852e-01,  1.4414e-01,  3.7884e-02,\n","          8.1300e-02, -1.8726e-01,  5.2956e-01,  1.5586e-01, -1.0809e+00,\n","         -1.6325e+00,  2.9244e-01,  5.7484e-01, -5.2840e-01,  5.0348e-02,\n","          7.0609e-01,  4.6086e-01,  3.2469e-01]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   2% 50/2714 [00:19<17:08,  2.59it/s]\u001b[Aoutputs:\n","(tensor([[[ 1.4417e-01,  9.2778e-02, -4.3530e-02,  ..., -5.0140e-02,\n","           5.1568e-01,  2.3496e-01],\n","         [-3.3656e-01, -4.4324e-01, -1.2231e-01,  ...,  2.2383e-01,\n","           4.7998e-01, -8.7082e-02],\n","         [-3.6129e-01,  2.7480e-01, -1.5256e-02,  ...,  7.7300e-02,\n","          -4.9018e-01,  5.6362e-03],\n","         ...,\n","         [ 5.4711e-02,  3.6451e-01, -2.6365e-01,  ...,  1.9942e-01,\n","           1.4103e-01, -3.3047e-01],\n","         [ 1.0497e-01,  9.7184e-02, -4.9995e-02,  ...,  9.5713e-02,\n","          -1.4101e-02,  9.3167e-02],\n","         [ 2.2857e-01, -5.1219e-02,  5.9115e-03,  ...,  2.6378e-01,\n","           6.1976e-02,  1.3056e-01]],\n","\n","        [[ 3.0254e-01, -9.7868e-02, -2.1521e-01,  ..., -1.7192e-02,\n","           2.9675e-02,  4.4927e-01],\n","         [ 6.9429e-01, -5.6616e-01,  3.1781e-01,  ..., -6.0850e-04,\n","           1.9303e-01,  2.0089e-02],\n","         [ 4.6380e-01, -4.9303e-01, -1.9903e-01,  ...,  3.3838e-01,\n","          -2.5727e-03,  7.4830e-01],\n","         ...,\n","         [ 1.3042e-01, -1.4640e-01, -1.9711e-01,  ...,  1.8858e-01,\n","           3.0183e-01,  3.9988e-01],\n","         [ 1.5181e-01, -4.6253e-02, -1.8629e-01,  ..., -3.0403e-02,\n","           3.4687e-01,  4.1608e-01],\n","         [ 4.8619e-03, -1.5982e-01, -3.2103e-01,  ..., -4.8749e-02,\n","          -7.8921e-03,  2.5484e-01]],\n","\n","        [[ 5.4166e-01,  2.5944e-01, -6.3849e-02,  ..., -2.5810e-02,\n","           4.8581e-01, -1.5134e-01],\n","         [ 2.9374e-01, -7.6124e-01,  6.9159e-01,  ..., -5.2940e-01,\n","           9.0928e-02,  2.4720e-01],\n","         [-1.0018e-01, -2.9298e-01,  7.8401e-02,  ...,  7.5707e-03,\n","          -3.1267e-01, -5.1476e-02],\n","         ...,\n","         [-4.6266e-02,  5.7826e-02, -2.7388e-02,  ..., -1.1800e-01,\n","           1.8617e-01, -1.6043e-01],\n","         [ 1.4652e-01, -5.1030e-02,  9.6145e-02,  ..., -2.5120e-02,\n","           4.0541e-01, -7.6945e-02],\n","         [ 2.2834e-01, -1.7072e-01,  5.5405e-01,  ..., -1.4903e-01,\n","           3.3024e-01, -1.6653e-01]],\n","\n","        ...,\n","\n","        [[ 4.5485e-01,  1.1991e-01, -2.7245e-01,  ..., -1.4926e-01,\n","           9.9699e-02, -3.3210e-02],\n","         [ 3.4251e-01,  3.0776e-02,  3.1742e-01,  ...,  3.0163e-01,\n","           9.1667e-02, -1.3232e-01],\n","         [ 8.1449e-01, -4.5575e-01, -1.8393e-01,  ...,  1.7933e-01,\n","          -2.5286e-01,  2.3632e-01],\n","         ...,\n","         [ 2.4441e-01, -4.2744e-03, -1.4102e-01,  ...,  6.0780e-02,\n","          -3.9911e-02, -6.5906e-02],\n","         [ 7.1988e-02, -1.6379e-01, -4.3230e-01,  ...,  2.0708e-01,\n","          -1.1439e-01, -4.6805e-01],\n","         [ 1.1906e-01,  1.1815e-01, -2.1455e-01,  ..., -5.1776e-01,\n","           2.3970e-01,  3.4424e-01]],\n","\n","        [[ 6.4832e-01,  3.5455e-01,  2.3850e-01,  ..., -7.5909e-02,\n","           4.1353e-01,  2.1419e-01],\n","         [-2.8079e-01, -1.6195e-01,  6.8038e-02,  ..., -1.4242e-01,\n","           6.8897e-01, -9.7473e-02],\n","         [ 3.6277e-01,  4.3788e-01, -1.0575e-01,  ...,  4.3134e-01,\n","           7.5860e-01,  3.0899e-01],\n","         ...,\n","         [-2.3005e-02, -5.0699e-01,  2.4681e-01,  ..., -2.3044e-01,\n","           6.1810e-01, -2.9105e-01],\n","         [ 2.8625e-01,  7.4505e-02, -8.7268e-02,  ...,  4.1647e-01,\n","           6.3895e-01, -5.9505e-02],\n","         [-9.5590e-02, -4.1577e-01,  3.3130e-02,  ..., -1.7748e-01,\n","           6.2466e-01, -2.2182e-01]],\n","\n","        [[ 7.0978e-01, -5.9103e-02, -1.5325e-02,  ..., -8.0497e-02,\n","           5.1566e-01,  3.1637e-01],\n","         [ 6.6046e-01, -4.2427e-01,  6.7216e-01,  ..., -9.5312e-02,\n","           3.7106e-01,  2.9083e-01],\n","         [ 8.4168e-01,  1.4654e-02, -5.6207e-01,  ...,  2.6948e-01,\n","          -8.3792e-02, -4.0027e-02],\n","         ...,\n","         [ 5.0356e-01, -3.1939e-01,  6.3970e-02,  ...,  3.8156e-01,\n","           1.6932e-02, -8.9262e-03],\n","         [ 2.9311e-01, -2.9267e-01, -7.1512e-02,  ...,  1.9761e-01,\n","           8.3004e-02, -3.9687e-02],\n","         [ 2.3051e-01, -1.8090e-01,  1.0750e-01,  ...,  2.2362e-01,\n","          -8.2021e-03, -1.4214e-02]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward>), tensor([[-0.7687,  0.5065,  0.9999,  ...,  1.0000, -0.5942,  0.9924],\n","        [-0.8257,  0.3902,  0.9998,  ...,  0.9999, -0.3600,  0.9805],\n","        [-0.6046,  0.3651,  0.9997,  ...,  0.9999, -0.7762,  0.9911],\n","        ...,\n","        [-0.5944,  0.5216,  0.9997,  ...,  0.9999, -0.5223,  0.9839],\n","        [-0.6429,  0.5026,  0.9999,  ...,  1.0000, -0.7758,  0.9940],\n","        [-0.8443,  0.6060,  1.0000,  ...,  1.0000,  0.2717,  0.9912]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.7687,  0.5065,  0.9999,  ...,  1.0000, -0.5942,  0.9924],\n","        [-0.8257,  0.3902,  0.9998,  ...,  0.9999, -0.3600,  0.9805],\n","        [-0.6046,  0.3651,  0.9997,  ...,  0.9999, -0.7762,  0.9911],\n","        ...,\n","        [-0.5944,  0.5216,  0.9997,  ...,  0.9999, -0.5223,  0.9839],\n","        [-0.6429,  0.5026,  0.9999,  ...,  1.0000, -0.7758,  0.9940],\n","        [-0.8443,  0.6060,  1.0000,  ...,  1.0000,  0.2717,  0.9912]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-0.7350, -0.6051,  0.3741, -0.2106,  0.1371,  0.3975, -1.0428,  0.6284,\n","         -0.2646, -0.5483,  0.0459,  0.3858, -0.4671,  0.6031,  0.1880, -0.0329,\n","         -0.0221,  0.5436,  0.3591, -0.8183, -1.5675,  0.0873,  0.4391, -0.3698,\n","          0.0949,  0.6587,  0.0851,  0.3967],\n","        [-0.7403, -0.6645,  0.0651,  0.0609,  0.5434,  0.6570, -0.7517,  0.4703,\n","         -0.2226, -0.4162, -0.0973,  0.8327, -0.0645,  0.0277,  0.1287, -0.0805,\n","          0.0458,  0.6021,  0.1851, -0.7774, -1.5240, -0.4531,  0.4135, -0.2042,\n","          0.2118,  0.5871, -0.0639,  0.4808],\n","        [-1.0818, -0.9792,  0.1278, -0.1348,  0.4633,  0.5535, -1.0401,  0.7858,\n","          0.0182, -0.2887, -0.1105,  0.8071, -0.1450,  0.3322, -0.0037,  0.3396,\n","         -0.1612,  0.9089,  0.2926, -0.8454, -1.4687,  0.1443,  0.2034, -0.0225,\n","          0.1155,  1.0723,  0.3090,  0.5075],\n","        [-0.6373, -0.6780,  0.5462, -0.1623,  0.3101,  0.2018, -1.2494,  0.6120,\n","         -0.3427, -0.4124, -0.0538,  0.5037, -0.3442,  0.1579,  0.0890,  0.0138,\n","          0.2374,  0.1587,  0.2728, -0.6798, -1.4038, -0.0920,  0.5944,  0.0063,\n","          0.1428,  0.6899,  0.1155,  0.1594],\n","        [-0.6268, -0.8314,  0.3565, -0.0533,  0.3481,  0.7768, -0.8590,  0.7928,\n","         -0.3779, -0.5853, -0.1520,  0.5826, -0.6537,  0.2092, -0.2780,  0.1136,\n","         -0.1836,  0.7607,  0.1647, -0.4127, -1.3447, -0.1038,  0.3777, -0.4812,\n","          0.0907,  0.6800,  0.1326,  0.0669],\n","        [-0.8454, -0.8161,  0.2543, -0.1026,  0.4454,  0.5792, -0.7764,  0.7713,\n","         -0.3542, -0.7487,  0.0445,  0.6293, -0.0437,  0.2102, -0.1002,  0.3156,\n","         -0.2167,  0.7076,  0.0511, -0.7338, -1.5411,  0.0736,  0.2988, -0.2598,\n","          0.4714,  0.7593,  0.0468,  0.6250],\n","        [-0.7195, -0.5175,  0.2178,  0.1545,  0.5329,  0.6418, -0.9194,  0.7828,\n","         -0.0199, -0.1963, -0.1537,  0.8081, -0.4495,  0.2768, -0.2196,  0.1925,\n","          0.0789,  0.4385,  0.0127, -0.8882, -1.4123, -0.1583,  0.3972, -0.0767,\n","          0.0679,  0.5753,  0.2522,  0.3626],\n","        [-0.5256, -0.9867,  0.5121, -0.0569,  0.2504,  0.6552, -0.9973,  0.7240,\n","         -0.2103, -0.6396, -0.1835,  0.2917, -0.2850,  0.5534,  0.1601, -0.0916,\n","         -0.2403,  0.8115, -0.0656, -0.4293, -1.7714, -0.2488, -0.0294, -0.3642,\n","          0.2547,  0.9244,  0.1012,  0.3027],\n","        [-0.8491, -0.8438,  0.4194, -0.2268,  0.4161,  0.8534, -0.8929,  0.8393,\n","         -0.4980, -0.6748, -0.1270,  0.7941, -0.2426,  0.3303,  0.0940,  0.2437,\n","         -0.1303,  0.8152, -0.3577, -1.0462, -1.5732,  0.3192,  0.3440, -0.2512,\n","          0.2703,  0.7685,  0.2662,  0.6083],\n","        [-1.0634, -0.4344, -0.0524, -0.3610,  0.6532,  0.6414, -1.0006,  0.6544,\n","         -0.3955, -0.5166, -0.3169,  0.5817, -0.0750,  0.6659,  0.1804,  0.2173,\n","          0.1478,  1.0116, -0.0265, -0.4177, -1.5236,  0.2557,  0.3153, -0.0699,\n","          0.2832,  0.5291,  0.1396,  0.8242],\n","        [-0.7173, -0.6802,  0.3838, -0.3624,  0.0481,  0.5260, -0.9746,  0.7356,\n","         -0.3162, -0.2847, -0.0501,  0.6795, -0.3230,  0.2460, -0.0988,  0.2315,\n","         -0.1856,  0.7175,  0.0752, -0.7659, -1.9555, -0.0021,  0.5073, -0.4273,\n","          0.1788,  0.6361,  0.0654,  0.4139],\n","        [-0.6879, -0.9107,  0.2110, -0.0586,  0.1511,  0.4665, -1.0850,  1.1510,\n","         -0.1925, -0.6855,  0.0260,  0.7044, -0.2405,  0.4106,  0.1340,  0.0303,\n","          0.1113,  0.7258,  0.0557, -0.8204, -1.5892,  0.1492,  0.2655,  0.0593,\n","          0.0605,  0.6425,  0.2819,  0.3693],\n","        [-0.6489, -0.7610,  0.6163,  0.2644,  0.2531,  0.4230, -0.7887,  0.6514,\n","         -0.2592, -0.5099,  0.0521,  0.5772, -0.2772, -0.0226, -0.0984, -0.2360,\n","          0.0226,  0.4095,  0.0932, -0.8748, -1.5309, -0.3292,  0.3722, -0.3563,\n","         -0.0827,  0.6575, -0.0873,  0.1718],\n","        [-0.5829, -0.8246,  0.4701,  0.1574,  0.5986,  0.5455, -0.9934,  0.5836,\n","         -0.2189, -0.7188, -0.1279,  0.6530, -0.3111,  0.1724, -0.2236,  0.2472,\n","         -0.1990,  0.6550, -0.0530, -0.7827, -1.6522,  0.1204,  0.2540, -0.3391,\n","          0.2431,  0.7829,  0.2700,  0.5551],\n","        [-0.9264, -0.7517,  0.2886, -0.0986,  0.3827,  0.6298, -0.6399,  0.6519,\n","         -0.3242, -0.6266, -0.1363,  0.7604, -0.4399,  0.5002, -0.1937,  0.1695,\n","         -0.0211,  0.8115, -0.0509, -0.8063, -1.7774,  0.1202,  0.2546, -0.2888,\n","          0.1518,  0.9585,  0.1867,  0.3598],\n","        [-0.7551, -0.6760,  0.5047,  0.2579,  0.2532,  0.4801, -0.7480,  0.4970,\n","         -0.0584, -0.4806,  0.0063,  0.5025, -0.6995, -0.1195,  0.0152,  0.0496,\n","         -0.1379,  0.5595,  0.1078, -0.5378, -1.9488,  0.1213,  0.3457, -0.4805,\n","          0.0740,  0.7219, -0.1155,  0.1611]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   2% 51/2714 [00:19<17:05,  2.60it/s]\u001b[Aoutputs:\n","(tensor([[[ 0.6075,  0.1629, -0.1362,  ..., -0.2651,  0.2648, -0.3938],\n","         [ 0.7233, -0.3690,  0.5829,  ..., -0.0328,  0.2814,  0.1282],\n","         [ 0.5612, -0.3351,  0.0923,  ...,  0.3115, -0.5671,  0.0777],\n","         ...,\n","         [ 0.2251,  0.5690, -0.1081,  ..., -0.2086, -0.0179, -0.0920],\n","         [ 0.4772,  0.1136, -0.1606,  ..., -0.2830,  0.3358,  0.1040],\n","         [ 0.5269,  0.1621,  0.0749,  ...,  0.0312, -0.0653,  0.1241]],\n","\n","        [[ 0.3536,  0.1319,  0.0580,  ..., -0.1856,  0.3879,  0.0290],\n","         [ 0.5789, -0.4622,  0.6258,  ..., -0.1414,  0.0888,  0.0898],\n","         [ 0.2266, -0.4938,  0.2270,  ...,  0.6866, -0.5123, -0.3995],\n","         ...,\n","         [-0.1001,  0.1870, -0.1127,  ..., -0.0041, -0.2481,  0.0181],\n","         [-0.1127,  0.2471, -0.0761,  ...,  0.0995,  0.0276,  0.0595],\n","         [ 0.2664,  0.2595,  0.3719,  ...,  0.1403, -0.3190,  0.5337]],\n","\n","        [[ 0.1850, -0.0426, -0.0952,  ...,  0.0641,  0.2113,  0.1134],\n","         [ 0.0039, -0.3982, -0.1745,  ...,  0.6984,  0.4574,  0.0993],\n","         [ 0.5293, -0.1469, -0.3272,  ...,  0.1809, -0.3621,  0.2451],\n","         ...,\n","         [ 0.3749, -0.0078,  0.1651,  ..., -0.1409,  0.1819, -0.1426],\n","         [ 0.1138, -0.0297,  0.0229,  ..., -0.1092,  0.3801, -0.0124],\n","         [ 0.1310,  0.0048,  0.0991,  ..., -0.2301,  0.1434, -0.1936]],\n","\n","        ...,\n","\n","        [[ 0.1727, -0.1001, -0.1023,  ...,  0.2218,  0.4838,  0.3306],\n","         [-0.0379,  0.0127,  0.0585,  ...,  0.5253, -0.2892,  0.6813],\n","         [-0.1054,  0.4988, -0.3338,  ...,  1.0611, -0.3328,  0.2023],\n","         ...,\n","         [ 0.0928,  0.0849, -0.1977,  ..., -0.2074,  0.2163,  0.5012],\n","         [ 0.0332,  0.1004, -0.1155,  ...,  0.3681,  0.6036,  0.0456],\n","         [ 0.1072,  0.2643, -0.1945,  ...,  0.1842, -0.0606,  0.0643]],\n","\n","        [[ 0.5229,  0.1722,  0.0758,  ..., -0.1244,  0.2938,  0.1582],\n","         [ 0.6604, -0.1947,  0.4380,  ..., -0.2417,  0.3723,  0.2483],\n","         [ 0.4634,  0.1745,  0.4912,  ...,  0.0723,  0.9009,  0.1384],\n","         ...,\n","         [ 0.1030,  0.2746,  0.0670,  ...,  0.1780, -0.2026, -0.2048],\n","         [ 0.1170,  0.4254,  0.1351,  ...,  0.0049,  0.2313, -0.5715],\n","         [ 0.0159,  0.2283,  0.1871,  ...,  0.0208,  0.2038,  0.0539]],\n","\n","        [[ 0.2499,  0.2438, -0.0749,  ..., -0.2029,  0.4095, -0.2833],\n","         [ 0.2455, -0.1944,  0.4810,  ..., -0.0989,  0.0620, -0.0643],\n","         [-0.7190, -0.3146, -0.6085,  ...,  0.1534,  0.3685, -0.5035],\n","         ...,\n","         [ 0.1847,  0.2142, -0.4162,  ...,  0.1573, -0.2842, -0.2534],\n","         [ 0.2680,  0.3844, -0.1084,  ...,  0.0709, -0.1811, -0.1802],\n","         [ 0.1874,  0.1672, -0.2511,  ..., -0.0245, -0.1583, -0.0532]]],\n","       device='cuda:0', grad_fn=<NativeLayerNormBackward>), tensor([[-0.6587,  0.5860,  1.0000,  ...,  1.0000, -0.6079,  0.9972],\n","        [-0.7007,  0.4410,  0.9999,  ...,  1.0000, -0.5152,  0.9894],\n","        [-0.7383,  0.4378,  0.9999,  ...,  0.9999, -0.4246,  0.9909],\n","        ...,\n","        [-0.7911,  0.4570,  0.9999,  ...,  1.0000, -0.4223,  0.9941],\n","        [-0.7353,  0.5307,  0.9999,  ...,  1.0000, -0.5612,  0.9942],\n","        [-0.5595,  0.4943,  0.9999,  ...,  1.0000, -0.2728,  0.9893]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.6587,  0.5860,  1.0000,  ...,  1.0000, -0.6079,  0.9972],\n","        [-0.7007,  0.4410,  0.9999,  ...,  1.0000, -0.5152,  0.9894],\n","        [-0.7383,  0.4378,  0.9999,  ...,  0.9999, -0.4246,  0.9909],\n","        ...,\n","        [-0.7911,  0.4570,  0.9999,  ...,  1.0000, -0.4223,  0.9941],\n","        [-0.7353,  0.5307,  0.9999,  ...,  1.0000, -0.5612,  0.9942],\n","        [-0.5595,  0.4943,  0.9999,  ...,  1.0000, -0.2728,  0.9893]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-0.7674, -0.6892,  0.3956,  0.1175,  0.1776,  0.6180, -0.8906,  0.6497,\n","         -0.6765, -0.6033,  0.0377,  0.7874, -0.3537,  0.4496,  0.1929,  0.1085,\n","         -0.0232,  0.7575, -0.1524, -0.5602, -1.5729, -0.0264,  0.3085, -0.1960,\n","         -0.0020,  0.7550,  0.0349,  0.2495],\n","        [-0.7928, -0.6774,  0.3868, -0.1382,  0.2100,  0.5195, -0.7216,  0.5974,\n","         -0.2829, -0.5082,  0.1880,  0.5904, -0.1204,  0.3591, -0.0876,  0.1256,\n","          0.0334,  0.8315,  0.1577, -0.4326, -1.5387,  0.4046,  0.2612, -0.0733,\n","          0.2457,  0.8394,  0.2794,  0.4202],\n","        [-0.5629, -0.7311,  0.1993, -0.1568, -0.0053,  0.5308, -1.1737,  0.7877,\n","          0.0605, -0.7467, -0.2466,  1.0187, -0.0849,  0.1628,  0.1652,  0.2040,\n","         -0.1474,  0.8217,  0.1262, -0.5920, -1.6617,  0.0447,  0.5515, -0.2501,\n","         -0.3458,  0.8192, -0.0643,  0.3039],\n","        [-0.7497, -0.7588,  0.2513,  0.0466,  0.0949,  0.3819, -0.9582,  0.6684,\n","         -0.1572, -0.6619,  0.0069,  0.4090, -0.4190,  0.4213, -0.0884,  0.1333,\n","         -0.0087,  0.6472, -0.0250, -0.7896, -1.3682,  0.0291,  0.4663, -0.3183,\n","          0.1672,  0.4995,  0.3225,  0.2820],\n","        [-0.8850, -0.3444,  0.4429, -0.2133,  0.0674,  0.5566, -0.9417,  0.6278,\n","         -0.1924, -0.7427, -0.2038,  0.7725, -0.1343,  0.0927, -0.0656,  0.2876,\n","          0.1615,  0.6960,  0.0482, -0.5422, -1.4069,  0.1761,  0.3132, -0.2710,\n","          0.0237,  0.8037,  0.1787,  0.2697],\n","        [-0.6012, -0.5223,  0.2011, -0.0059,  0.2893,  0.6167, -1.0587,  0.6810,\n","         -0.0845, -0.2827, -0.1967,  0.6445, -0.3614,  0.0733, -0.2438, -0.2033,\n","         -0.3384,  0.6128,  0.0607, -0.7053, -1.4238,  0.0860,  0.3191, -0.1433,\n","          0.0471,  0.6961,  0.1584,  0.1040],\n","        [-0.6289, -0.5085,  0.2579, -0.2288,  0.2233,  0.5611, -0.7970,  0.7670,\n","         -0.2074, -0.6783, -0.1290,  0.6650, -0.3718,  0.2597,  0.1810,  0.0817,\n","          0.1247,  0.6165,  0.2878, -0.8625, -1.6453,  0.2139,  0.1744, -0.0718,\n","          0.2303,  0.8350,  0.1638,  0.4622],\n","        [-0.5372, -0.6272,  0.3944, -0.1316,  0.3992,  0.4271, -0.9243,  0.6028,\n","         -0.0451, -0.4198, -0.1438,  0.4927, -0.4224, -0.1221,  0.2317, -0.1478,\n","          0.0604,  0.8104,  0.0830, -0.5692, -1.4765, -0.4270,  0.5612, -0.4270,\n","          0.1929,  0.8721,  0.0767, -0.0448],\n","        [-0.6748, -0.8146,  0.0484, -0.2519,  0.5254,  0.2189, -0.7174,  0.6653,\n","         -0.0277, -0.3083, -0.1827,  0.6652, -0.0441,  0.7763, -0.1633,  0.3995,\n","         -0.3671,  0.6967, -0.1322, -0.6474, -1.4274,  0.2102,  0.1464, -0.0739,\n","          0.2931,  0.8620,  0.1651,  0.0809],\n","        [-0.6472, -0.7272, -0.1783,  0.0146,  0.6174,  0.5169, -1.1283,  0.6582,\n","         -0.4504, -0.7506, -0.0811,  0.5669, -0.1255,  0.4958,  0.0890,  0.0394,\n","         -0.0810,  0.9583, -0.0281, -0.8392, -1.3308, -0.0157,  0.3357, -0.2969,\n","          0.1518,  0.8630,  0.2072,  0.4018],\n","        [-0.3701, -0.5445,  0.0520, -0.1147,  0.1642,  0.6611, -0.9050,  0.5847,\n","         -0.0852, -0.2730, -0.1106,  0.7158, -0.4253,  0.3326,  0.1393,  0.0580,\n","          0.1971,  0.4685,  0.0239, -0.4988, -1.7536, -0.0604,  0.3468, -0.3365,\n","         -0.1068,  0.6569,  0.0841,  0.2023],\n","        [-0.7440, -1.0293,  0.6623,  0.1898,  0.2871,  0.4982, -0.9156,  0.3933,\n","         -0.2285, -0.2812, -0.0325,  0.7029, -0.3855, -0.0072,  0.1175,  0.0943,\n","         -0.1079,  0.6586,  0.0878, -0.5468, -1.3794, -0.0453,  0.1526, -0.3722,\n","          0.3253,  0.7036,  0.1797,  0.2401],\n","        [-0.5386, -0.3243,  0.1719, -0.2548,  0.3909,  0.6494, -1.0511,  0.8494,\n","         -0.1458, -0.4110,  0.0132,  0.7103, -0.2538,  0.5605, -0.0163,  0.5021,\n","         -0.4591,  0.6696, -0.1662, -0.8182, -1.6021,  0.2935,  0.3260, -0.1036,\n","          0.1300,  0.6031,  0.1873,  0.5294],\n","        [-0.7540, -0.7514,  0.4044, -0.2620,  0.0683,  0.4308, -1.2207,  0.6592,\n","         -0.1468, -0.6016, -0.1120,  0.5793, -0.5490,  0.2426, -0.0563,  0.2095,\n","         -0.2228,  0.4779, -0.1485, -0.6685, -1.5511, -0.0339,  0.2773, -0.2241,\n","          0.0771,  0.9178, -0.0284, -0.0480],\n","        [-0.8650, -0.8144,  0.4739, -0.2065,  0.3350,  0.4099, -0.9385,  0.6702,\n","         -0.2899, -0.4288, -0.2491,  0.5056, -0.4380,  0.2469, -0.1244, -0.0048,\n","         -0.1378,  0.6591, -0.1166, -0.7110, -1.4569, -0.1790,  0.4518, -0.2435,\n","         -0.1323,  0.9163,  0.1488,  0.2688],\n","        [-0.7763, -0.4880,  0.1306, -0.1345,  0.3845,  0.6366, -0.8276,  0.6356,\n","         -0.1245, -0.4764, -0.0675,  0.9451, -0.1750,  0.2187,  0.1892,  0.2293,\n","         -0.0298,  0.7484,  0.3117, -0.6844, -1.5870, -0.0064,  0.4976, -0.3798,\n","          0.4847,  0.7337, -0.0130,  0.5324]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   2% 52/2714 [00:20<17:04,  2.60it/s]\u001b[Aoutputs:\n","(tensor([[[ 3.5199e-01,  4.2255e-01, -7.9283e-03,  ..., -3.8752e-01,\n","           5.0632e-01, -3.1774e-01],\n","         [ 5.4926e-01, -5.2810e-01,  4.6807e-01,  ..., -3.6845e-01,\n","           3.7011e-01, -1.4700e-01],\n","         [ 3.2113e-02,  5.6060e-02,  4.4232e-01,  ..., -3.4756e-01,\n","           6.8163e-02, -5.8258e-01],\n","         ...,\n","         [ 1.4276e-02,  6.8218e-02,  2.9486e-01,  ..., -8.1445e-02,\n","           5.7974e-01, -2.0255e-01],\n","         [-3.3774e-02,  1.2003e-01,  3.0097e-01,  ..., -2.4879e-01,\n","           6.1232e-01, -2.2937e-01],\n","         [-4.6705e-01, -5.6312e-01,  3.9294e-01,  ..., -8.0623e-02,\n","           6.1972e-01, -1.5590e-01]],\n","\n","        [[ 4.2570e-01,  2.2263e-01, -1.7616e-01,  ..., -2.8634e-01,\n","           3.6092e-01, -4.1264e-02],\n","         [ 3.9004e-01, -2.5601e-01,  4.4553e-01,  ..., -3.7739e-03,\n","           2.1092e-01, -1.9226e-01],\n","         [ 6.2682e-01,  1.1581e-01,  1.2799e-01,  ..., -4.5907e-02,\n","          -1.4621e-01,  2.3510e-01],\n","         ...,\n","         [ 3.1896e-01,  1.8589e-01,  4.0249e-03,  ..., -1.9556e-01,\n","           2.3357e-01, -1.3921e-01],\n","         [ 3.9150e-01,  1.8454e-01,  1.3984e-01,  ...,  7.9551e-02,\n","           2.5497e-01,  1.2297e-01],\n","         [ 7.1243e-02, -1.3126e-01, -1.6305e-01,  ...,  2.9462e-01,\n","           1.7793e-01,  2.1834e-01]],\n","\n","        [[ 3.5176e-01,  2.3831e-01,  2.8693e-02,  ..., -2.2132e-02,\n","           2.5787e-01,  7.4954e-02],\n","         [ 5.4100e-01, -3.5062e-01,  5.2987e-01,  ..., -3.8596e-01,\n","           2.7550e-01,  2.2271e-01],\n","         [ 4.3740e-01,  1.8260e-01,  2.2580e-01,  ...,  3.2142e-01,\n","           6.7995e-01, -1.3016e-01],\n","         ...,\n","         [-1.8800e-02,  2.0183e-01,  2.5366e-01,  ..., -9.8986e-02,\n","           2.1821e-01,  2.8079e-02],\n","         [ 1.8814e-01, -2.7119e-04,  5.0596e-02,  ...,  2.8923e-02,\n","           5.1281e-01, -2.4134e-02],\n","         [ 1.1372e-01,  2.3060e-01, -1.4366e-01,  ..., -8.8834e-02,\n","           4.0037e-01,  7.4738e-02]],\n","\n","        ...,\n","\n","        [[ 5.7549e-01,  1.3680e-01,  4.9263e-03,  ..., -5.0439e-01,\n","           4.3765e-01,  1.0491e-01],\n","         [ 7.1321e-01, -3.8500e-01,  6.0074e-01,  ..., -3.6684e-01,\n","           1.9251e-01, -1.7162e-02],\n","         [ 9.0588e-01, -2.8277e-01,  7.9687e-02,  ..., -3.6488e-02,\n","          -2.9042e-01,  1.5880e-01],\n","         ...,\n","         [ 4.5219e-01,  2.1999e-01, -1.0818e-01,  ...,  1.8348e-02,\n","           4.2052e-01,  1.2350e-01],\n","         [ 3.8584e-01, -3.8287e-02, -1.2519e-01,  ..., -1.0666e-01,\n","           6.3454e-01,  2.9601e-01],\n","         [ 6.0788e-01,  1.8927e-01, -2.8582e-02,  ..., -5.2525e-02,\n","           2.3061e-01, -2.6041e-01]],\n","\n","        [[ 8.6215e-01,  7.3284e-02,  2.2660e-01,  ..., -2.0218e-01,\n","           3.8705e-01, -3.2158e-02],\n","         [ 4.0628e-01, -3.8748e-01,  6.9295e-01,  ..., -1.1889e-01,\n","           6.4492e-01,  2.1990e-01],\n","         [ 7.2178e-01,  3.3594e-01,  7.1584e-01,  ..., -1.0910e-02,\n","           4.9949e-02, -1.4699e-01],\n","         ...,\n","         [ 3.3147e-01,  5.5114e-02,  9.9560e-02,  ..., -2.2058e-01,\n","           1.0997e-01, -3.5728e-01],\n","         [ 2.2903e-01,  6.1547e-03,  3.0950e-01,  ..., -1.2505e-01,\n","           6.0585e-01, -2.8060e-01],\n","         [-4.1088e-02, -2.1728e-01, -5.7715e-02,  ..., -3.5070e-01,\n","           3.4112e-01, -3.8522e-01]],\n","\n","        [[ 5.5360e-01,  3.2721e-01, -1.0193e-01,  ...,  7.9876e-03,\n","           4.0449e-01,  1.9012e-01],\n","         [ 4.3824e-01,  1.7781e-01,  3.4590e-01,  ...,  2.1647e-01,\n","           1.6987e-01,  3.6957e-01],\n","         [ 5.5369e-01,  3.5510e-01, -4.4803e-01,  ...,  1.2779e-01,\n","           1.2118e-01,  1.6212e-01],\n","         ...,\n","         [ 4.7762e-01, -2.2803e-02,  1.0117e-01,  ...,  3.0828e-01,\n","           1.0378e-01, -3.5508e-02],\n","         [ 3.0053e-02,  9.2793e-03,  2.2340e-01,  ...,  1.6078e-01,\n","           1.1588e-01, -3.3912e-01],\n","         [ 2.2310e-02,  1.3663e-01, -4.8882e-02,  ...,  1.8226e-01,\n","           1.7847e-01, -1.2234e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward>), tensor([[-0.8235,  0.4779,  1.0000,  ...,  1.0000, -0.6385,  0.9986],\n","        [-0.6890,  0.4941,  1.0000,  ...,  1.0000, -0.5121,  0.9971],\n","        [-0.6615,  0.3896,  0.9998,  ...,  0.9999, -0.5881,  0.9911],\n","        ...,\n","        [-0.7498,  0.4964,  0.9999,  ...,  1.0000, -0.3769,  0.9962],\n","        [-0.7940,  0.4867,  0.9999,  ...,  1.0000, -0.6678,  0.9919],\n","        [-0.7546,  0.3573,  0.9999,  ...,  1.0000, -0.7818,  0.9864]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.8235,  0.4779,  1.0000,  ...,  1.0000, -0.6385,  0.9986],\n","        [-0.6890,  0.4941,  1.0000,  ...,  1.0000, -0.5121,  0.9971],\n","        [-0.6615,  0.3896,  0.9998,  ...,  0.9999, -0.5881,  0.9911],\n","        ...,\n","        [-0.7498,  0.4964,  0.9999,  ...,  1.0000, -0.3769,  0.9962],\n","        [-0.7940,  0.4867,  0.9999,  ...,  1.0000, -0.6678,  0.9919],\n","        [-0.7546,  0.3573,  0.9999,  ...,  1.0000, -0.7818,  0.9864]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-8.3574e-01, -5.5517e-01,  2.5350e-01, -3.1146e-01,  4.1618e-01,\n","          5.3181e-01, -1.0965e+00,  5.8014e-01, -4.7337e-01, -6.8092e-01,\n","          1.2974e-02,  4.0042e-01, -8.8375e-02,  2.9993e-01,  3.8843e-02,\n","          1.5205e-01,  4.1047e-02,  7.6327e-01,  5.7131e-02, -8.5855e-01,\n","         -1.2409e+00,  4.7278e-01,  4.5006e-01, -7.5819e-02, -5.3056e-02,\n","          8.5389e-01,  2.2408e-01,  2.7981e-01],\n","        [-6.8843e-01, -8.1960e-01,  4.4422e-01,  1.0845e-01,  3.8199e-01,\n","          5.3084e-01, -7.2483e-01,  6.6020e-01, -5.0735e-01, -7.9429e-01,\n","          8.2543e-02,  5.2717e-01, -2.3662e-01,  4.2606e-01,  8.4933e-02,\n","          2.0452e-01,  2.6330e-01,  6.8338e-01,  2.5050e-01, -9.6718e-01,\n","         -1.4486e+00,  5.4241e-02,  5.1971e-01, -2.9064e-01,  2.9306e-01,\n","          8.5920e-01,  2.1735e-01,  3.8008e-01],\n","        [-5.7841e-01, -5.7955e-01,  2.8467e-01,  1.7010e-01,  2.2341e-01,\n","          5.4801e-01, -8.2021e-01,  8.7018e-01, -6.3513e-01, -3.4771e-01,\n","          1.3816e-01,  5.0083e-01, -4.2869e-01,  4.0034e-01,  2.3524e-01,\n","         -4.6423e-03, -3.2237e-03,  6.8535e-01,  7.8093e-02, -5.5476e-01,\n","         -1.5509e+00,  1.2990e-02,  3.6337e-01, -1.2005e-01,  3.2572e-01,\n","          7.3248e-01, -8.2882e-02,  4.1604e-01],\n","        [-4.3473e-01, -8.7522e-01,  3.8294e-01,  1.6707e-01,  7.4252e-03,\n","          4.0828e-01, -7.7211e-01,  6.3349e-01, -8.5164e-02, -2.8467e-01,\n","         -1.3208e-02,  5.5913e-01, -4.1051e-01,  5.4682e-02, -2.1202e-02,\n","          3.1939e-01,  4.0452e-01,  3.7189e-01,  3.2010e-01, -7.3201e-01,\n","         -1.5311e+00, -1.1464e-01,  4.6774e-01, -1.3519e-01, -1.8018e-02,\n","          6.6230e-01, -4.4037e-02,  1.0412e-01],\n","        [-7.8958e-01, -7.6532e-01,  2.8628e-01,  2.1440e-01,  4.2921e-01,\n","          3.4085e-01, -7.5982e-01,  6.7467e-01, -3.9572e-01, -6.8755e-01,\n","          5.2198e-02,  7.1149e-01, -4.1284e-01,  4.1851e-01, -1.5504e-01,\n","          1.5488e-01, -1.2335e-01,  7.1392e-01,  1.5855e-02, -8.7711e-01,\n","         -1.5463e+00, -1.3294e-01,  2.7854e-01, -1.4175e-01,  4.0962e-02,\n","          1.0336e+00,  1.2540e-01,  2.1966e-01],\n","        [-9.3069e-01, -5.5279e-01,  2.8856e-01, -2.3591e-01,  2.6178e-01,\n","          4.9630e-01, -9.4793e-01,  6.3412e-01, -3.1672e-02, -4.7144e-01,\n","          6.9856e-02,  6.6874e-01, -2.3157e-01,  4.4562e-01,  3.7267e-02,\n","          2.3138e-01,  1.9400e-01,  6.9921e-01,  8.5519e-02, -6.1224e-01,\n","         -1.3529e+00,  6.7346e-02,  3.5707e-01, -1.2747e-01,  2.4106e-01,\n","          6.3257e-01,  3.7964e-01,  4.9303e-01],\n","        [-6.0658e-01, -9.3353e-01,  5.0894e-01,  8.2322e-02,  4.5501e-01,\n","         -1.3287e-02, -9.1932e-01,  6.0518e-01, -1.0600e-01, -9.3672e-01,\n","          7.7977e-02,  5.7538e-01, -6.6471e-01,  4.1235e-01, -9.1063e-02,\n","          2.7611e-01, -3.3165e-02,  4.6610e-01,  2.1778e-01, -7.8159e-01,\n","         -1.6374e+00, -1.7339e-01,  3.2969e-01, -4.5292e-01, -4.8612e-02,\n","          6.9993e-01, -2.1203e-01,  3.7371e-01],\n","        [-7.9116e-01, -6.7991e-01,  2.1779e-01,  7.6231e-02,  2.8255e-01,\n","          4.4393e-01, -1.1342e+00,  6.7273e-01, -4.5751e-01, -7.4444e-01,\n","          4.8156e-02,  5.9284e-01, -1.6295e-01,  3.6133e-01, -1.3685e-01,\n","          3.1965e-01,  9.3454e-02,  9.7757e-01, -1.2189e-01, -6.3257e-01,\n","         -1.8346e+00,  7.5028e-02,  5.3882e-01, -1.6934e-01,  1.6250e-01,\n","          8.9481e-01,  1.2717e-01,  3.6596e-01],\n","        [-7.6087e-01, -6.8829e-01, -1.3466e-01, -1.4742e-01,  3.4075e-01,\n","          4.5185e-01, -8.8897e-01,  8.9880e-01, -1.3360e-01, -5.5832e-01,\n","          6.0523e-03,  6.4301e-01, -2.5850e-01,  2.6602e-01,  3.5537e-02,\n","          3.5777e-04, -4.7647e-02,  8.1344e-01, -1.5069e-01, -6.9264e-01,\n","         -1.4581e+00,  2.6007e-01,  4.9096e-01, -2.6238e-01,  2.4710e-02,\n","          8.2429e-01,  3.7149e-01,  2.3443e-01],\n","        [-7.4985e-01, -8.5015e-01,  2.0898e-01, -2.7946e-01,  3.3912e-01,\n","          6.3528e-01, -8.5358e-01,  6.6465e-01, -2.5295e-01, -3.7446e-01,\n","          9.5641e-02,  5.8422e-01, -1.8090e-01,  4.6402e-01, -5.0359e-02,\n","          3.3369e-01, -1.4820e-01,  6.7084e-01,  1.6413e-01, -8.7548e-01,\n","         -1.3452e+00,  1.5589e-02,  4.9309e-01, -7.5435e-02,  1.1887e-01,\n","          7.3393e-01,  2.8008e-01,  5.8722e-01],\n","        [-7.9994e-01, -7.1798e-01,  6.2586e-02, -2.0207e-01,  4.3994e-01,\n","          5.9558e-01, -1.1479e+00,  9.1920e-01, -2.6227e-01, -9.0255e-01,\n","         -1.0109e-01,  8.1424e-01, -2.2544e-02,  3.6842e-01,  2.9934e-01,\n","          2.9362e-01, -1.1176e-01,  6.0539e-01, -6.3556e-02, -8.9111e-01,\n","         -1.7565e+00,  2.4016e-01,  1.8618e-01, -3.7221e-01,  1.7078e-01,\n","          6.7403e-01,  1.9035e-01,  3.4050e-01],\n","        [-6.3595e-01, -6.0862e-01,  3.8655e-01, -1.4685e-01,  4.4148e-01,\n","          4.3565e-01, -9.6730e-01,  5.0769e-01, -3.3084e-01, -7.4906e-01,\n","          9.2366e-02,  4.6589e-01, -2.1235e-02,  3.3886e-01, -2.3297e-02,\n","          3.5204e-01, -2.5407e-01,  1.1094e+00, -9.2147e-04, -9.2180e-01,\n","         -1.3373e+00,  2.7088e-01,  3.9882e-01, -1.2058e-01,  3.9446e-01,\n","          7.4412e-01,  2.6034e-01,  2.9715e-01],\n","        [-9.1225e-01, -7.7371e-01,  4.0411e-01,  1.9791e-02,  2.6831e-01,\n","          4.2533e-01, -7.7685e-01,  7.6090e-01,  1.7805e-01, -4.6868e-01,\n","          2.0267e-01,  5.9010e-01, -1.8766e-01,  3.2886e-01, -4.7153e-02,\n","         -6.1539e-03, -1.0181e-01,  7.5461e-01,  1.0510e-01, -6.0952e-01,\n","         -1.4233e+00,  6.1474e-02, -9.4857e-02, -3.4341e-01, -1.9486e-01,\n","          6.7044e-01,  1.8302e-01,  1.8319e-01],\n","        [-6.3427e-01, -7.2579e-01,  5.9153e-01, -1.0663e-01,  3.8162e-01,\n","          3.2929e-01, -7.4947e-01,  5.0537e-01, -4.1755e-02, -5.3274e-01,\n","          1.4636e-01,  6.5716e-01, -3.1615e-01,  4.8398e-01,  1.0650e-01,\n","          5.2328e-02, -7.3422e-02,  8.1943e-01,  3.8404e-02, -8.2408e-01,\n","         -1.6142e+00,  1.6526e-01,  5.5079e-01, -2.9812e-01,  1.7063e-01,\n","          3.1001e-01, -4.2964e-02,  3.6626e-01],\n","        [-6.9707e-01, -1.0689e+00,  4.5197e-01, -1.1099e-01,  1.9029e-01,\n","          6.7448e-01, -9.4079e-01,  6.8551e-01, -2.6776e-01, -5.6911e-01,\n","         -3.1084e-01,  3.0158e-01, -1.5545e-01,  3.1166e-01,  1.6108e-01,\n","          1.8557e-01, -1.3486e-02,  8.0715e-01,  9.2828e-02, -6.8095e-01,\n","         -1.5763e+00,  8.9622e-02,  5.0657e-01, -4.8483e-01,  3.7971e-01,\n","          7.6595e-01,  2.0229e-01,  4.9017e-01],\n","        [-1.0330e+00, -9.7904e-01,  2.9202e-01,  8.7834e-02,  3.0845e-01,\n","          4.0482e-01, -9.1309e-01,  4.8473e-01, -3.8427e-01, -5.9975e-01,\n","         -1.1960e-01,  7.4756e-01, -1.0632e-01,  5.0796e-01,  1.7128e-01,\n","          4.7104e-01, -1.7735e-01,  8.0908e-01, -1.7702e-01, -5.9993e-01,\n","         -1.5173e+00,  3.9878e-02,  4.9721e-01, -1.1546e-01,  2.7360e-01,\n","          9.9857e-01,  1.5022e-01,  3.3440e-01]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   2% 53/2714 [00:20<17:01,  2.60it/s]\u001b[Aoutputs:\n","(tensor([[[ 4.5654e-01,  3.7519e-02, -3.2738e-01,  ...,  1.4425e-01,\n","           3.2747e-01,  3.7565e-01],\n","         [ 5.4066e-01, -5.5408e-01,  1.1556e-01,  ...,  4.1708e-02,\n","           1.7334e-01,  4.2324e-01],\n","         [ 3.7431e-01,  1.0401e-01, -2.0527e-02,  ..., -4.5067e-02,\n","           5.2880e-01,  5.8388e-01],\n","         ...,\n","         [ 1.8024e-01,  3.3056e-01, -3.0211e-01,  ...,  2.2548e-02,\n","           7.9256e-02, -9.2383e-02],\n","         [ 1.8175e-01,  3.9242e-01, -3.8513e-01,  ...,  6.7310e-02,\n","          -1.1832e-01,  9.7564e-02],\n","         [ 5.6513e-02,  1.8082e-01, -4.1664e-01,  ..., -3.7857e-02,\n","          -1.4188e-01,  3.1596e-01]],\n","\n","        [[ 6.3574e-01,  2.2768e-01,  3.2474e-01,  ..., -3.9753e-01,\n","           1.6219e-01, -4.2711e-01],\n","         [ 2.6681e-01, -6.2984e-01,  6.7871e-01,  ..., -2.0332e-01,\n","           9.7748e-02,  1.8208e-01],\n","         [-7.1443e-02, -2.0174e-02, -1.4005e-01,  ...,  3.4496e-01,\n","          -3.0079e-01, -3.8066e-01],\n","         ...,\n","         [-3.9638e-01,  1.1467e-01,  2.6991e-01,  ...,  2.6142e-01,\n","          -1.7706e-01,  2.5265e-01],\n","         [-1.1562e-02,  2.3344e-02, -1.1154e-01,  ...,  1.2465e-01,\n","          -8.3071e-03,  1.4994e-01],\n","         [ 4.5119e-03, -1.0253e-01, -9.5499e-02,  ..., -5.5902e-02,\n","          -1.6426e-01, -2.9654e-02]],\n","\n","        [[ 4.9808e-01,  3.8918e-02, -1.0698e-01,  ...,  5.2662e-02,\n","           4.8967e-01,  2.6067e-01],\n","         [-3.7243e-02, -7.2298e-01, -2.7373e-01,  ...,  1.7819e-01,\n","           3.8325e-03,  7.7416e-01],\n","         [-5.8706e-01, -6.1557e-02, -4.4186e-01,  ...,  1.5542e-01,\n","          -1.1328e-01,  4.3473e-01],\n","         ...,\n","         [ 4.5308e-02,  1.3943e-02, -3.6937e-02,  ...,  4.2347e-01,\n","           2.5937e-01,  6.6558e-02],\n","         [ 2.0472e-01,  2.0490e-01, -2.5256e-02,  ...,  3.7705e-01,\n","           2.9713e-01,  3.1912e-01],\n","         [ 1.6009e-01, -2.7685e-03, -3.7807e-01,  ...,  1.6409e-01,\n","           1.3054e-01,  2.2466e-01]],\n","\n","        ...,\n","\n","        [[ 7.6307e-01,  2.9016e-01, -1.7765e-01,  ..., -3.8683e-01,\n","           7.5323e-02, -1.0839e-01],\n","         [-1.4675e-01, -3.2809e-01,  8.7981e-01,  ..., -3.2224e-01,\n","           4.7150e-01, -2.5692e-01],\n","         [ 4.6296e-01,  3.0350e-01,  3.6646e-01,  ...,  3.2391e-01,\n","           3.0134e-01, -5.1756e-01],\n","         ...,\n","         [-2.7379e-02, -1.2831e-02, -1.0657e-02,  ...,  2.2532e-02,\n","           5.6659e-01, -3.5263e-01],\n","         [ 1.9124e-01,  5.7102e-02,  8.1828e-02,  ..., -4.8514e-03,\n","           7.2150e-01, -2.8769e-01],\n","         [ 2.9064e-01,  2.2278e-01,  1.7575e-01,  ..., -3.0572e-01,\n","          -9.7854e-02, -3.5966e-01]],\n","\n","        [[ 2.3409e-01,  2.5355e-01, -2.9961e-02,  ..., -3.7322e-01,\n","           5.2763e-01,  5.0265e-02],\n","         [ 1.0245e-02, -6.0398e-01,  5.1693e-01,  ..., -1.7460e-01,\n","           4.5913e-01, -1.3301e-01],\n","         [-3.2576e-01, -6.3376e-01, -3.7896e-01,  ..., -7.7837e-01,\n","           2.1612e-01, -3.7774e-01],\n","         ...,\n","         [-3.0840e-01,  3.7503e-02, -4.6530e-02,  ...,  3.0266e-01,\n","           9.5775e-02, -4.2765e-02],\n","         [-1.5373e-01, -1.2119e-01, -1.8876e-01,  ...,  3.1273e-01,\n","           1.3815e-01,  1.0686e-01],\n","         [-2.4679e-01, -3.5310e-04, -6.9823e-02,  ...,  3.6854e-01,\n","           2.6590e-01,  3.7221e-01]],\n","\n","        [[ 2.7399e-01,  8.0747e-02,  2.3205e-02,  ...,  3.2207e-01,\n","           4.3055e-01,  1.9893e-01],\n","         [-3.9309e-01,  2.5899e-01, -3.1696e-01,  ...,  6.4992e-01,\n","          -6.6605e-02,  8.0015e-01],\n","         [-1.6750e-01,  2.8559e-01,  3.9902e-01,  ...,  9.0625e-01,\n","           1.0049e+00,  1.8563e-01],\n","         ...,\n","         [ 4.7682e-01,  1.5853e-01,  1.7818e-01,  ...,  2.4994e-01,\n","           1.1353e-01, -6.8243e-02],\n","         [ 1.6651e-01,  1.4414e-01,  4.9999e-02,  ...,  4.7392e-01,\n","           3.3611e-01,  3.1232e-01],\n","         [ 5.4693e-01, -1.5266e-01, -8.5486e-02,  ...,  1.1185e-01,\n","           3.4240e-01,  8.5327e-02]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward>), tensor([[-0.8044,  0.4859,  0.9999,  ...,  0.9999, -0.3660,  0.9820],\n","        [-0.6725,  0.3818,  0.9999,  ...,  1.0000, -0.9133,  0.9973],\n","        [-0.6196,  0.4791,  0.9997,  ...,  0.9999, -0.2966,  0.9812],\n","        ...,\n","        [-0.5011,  0.4297,  0.9998,  ...,  0.9999, -0.5239,  0.9932],\n","        [-0.7307,  0.4671,  0.9998,  ...,  0.9999, -0.5126,  0.9840],\n","        [-0.6948,  0.5570,  1.0000,  ...,  1.0000, -0.5887,  0.9967]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.8044,  0.4859,  0.9999,  ...,  0.9999, -0.3660,  0.9820],\n","        [-0.6725,  0.3818,  0.9999,  ...,  1.0000, -0.9133,  0.9973],\n","        [-0.6196,  0.4791,  0.9997,  ...,  0.9999, -0.2966,  0.9812],\n","        ...,\n","        [-0.5011,  0.4297,  0.9998,  ...,  0.9999, -0.5239,  0.9932],\n","        [-0.7307,  0.4671,  0.9998,  ...,  0.9999, -0.5126,  0.9840],\n","        [-0.6948,  0.5570,  1.0000,  ...,  1.0000, -0.5887,  0.9967]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-0.7170, -0.5407,  0.2358, -0.2243,  0.1786,  0.4443, -0.9218,  0.6569,\n","         -0.0950, -0.4731, -0.1683,  0.7299, -0.3687,  0.3737, -0.1040,  0.1027,\n","         -0.0630,  0.5395,  0.0396, -0.8934, -1.4336,  0.0406,  0.4006, -0.2527,\n","          0.0460,  0.8342, -0.0170,  0.3745],\n","        [-0.7634, -0.7278,  0.0110, -0.1804,  0.5131,  0.5513, -0.9512,  0.6659,\n","         -0.6946, -0.3908, -0.1277,  0.5302,  0.0810,  0.5279, -0.0403,  0.3708,\n","         -0.3411,  1.1233, -0.4092, -0.6949, -1.4392,  0.3624,  0.2832,  0.2628,\n","          0.5987,  0.7923,  0.1604,  0.5607],\n","        [-0.9291, -1.1019,  0.4178,  0.1146,  0.2856,  0.3795, -1.2299,  0.4444,\n","          0.0404, -0.6096,  0.0446,  0.5914, -0.3194,  0.2060, -0.0252, -0.0851,\n","          0.0687,  0.5571, -0.0150, -0.9571, -1.4523, -0.1221,  0.3421, -0.4799,\n","          0.1149,  1.0437, -0.0342,  0.1161],\n","        [-0.5587, -0.7171,  0.5001, -0.0796,  0.1198,  0.7616, -0.8952,  0.6444,\n","         -0.0339, -0.2707, -0.1816,  0.7139, -0.4730,  0.0946,  0.0036,  0.2781,\n","         -0.2230,  0.5878, -0.0622, -0.9112, -1.6891,  0.0718,  0.1216, -0.1999,\n","         -0.0280,  0.6628,  0.1901,  0.3347],\n","        [-0.9848, -0.6003,  0.2313, -0.2988,  0.4041,  0.2726, -1.0386,  0.8694,\n","         -0.2171, -0.6299,  0.2014,  0.5286, -0.2316,  0.2909,  0.0801,  0.2296,\n","         -0.1800,  0.7718, -0.1784, -0.6518, -1.5373,  0.1289,  0.0236, -0.2601,\n","          0.0706,  0.8340,  0.5157,  0.4256],\n","        [-0.8214, -0.9418,  0.8927, -0.0870,  0.0243,  0.5674, -0.7062,  0.5219,\n","         -0.1866, -0.5799, -0.2758,  0.3805, -0.4753,  0.2726, -0.0097,  0.2909,\n","          0.1235,  0.8515,  0.2860, -0.8135, -1.3576,  0.1425,  0.6097, -0.2793,\n","          0.0208,  0.6364, -0.0615,  0.3019],\n","        [-0.6034, -0.9565,  0.4469,  0.0125,  0.0838,  0.3821, -0.7468,  0.7314,\n","         -0.2598, -0.1740, -0.0606,  0.5398, -0.2133,  0.0113,  0.0832,  0.0789,\n","         -0.1008,  0.5705,  0.1373, -0.7680, -1.7742, -0.0454,  0.2910, -0.2770,\n","         -0.2866,  0.7811,  0.1845,  0.1388],\n","        [-0.6582, -0.6450,  0.2017, -0.3989,  0.2740,  0.2542, -1.3898,  0.5318,\n","         -0.2381, -0.4917, -0.1939,  0.4307,  0.1572,  0.4261, -0.1090,  0.2532,\n","         -0.3675,  0.9935, -0.3642, -0.6251, -1.1381, -0.1390,  0.3574, -0.0939,\n","          0.2730,  0.7879,  0.2087,  0.5039],\n","        [-0.7130, -0.7525,  0.4375, -0.0268,  0.0938,  0.5498, -0.8632,  0.7557,\n","          0.0091, -0.3946, -0.0367,  0.3850, -0.1257,  0.1909,  0.2326,  0.1811,\n","          0.1217,  0.5137,  0.1553, -0.6073, -1.5613, -0.2136, -0.0394, -0.2930,\n","          0.1882,  1.0510, -0.1290,  0.2991],\n","        [-0.5043, -0.5023, -0.0025,  0.1268,  0.1042,  0.3540, -1.0493,  0.5541,\n","         -0.0854, -0.6593, -0.1471,  0.8989, -0.3556,  0.2656, -0.0745,  0.0751,\n","         -0.0535,  0.6500,  0.1400, -0.6919, -1.7867,  0.0304,  0.1305, -0.4676,\n","          0.0895,  0.8071,  0.1103,  0.1741],\n","        [-0.9450, -0.6457,  0.2294, -0.2718,  0.4073,  0.5800, -0.9728,  0.6694,\n","         -0.2578, -0.5157, -0.2022,  0.8268, -0.3216,  0.2962, -0.1706,  0.0923,\n","          0.3823,  0.7697,  0.2420, -0.7817, -1.5384, -0.1776,  0.4864, -0.1159,\n","          0.3414,  0.8737,  0.3487,  0.1102],\n","        [-0.9018, -0.4789,  0.2349, -0.1312,  0.4031,  0.6264, -0.8760,  0.6766,\n","         -0.1618, -0.5802, -0.3401,  0.8325, -0.1548,  0.2302,  0.2554,  0.3902,\n","         -0.0650,  0.6906,  0.2795, -0.7987, -1.4626,  0.3021,  0.2619, -0.3160,\n","         -0.0163,  0.5746,  0.3979,  0.2376],\n","        [-0.7688, -0.8603,  0.5803,  0.1785,  0.0448,  0.2445, -0.7769,  0.4394,\n","         -0.2733, -0.5222,  0.2383,  0.6821, -0.7858, -0.1072,  0.3106, -0.0622,\n","          0.1479,  0.5195,  0.2495, -0.6615, -1.4616,  0.0147,  0.3814, -0.3045,\n","         -0.0671,  0.7943, -0.3881,  0.1079],\n","        [-0.8782, -0.8335,  0.2726, -0.2025,  0.2711,  0.5431, -1.1055,  0.6007,\n","         -0.1510, -0.1813, -0.1460,  0.4367, -0.0932,  0.5232, -0.1306,  0.2335,\n","         -0.3376,  0.7247,  0.2199, -0.7373, -1.6441, -0.1035,  0.0104, -0.5228,\n","          0.2385,  0.8515,  0.4686,  0.4316],\n","        [-0.3917, -0.9180,  0.5750,  0.0834,  0.3730,  0.6461, -0.8725,  0.7089,\n","         -0.3737, -0.3577, -0.0170,  0.3259, -0.3583,  0.1343,  0.0052, -0.1588,\n","          0.0255,  0.8147, -0.1025, -0.6276, -1.4929, -0.1716,  0.3274, -0.2186,\n","         -0.0646,  0.8245,  0.0847,  0.2655],\n","        [-0.6232, -0.8976,  0.3519,  0.2236, -0.0994,  0.4159, -1.1123,  0.7751,\n","         -0.1721, -0.2591,  0.0626,  0.5779, -0.4170,  0.4103,  0.2530, -0.2503,\n","         -0.0105,  0.3516,  0.5377, -0.5796, -1.7034,  0.0062,  0.2462, -0.4049,\n","          0.0515,  0.6956, -0.2293, -0.0333]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   2% 54/2714 [00:20<16:56,  2.62it/s]\u001b[Aoutputs:\n","(tensor([[[ 4.4908e-01,  9.3981e-02, -2.4476e-01,  ..., -2.3427e-01,\n","           3.4267e-01, -1.9543e-02],\n","         [ 3.6716e-01, -6.5257e-01,  1.1714e-01,  ..., -8.8365e-02,\n","           8.3080e-03,  2.9716e-02],\n","         [ 3.2360e-01,  2.4431e-01, -2.8540e-01,  ...,  7.1234e-01,\n","           1.7755e-01,  2.4120e-01],\n","         ...,\n","         [ 2.3440e-01, -4.1933e-01, -1.8135e-01,  ...,  4.1178e-01,\n","           1.8167e-01,  2.5721e-01],\n","         [ 2.4890e-01, -4.2918e-01,  8.7431e-02,  ...,  1.4257e-01,\n","           1.9886e-01,  2.1952e-01],\n","         [-1.9414e-01,  2.7535e-01, -5.8406e-01,  ...,  2.3290e-01,\n","          -7.6844e-02,  1.2958e-01]],\n","\n","        [[ 5.5267e-01,  3.6840e-01,  2.3983e-01,  ..., -3.9732e-01,\n","           3.3682e-01, -2.8783e-01],\n","         [ 7.5893e-01, -1.9412e-01,  7.5890e-01,  ..., -4.4557e-01,\n","           4.0490e-01, -8.5949e-02],\n","         [ 4.8604e-01,  4.9643e-01,  6.9840e-02,  ...,  2.1093e-01,\n","           7.5147e-01, -3.9696e-01],\n","         ...,\n","         [ 1.3893e-01,  3.1323e-01, -2.3099e-01,  ..., -1.2091e-01,\n","           5.4241e-01, -2.4963e-01],\n","         [ 1.7633e-01,  3.9736e-01,  1.9228e-03,  ...,  9.2784e-02,\n","           3.9032e-01, -1.9901e-01],\n","         [ 2.4186e-01,  1.0852e-01, -3.7241e-02,  ...,  3.3895e-02,\n","           2.3597e-01, -7.3657e-01]],\n","\n","        [[ 8.9651e-01, -1.5329e-01, -4.2521e-03,  ..., -8.5938e-02,\n","           4.8336e-01,  2.9429e-01],\n","         [-1.9958e-01,  2.9907e-01, -7.2144e-01,  ...,  1.3914e-01,\n","           5.2586e-01, -1.4895e-01],\n","         [ 1.0504e-01, -2.9796e-02, -2.1106e-02,  ...,  4.0222e-01,\n","           8.3169e-01,  3.1566e-01],\n","         ...,\n","         [ 1.7802e-01,  3.7099e-01,  8.7160e-03,  ..., -1.3403e-01,\n","          -1.0084e-01,  1.0182e-03],\n","         [ 2.1035e-01,  3.2924e-01,  1.6106e-02,  ...,  1.7438e-01,\n","           3.9582e-02, -2.8067e-01],\n","         [ 1.0731e-01,  2.8041e-01,  7.7661e-04,  ...,  3.9084e-01,\n","           1.4729e-01, -1.7530e-02]],\n","\n","        ...,\n","\n","        [[ 3.1210e-02,  2.0471e-02, -2.5727e-01,  ...,  1.7144e-01,\n","           2.3554e-01,  2.6507e-01],\n","         [-6.1814e-02, -4.7638e-03,  7.5833e-03,  ...,  3.9483e-02,\n","           4.8931e-01,  1.1644e-01],\n","         [ 8.6968e-03,  5.0630e-02,  7.6301e-02,  ...,  5.6924e-01,\n","           3.7439e-01,  1.0862e-01],\n","         ...,\n","         [ 1.4202e-01,  1.2528e-01, -1.0953e-01,  ..., -9.2506e-02,\n","           1.0615e-01, -9.1282e-02],\n","         [-5.1563e-02,  4.8160e-02, -1.8202e-01,  ...,  1.8612e-01,\n","           2.6573e-01,  3.8782e-01],\n","         [-1.2441e-01,  1.6055e-01,  1.2688e-02,  ...,  7.8874e-02,\n","           2.3515e-01,  1.8727e-01]],\n","\n","        [[ 2.2454e-01,  2.4182e-01, -1.2567e-01,  ..., -3.2774e-01,\n","           2.4032e-01,  9.5130e-02],\n","         [ 4.2807e-01, -1.5569e-01,  3.7351e-01,  ..., -1.8261e-01,\n","           2.8273e-01, -3.8946e-02],\n","         [ 3.2133e-01,  4.8828e-01,  3.0910e-02,  ..., -3.7505e-02,\n","           2.3496e-01, -1.0038e-01],\n","         ...,\n","         [-1.9918e-02,  1.9464e-01,  2.1187e-01,  ..., -1.1850e-01,\n","           1.4285e-01, -3.3478e-01],\n","         [ 9.8984e-02,  7.3462e-02,  5.6612e-02,  ..., -9.2802e-03,\n","           3.6954e-01, -2.4709e-01],\n","         [-2.1894e-01, -9.4963e-02, -8.1338e-02,  ...,  1.1159e-01,\n","           2.0911e-01, -2.1478e-01]],\n","\n","        [[ 3.3591e-01,  2.4881e-01,  4.0622e-02,  ...,  1.7197e-01,\n","           2.1635e-01,  3.3310e-02],\n","         [-1.5349e-01, -5.6838e-01,  6.4199e-01,  ...,  3.1976e-01,\n","          -2.3389e-01,  6.3981e-01],\n","         [ 5.0085e-01,  2.2789e-02, -1.9369e-01,  ...,  3.2022e-01,\n","          -9.8534e-02,  1.6644e-01],\n","         ...,\n","         [-1.5232e-01,  2.4282e-01,  2.2125e-01,  ...,  1.3683e-01,\n","           5.4002e-03,  1.3272e-01],\n","         [ 1.2988e-01,  2.9412e-01, -1.0672e-01,  ...,  3.9560e-01,\n","           2.2680e-01,  1.9507e-01],\n","         [ 5.5953e-02,  2.9061e-01,  2.4144e-01,  ...,  3.4166e-01,\n","          -1.3916e-01, -1.1136e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward>), tensor([[-0.7584,  0.5009,  0.9999,  ...,  1.0000, -0.5049,  0.9929],\n","        [-0.5939,  0.4520,  0.9999,  ...,  1.0000, -0.6300,  0.9853],\n","        [-0.6951,  0.3480,  0.9998,  ...,  0.9999, -0.1924,  0.9866],\n","        ...,\n","        [-0.7404,  0.5645,  0.9998,  ...,  0.9999, -0.4088,  0.9838],\n","        [-0.7009,  0.4730,  0.9999,  ...,  1.0000, -0.5432,  0.9977],\n","        [-0.6550,  0.3853,  0.9999,  ...,  1.0000, -0.7540,  0.9948]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.7584,  0.5009,  0.9999,  ...,  1.0000, -0.5049,  0.9929],\n","        [-0.5939,  0.4520,  0.9999,  ...,  1.0000, -0.6300,  0.9853],\n","        [-0.6951,  0.3480,  0.9998,  ...,  0.9999, -0.1924,  0.9866],\n","        ...,\n","        [-0.7404,  0.5645,  0.9998,  ...,  0.9999, -0.4088,  0.9838],\n","        [-0.7009,  0.4730,  0.9999,  ...,  1.0000, -0.5432,  0.9977],\n","        [-0.6550,  0.3853,  0.9999,  ...,  1.0000, -0.7540,  0.9948]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-7.0376e-01, -7.3008e-01,  4.1352e-01, -1.0850e-01,  3.2316e-01,\n","          4.1900e-01, -9.5228e-01,  7.8179e-01, -5.1101e-01, -5.9112e-01,\n","         -1.7165e-01,  6.5212e-01, -1.4292e-01,  3.5517e-02,  6.4843e-02,\n","          2.2693e-01, -1.7278e-02,  6.5863e-01, -1.5934e-01, -8.9920e-01,\n","         -1.6725e+00,  1.5923e-03,  5.2247e-01, -1.6353e-01, -1.3191e-01,\n","          4.7669e-01,  1.9605e-01,  3.7692e-01],\n","        [-5.7990e-01, -6.9307e-01, -2.7405e-02, -1.7048e-01,  3.9952e-01,\n","          4.1590e-01, -9.8510e-01,  6.8148e-01, -3.3041e-01, -3.1283e-01,\n","          2.0972e-02,  8.4563e-01,  6.7263e-02,  3.7174e-01, -1.4673e-01,\n","          2.3353e-01, -2.4625e-01,  6.0625e-01, -1.1848e-01, -8.3933e-01,\n","         -1.4255e+00,  6.2770e-02,  4.3419e-01,  9.6266e-02,  2.1896e-01,\n","          1.2429e+00,  3.0968e-01,  6.4196e-01],\n","        [-7.3955e-01, -7.4882e-01,  4.4400e-01,  4.9874e-02,  1.3920e-01,\n","          4.1638e-01, -1.0160e+00,  7.1809e-01, -1.8036e-01, -5.7521e-01,\n","         -1.4728e-01,  4.7216e-01, -3.7660e-01,  7.3792e-02,  9.2010e-02,\n","          1.6745e-01, -7.5992e-02,  5.4285e-01,  1.0041e-01, -8.8269e-01,\n","         -1.2104e+00, -1.7178e-01,  6.2726e-01, -3.6649e-01, -2.2441e-02,\n","          6.1299e-01, -1.0746e-01,  8.9270e-02],\n","        [-8.1782e-01, -8.4282e-01,  4.5211e-01,  1.0584e-01,  3.3200e-01,\n","          2.1012e-01, -8.7536e-01,  9.1362e-01, -1.0723e-01, -4.6367e-01,\n","         -9.8631e-02,  4.9371e-01, -3.1281e-01,  9.4681e-03, -5.3779e-03,\n","          1.7036e-01,  1.3226e-01,  6.3343e-01,  1.1249e-02, -9.1635e-01,\n","         -1.7505e+00, -1.8196e-02,  4.4626e-01, -2.2617e-01, -1.1361e-03,\n","          7.8876e-01, -2.5311e-02, -1.8953e-02],\n","        [-7.4104e-01, -7.8671e-01,  3.6381e-01,  1.0972e-01,  1.8874e-01,\n","          4.2099e-01, -1.1072e+00,  7.7769e-01, -2.7895e-01, -4.4261e-01,\n","         -5.3930e-03,  7.5048e-01, -2.2793e-01,  7.6464e-02,  2.2835e-01,\n","          1.4528e-01,  1.6449e-01,  5.0255e-01,  2.8167e-01, -6.8382e-01,\n","         -1.7904e+00,  2.1299e-02,  2.7470e-01, -2.5412e-01,  1.6828e-01,\n","          5.8864e-01,  1.0184e-01,  3.6356e-01],\n","        [-8.0680e-01, -8.4755e-01,  2.8200e-01, -1.0683e-01,  2.5571e-01,\n","          5.6530e-01, -8.7390e-01,  4.1503e-01,  2.9533e-02, -4.0632e-01,\n","         -6.9394e-02,  3.9683e-01, -6.2060e-01,  2.8147e-01,  3.9662e-02,\n","         -4.4386e-02, -4.6764e-02,  6.6312e-01, -3.9378e-02, -7.9209e-01,\n","         -1.3835e+00,  1.0383e-01,  7.5386e-01, -1.1907e-01,  2.0939e-01,\n","          5.1790e-01,  8.0792e-03,  4.2222e-01],\n","        [-6.4783e-01, -7.0283e-01,  4.9633e-01, -3.9663e-02,  2.7233e-01,\n","          3.5110e-01, -7.3398e-01,  5.5673e-01, -2.6743e-01, -5.5676e-01,\n","          9.3541e-03,  4.0838e-01, -1.0065e-01,  5.1314e-01, -7.6097e-02,\n","         -1.6584e-01,  1.2209e-01,  5.2253e-01, -3.5306e-02, -7.5378e-01,\n","         -1.7449e+00, -5.6567e-02,  5.1677e-01, -3.4092e-01,  1.7014e-01,\n","          6.2730e-01, -1.3492e-01, -6.9327e-03],\n","        [-7.5799e-01, -9.3130e-01,  5.3553e-01,  3.1491e-02,  3.2876e-01,\n","          3.3026e-01, -9.1490e-01,  4.2049e-01, -2.6488e-03, -6.8659e-01,\n","         -1.1751e-01,  6.1633e-01, -2.0690e-01,  3.0438e-01,  7.7875e-02,\n","          1.4424e-01, -1.2803e-01,  6.0046e-01, -4.0382e-02, -8.3909e-01,\n","         -1.5857e+00,  1.0117e-01,  5.0036e-01, -2.9820e-01, -3.9245e-02,\n","          7.2183e-01,  1.5655e-01,  3.1200e-01],\n","        [-9.6555e-01, -9.1532e-01,  7.0001e-01, -5.4169e-02,  3.8875e-01,\n","          3.4606e-01, -9.6669e-01,  5.1298e-01, -1.9160e-01, -5.2484e-01,\n","         -6.2344e-02,  4.7528e-01, -2.2891e-01,  2.0224e-01,  9.2308e-02,\n","         -4.5976e-03, -2.0386e-01,  5.8803e-01,  1.2530e-01, -8.5842e-01,\n","         -1.6118e+00,  3.1440e-01,  6.1379e-01, -4.0174e-01,  1.0651e-01,\n","          1.0656e+00, -7.9052e-02,  3.9249e-01],\n","        [-6.3170e-01, -7.4891e-01,  3.5775e-01,  7.8061e-02,  3.6093e-01,\n","          3.5966e-01, -1.1378e+00,  6.4657e-01, -1.0158e-01, -4.5000e-01,\n","          2.0614e-01,  6.2890e-01, -4.5010e-01,  1.7071e-01,  4.3636e-01,\n","          2.6927e-02, -4.6500e-02,  5.5214e-01,  2.4611e-01, -8.6027e-01,\n","         -1.4046e+00, -9.5065e-02,  2.2447e-01, -2.8021e-01,  1.6314e-01,\n","          8.2872e-01,  9.6759e-02,  3.3682e-01],\n","        [-7.6703e-01, -7.0573e-01,  4.0366e-01, -1.5162e-01,  3.1676e-01,\n","          4.5839e-01, -9.5031e-01,  6.1361e-01, -2.5029e-01, -6.1987e-01,\n","         -1.2870e-01,  6.7030e-01, -4.0335e-01,  2.7902e-01, -2.7748e-02,\n","          5.6622e-02,  3.7348e-02,  6.6162e-01, -2.7013e-01, -5.9115e-01,\n","         -1.4207e+00,  1.9870e-02,  4.7660e-01, -1.5124e-01,  2.0161e-01,\n","          8.4911e-01,  2.4950e-01,  1.7465e-01],\n","        [-5.3334e-01, -6.9379e-01,  3.0939e-01, -2.8782e-01,  2.4987e-02,\n","          5.9872e-01, -8.1946e-01,  9.0650e-01, -2.4074e-01, -1.2872e-01,\n","          1.2513e-01,  7.7861e-01, -1.9462e-01,  1.0543e-01,  1.2373e-01,\n","          9.5306e-02,  1.9420e-02,  7.6217e-01,  2.1455e-01, -8.4849e-01,\n","         -1.5366e+00,  1.1004e-01,  2.5461e-01, -1.5658e-01,  6.5478e-02,\n","          8.1759e-01,  4.2843e-01,  9.0166e-02],\n","        [-7.4094e-01, -7.8313e-01,  2.3877e-01, -3.1190e-01,  5.1062e-01,\n","          4.5164e-01, -9.2139e-01,  7.0032e-01, -1.8327e-01, -7.3187e-01,\n","          1.8254e-01,  4.4777e-01, -2.3156e-01,  3.9797e-01,  2.1861e-01,\n","         -2.8629e-01,  1.9035e-02,  7.6831e-01,  9.0302e-02, -8.7483e-01,\n","         -1.4809e+00,  5.5751e-02,  6.3879e-02, -1.3714e-01,  2.0192e-02,\n","          9.5724e-01,  1.1284e-01,  6.2245e-01],\n","        [-6.0547e-01, -9.4420e-01,  3.9279e-01, -5.4602e-02,  4.4103e-01,\n","          3.0854e-01, -7.2737e-01,  5.6007e-01, -3.4519e-01, -3.9658e-01,\n","         -4.2746e-01,  7.1564e-01, -4.5967e-01,  2.5681e-01,  1.6542e-01,\n","          8.5763e-02,  7.1614e-04,  6.5665e-01,  9.7111e-02, -7.0925e-01,\n","         -1.6276e+00, -1.0021e-01,  3.6360e-01, -3.1814e-01, -1.2663e-01,\n","          4.8720e-01, -1.7620e-02,  2.5284e-01],\n","        [-6.6263e-01, -8.9660e-01,  3.4847e-01, -2.6628e-01,  4.1571e-01,\n","          4.3143e-01, -9.2741e-01,  7.8602e-01, -2.1457e-01, -4.4250e-01,\n","         -7.2658e-02,  6.7944e-01, -4.8795e-01,  2.5721e-01,  2.8014e-02,\n","          1.3500e-01, -4.0809e-01,  8.2989e-01, -1.1286e-01, -7.0258e-01,\n","         -1.7053e+00,  1.7227e-01,  3.2921e-01, -1.9933e-01,  4.7224e-01,\n","          9.3135e-01,  7.9690e-02,  2.2122e-01],\n","        [-7.4082e-01, -6.9063e-01,  4.4623e-01,  2.0362e-01,  3.2196e-01,\n","          2.7100e-01, -1.0551e+00,  7.6407e-01, -3.1260e-01, -6.7239e-01,\n","         -1.9759e-01,  8.4024e-01, -2.9602e-01,  3.7921e-01,  1.8411e-01,\n","          2.0872e-01, -3.7780e-02,  7.2652e-01, -6.6827e-02, -5.3343e-01,\n","         -1.4989e+00,  7.2029e-03,  2.4349e-01, -8.0148e-02,  3.4189e-01,\n","          5.8550e-01, -5.2485e-02,  3.0464e-01]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   2% 55/2714 [00:21<17:08,  2.59it/s]\u001b[Aoutputs:\n","(tensor([[[ 2.5803e-01, -5.4545e-02, -9.0882e-03,  ..., -3.4208e-02,\n","          -1.0730e-01, -1.7656e-02],\n","         [ 5.0918e-02, -7.1928e-02, -2.7978e-01,  ..., -1.4023e-01,\n","          -5.8438e-01,  6.7053e-01],\n","         [ 1.3187e-01,  1.6455e-01, -2.4552e-01,  ..., -1.4813e-01,\n","          -3.8073e-02, -8.0080e-02],\n","         ...,\n","         [-2.4147e-02, -3.5311e-01,  8.5409e-02,  ...,  1.3115e-01,\n","          -6.6415e-02, -4.8420e-02],\n","         [ 4.1128e-02, -3.3406e-01, -1.0684e-01,  ...,  2.1988e-01,\n","          -8.5050e-02,  7.7540e-02],\n","         [-2.0313e-01, -6.5593e-03,  1.1379e-01,  ...,  2.5501e-01,\n","          -3.3310e-01,  2.3851e-01]],\n","\n","        [[ 3.9177e-01,  2.5543e-01, -3.1061e-01,  ..., -1.2824e-01,\n","           2.6853e-01,  1.7039e-01],\n","         [ 1.2541e-01, -3.9829e-01,  8.0050e-02,  ...,  1.6954e-01,\n","           4.2004e-01,  1.3599e-01],\n","         [ 2.4966e-01,  3.7734e-01, -5.0161e-02,  ..., -1.4173e-01,\n","          -1.0905e-01, -1.7370e-01],\n","         ...,\n","         [-1.0157e-01,  2.8748e-01, -3.6558e-01,  ...,  8.0141e-02,\n","           1.8212e-01,  5.9027e-02],\n","         [ 1.4463e-02,  2.3397e-01, -1.3524e-01,  ...,  2.8055e-01,\n","           2.0167e-01,  2.2817e-02],\n","         [ 4.6948e-02,  3.1429e-01, -2.2439e-02,  ..., -3.6924e-02,\n","          -5.9329e-02, -3.2914e-01]],\n","\n","        [[ 7.4103e-02,  6.2853e-02, -2.6041e-01,  ...,  1.9871e-01,\n","           2.4886e-01,  9.9104e-02],\n","         [ 5.3232e-01,  1.5025e-01, -6.7424e-02,  ...,  8.1569e-01,\n","          -4.2060e-01,  3.6741e-01],\n","         [ 4.2070e-01,  9.5308e-02, -2.2868e-01,  ...,  8.3755e-01,\n","          -2.7260e-02, -6.2619e-02],\n","         ...,\n","         [ 1.0018e-01,  4.5380e-01, -5.5033e-01,  ...,  4.2181e-01,\n","           7.1365e-02, -2.7664e-01],\n","         [ 2.1449e-01,  1.9379e-01, -1.0560e-01,  ...,  4.6643e-01,\n","          -1.7982e-02, -1.6728e-01],\n","         [-2.4991e-02,  2.6812e-01, -5.7106e-01,  ...,  4.2940e-01,\n","           4.3325e-02, -3.4565e-01]],\n","\n","        ...,\n","\n","        [[ 2.4640e-01, -2.9779e-01, -1.1227e-01,  ..., -1.6657e-02,\n","           1.6378e-01,  1.0446e-01],\n","         [ 4.0694e-01, -1.0780e-01,  2.5689e-04,  ..., -4.8211e-03,\n","           1.1609e-01, -5.9596e-04],\n","         [ 3.7559e-02, -3.2649e-01,  2.5661e-01,  ...,  2.9516e-01,\n","           1.6254e-02,  1.6390e-01],\n","         ...,\n","         [-1.4005e-01,  1.2894e-01, -8.0675e-02,  ...,  1.4205e-01,\n","           1.5735e-01,  1.3714e-01],\n","         [ 1.5191e-01, -1.6778e-01,  2.3153e-01,  ...,  2.8438e-01,\n","           1.5581e-01,  1.6157e-02],\n","         [ 2.7403e-02, -2.5109e-01,  1.3587e-01,  ...,  2.8607e-01,\n","           1.0977e-01, -9.2514e-02]],\n","\n","        [[ 5.4836e-01,  9.0108e-02, -1.1385e-01,  ..., -1.2439e-01,\n","           1.5095e-01,  1.0594e-02],\n","         [ 4.8542e-01,  8.8413e-02,  2.0516e-01,  ..., -6.5075e-02,\n","          -3.6086e-02,  2.1973e-02],\n","         [ 3.2432e-01,  4.0291e-01, -3.6529e-02,  ..., -1.9521e-01,\n","           3.8558e-01, -1.6458e-01],\n","         ...,\n","         [ 3.0925e-01,  3.1471e-01, -1.0266e-01,  ...,  3.5522e-01,\n","           5.7127e-01, -3.9253e-01],\n","         [ 1.5190e-01,  5.2446e-01,  1.2286e-01,  ...,  1.3646e-01,\n","           3.2889e-01,  1.4329e-01],\n","         [-1.3778e-01,  3.0637e-01, -1.9066e-01,  ...,  6.8276e-02,\n","          -2.6717e-01, -6.3578e-02]],\n","\n","        [[ 3.8215e-01,  2.1491e-01, -5.7128e-02,  ..., -3.9184e-01,\n","           1.8019e-01,  3.5847e-02],\n","         [ 5.6171e-01, -4.4927e-01,  5.1765e-01,  ..., -2.9493e-01,\n","           2.6319e-01,  3.4868e-01],\n","         [ 3.4482e-01,  2.7801e-01,  2.0776e-01,  ...,  6.5017e-01,\n","          -1.9294e-01,  3.8147e-01],\n","         ...,\n","         [-2.0921e-01, -1.3741e-01, -4.1887e-01,  ..., -5.7722e-04,\n","           2.4098e-01, -4.5678e-02],\n","         [-1.1024e-02,  2.9624e-02, -4.0749e-01,  ..., -3.0775e-02,\n","           5.8074e-01, -3.9889e-02],\n","         [-1.6549e-01,  8.4149e-02,  2.8628e-01,  ...,  2.4916e-01,\n","           3.3778e-01,  5.4198e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward>), tensor([[-0.5454,  0.3199,  0.9995,  ...,  0.9999, -0.6906,  0.9845],\n","        [-0.8266,  0.5663,  1.0000,  ...,  1.0000,  0.2922,  0.9961],\n","        [-0.7215,  0.4521,  0.9999,  ...,  1.0000, -0.1047,  0.9975],\n","        ...,\n","        [-0.6522,  0.5305,  0.9999,  ...,  0.9999, -0.4572,  0.9730],\n","        [-0.7634,  0.4560,  0.9998,  ...,  0.9999, -0.3516,  0.9685],\n","        [-0.7048,  0.4048,  0.9999,  ...,  1.0000, -0.4758,  0.9933]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.5454,  0.3199,  0.9995,  ...,  0.9999, -0.6906,  0.9845],\n","        [-0.8266,  0.5663,  1.0000,  ...,  1.0000,  0.2922,  0.9961],\n","        [-0.7215,  0.4521,  0.9999,  ...,  1.0000, -0.1047,  0.9975],\n","        ...,\n","        [-0.6522,  0.5305,  0.9999,  ...,  0.9999, -0.4572,  0.9730],\n","        [-0.7634,  0.4560,  0.9998,  ...,  0.9999, -0.3516,  0.9685],\n","        [-0.7048,  0.4048,  0.9999,  ...,  1.0000, -0.4758,  0.9933]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-7.7203e-01, -7.6349e-01,  7.3607e-02, -1.0073e-01,  5.5927e-01,\n","          5.2545e-01, -9.2963e-01,  6.1429e-01, -3.8649e-01, -5.2868e-01,\n","          2.3698e-01,  3.7508e-01, -4.4361e-02,  8.4912e-02, -9.8664e-02,\n","          5.4036e-02, -2.9755e-01,  8.6361e-01, -1.7618e-01, -7.4764e-01,\n","         -1.7132e+00, -9.5078e-02,  5.3437e-01,  4.3787e-02,  3.2887e-01,\n","          8.4601e-01, -1.2959e-01,  2.0570e-01],\n","        [-5.4623e-01, -6.0895e-01,  3.0381e-01,  3.9061e-01,  3.2352e-02,\n","          4.9060e-01, -6.2835e-01,  6.7906e-01, -3.6620e-01, -6.5670e-01,\n","          8.1750e-02,  7.2788e-01, -1.7741e-01,  6.0140e-02,  3.0107e-01,\n","          2.0706e-01,  2.2114e-01,  3.7528e-01, -1.1741e-02, -6.3814e-01,\n","         -1.5058e+00, -2.2300e-01,  3.8042e-01, -2.2759e-01, -1.8162e-01,\n","          6.6378e-01, -2.5831e-03,  1.4440e-02],\n","        [-7.3449e-01, -9.5060e-01,  3.5939e-01, -3.1324e-01, -1.1585e-01,\n","          5.0957e-01, -1.1975e+00,  8.0639e-01, -5.7999e-02, -3.5571e-01,\n","          2.0478e-02,  5.1007e-01, -3.3656e-01,  2.5725e-01,  7.6008e-02,\n","          1.6431e-01,  1.9110e-01,  3.4743e-01,  3.4068e-01, -8.9370e-01,\n","         -1.5066e+00, -1.5796e-01,  5.0413e-01,  3.6681e-02,  1.2166e-01,\n","          5.1350e-01,  2.9123e-01,  1.8720e-01],\n","        [-9.2149e-01, -7.6325e-01,  3.7363e-01,  1.3659e-01,  2.3027e-01,\n","          4.7648e-01, -8.6993e-01,  7.5999e-01, -1.1279e-01, -3.2125e-01,\n","         -8.5900e-02,  6.7589e-01, -2.0982e-01,  1.1203e-01,  3.4435e-01,\n","          1.9939e-01,  2.3173e-02,  6.8768e-01,  2.8025e-01, -5.9445e-01,\n","         -1.4904e+00,  2.4809e-01,  6.7011e-02, -3.5260e-01, -1.8716e-01,\n","          5.9214e-01, -3.0390e-03,  3.2473e-01],\n","        [-6.0020e-01, -6.1181e-01,  2.1846e-02, -1.5368e-01,  3.6203e-01,\n","          3.0678e-01, -9.1923e-01,  5.6458e-01, -3.9040e-01, -4.9723e-01,\n","          2.1240e-03,  5.4625e-01, -4.3324e-01,  4.4086e-01, -7.2716e-02,\n","          6.7997e-02, -1.6267e-02,  6.2712e-01,  3.3984e-02, -1.0855e+00,\n","         -1.7261e+00,  1.0031e-01,  2.1974e-01, -1.0429e-01,  4.5870e-01,\n","          8.2099e-01,  2.5403e-01,  4.3984e-01],\n","        [-8.8527e-01, -8.4688e-01,  3.0710e-01, -2.9831e-01,  4.5896e-01,\n","          3.6617e-01, -1.0737e+00,  5.0853e-01, -3.1636e-01, -5.8863e-01,\n","          7.9922e-02,  8.2650e-01, -3.2479e-01,  3.9362e-01,  9.8851e-02,\n","          1.2396e-01,  4.2606e-02,  8.7425e-01,  2.1850e-01, -6.4638e-01,\n","         -1.6981e+00,  1.4098e-01,  4.3902e-01, -3.3474e-01,  1.1909e-01,\n","          4.3897e-01,  9.1645e-02,  4.3613e-01],\n","        [-5.3631e-01, -7.2534e-01,  9.4189e-02, -1.6106e-01,  2.3932e-01,\n","          5.7006e-01, -1.0999e+00,  8.7291e-01, -2.7357e-01, -5.8402e-01,\n","         -1.6953e-01,  6.5555e-01, -3.1080e-01,  3.0500e-01,  1.0762e-01,\n","          1.2427e-01, -7.4518e-02,  6.6155e-01, -4.7873e-02, -6.1399e-01,\n","         -1.5433e+00, -1.4791e-01,  3.0949e-01, -2.7255e-01,  3.1667e-01,\n","          7.7513e-01, -5.3080e-02,  5.5827e-01],\n","        [-4.0859e-01, -6.9605e-01,  2.8608e-01,  1.0860e-01,  4.4839e-01,\n","          6.4388e-01, -9.1889e-01,  6.2799e-01, -3.1923e-01, -7.7293e-01,\n","         -2.4890e-02,  3.8755e-01, -2.4364e-01,  3.0246e-01,  2.2086e-03,\n","          1.6102e-02, -9.7399e-02,  7.5133e-01,  3.1493e-01, -1.0593e+00,\n","         -1.6801e+00, -4.9668e-02,  5.0991e-01, -3.9517e-01,  9.1490e-02,\n","          6.8079e-01,  5.3173e-02,  2.4607e-01],\n","        [-6.9758e-01, -7.2814e-01,  1.8743e-01,  3.6932e-04,  2.9956e-01,\n","          4.3423e-01, -9.6032e-01,  6.8257e-01, -3.8557e-01, -5.3231e-01,\n","         -2.0757e-01,  5.8306e-01, -1.8219e-01,  8.8099e-02,  2.2924e-01,\n","          2.8241e-01,  4.7226e-02,  7.1100e-01,  1.0501e-01, -8.4481e-01,\n","         -1.4776e+00,  2.8802e-01,  4.6093e-01, -1.5486e-01, -1.5729e-01,\n","          8.0441e-01,  2.9588e-01,  2.0983e-01],\n","        [-5.7014e-01, -9.0697e-01,  4.2026e-01, -2.2594e-01,  1.2530e-01,\n","          5.3853e-01, -8.6540e-01,  5.8263e-01, -2.1414e-01, -4.5023e-01,\n","          7.3044e-02,  4.5729e-01, -5.9544e-01,  1.4005e-01,  1.1869e-01,\n","         -1.1106e-02, -2.2698e-01,  6.5846e-01,  2.7505e-02, -6.5970e-01,\n","         -1.3847e+00, -1.6690e-01,  3.6962e-01, -4.0135e-01, -1.2519e-01,\n","          5.5721e-01, -1.2923e-01,  2.5936e-01],\n","        [-8.4298e-01, -6.2691e-01,  4.6522e-02,  2.4386e-03,  1.8771e-01,\n","          3.4267e-01, -8.2834e-01,  7.3991e-01, -4.2612e-01, -4.7702e-01,\n","         -2.0996e-01,  5.4532e-01, -3.0335e-01,  2.3137e-01, -1.1546e-01,\n","          1.7165e-01, -2.5490e-01,  6.4297e-01, -5.6003e-02, -1.1862e+00,\n","         -1.5042e+00,  3.1196e-01,  5.4750e-01, -4.3001e-01,  3.8343e-01,\n","          7.8513e-01, -4.0065e-02,  3.9083e-01],\n","        [-4.0185e-01, -6.2239e-01,  1.6627e-01, -1.3442e-01,  1.1854e-01,\n","          2.3828e-01, -9.6538e-01,  7.3779e-01,  2.0787e-02, -2.9517e-01,\n","          8.9673e-02,  5.6067e-01, -8.0572e-02,  2.1694e-02, -1.8691e-02,\n","          1.9239e-01, -2.2195e-01,  4.4581e-01,  2.7163e-01, -8.5905e-01,\n","         -1.4566e+00, -3.1707e-02,  3.3877e-01, -1.6184e-01,  1.4925e-01,\n","          5.8750e-01,  2.2427e-01,  3.4122e-01],\n","        [-5.9671e-01, -7.7802e-01,  3.7150e-01,  2.1024e-01,  4.8306e-01,\n","          3.5014e-01, -9.4889e-01,  5.6587e-01, -5.2862e-01, -4.2146e-01,\n","          2.6556e-02,  5.9164e-01, -2.8821e-01,  4.8370e-02, -1.2732e-01,\n","          1.2308e-01,  4.0031e-02,  4.1697e-01,  7.9071e-03, -7.8753e-01,\n","         -1.4453e+00,  3.9182e-02,  3.1946e-01, -4.9575e-01, -2.1998e-01,\n","          6.0284e-01,  1.6719e-01,  1.2015e-01],\n","        [-6.4338e-01, -8.4728e-01,  4.6904e-01,  1.2483e-01,  4.8156e-02,\n","          4.5438e-01, -9.3127e-01,  6.8887e-01, -4.1369e-01, -1.9878e-01,\n","          1.3800e-01,  7.1946e-01, -3.3764e-01,  1.3259e-01,  2.6167e-01,\n","          1.8828e-01, -6.3344e-02,  5.1625e-01, -4.3719e-02, -6.1617e-01,\n","         -1.5229e+00,  6.0988e-02,  2.1053e-01, -2.6753e-01,  8.5096e-02,\n","          5.5303e-01,  2.0319e-01,  1.0850e-01],\n","        [-5.8077e-01, -5.2649e-01,  3.7343e-01,  2.1012e-01,  2.6410e-01,\n","          1.0349e-01, -1.1241e+00,  5.6952e-01,  3.6202e-02, -5.1700e-01,\n","         -3.4330e-03,  5.7591e-01, -3.2654e-01,  4.2950e-01,  2.8234e-01,\n","          1.7432e-01, -1.6487e-01,  4.7869e-01,  1.1563e-01, -8.4260e-01,\n","         -1.5450e+00,  5.6695e-02,  2.4177e-01, -4.4859e-02,  5.7016e-02,\n","          4.7091e-01,  1.7140e-01,  2.5341e-01],\n","        [-7.9854e-01, -6.1319e-01,  3.6248e-01,  3.2018e-03,  4.9949e-01,\n","          6.5878e-01, -1.0653e+00,  3.9557e-01, -3.8405e-01, -6.1214e-01,\n","         -6.0367e-03,  5.3125e-01, -1.4449e-01,  5.0318e-01,  8.9006e-02,\n","          8.8243e-02, -8.9606e-02,  6.1892e-01, -2.0808e-01, -9.7290e-01,\n","         -1.2957e+00,  5.2122e-02,  5.0173e-01, -2.4902e-01,  3.5416e-01,\n","          8.9318e-01,  4.3735e-02,  4.6223e-01]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","\n","Iteration:   2% 56/2714 [00:21<17:22,  2.55it/s]\u001b[Aoutputs:\n","(tensor([[[ 5.7538e-01,  3.5853e-01, -2.7018e-01,  ..., -1.2716e-02,\n","           5.4205e-01,  2.7414e-01],\n","         [ 3.3158e-01,  2.4969e-01, -2.1568e-01,  ...,  3.8878e-02,\n","           1.3948e-01,  3.5935e-01],\n","         [ 6.0809e-01,  1.5756e-01, -4.6567e-02,  ...,  4.2550e-01,\n","           7.5703e-02,  2.3255e-01],\n","         ...,\n","         [ 1.9356e-01,  4.3674e-01,  2.9874e-02,  ...,  5.3676e-01,\n","           4.7780e-01, -1.5278e-01],\n","         [-7.9687e-02,  3.3088e-01, -6.4374e-02,  ...,  5.4979e-01,\n","           2.4695e-01, -3.4025e-02],\n","         [-1.1706e-01,  1.4371e-01,  1.2402e-03,  ...,  2.6324e-01,\n","          -2.5060e-02, -1.0762e-01]],\n","\n","        [[ 4.4337e-01,  1.2648e-01,  7.4273e-02,  ..., -4.0709e-01,\n","           5.5840e-01, -5.2319e-01],\n","         [ 3.0128e-01, -1.8638e-01,  4.3681e-01,  ..., -3.3448e-01,\n","           4.6221e-01, -4.6101e-01],\n","         [-1.1750e-01, -5.2838e-02, -9.2890e-02,  ..., -5.7366e-01,\n","           4.8219e-01,  2.0536e-01],\n","         ...,\n","         [ 2.1033e-01,  2.3952e-01,  8.4163e-02,  ..., -1.6111e-01,\n","           3.3962e-01, -5.9744e-01],\n","         [ 2.5929e-01, -7.4009e-02, -1.0672e-01,  ...,  5.4006e-02,\n","           5.8821e-01, -3.4474e-01],\n","         [ 5.1184e-01, -2.4915e-01,  4.7460e-02,  ...,  6.3922e-02,\n","           6.9944e-01, -7.8685e-02]],\n","\n","        [[ 3.6404e-01,  2.6126e-01, -1.7316e-01,  ..., -3.2249e-02,\n","           5.2860e-01,  7.8847e-02],\n","         [ 2.7296e-01, -3.7941e-01, -3.9957e-02,  ...,  3.3811e-01,\n","           1.3730e-01,  8.5428e-02],\n","         [ 6.0993e-01, -2.4765e-01,  4.5241e-01,  ...,  2.7409e-01,\n","           2.0734e-01,  7.1376e-01],\n","         ...,\n","         [-2.9966e-01,  6.5631e-01,  1.3412e-02,  ..., -1.2564e-01,\n","           5.0681e-01,  3.6129e-02],\n","         [-3.2805e-01,  6.1503e-01, -6.0515e-02,  ..., -7.7987e-02,\n","           5.5086e-01,  1.2852e-01],\n","         [-1.5784e-02,  2.1218e-01,  1.3289e-02,  ...,  2.0886e-01,\n","           1.2858e-01,  2.5356e-01]],\n","\n","        ...,\n","\n","        [[ 2.8353e-01,  1.3867e-01, -3.9460e-01,  ..., -2.8357e-01,\n","           2.7763e-01,  2.5950e-01],\n","         [ 6.9446e-01, -7.5879e-01,  3.2340e-01,  ..., -3.3907e-01,\n","          -1.3733e-01,  3.4344e-01],\n","         [ 2.4533e-01, -1.3897e-01, -4.9913e-01,  ...,  6.4296e-01,\n","          -3.8758e-02,  7.3808e-01],\n","         ...,\n","         [ 4.9691e-02,  1.2493e-01,  8.1449e-04,  ...,  8.7714e-02,\n","           3.6772e-01, -5.5955e-02],\n","         [ 8.7417e-02,  2.2385e-01, -4.7222e-01,  ..., -1.2960e-01,\n","           4.2525e-01, -6.6643e-02],\n","         [ 4.2442e-02, -3.3272e-02,  6.8242e-02,  ...,  4.5165e-02,\n","          -5.5965e-02,  1.2530e-02]],\n","\n","        [[ 4.6686e-01,  2.9952e-01, -2.8753e-01,  ...,  9.5992e-02,\n","           2.2262e-01,  1.7166e-02],\n","         [ 2.6283e-01, -2.4759e-01,  1.9245e-01,  ..., -3.3410e-02,\n","           6.8722e-02,  4.5905e-01],\n","         [ 4.3333e-01,  7.2921e-01,  1.2992e-01,  ..., -3.7224e-01,\n","           3.4854e-01,  2.8828e-01],\n","         ...,\n","         [ 2.2552e-01,  4.0539e-01,  3.3672e-02,  ..., -5.9143e-02,\n","           5.7833e-01,  1.2692e-01],\n","         [ 2.8180e-01,  2.7111e-01,  1.6461e-01,  ...,  1.4894e-01,\n","           2.9705e-01, -2.8355e-01],\n","         [ 7.3267e-02,  3.9774e-01, -9.7576e-02,  ...,  2.5519e-02,\n","           2.9198e-01,  1.8632e-01]],\n","\n","        [[ 6.0061e-01,  3.0869e-01,  1.1772e-02,  ..., -3.6922e-01,\n","           3.1807e-01,  1.8600e-01],\n","         [ 1.2607e-01, -3.9914e-01,  1.4515e-01,  ..., -2.2697e-01,\n","           2.4346e-01, -1.3070e-01],\n","         [ 9.8983e-01,  6.1136e-02, -2.3503e-01,  ...,  6.3814e-01,\n","           1.1261e-01,  1.5178e-01],\n","         ...,\n","         [ 1.3060e-01,  1.1200e-01, -2.6654e-01,  ..., -1.9121e-01,\n","           6.6146e-01, -4.9834e-04],\n","         [ 1.7927e-01,  2.3513e-01, -2.3277e-01,  ...,  5.2441e-02,\n","           7.5391e-01, -1.6918e-01],\n","         [-1.7536e-01,  4.5227e-02, -1.8011e-01,  ..., -1.4102e-01,\n","           5.0801e-01,  2.0130e-01]]], device='cuda:0',\n","       grad_fn=<NativeLayerNormBackward>), tensor([[-0.8084,  0.5393,  1.0000,  ...,  1.0000, -0.6627,  0.9952],\n","        [-0.5991,  0.5674,  0.9999,  ...,  1.0000, -0.4215,  0.9929],\n","        [-0.8505,  0.5614,  1.0000,  ...,  1.0000, -0.1508,  0.9955],\n","        ...,\n","        [-0.7534,  0.4877,  0.9999,  ...,  1.0000, -0.5142,  0.9948],\n","        [-0.8120,  0.5984,  0.9999,  ...,  1.0000, -0.4342,  0.9897],\n","        [-0.8742,  0.5480,  1.0000,  ...,  1.0000,  0.0355,  0.9975]],\n","       device='cuda:0', grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.8084,  0.5393,  1.0000,  ...,  1.0000, -0.6627,  0.9952],\n","        [-0.5991,  0.5674,  0.9999,  ...,  1.0000, -0.4215,  0.9929],\n","        [-0.8505,  0.5614,  1.0000,  ...,  1.0000, -0.1508,  0.9955],\n","        ...,\n","        [-0.7534,  0.4877,  0.9999,  ...,  1.0000, -0.5142,  0.9948],\n","        [-0.8120,  0.5984,  0.9999,  ...,  1.0000, -0.4342,  0.9897],\n","        [-0.8742,  0.5480,  1.0000,  ...,  1.0000,  0.0355,  0.9975]],\n","       device='cuda:0', grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-3.5373e-01, -6.1232e-01,  1.5075e-01, -1.4005e-02,  3.8888e-01,\n","          4.3749e-01, -1.0140e+00,  5.0592e-01, -2.9140e-01, -5.8440e-01,\n","         -1.4285e-01,  6.3260e-01, -3.7505e-01,  1.7983e-01,  3.7094e-02,\n","         -2.1974e-01,  5.0159e-02,  7.0821e-01,  7.6270e-02, -8.3557e-01,\n","         -1.5804e+00, -1.4994e-02,  2.8986e-01, -1.6371e-01,  1.4886e-01,\n","          4.8457e-01, -4.4926e-04,  4.6714e-01],\n","        [-8.8268e-01, -4.1396e-01,  4.3599e-01, -2.2828e-01,  4.6954e-01,\n","          2.8397e-01, -8.2363e-01,  7.0605e-01, -2.5306e-01, -7.3397e-01,\n","          1.3994e-01,  1.0484e+00, -4.9607e-01,  6.2180e-02,  7.2056e-02,\n","          1.4700e-01,  8.9269e-02,  8.6375e-01,  1.6918e-01, -9.0046e-01,\n","         -1.7611e+00,  1.0458e-01,  2.4492e-01, -9.9105e-02,  2.3066e-01,\n","          7.6637e-01,  1.9910e-01,  3.0725e-01],\n","        [-5.0943e-01, -8.2291e-01,  5.2134e-01,  3.1058e-01,  9.0344e-02,\n","          4.6788e-01, -8.0668e-01,  9.8350e-01, -2.6783e-01, -3.9834e-01,\n","          1.5585e-01,  7.7720e-01, -4.1843e-01,  2.6808e-01,  2.1668e-01,\n","          1.2088e-01,  8.3139e-03,  4.3045e-01,  3.1942e-01, -6.4889e-01,\n","         -1.7218e+00, -7.6960e-02,  4.4039e-01, -3.9534e-01, -1.2293e-01,\n","          9.4806e-01, -2.2302e-02,  5.3032e-02],\n","        [-8.5345e-01, -7.4579e-01,  3.8839e-01, -1.8612e-01,  2.5254e-01,\n","          1.6858e-01, -6.5463e-01,  1.1549e+00, -7.4136e-02, -3.8495e-01,\n","          1.8141e-02,  7.8595e-01, -2.7973e-01,  2.6720e-01, -1.7177e-01,\n","          5.0068e-02,  1.3866e-01,  9.2095e-01,  5.2061e-02, -8.2436e-01,\n","         -1.7559e+00,  1.1330e-01,  3.1113e-01, -4.5304e-01, -6.8279e-02,\n","          8.8741e-01,  9.5568e-02,  3.6827e-01],\n","        [-6.3946e-01, -6.5335e-01,  5.8154e-01,  1.4965e-01,  2.3555e-01,\n","          5.1590e-01, -9.6701e-01,  5.8814e-01, -1.8820e-01, -3.3721e-01,\n","          5.2029e-02,  6.4865e-01, -2.6633e-01,  1.7521e-01,  1.8124e-01,\n","          2.0612e-02, -5.4431e-02,  4.4731e-01, -2.2938e-02, -8.8411e-01,\n","         -1.5099e+00,  4.1077e-02,  4.7720e-01, -3.3519e-01, -1.2402e-02,\n","          6.4933e-01, -4.8982e-02,  2.3420e-01],\n","        [-1.0491e+00, -7.9900e-01,  4.6202e-01, -2.4830e-01,  4.5775e-02,\n","          8.6176e-01, -1.0850e+00,  6.6821e-01, -2.5923e-01, -4.6392e-01,\n","          9.3195e-03,  5.3483e-01, -1.0155e-01,  3.4656e-01,  3.7729e-02,\n","          2.5417e-01, -4.5871e-02,  1.0540e+00, -8.6166e-02, -8.1792e-01,\n","         -1.4178e+00,  3.4911e-01,  1.2354e-01, -3.3122e-01,  3.1567e-01,\n","          8.5152e-01,  3.1392e-01,  4.7654e-01],\n","        [-7.6332e-01, -9.0115e-01,  5.9931e-01,  1.3441e-02,  3.9819e-01,\n","          4.7179e-01, -8.2922e-01,  2.1201e-01, -5.6101e-01, -5.5968e-01,\n","          2.2856e-01,  4.7164e-01, -3.7893e-01,  1.9034e-01,  7.9420e-03,\n","          9.6419e-02,  1.2672e-01,  6.3614e-01, -3.9761e-02, -7.1917e-01,\n","         -1.9423e+00, -3.9306e-02,  3.5435e-01, -3.1266e-01,  2.1674e-01,\n","          6.0333e-01, -7.7960e-02,  4.2140e-01],\n","        [-8.1491e-01, -6.5527e-01,  3.4266e-01, -1.5479e-01,  4.8567e-01,\n","          4.7184e-01, -1.0219e+00,  6.1998e-01, -9.0726e-02, -7.4504e-01,\n","          2.2588e-01,  6.5425e-01, -4.3668e-02,  7.1656e-02, -1.3179e-01,\n","          2.0607e-01, -1.2504e-01,  8.1737e-01, -1.4490e-02, -9.7937e-01,\n","         -1.4247e+00,  5.3236e-02,  5.1229e-01, -4.1239e-01,  2.0281e-01,\n","          8.6294e-01,  9.5908e-02,  6.9685e-01],\n","        [-5.0577e-01, -5.8828e-01,  6.1944e-01,  1.8293e-01, -1.0458e-02,\n","          3.2417e-01, -9.0567e-01,  7.1004e-01, -1.9506e-01, -5.0733e-01,\n","         -4.2698e-02,  5.7517e-01, -4.8135e-01,  5.2897e-03,  1.3499e-01,\n","          4.6858e-02,  1.3860e-02,  2.5777e-01,  2.2735e-01, -6.6406e-01,\n","         -1.5377e+00, -2.3881e-01,  5.3265e-01, -3.8122e-01, -5.7713e-02,\n","          5.9875e-01,  1.2594e-01, -2.1117e-02],\n","        [-5.9127e-01, -4.0962e-01,  4.5418e-01, -1.5775e-01,  5.4631e-01,\n","          4.4170e-01, -9.3514e-01,  7.9983e-01, -2.0354e-01, -3.4074e-01,\n","          1.9206e-02,  3.9824e-01, -1.4414e-01,  1.8786e-01, -3.5121e-02,\n","          1.6971e-01, -2.1388e-01,  5.2654e-01, -1.6767e-01, -7.2788e-01,\n","         -1.3962e+00,  1.6815e-01,  4.4013e-01, -3.5639e-01,  2.3017e-01,\n","          9.6839e-01,  2.4182e-01,  3.7624e-01],\n","        [-4.8207e-01, -8.6537e-01,  8.8599e-02, -2.8350e-01,  3.4490e-01,\n","          4.7457e-01, -7.6484e-01,  7.7723e-01, -3.1981e-01, -4.0601e-01,\n","          2.4047e-01,  6.7931e-01, -4.7562e-01,  3.0472e-01,  1.7457e-01,\n","          2.3322e-02, -2.3079e-01,  8.0153e-01, -1.1039e-01, -8.1714e-01,\n","         -1.7320e+00,  1.4675e-01,  4.1386e-01, -1.5962e-01,  7.3010e-02,\n","          4.8283e-01, -1.3301e-01,  2.4080e-01],\n","        [-8.1145e-01, -4.2560e-01,  5.1162e-01,  4.0803e-02,  2.5434e-01,\n","          6.4567e-01, -8.6450e-01,  6.3641e-01, -2.5622e-01, -3.0979e-01,\n","         -2.2379e-02,  1.7643e-01, -4.9993e-01,  3.9152e-01, -1.4568e-01,\n","          1.3255e-01, -4.7604e-02,  5.8825e-01,  8.5217e-02, -7.9894e-01,\n","         -1.3502e+00, -1.5173e-01, -2.9380e-02, -1.1091e-01,  8.8004e-02,\n","          7.2238e-01,  1.1908e-01,  3.4784e-01],\n","        [-8.6145e-01, -7.0506e-01,  1.8086e-01, -7.7469e-02,  9.1243e-02,\n","          4.4603e-01, -8.3539e-01,  5.7185e-01, -3.3865e-01, -5.8464e-01,\n","         -1.8280e-01,  6.3823e-01, -3.7723e-01,  4.8342e-01, -4.8393e-03,\n","          1.7813e-01, -1.2303e-01,  6.8601e-01, -5.7944e-02, -7.6163e-01,\n","         -1.5213e+00,  1.4080e-01,  7.1842e-01, -3.9054e-01,  2.8059e-01,\n","          8.8524e-01,  1.2554e-01,  7.3960e-02],\n","        [-6.5900e-01, -8.2199e-01,  4.3147e-01,  1.4071e-01,  2.7208e-01,\n","          6.0113e-01, -1.2130e+00,  5.1804e-01, -5.8162e-02, -5.0064e-01,\n","         -4.7913e-02,  5.2006e-01, -4.7416e-01,  7.3817e-02,  1.9244e-01,\n","         -5.0860e-02, -1.7253e-01,  3.4862e-01,  3.5890e-02, -9.5019e-01,\n","         -1.7286e+00,  1.6342e-01,  2.5435e-01, -1.5094e-01, -1.3072e-01,\n","          9.9276e-01, -9.0227e-02,  2.3061e-01],\n","        [-5.6700e-01, -8.0415e-01,  6.2335e-01, -1.5985e-01,  8.0117e-02,\n","          4.0267e-01, -5.9355e-01,  8.9444e-01,  6.7049e-02, -7.3275e-01,\n","          3.8010e-02,  7.8061e-01, -1.2002e-01,  1.8744e-01,  1.1008e-01,\n","         -8.3512e-02,  8.7465e-02,  5.5001e-01, -1.5332e-01, -2.2383e-01,\n","         -1.4177e+00, -4.1937e-02,  2.3010e-01, -4.9223e-01, -2.2998e-01,\n","          7.8867e-01, -1.1417e-01,  1.9609e-01],\n","        [-4.9986e-01, -5.5732e-01,  3.7806e-01, -1.6535e-01,  7.4551e-02,\n","          8.7632e-01, -8.5339e-01,  7.5784e-01, -2.2641e-01, -2.2106e-01,\n","         -3.5703e-02,  5.8475e-01, -4.7762e-01,  1.9896e-01,  2.7093e-01,\n","         -7.4309e-02,  1.9547e-02,  6.3327e-01,  1.6998e-01, -8.0009e-01,\n","         -1.7142e+00,  1.3802e-01,  2.7214e-01, -3.3223e-01,  2.6673e-01,\n","          4.7710e-01,  1.0403e-02,  2.5605e-01]], device='cuda:0',\n","       grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","Iteration:   2% 56/2714 [00:22<17:26,  2.54it/s]\n","Epoch:   0% 0/10 [00:22<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"run_goemotions.py\", line 336, in <module>\n","    main(cli_args)\n","  File \"run_goemotions.py\", line 301, in main\n","    global_step, tr_loss = train(args, model, tokenizer, train_dataset, dev_dataset, test_dataset)\n","  File \"run_goemotions.py\", line 109, in train\n","    loss.backward()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 195, in backward\n","    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 99, in backward\n","    allow_unreachable=True)  # allow_unreachable flag\n","KeyboardInterrupt\n"]}],"source":["!python3 run_goemotions.py --taxonomy original"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25058,"status":"ok","timestamp":1638976625005,"user":{"displayName":"Faryab Haye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16087714056557341269"},"user_tz":300},"id":"aYoaX9RNbv82","outputId":"17af891e-52a6-425f-d556-1e92a3b98bfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: content/ckpt/original/bert-base-cased-goemotions-original/checkpoint-6000/ (stored 0%)\n","  adding: content/ckpt/original/bert-base-cased-goemotions-original/checkpoint-6000/tokenizer_config.json (deflated 31%)\n","  adding: content/ckpt/original/bert-base-cased-goemotions-original/checkpoint-6000/config.json (deflated 61%)\n","  adding: content/ckpt/original/bert-base-cased-goemotions-original/checkpoint-6000/training_args.bin (deflated 39%)\n","  adding: content/ckpt/original/bert-base-cased-goemotions-original/checkpoint-6000/special_tokens_map.json (deflated 34%)\n","  adding: content/ckpt/original/bert-base-cased-goemotions-original/checkpoint-6000/pytorch_model.bin (deflated 7%)\n","  adding: content/ckpt/original/bert-base-cased-goemotions-original/checkpoint-6000/vocab.txt (deflated 49%)\n"]}],"source":["!zip -r /content/checkpoint-6000 /content/ckpt/original/bert-base-cased-goemotions-original/checkpoint-6000 "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B5GAauVSnmD1"},"outputs":[],"source":["from google.colab import files\n","files.download(\"/content/checkpoint-6000.zip\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":537,"status":"ok","timestamp":1638976638767,"user":{"displayName":"Faryab Haye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16087714056557341269"},"user_tz":300},"id":"jaBw4wtInrwN","outputId":"b95e4fac-6c10-4d86-838e-4d420c2a240b"},"outputs":[{"name":"stdout","output_type":"stream","text":["checkpoint-6000.zip  GoEmotions-pytorch      README.md\n","ckpt\t\t     LICENSE\t\t     requirements.txt\n","config\t\t     model.py\t\t     run_goemotions.py\n","data\t\t     multilabel_pipeline.py  sample_data\n","data_loader.py\t     __pycache__\t     utils.py\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28758,"status":"ok","timestamp":1638976854463,"user":{"displayName":"Faryab Haye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16087714056557341269"},"user_tz":300},"id":"1334m0L_oIRT","outputId":"31279150-12b7-45c7-b38a-46486f3dd2ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: content/ckpt/original/bert-base-cased-goemotions-original/checkpoint-6000/ (stored 0%)\n","  adding: content/ckpt/original/bert-base-cased-goemotions-original/checkpoint-6000/tokenizer_config.json (deflated 31%)\n","  adding: content/ckpt/original/bert-base-cased-goemotions-original/checkpoint-6000/config.json (deflated 61%)\n","  adding: content/ckpt/original/bert-base-cased-goemotions-original/checkpoint-6000/training_args.bin (deflated 39%)\n","  adding: content/ckpt/original/bert-base-cased-goemotions-original/checkpoint-6000/special_tokens_map.json (deflated 34%)\n","  adding: content/ckpt/original/bert-base-cased-goemotions-original/checkpoint-6000/pytorch_model.bin (deflated 7%)\n","  adding: content/ckpt/original/bert-base-cased-goemotions-original/checkpoint-6000/vocab.txt (deflated 49%)\n"]}],"source":["!zip -r /content/drive/MyDrive/torch-goemotions-checkpoint-6000.zip /content/ckpt/original/bert-base-cased-goemotions-original/checkpoint-6000 "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xAXF2v_4RNRp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639521073445,"user_tz":300,"elapsed":179,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"}},"outputId":"6d39f368-a330-46fa-9fcc-1cc9864fabf5"},"outputs":[{"output_type":"stream","name":"stdout","text":["original\n"]}],"source":["!ls ckpt"]},{"cell_type":"code","source":["!zip -r \"./roberta\" \"/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-xN0gj8TEeVP","executionInfo":{"status":"ok","timestamp":1639521235333,"user_tz":300,"elapsed":59542,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"}},"outputId":"3a472f64-dace-41b4-f80a-0c5336c9ce84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/ (stored 0%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/ (stored 0%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/config.json (deflated 61%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/training_args.bin (deflated 37%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/pytorch_model.bin (deflated 7%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/merges.txt (deflated 53%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/vocab.json (deflated 63%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/tokenizer_config.json (stored 0%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/special_tokens_map.json (deflated 56%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/dev/ (stored 0%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/dev/dev-2000.txt (deflated 51%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/dev/dev-1000.txt (deflated 51%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/ (stored 0%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/config.json (deflated 61%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/training_args.bin (deflated 37%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/pytorch_model.bin (deflated 7%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/merges.txt (deflated 53%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/vocab.json (deflated 63%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/tokenizer_config.json (stored 0%)\n","  adding: content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/special_tokens_map.json (deflated 56%)\n"]}]},{"cell_type":"code","source":["!mv \"./roberta.zip\" \"/content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/roberta.zip\""],"metadata":{"id":"vIYa7ZRwEsJc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip \"/content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/roberta.zip\" -d \"/content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"98ilrO8NFKQh","executionInfo":{"status":"ok","timestamp":1639521353137,"user_tz":300,"elapsed":17684,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"}},"outputId":"0aa80c8a-26c4-4806-ee6d-fe0ef828922d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/roberta.zip\n","   creating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/\n","   creating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/\n","  inflating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/config.json  \n","  inflating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/training_args.bin  \n","  inflating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/pytorch_model.bin  \n","  inflating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/merges.txt  \n","  inflating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/vocab.json  \n"," extracting: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/tokenizer_config.json  \n","  inflating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/special_tokens_map.json  \n","   creating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/dev/\n","  inflating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/dev/dev-2000.txt  \n","  inflating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/dev/dev-1000.txt  \n","   creating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/\n","  inflating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/config.json  \n","  inflating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/training_args.bin  \n","  inflating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/pytorch_model.bin  \n","  inflating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/merges.txt  \n","  inflating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/vocab.json  \n"," extracting: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/tokenizer_config.json  \n","  inflating: /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/content/ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/special_tokens_map.json  \n"]}]},{"cell_type":"code","source":["!ls \"/content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-2000/pytorch_model.bin\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DiJQ5mHwFktO","executionInfo":{"status":"ok","timestamp":1639521643252,"user_tz":300,"elapsed":265,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"}},"outputId":"6cf1488c-c91e-4d75-d764-0e5c93a3ea02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["config.json  pytorch_model.bin\t      tokenizer_config.json  vocab.json\n","merges.txt   special_tokens_map.json  training_args.bin\n"]}]},{"cell_type":"markdown","metadata":{"id":"zyPxYzaXRNrl"},"source":["## Try Running RoBERTa"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9piWoK8moTH6","outputId":"3bcbd1f2-a477-4c25-c9af-af72d0b3fd84","executionInfo":{"status":"ok","timestamp":1639520961162,"user_tz":300,"elapsed":3129615,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["12/14/2021 21:37:19 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpd2bx9l0o\n","\rDownloading:   0% 0.00/481 [00:00<?, ?B/s]\rDownloading: 100% 481/481 [00:00<00:00, 540kB/s]\n","12/14/2021 21:37:19 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json in cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","12/14/2021 21:37:19 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","12/14/2021 21:37:19 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690\n","12/14/2021 21:37:19 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": \"goemotions\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"admiration\",\n","    \"1\": \"amusement\",\n","    \"10\": \"disapproval\",\n","    \"11\": \"disgust\",\n","    \"12\": \"embarrassment\",\n","    \"13\": \"excitement\",\n","    \"14\": \"fear\",\n","    \"15\": \"gratitude\",\n","    \"16\": \"grief\",\n","    \"17\": \"joy\",\n","    \"18\": \"love\",\n","    \"19\": \"nervousness\",\n","    \"2\": \"anger\",\n","    \"20\": \"optimism\",\n","    \"21\": \"pride\",\n","    \"22\": \"realization\",\n","    \"23\": \"relief\",\n","    \"24\": \"remorse\",\n","    \"25\": \"sadness\",\n","    \"26\": \"surprise\",\n","    \"27\": \"neutral\",\n","    \"3\": \"annoyance\",\n","    \"4\": \"approval\",\n","    \"5\": \"caring\",\n","    \"6\": \"confusion\",\n","    \"7\": \"curiosity\",\n","    \"8\": \"desire\",\n","    \"9\": \"disappointment\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"admiration\": 0,\n","    \"amusement\": 1,\n","    \"anger\": 2,\n","    \"annoyance\": 3,\n","    \"approval\": 4,\n","    \"caring\": 5,\n","    \"confusion\": 6,\n","    \"curiosity\": 7,\n","    \"desire\": 8,\n","    \"disappointment\": 9,\n","    \"disapproval\": 10,\n","    \"disgust\": 11,\n","    \"embarrassment\": 12,\n","    \"excitement\": 13,\n","    \"fear\": 14,\n","    \"gratitude\": 15,\n","    \"grief\": 16,\n","    \"joy\": 17,\n","    \"love\": 18,\n","    \"nervousness\": 19,\n","    \"neutral\": 27,\n","    \"optimism\": 20,\n","    \"pride\": 21,\n","    \"realization\": 22,\n","    \"relief\": 23,\n","    \"remorse\": 24,\n","    \"sadness\": 25,\n","    \"surprise\": 26\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","12/14/2021 21:37:19 - INFO - transformers.file_utils -   https://cdn.huggingface.co/roberta-base-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmppqyxg95r\n","Downloading: 100% 501M/501M [00:45<00:00, 11.1MB/s]\n","12/14/2021 21:38:04 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/roberta-base-pytorch_model.bin in cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","12/14/2021 21:38:04 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","12/14/2021 21:38:04 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","12/14/2021 21:38:09 - INFO - transformers.modeling_utils -   Weights of RobertaForMultiLabelClassification not initialized from pretrained model: ['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n","12/14/2021 21:38:09 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in RobertaForMultiLabelClassification: ['roberta.embeddings.word_embeddings.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","12/14/2021 21:38:09 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpkjst91ol\n","Downloading: 100% 899k/899k [00:00<00:00, 1.23MB/s]\n","12/14/2021 21:38:10 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json in cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","12/14/2021 21:38:10 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","12/14/2021 21:38:11 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp4faoxshj\n","Downloading: 100% 456k/456k [00:00<00:00, 1.07MB/s]\n","12/14/2021 21:38:11 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt in cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","12/14/2021 21:38:11 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","12/14/2021 21:38:11 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","12/14/2021 21:38:11 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","12/14/2021 21:38:13 - INFO - data_loader -   Creating features from dataset file at data/original\n","12/14/2021 21:38:13 - INFO - data_loader -   LOOKING AT data/original/train.tsv\n","12/14/2021 21:38:13 - INFO - data_loader -   My favourite food is anything I didn't have to cook myself.\t27\teebbqej\n","12/14/2021 21:38:13 - INFO - data_loader -   What’s that extra B for?\t6,7\tedo4lm1\n","12/14/2021 21:38:13 - INFO - data_loader -   Quick... there's a boot somewhere that you haven't licked today yet!\t27\tedoblwt\n","12/14/2021 21:38:13 - INFO - data_loader -   I'm so gay I can't even drive straight - a bumper sticker older than most redditors\t19\tedfval6\n","12/14/2021 21:38:13 - INFO - data_loader -   I don't know\t27\ted98qh1\n","12/14/2021 21:38:13 - INFO - data_loader -   Broom him fast.\t27\tedket23\n","12/14/2021 21:38:13 - INFO - data_loader -   The balance above the base fee gets put somewhere else. Education, healthcare, etc. Voila, police aren't biased, people are proportionally fined. \t27\teepn62z\n","12/14/2021 21:38:13 - INFO - data_loader -   Hi [NAME], I love you, that is all. Can't wait to see you in Worcester in February!\t17,18\tee8wndy\n","12/14/2021 21:38:13 - INFO - data_loader -   I mean it sucks but that man looks deaded\t11,22\ted917ws\n","12/14/2021 21:38:22 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:22 - INFO - data_loader -   guid: train-0\n","12/14/2021 21:38:22 - INFO - data_loader -   sentence: My favourite food is anything I didn't have to cook myself.\n","12/14/2021 21:38:22 - INFO - data_loader -   tokens: My Ġfavourite Ġfood Ġis Ġanything ĠI Ġdidn 't Ġhave Ġto Ġcook Ġmyself .\n","12/14/2021 21:38:22 - INFO - data_loader -   input_ids: 0 1308 5548 689 16 932 38 399 75 33 7 7142 2185 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:22 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:22 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/14/2021 21:38:22 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:22 - INFO - data_loader -   guid: train-1\n","12/14/2021 21:38:22 - INFO - data_loader -   sentence: Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead\n","12/14/2021 21:38:22 - INFO - data_loader -   tokens: Now Ġif Ġhe Ġdoes Ġoff Ġhimself , Ġeveryone Ġwill Ġthink Ġhes Ġhaving Ġa Ġlaugh Ġscrew ing Ġwith Ġpeople Ġinstead Ġof Ġactually Ġdead\n","12/14/2021 21:38:22 - INFO - data_loader -   input_ids: 0 978 114 37 473 160 1003 6 961 40 206 36279 519 10 7923 21927 154 19 82 1386 9 888 1462 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:22 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:22 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/14/2021 21:38:22 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:22 - INFO - data_loader -   guid: train-2\n","12/14/2021 21:38:22 - INFO - data_loader -   sentence: WHY THE FUCK IS BAYLESS ISOING\n","12/14/2021 21:38:22 - INFO - data_loader -   tokens: WH Y ĠTHE ĠFUCK ĠIS ĠB AY LESS ĠISO ING\n","12/14/2021 21:38:22 - INFO - data_loader -   input_ids: 0 34912 1941 46997 3703 163 2547 43023 26553 1862 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:22 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:22 - INFO - data_loader -   label: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:22 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:22 - INFO - data_loader -   guid: train-3\n","12/14/2021 21:38:22 - INFO - data_loader -   sentence: To make her feel threatened\n","12/14/2021 21:38:22 - INFO - data_loader -   tokens: To Ġmake Ġher Ġfeel Ġthreatened\n","12/14/2021 21:38:22 - INFO - data_loader -   input_ids: 0 598 146 69 619 3711 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:22 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:22 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:22 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:22 - INFO - data_loader -   guid: train-4\n","12/14/2021 21:38:22 - INFO - data_loader -   sentence: Dirty Southern Wankers\n","12/14/2021 21:38:22 - INFO - data_loader -   tokens: D irty ĠSouthern ĠW ank ers\n","12/14/2021 21:38:22 - INFO - data_loader -   input_ids: 0 30375 2944 305 3153 268 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:22 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:22 - INFO - data_loader -   label: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:22 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:22 - INFO - data_loader -   guid: train-5\n","12/14/2021 21:38:22 - INFO - data_loader -   sentence: OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe PlAyOfFs! Dumbass Broncos fans circa December 2015.\n","12/14/2021 21:38:22 - INFO - data_loader -   tokens: O m G Ġp Ey To N Ġi Sn ' T Ġg O o D Ġe No U g H Ġt O Ġh El P Ġu S Ġi N Ġt He ĠPl Ay Of Fs ! ĠDumb ass ĠBroncos Ġfans Ġcirca ĠDecember Ġ2015 .\n","12/14/2021 21:38:22 - INFO - data_loader -   input_ids: 0 13292 534 181 43431 3972 487 939 37790 108 565 821 673 139 495 364 3084 791 571 725 326 673 1368 9682 510 1717 104 939 487 326 894 3037 41585 10643 34417 328 37098 2401 7609 841 33570 719 570 4 2 1 1 1 1 1\n","12/14/2021 21:38:22 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n","12/14/2021 21:38:22 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n","12/14/2021 21:38:22 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:22 - INFO - data_loader -   guid: train-6\n","12/14/2021 21:38:22 - INFO - data_loader -   sentence: Yes I heard abt the f bombs! That has to be why. Thanks for your reply:) until then hubby and I will anxiously wait 😝\n","12/14/2021 21:38:22 - INFO - data_loader -   tokens: Yes ĠI Ġheard Ġab t Ġthe Ġf Ġbombs ! ĠThat Ġhas Ġto Ġbe Ġwhy . ĠThanks Ġfor Ġyour Ġreply : ) Ġuntil Ġthen Ġhub by Ġand ĠI Ġwill Ġanx iously Ġwait ĠðŁĺ Ŀ\n","12/14/2021 21:38:22 - INFO - data_loader -   input_ids: 0 3216 38 1317 4091 90 5 856 10834 328 280 34 7 28 596 4 4557 13 110 10418 35 43 454 172 6756 1409 8 38 40 27442 9997 2067 17841 46 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:22 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:22 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:22 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:22 - INFO - data_loader -   guid: train-7\n","12/14/2021 21:38:22 - INFO - data_loader -   sentence: We need more boards and to create a bit more space for [NAME]. Then we’ll be good.\n","12/14/2021 21:38:22 - INFO - data_loader -   tokens: We Ġneed Ġmore Ġboards Ġand Ġto Ġcreate Ġa Ġbit Ġmore Ġspace Ġfor Ġ[ NAME ]. ĠThen Ġwe âĢ Ļ ll Ġbe Ġgood .\n","12/14/2021 21:38:22 - INFO - data_loader -   input_ids: 0 166 240 55 6904 8 7 1045 10 828 55 980 13 646 48307 8174 1892 52 17 27 890 28 205 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:22 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:22 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n","12/14/2021 21:38:22 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:22 - INFO - data_loader -   guid: train-8\n","12/14/2021 21:38:22 - INFO - data_loader -   sentence: Damn youtube and outrage drama is super lucrative for reddit\n","12/14/2021 21:38:22 - INFO - data_loader -   tokens: Damn Ġyoutube Ġand Ġoutrage Ġdrama Ġis Ġsuper Ġlucrative Ġfor Ġreddit\n","12/14/2021 21:38:22 - INFO - data_loader -   input_ids: 0 41163 44736 8 10618 4149 16 2422 11874 13 44014 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:22 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:22 - INFO - data_loader -   label: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:22 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:22 - INFO - data_loader -   guid: train-9\n","12/14/2021 21:38:22 - INFO - data_loader -   sentence: It might be linked to the trust factor of your friend.\n","12/14/2021 21:38:22 - INFO - data_loader -   tokens: It Ġmight Ġbe Ġlinked Ġto Ġthe Ġtrust Ġfactor Ġof Ġyour Ġfriend .\n","12/14/2021 21:38:22 - INFO - data_loader -   input_ids: 0 85 429 28 3307 7 5 2416 3724 9 110 1441 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:22 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:22 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/14/2021 21:38:22 - INFO - data_loader -   Saving features into cached file data/original/cached_goemotions_roberta-base_50_train\n","12/14/2021 21:38:26 - INFO - data_loader -   Creating features from dataset file at data/original\n","12/14/2021 21:38:26 - INFO - data_loader -   LOOKING AT data/original/dev.tsv\n","12/14/2021 21:38:26 - INFO - data_loader -   Is this in New Orleans?? I really feel like this is New Orleans.\t27\tedgurhb\n","12/14/2021 21:38:26 - INFO - data_loader -   [NAME] is vastly overrated. Much bette4 [RELIGION] delis in the outer Burroughs\t4\tedc0amo\n","12/14/2021 21:38:27 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:27 - INFO - data_loader -   guid: dev-0\n","12/14/2021 21:38:27 - INFO - data_loader -   sentence: Is this in New Orleans?? I really feel like this is New Orleans.\n","12/14/2021 21:38:27 - INFO - data_loader -   tokens: Is Ġthis Ġin ĠNew ĠOrleans ?? ĠI Ġreally Ġfeel Ġlike Ġthis Ġis ĠNew ĠOrleans .\n","12/14/2021 21:38:27 - INFO - data_loader -   input_ids: 0 1534 42 11 188 4942 28749 38 269 619 101 42 16 188 4942 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:27 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:27 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/14/2021 21:38:27 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:27 - INFO - data_loader -   guid: dev-1\n","12/14/2021 21:38:27 - INFO - data_loader -   sentence: You know the answer man, you are programmed to capture those codes they send you, don’t avoid them!\n","12/14/2021 21:38:27 - INFO - data_loader -   tokens: You Ġknow Ġthe Ġanswer Ġman , Ġyou Ġare Ġprogrammed Ġto Ġcapture Ġthose Ġcodes Ġthey Ġsend Ġyou , Ġdon âĢ Ļ t Ġavoid Ġthem !\n","12/14/2021 21:38:27 - INFO - data_loader -   input_ids: 0 370 216 5 1948 313 6 47 32 30825 7 5604 167 14284 51 2142 47 6 218 17 27 90 1877 106 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:27 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:27 - INFO - data_loader -   label: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/14/2021 21:38:27 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:27 - INFO - data_loader -   guid: dev-2\n","12/14/2021 21:38:27 - INFO - data_loader -   sentence: I've never been this sad in my life!\n","12/14/2021 21:38:27 - INFO - data_loader -   tokens: I 've Ġnever Ġbeen Ġthis Ġsad Ġin Ġmy Ġlife !\n","12/14/2021 21:38:27 - INFO - data_loader -   input_ids: 0 38 348 393 57 42 5074 11 127 301 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:27 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:27 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n","12/14/2021 21:38:27 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:27 - INFO - data_loader -   guid: dev-3\n","12/14/2021 21:38:27 - INFO - data_loader -   sentence: The economy is heavily controlled and subsidized by the government. In any case, I was poking at the lack of nuance in US politics today\n","12/14/2021 21:38:27 - INFO - data_loader -   tokens: The Ġeconomy Ġis Ġheavily Ġcontrolled Ġand Ġsubsidized Ġby Ġthe Ġgovernment . ĠIn Ġany Ġcase , ĠI Ġwas Ġpoking Ġat Ġthe Ġlack Ġof Ġnuance Ġin ĠUS Ġpolitics Ġtoday\n","12/14/2021 21:38:27 - INFO - data_loader -   input_ids: 0 20 866 16 4008 4875 8 28397 30 5 168 4 96 143 403 6 38 21 34552 23 5 1762 9 37784 11 382 2302 452 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:27 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:27 - INFO - data_loader -   label: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/14/2021 21:38:27 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:27 - INFO - data_loader -   guid: dev-4\n","12/14/2021 21:38:27 - INFO - data_loader -   sentence: He could have easily taken a real camera from a legitimate source and change the price in Word/Photoshop and then print it out.\n","12/14/2021 21:38:27 - INFO - data_loader -   tokens: He Ġcould Ġhave Ġeasily Ġtaken Ġa Ġreal Ġcamera Ġfrom Ġa Ġlegitimate Ġsource Ġand Ġchange Ġthe Ġprice Ġin ĠWord / Phot oshop Ġand Ġthen Ġprint Ġit Ġout .\n","12/14/2021 21:38:27 - INFO - data_loader -   input_ids: 0 91 115 33 2773 551 10 588 2280 31 10 8134 1300 8 464 5 425 11 15690 73 41612 46491 8 172 5780 24 66 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:27 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:27 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n","12/14/2021 21:38:27 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:27 - INFO - data_loader -   guid: dev-5\n","12/14/2021 21:38:27 - INFO - data_loader -   sentence: Thank you for your vote of confidence, but we statistically can't get to 10 wins.\n","12/14/2021 21:38:27 - INFO - data_loader -   tokens: Thank Ġyou Ġfor Ġyour Ġvote Ġof Ġconfidence , Ġbut Ġwe Ġstatistically Ġcan 't Ġget Ġto Ġ10 Ġwins .\n","12/14/2021 21:38:27 - INFO - data_loader -   input_ids: 0 3837 47 13 110 900 9 2123 6 53 52 27697 64 75 120 7 158 2693 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:27 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:27 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:27 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:27 - INFO - data_loader -   guid: dev-6\n","12/14/2021 21:38:27 - INFO - data_loader -   sentence: Wah Mum other people call me on my bullshit and I can't ban them , Go out side son.\n","12/14/2021 21:38:27 - INFO - data_loader -   tokens: W ah ĠMum Ġother Ġpeople Ġcall Ġme Ġon Ġmy Ġbullshit Ġand ĠI Ġcan 't Ġban Ġthem Ġ, ĠGo Ġout Ġside Ġson .\n","12/14/2021 21:38:27 - INFO - data_loader -   input_ids: 0 19478 20675 97 82 486 162 15 127 37568 8 38 64 75 2020 106 2156 2381 66 526 979 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:27 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:27 - INFO - data_loader -   label: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:27 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:27 - INFO - data_loader -   guid: dev-7\n","12/14/2021 21:38:27 - INFO - data_loader -   sentence: There it is!\n","12/14/2021 21:38:27 - INFO - data_loader -   tokens: There Ġit Ġis !\n","12/14/2021 21:38:27 - INFO - data_loader -   input_ids: 0 345 24 16 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:27 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:27 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/14/2021 21:38:27 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:27 - INFO - data_loader -   guid: dev-8\n","12/14/2021 21:38:27 - INFO - data_loader -   sentence: At least now [NAME] has more time to gain his confidence\n","12/14/2021 21:38:27 - INFO - data_loader -   tokens: At Ġleast Ġnow Ġ[ NAME ] Ġhas Ġmore Ġtime Ġto Ġgain Ġhis Ġconfidence\n","12/14/2021 21:38:27 - INFO - data_loader -   input_ids: 0 497 513 122 646 48307 742 34 55 86 7 2364 39 2123 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:27 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:27 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n","12/14/2021 21:38:27 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:27 - INFO - data_loader -   guid: dev-9\n","12/14/2021 21:38:27 - INFO - data_loader -   sentence: Good. We don't want more thrash liberal offspring in this world.\n","12/14/2021 21:38:27 - INFO - data_loader -   tokens: Good . ĠWe Ġdon 't Ġwant Ġmore Ġthr ash Ġliberal Ġoffspring Ġin Ġthis Ġworld .\n","12/14/2021 21:38:27 - INFO - data_loader -   input_ids: 0 2497 4 166 218 75 236 55 10161 1671 6176 28491 11 42 232 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:27 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:27 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:27 - INFO - data_loader -   Saving features into cached file data/original/cached_goemotions_roberta-base_50_dev\n","12/14/2021 21:38:27 - INFO - data_loader -   Creating features from dataset file at data/original\n","12/14/2021 21:38:27 - INFO - data_loader -   LOOKING AT data/original/test.tsv\n","12/14/2021 21:38:27 - INFO - data_loader -   I’m really sorry about your situation :( Although I love the names Sapphira, Cirilla, and Scarlett!\t25\teecwqtt\n","12/14/2021 21:38:27 - INFO - data_loader -   Well I am a lady, so that would probably just freak them out. Oh, Reddit. Everyone is a man haha. \t1\teez3kgr\n","12/14/2021 21:38:28 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:28 - INFO - data_loader -   guid: test-0\n","12/14/2021 21:38:28 - INFO - data_loader -   sentence: I’m really sorry about your situation :( Although I love the names Sapphira, Cirilla, and Scarlett!\n","12/14/2021 21:38:28 - INFO - data_loader -   tokens: I âĢ Ļ m Ġreally Ġsorry Ġabout Ġyour Ġsituation Ġ:( ĠAlthough ĠI Ġlove Ġthe Ġnames ĠSapp h ira , ĠCir illa , Ġand ĠScarlett !\n","12/14/2021 21:38:28 - INFO - data_loader -   input_ids: 0 38 17 27 119 269 6661 59 110 1068 46225 2223 38 657 5 2523 37151 298 3578 6 24223 4699 6 8 27473 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:28 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:28 - INFO - data_loader -   guid: test-1\n","12/14/2021 21:38:28 - INFO - data_loader -   sentence: It's wonderful because it's awful. At not with.\n","12/14/2021 21:38:28 - INFO - data_loader -   tokens: It 's Ġwonderful Ġbecause Ġit 's Ġawful . ĠAt Ġnot Ġwith .\n","12/14/2021 21:38:28 - INFO - data_loader -   input_ids: 0 85 18 4613 142 24 18 11522 4 497 45 19 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:28 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   label: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:28 - INFO - data_loader -   guid: test-2\n","12/14/2021 21:38:28 - INFO - data_loader -   sentence: Kings fan here, good luck to you guys! Will be an interesting game to watch! \n","12/14/2021 21:38:28 - INFO - data_loader -   tokens: Kings Ġfan Ġhere , Ġgood Ġluck Ġto Ġyou Ġguys ! ĠWill Ġbe Ġan Ġinteresting Ġgame Ġto Ġwatch !\n","12/14/2021 21:38:28 - INFO - data_loader -   input_ids: 0 5414 2378 259 6 205 6620 7 47 1669 328 2290 28 41 2679 177 7 1183 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:28 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:28 - INFO - data_loader -   guid: test-3\n","12/14/2021 21:38:28 - INFO - data_loader -   sentence: I didn't know that, thank you for teaching me something today!\n","12/14/2021 21:38:28 - INFO - data_loader -   tokens: I Ġdidn 't Ġknow Ġthat , Ġthank Ġyou Ġfor Ġteaching Ġme Ġsomething Ġtoday !\n","12/14/2021 21:38:28 - INFO - data_loader -   input_ids: 0 38 399 75 216 14 6 3392 47 13 5307 162 402 452 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:28 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:28 - INFO - data_loader -   guid: test-4\n","12/14/2021 21:38:28 - INFO - data_loader -   sentence: They got bored from haunting earth for thousands of years and ultimately moved on to the afterlife.\n","12/14/2021 21:38:28 - INFO - data_loader -   tokens: They Ġgot Ġbored Ġfrom Ġhaunting Ġearth Ġfor Ġthousands Ġof Ġyears Ġand Ġultimately Ġmoved Ġon Ġto Ġthe Ġafterlife .\n","12/14/2021 21:38:28 - INFO - data_loader -   input_ids: 0 252 300 23809 31 29475 6872 13 1583 9 107 8 3284 1410 15 7 5 42873 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:28 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/14/2021 21:38:28 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:28 - INFO - data_loader -   guid: test-5\n","12/14/2021 21:38:28 - INFO - data_loader -   sentence: Thank you for asking questions and recognizing that there may be things that you don’t know or understand about police tactics. Seriously. Thank you.\n","12/14/2021 21:38:28 - INFO - data_loader -   tokens: Thank Ġyou Ġfor Ġasking Ġquestions Ġand Ġrecognizing Ġthat Ġthere Ġmay Ġbe Ġthings Ġthat Ġyou Ġdon âĢ Ļ t Ġknow Ġor Ġunderstand Ġabout Ġpolice Ġtactics . ĠSeriously . ĠThank Ġyou .\n","12/14/2021 21:38:28 - INFO - data_loader -   input_ids: 0 3837 47 13 1996 1142 8 16257 14 89 189 28 383 14 47 218 17 27 90 216 50 1346 59 249 8893 4 29945 4 3837 47 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:28 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:28 - INFO - data_loader -   guid: test-6\n","12/14/2021 21:38:28 - INFO - data_loader -   sentence: You’re welcome\n","12/14/2021 21:38:28 - INFO - data_loader -   tokens: You âĢ Ļ re Ġwelcome\n","12/14/2021 21:38:28 - INFO - data_loader -   input_ids: 0 370 17 27 241 2814 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:28 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:28 - INFO - data_loader -   guid: test-7\n","12/14/2021 21:38:28 - INFO - data_loader -   sentence: 100%! Congrats on your job too!\n","12/14/2021 21:38:28 - INFO - data_loader -   tokens: 100 % ! ĠCong rats Ġon Ġyour Ġjob Ġtoo !\n","12/14/2021 21:38:28 - INFO - data_loader -   input_ids: 0 727 207 328 12249 28814 15 110 633 350 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:28 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:28 - INFO - data_loader -   guid: test-8\n","12/14/2021 21:38:28 - INFO - data_loader -   sentence: I’m sorry to hear that friend :(. It’s for the best most likely if she didn’t accept you for who you are\n","12/14/2021 21:38:28 - INFO - data_loader -   tokens: I âĢ Ļ m Ġsorry Ġto Ġhear Ġthat Ġfriend Ġ:( . ĠIt âĢ Ļ s Ġfor Ġthe Ġbest Ġmost Ġlikely Ġif Ġshe Ġdidn âĢ Ļ t Ġaccept Ġyou Ġfor Ġwho Ġyou Ġare\n","12/14/2021 21:38:28 - INFO - data_loader -   input_ids: 0 38 17 27 119 6661 7 1798 14 1441 46225 4 85 17 27 29 13 5 275 144 533 114 79 399 17 27 90 3264 47 13 54 47 32 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:28 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   *** Example ***\n","12/14/2021 21:38:28 - INFO - data_loader -   guid: test-9\n","12/14/2021 21:38:28 - INFO - data_loader -   sentence: Girlfriend weak as well, that jump was pathetic.\n","12/14/2021 21:38:28 - INFO - data_loader -   tokens: G irlfriend Ġweak Ġas Ġwell , Ġthat Ġjump Ġwas Ġpathetic .\n","12/14/2021 21:38:28 - INFO - data_loader -   input_ids: 0 272 38883 3953 25 157 6 14 3704 21 31790 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 21:38:28 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n","12/14/2021 21:38:28 - INFO - data_loader -   Saving features into cached file data/original/cached_goemotions_roberta-base_50_test\n","12/14/2021 21:38:29 - INFO - __main__ -   ***** Running training *****\n","12/14/2021 21:38:29 - INFO - __main__ -     Num examples = 43410\n","12/14/2021 21:38:29 - INFO - __main__ -     Num Epochs = 10\n","12/14/2021 21:38:29 - INFO - __main__ -     Total train batch size = 64\n","12/14/2021 21:38:29 - INFO - __main__ -     Gradient Accumulation steps = 1\n","12/14/2021 21:38:29 - INFO - __main__ -     Total optimization steps = 6790\n","12/14/2021 21:38:29 - INFO - __main__ -     Logging steps = 1000\n","12/14/2021 21:38:29 - INFO - __main__ -     Save steps = 1000\n","Epoch:   0% 0/10 [00:00<?, ?it/s]\n","Iteration:   0% 0/679 [00:00<?, ?it/s]\u001b[A\n","Iteration:   0% 1/679 [00:01<13:46,  1.22s/it]\u001b[A\n","Iteration:   0% 2/679 [00:02<13:48,  1.22s/it]\u001b[A\n","Iteration:   0% 3/679 [00:03<13:49,  1.23s/it]\u001b[A\n","Iteration:   1% 4/679 [00:04<13:49,  1.23s/it]\u001b[A\n","Iteration:   1% 5/679 [00:06<13:49,  1.23s/it]\u001b[A\n","Iteration:   1% 6/679 [00:07<13:48,  1.23s/it]\u001b[A\n","Iteration:   1% 7/679 [00:08<13:47,  1.23s/it]\u001b[A\n","Iteration:   1% 8/679 [00:09<13:45,  1.23s/it]\u001b[A\n","Iteration:   1% 9/679 [00:11<13:45,  1.23s/it]\u001b[A\n","Iteration:   1% 10/679 [00:12<13:43,  1.23s/it]\u001b[A\n","Iteration:   2% 11/679 [00:13<13:42,  1.23s/it]\u001b[A\n","Iteration:   2% 12/679 [00:14<13:41,  1.23s/it]\u001b[A\n","Iteration:   2% 13/679 [00:16<13:41,  1.23s/it]\u001b[A\n","Iteration:   2% 14/679 [00:17<13:39,  1.23s/it]\u001b[A\n","Iteration:   2% 15/679 [00:18<13:37,  1.23s/it]\u001b[A\n","Iteration:   2% 16/679 [00:19<13:37,  1.23s/it]\u001b[A\n","Iteration:   3% 17/679 [00:20<13:36,  1.23s/it]\u001b[A\n","Iteration:   3% 18/679 [00:22<13:34,  1.23s/it]\u001b[A\n","Iteration:   3% 19/679 [00:23<13:33,  1.23s/it]\u001b[A\n","Iteration:   3% 20/679 [00:24<13:32,  1.23s/it]\u001b[A\n","Iteration:   3% 21/679 [00:25<13:30,  1.23s/it]\u001b[A\n","Iteration:   3% 22/679 [00:27<13:29,  1.23s/it]\u001b[A\n","Iteration:   3% 23/679 [00:28<13:28,  1.23s/it]\u001b[A\n","Iteration:   4% 24/679 [00:29<13:27,  1.23s/it]\u001b[A\n","Iteration:   4% 25/679 [00:30<13:25,  1.23s/it]\u001b[A\n","Iteration:   4% 26/679 [00:32<13:25,  1.23s/it]\u001b[A\n","Iteration:   4% 27/679 [00:33<13:24,  1.23s/it]\u001b[A\n","Iteration:   4% 28/679 [00:34<13:22,  1.23s/it]\u001b[A\n","Iteration:   4% 29/679 [00:35<13:22,  1.23s/it]\u001b[A\n","Iteration:   4% 30/679 [00:36<13:21,  1.23s/it]\u001b[A\n","Iteration:   5% 31/679 [00:38<13:20,  1.23s/it]\u001b[A\n","Iteration:   5% 32/679 [00:39<13:19,  1.24s/it]\u001b[A\n","Iteration:   5% 33/679 [00:40<13:18,  1.24s/it]\u001b[A\n","Iteration:   5% 34/679 [00:41<13:17,  1.24s/it]\u001b[A\n","Iteration:   5% 35/679 [00:43<13:15,  1.24s/it]\u001b[A\n","Iteration:   5% 36/679 [00:44<13:13,  1.23s/it]\u001b[A\n","Iteration:   5% 37/679 [00:45<13:13,  1.24s/it]\u001b[A\n","Iteration:   6% 38/679 [00:46<13:11,  1.24s/it]\u001b[A\n","Iteration:   6% 39/679 [00:48<13:08,  1.23s/it]\u001b[A\n","Iteration:   6% 40/679 [00:49<13:05,  1.23s/it]\u001b[A\n","Iteration:   6% 41/679 [00:50<13:03,  1.23s/it]\u001b[A\n","Iteration:   6% 42/679 [00:51<13:02,  1.23s/it]\u001b[A\n","Iteration:   6% 43/679 [00:52<12:59,  1.23s/it]\u001b[A\n","Iteration:   6% 44/679 [00:54<12:58,  1.23s/it]\u001b[A\n","Iteration:   7% 45/679 [00:55<12:57,  1.23s/it]\u001b[A\n","Iteration:   7% 46/679 [00:56<12:55,  1.23s/it]\u001b[A\n","Iteration:   7% 47/679 [00:57<12:55,  1.23s/it]\u001b[A\n","Iteration:   7% 48/679 [00:59<12:53,  1.23s/it]\u001b[A\n","Iteration:   7% 49/679 [01:00<12:51,  1.23s/it]\u001b[A\n","Iteration:   7% 50/679 [01:01<12:50,  1.22s/it]\u001b[A\n","Iteration:   8% 51/679 [01:02<12:49,  1.22s/it]\u001b[A\n","Iteration:   8% 52/679 [01:04<12:48,  1.23s/it]\u001b[A\n","Iteration:   8% 53/679 [01:05<12:47,  1.23s/it]\u001b[A\n","Iteration:   8% 54/679 [01:06<12:45,  1.23s/it]\u001b[A\n","Iteration:   8% 55/679 [01:07<12:44,  1.22s/it]\u001b[A\n","Iteration:   8% 56/679 [01:08<12:42,  1.22s/it]\u001b[A\n","Iteration:   8% 57/679 [01:10<12:42,  1.23s/it]\u001b[A\n","Iteration:   9% 58/679 [01:11<12:41,  1.23s/it]\u001b[A\n","Iteration:   9% 59/679 [01:12<12:39,  1.23s/it]\u001b[A\n","Iteration:   9% 60/679 [01:13<12:38,  1.23s/it]\u001b[A\n","Iteration:   9% 61/679 [01:15<12:36,  1.22s/it]\u001b[A\n","Iteration:   9% 62/679 [01:16<12:36,  1.23s/it]\u001b[A\n","Iteration:   9% 63/679 [01:17<12:35,  1.23s/it]\u001b[A\n","Iteration:   9% 64/679 [01:18<12:33,  1.23s/it]\u001b[A\n","Iteration:  10% 65/679 [01:19<12:32,  1.23s/it]\u001b[A\n","Iteration:  10% 66/679 [01:21<12:30,  1.22s/it]\u001b[A\n","Iteration:  10% 67/679 [01:22<12:30,  1.23s/it]\u001b[A\n","Iteration:  10% 68/679 [01:23<12:28,  1.22s/it]\u001b[A\n","Iteration:  10% 69/679 [01:24<12:26,  1.22s/it]\u001b[A\n","Iteration:  10% 70/679 [01:26<12:25,  1.22s/it]\u001b[A\n","Iteration:  10% 71/679 [01:27<12:24,  1.22s/it]\u001b[A\n","Iteration:  11% 72/679 [01:28<12:23,  1.23s/it]\u001b[A\n","Iteration:  11% 73/679 [01:29<12:22,  1.23s/it]\u001b[A\n","Iteration:  11% 74/679 [01:30<12:20,  1.22s/it]\u001b[A\n","Iteration:  11% 75/679 [01:32<12:19,  1.22s/it]\u001b[A\n","Iteration:  11% 76/679 [01:33<12:18,  1.22s/it]\u001b[A\n","Iteration:  11% 77/679 [01:34<12:17,  1.23s/it]\u001b[A\n","Iteration:  11% 78/679 [01:35<12:16,  1.23s/it]\u001b[A\n","Iteration:  12% 79/679 [01:37<12:15,  1.23s/it]\u001b[A\n","Iteration:  12% 80/679 [01:38<12:13,  1.23s/it]\u001b[A\n","Iteration:  12% 81/679 [01:39<12:12,  1.23s/it]\u001b[A\n","Iteration:  12% 82/679 [01:40<12:11,  1.23s/it]\u001b[A\n","Iteration:  12% 83/679 [01:41<12:10,  1.23s/it]\u001b[A\n","Iteration:  12% 84/679 [01:43<12:08,  1.22s/it]\u001b[A\n","Iteration:  13% 85/679 [01:44<12:07,  1.22s/it]\u001b[A\n","Iteration:  13% 86/679 [01:45<12:06,  1.22s/it]\u001b[A\n","Iteration:  13% 87/679 [01:46<12:05,  1.23s/it]\u001b[A\n","Iteration:  13% 88/679 [01:48<12:04,  1.23s/it]\u001b[A\n","Iteration:  13% 89/679 [01:49<12:02,  1.22s/it]\u001b[A\n","Iteration:  13% 90/679 [01:50<12:00,  1.22s/it]\u001b[A\n","Iteration:  13% 91/679 [01:51<11:59,  1.22s/it]\u001b[A\n","Iteration:  14% 92/679 [01:53<12:00,  1.23s/it]\u001b[A\n","Iteration:  14% 93/679 [01:54<11:58,  1.23s/it]\u001b[A\n","Iteration:  14% 94/679 [01:55<11:57,  1.23s/it]\u001b[A\n","Iteration:  14% 95/679 [01:56<11:55,  1.23s/it]\u001b[A\n","Iteration:  14% 96/679 [01:57<11:53,  1.22s/it]\u001b[A\n","Iteration:  14% 97/679 [01:59<11:53,  1.23s/it]\u001b[A\n","Iteration:  14% 98/679 [02:00<11:52,  1.23s/it]\u001b[A\n","Iteration:  15% 99/679 [02:01<11:50,  1.22s/it]\u001b[A\n","Iteration:  15% 100/679 [02:02<11:49,  1.23s/it]\u001b[A\n","Iteration:  15% 101/679 [02:04<11:48,  1.23s/it]\u001b[A\n","Iteration:  15% 102/679 [02:05<11:47,  1.23s/it]\u001b[A\n","Iteration:  15% 103/679 [02:06<11:45,  1.23s/it]\u001b[A\n","Iteration:  15% 104/679 [02:07<11:44,  1.22s/it]\u001b[A\n","Iteration:  15% 105/679 [02:08<11:42,  1.22s/it]\u001b[A\n","Iteration:  16% 106/679 [02:10<11:41,  1.22s/it]\u001b[A\n","Iteration:  16% 107/679 [02:11<11:40,  1.22s/it]\u001b[A\n","Iteration:  16% 108/679 [02:12<11:39,  1.22s/it]\u001b[A\n","Iteration:  16% 109/679 [02:13<11:38,  1.23s/it]\u001b[A\n","Iteration:  16% 110/679 [02:15<11:37,  1.23s/it]\u001b[A\n","Iteration:  16% 111/679 [02:16<11:36,  1.23s/it]\u001b[A\n","Iteration:  16% 112/679 [02:17<11:34,  1.23s/it]\u001b[A\n","Iteration:  17% 113/679 [02:18<11:33,  1.23s/it]\u001b[A\n","Iteration:  17% 114/679 [02:19<11:32,  1.23s/it]\u001b[A\n","Iteration:  17% 115/679 [02:21<11:31,  1.23s/it]\u001b[A\n","Iteration:  17% 116/679 [02:22<11:29,  1.22s/it]\u001b[A\n","Iteration:  17% 117/679 [02:23<11:27,  1.22s/it]\u001b[A\n","Iteration:  17% 118/679 [02:24<11:26,  1.22s/it]\u001b[A\n","Iteration:  18% 119/679 [02:26<11:25,  1.22s/it]\u001b[A\n","Iteration:  18% 120/679 [02:27<11:24,  1.22s/it]\u001b[A\n","Iteration:  18% 121/679 [02:28<11:23,  1.22s/it]\u001b[A\n","Iteration:  18% 122/679 [02:29<11:22,  1.23s/it]\u001b[A\n","Iteration:  18% 123/679 [02:30<11:21,  1.23s/it]\u001b[A\n","Iteration:  18% 124/679 [02:32<11:19,  1.22s/it]\u001b[A\n","Iteration:  18% 125/679 [02:33<11:18,  1.22s/it]\u001b[A\n","Iteration:  19% 126/679 [02:34<11:16,  1.22s/it]\u001b[A\n","Iteration:  19% 127/679 [02:35<11:15,  1.22s/it]\u001b[A\n","Iteration:  19% 128/679 [02:37<11:14,  1.22s/it]\u001b[A\n","Iteration:  19% 129/679 [02:38<11:13,  1.22s/it]\u001b[A\n","Iteration:  19% 130/679 [02:39<11:11,  1.22s/it]\u001b[A\n","Iteration:  19% 131/679 [02:40<11:10,  1.22s/it]\u001b[A\n","Iteration:  19% 132/679 [02:42<11:09,  1.22s/it]\u001b[A\n","Iteration:  20% 133/679 [02:43<11:08,  1.23s/it]\u001b[A\n","Iteration:  20% 134/679 [02:44<11:07,  1.22s/it]\u001b[A\n","Iteration:  20% 135/679 [02:45<11:06,  1.22s/it]\u001b[A\n","Iteration:  20% 136/679 [02:46<11:04,  1.22s/it]\u001b[A\n","Iteration:  20% 137/679 [02:48<11:05,  1.23s/it]\u001b[A\n","Iteration:  20% 138/679 [02:49<11:03,  1.23s/it]\u001b[A\n","Iteration:  20% 139/679 [02:50<11:01,  1.23s/it]\u001b[A\n","Iteration:  21% 140/679 [02:51<11:00,  1.23s/it]\u001b[A\n","Iteration:  21% 141/679 [02:53<10:58,  1.22s/it]\u001b[A\n","Iteration:  21% 142/679 [02:54<10:58,  1.23s/it]\u001b[A\n","Iteration:  21% 143/679 [02:55<10:56,  1.22s/it]\u001b[A\n","Iteration:  21% 144/679 [02:56<10:55,  1.23s/it]\u001b[A\n","Iteration:  21% 145/679 [02:57<10:54,  1.23s/it]\u001b[A\n","Iteration:  22% 146/679 [02:59<10:53,  1.23s/it]\u001b[A\n","Iteration:  22% 147/679 [03:00<10:52,  1.23s/it]\u001b[A\n","Iteration:  22% 148/679 [03:01<10:50,  1.23s/it]\u001b[A\n","Iteration:  22% 149/679 [03:02<10:49,  1.23s/it]\u001b[A\n","Iteration:  22% 150/679 [03:04<10:48,  1.23s/it]\u001b[A\n","Iteration:  22% 151/679 [03:05<10:46,  1.23s/it]\u001b[A\n","Iteration:  22% 152/679 [03:06<10:45,  1.23s/it]\u001b[A\n","Iteration:  23% 153/679 [03:07<10:44,  1.22s/it]\u001b[A\n","Iteration:  23% 154/679 [03:08<10:43,  1.23s/it]\u001b[A\n","Iteration:  23% 155/679 [03:10<10:42,  1.23s/it]\u001b[A\n","Iteration:  23% 156/679 [03:11<10:40,  1.23s/it]\u001b[A\n","Iteration:  23% 157/679 [03:12<10:39,  1.22s/it]\u001b[A\n","Iteration:  23% 158/679 [03:13<10:37,  1.22s/it]\u001b[A\n","Iteration:  23% 159/679 [03:15<10:35,  1.22s/it]\u001b[A\n","Iteration:  24% 160/679 [03:16<10:34,  1.22s/it]\u001b[A\n","Iteration:  24% 161/679 [03:17<10:33,  1.22s/it]\u001b[A\n","Iteration:  24% 162/679 [03:18<10:32,  1.22s/it]\u001b[A\n","Iteration:  24% 163/679 [03:19<10:31,  1.22s/it]\u001b[A\n","Iteration:  24% 164/679 [03:21<10:30,  1.22s/it]\u001b[A\n","Iteration:  24% 165/679 [03:22<10:29,  1.22s/it]\u001b[A\n","Iteration:  24% 166/679 [03:23<10:28,  1.22s/it]\u001b[A\n","Iteration:  25% 167/679 [03:24<10:27,  1.23s/it]\u001b[A\n","Iteration:  25% 168/679 [03:26<10:25,  1.22s/it]\u001b[A\n","Iteration:  25% 169/679 [03:27<10:23,  1.22s/it]\u001b[A\n","Iteration:  25% 170/679 [03:28<10:22,  1.22s/it]\u001b[A\n","Iteration:  25% 171/679 [03:29<10:21,  1.22s/it]\u001b[A\n","Iteration:  25% 172/679 [03:31<10:21,  1.23s/it]\u001b[A\n","Iteration:  25% 173/679 [03:32<10:19,  1.23s/it]\u001b[A\n","Iteration:  26% 174/679 [03:33<10:18,  1.23s/it]\u001b[A\n","Iteration:  26% 175/679 [03:34<10:17,  1.22s/it]\u001b[A\n","Iteration:  26% 176/679 [03:35<10:16,  1.22s/it]\u001b[A\n","Iteration:  26% 177/679 [03:37<10:15,  1.23s/it]\u001b[A\n","Iteration:  26% 178/679 [03:38<10:14,  1.23s/it]\u001b[A\n","Iteration:  26% 179/679 [03:39<10:12,  1.22s/it]\u001b[A\n","Iteration:  27% 180/679 [03:40<10:10,  1.22s/it]\u001b[A\n","Iteration:  27% 181/679 [03:42<10:09,  1.22s/it]\u001b[A\n","Iteration:  27% 182/679 [03:43<10:08,  1.23s/it]\u001b[A\n","Iteration:  27% 183/679 [03:44<10:07,  1.23s/it]\u001b[A\n","Iteration:  27% 184/679 [03:45<10:05,  1.22s/it]\u001b[A\n","Iteration:  27% 185/679 [03:46<10:04,  1.22s/it]\u001b[A\n","Iteration:  27% 186/679 [03:48<10:03,  1.22s/it]\u001b[A\n","Iteration:  28% 187/679 [03:49<10:02,  1.23s/it]\u001b[A\n","Iteration:  28% 188/679 [03:50<10:01,  1.23s/it]\u001b[A\n","Iteration:  28% 189/679 [03:51<09:59,  1.22s/it]\u001b[A\n","Iteration:  28% 190/679 [03:53<09:58,  1.22s/it]\u001b[A\n","Iteration:  28% 191/679 [03:54<09:57,  1.22s/it]\u001b[A\n","Iteration:  28% 192/679 [03:55<09:57,  1.23s/it]\u001b[A\n","Iteration:  28% 193/679 [03:56<09:55,  1.23s/it]\u001b[A\n","Iteration:  29% 194/679 [03:57<09:54,  1.23s/it]\u001b[A\n","Iteration:  29% 195/679 [03:59<09:52,  1.23s/it]\u001b[A\n","Iteration:  29% 196/679 [04:00<09:51,  1.23s/it]\u001b[A\n","Iteration:  29% 197/679 [04:01<09:50,  1.23s/it]\u001b[A\n","Iteration:  29% 198/679 [04:02<09:49,  1.23s/it]\u001b[A\n","Iteration:  29% 199/679 [04:04<09:47,  1.22s/it]\u001b[A\n","Iteration:  29% 200/679 [04:05<09:46,  1.22s/it]\u001b[A\n","Iteration:  30% 201/679 [04:06<09:44,  1.22s/it]\u001b[A\n","Iteration:  30% 202/679 [04:07<09:45,  1.23s/it]\u001b[A\n","Iteration:  30% 203/679 [04:08<09:43,  1.23s/it]\u001b[A\n","Iteration:  30% 204/679 [04:10<09:42,  1.23s/it]\u001b[A\n","Iteration:  30% 205/679 [04:11<09:40,  1.22s/it]\u001b[A\n","Iteration:  30% 206/679 [04:12<09:39,  1.22s/it]\u001b[A\n","Iteration:  30% 207/679 [04:13<09:38,  1.23s/it]\u001b[A\n","Iteration:  31% 208/679 [04:15<09:37,  1.23s/it]\u001b[A\n","Iteration:  31% 209/679 [04:16<09:35,  1.23s/it]\u001b[A\n","Iteration:  31% 210/679 [04:17<09:34,  1.22s/it]\u001b[A\n","Iteration:  31% 211/679 [04:18<09:32,  1.22s/it]\u001b[A\n","Iteration:  31% 212/679 [04:19<09:32,  1.23s/it]\u001b[A\n","Iteration:  31% 213/679 [04:21<09:30,  1.22s/it]\u001b[A\n","Iteration:  32% 214/679 [04:22<09:29,  1.23s/it]\u001b[A\n","Iteration:  32% 215/679 [04:23<09:28,  1.23s/it]\u001b[A\n","Iteration:  32% 216/679 [04:24<09:27,  1.23s/it]\u001b[A\n","Iteration:  32% 217/679 [04:26<09:27,  1.23s/it]\u001b[A\n","Iteration:  32% 218/679 [04:27<09:25,  1.23s/it]\u001b[A\n","Iteration:  32% 219/679 [04:28<09:24,  1.23s/it]\u001b[A\n","Iteration:  32% 220/679 [04:29<09:23,  1.23s/it]\u001b[A\n","Iteration:  33% 221/679 [04:31<09:21,  1.23s/it]\u001b[A\n","Iteration:  33% 222/679 [04:32<09:20,  1.23s/it]\u001b[A\n","Iteration:  33% 223/679 [04:33<09:18,  1.22s/it]\u001b[A\n","Iteration:  33% 224/679 [04:34<09:17,  1.22s/it]\u001b[A\n","Iteration:  33% 225/679 [04:35<09:16,  1.23s/it]\u001b[A\n","Iteration:  33% 226/679 [04:37<09:15,  1.23s/it]\u001b[A\n","Iteration:  33% 227/679 [04:38<09:14,  1.23s/it]\u001b[A\n","Iteration:  34% 228/679 [04:39<09:12,  1.23s/it]\u001b[A\n","Iteration:  34% 229/679 [04:40<09:11,  1.22s/it]\u001b[A\n","Iteration:  34% 230/679 [04:42<09:09,  1.22s/it]\u001b[A\n","Iteration:  34% 231/679 [04:43<09:08,  1.23s/it]\u001b[A\n","Iteration:  34% 232/679 [04:44<09:07,  1.23s/it]\u001b[A\n","Iteration:  34% 233/679 [04:45<09:05,  1.22s/it]\u001b[A\n","Iteration:  34% 234/679 [04:46<09:04,  1.22s/it]\u001b[A\n","Iteration:  35% 235/679 [04:48<09:03,  1.22s/it]\u001b[A\n","Iteration:  35% 236/679 [04:49<09:02,  1.22s/it]\u001b[A\n","Iteration:  35% 237/679 [04:50<09:01,  1.22s/it]\u001b[A\n","Iteration:  35% 238/679 [04:51<08:59,  1.22s/it]\u001b[A\n","Iteration:  35% 239/679 [04:53<08:58,  1.22s/it]\u001b[A\n","Iteration:  35% 240/679 [04:54<08:57,  1.22s/it]\u001b[A\n","Iteration:  35% 241/679 [04:55<08:56,  1.22s/it]\u001b[A\n","Iteration:  36% 242/679 [04:56<08:55,  1.22s/it]\u001b[A\n","Iteration:  36% 243/679 [04:57<08:53,  1.22s/it]\u001b[A\n","Iteration:  36% 244/679 [04:59<08:52,  1.22s/it]\u001b[A\n","Iteration:  36% 245/679 [05:00<08:51,  1.22s/it]\u001b[A\n","Iteration:  36% 246/679 [05:01<08:50,  1.22s/it]\u001b[A\n","Iteration:  36% 247/679 [05:02<08:49,  1.22s/it]\u001b[A\n","Iteration:  37% 248/679 [05:04<08:47,  1.22s/it]\u001b[A\n","Iteration:  37% 249/679 [05:05<08:46,  1.23s/it]\u001b[A\n","Iteration:  37% 250/679 [05:06<08:45,  1.22s/it]\u001b[A\n","Iteration:  37% 251/679 [05:07<08:44,  1.23s/it]\u001b[A\n","Iteration:  37% 252/679 [05:09<08:43,  1.23s/it]\u001b[A\n","Iteration:  37% 253/679 [05:10<08:42,  1.23s/it]\u001b[A\n","Iteration:  37% 254/679 [05:11<08:40,  1.23s/it]\u001b[A\n","Iteration:  38% 255/679 [05:12<08:39,  1.22s/it]\u001b[A\n","Iteration:  38% 256/679 [05:13<08:38,  1.22s/it]\u001b[A\n","Iteration:  38% 257/679 [05:15<08:36,  1.22s/it]\u001b[A\n","Iteration:  38% 258/679 [05:16<08:35,  1.22s/it]\u001b[A\n","Iteration:  38% 259/679 [05:17<08:34,  1.23s/it]\u001b[A\n","Iteration:  38% 260/679 [05:18<08:33,  1.23s/it]\u001b[A\n","Iteration:  38% 261/679 [05:20<08:32,  1.23s/it]\u001b[A\n","Iteration:  39% 262/679 [05:21<08:30,  1.23s/it]\u001b[A\n","Iteration:  39% 263/679 [05:22<08:29,  1.23s/it]\u001b[A\n","Iteration:  39% 264/679 [05:23<08:28,  1.22s/it]\u001b[A\n","Iteration:  39% 265/679 [05:24<08:27,  1.22s/it]\u001b[A\n","Iteration:  39% 266/679 [05:26<08:26,  1.23s/it]\u001b[A\n","Iteration:  39% 267/679 [05:27<08:24,  1.22s/it]\u001b[A\n","Iteration:  39% 268/679 [05:28<08:23,  1.23s/it]\u001b[A\n","Iteration:  40% 269/679 [05:29<08:22,  1.22s/it]\u001b[A\n","Iteration:  40% 270/679 [05:31<08:21,  1.23s/it]\u001b[A\n","Iteration:  40% 271/679 [05:32<08:19,  1.22s/it]\u001b[A\n","Iteration:  40% 272/679 [05:33<08:18,  1.22s/it]\u001b[A\n","Iteration:  40% 273/679 [05:34<08:17,  1.22s/it]\u001b[A\n","Iteration:  40% 274/679 [05:35<08:16,  1.23s/it]\u001b[A\n","Iteration:  41% 275/679 [05:37<08:14,  1.22s/it]\u001b[A\n","Iteration:  41% 276/679 [05:38<08:13,  1.22s/it]\u001b[A\n","Iteration:  41% 277/679 [05:39<08:12,  1.23s/it]\u001b[A\n","Iteration:  41% 278/679 [05:40<08:11,  1.22s/it]\u001b[A\n","Iteration:  41% 279/679 [05:42<08:09,  1.22s/it]\u001b[A\n","Iteration:  41% 280/679 [05:43<08:09,  1.23s/it]\u001b[A\n","Iteration:  41% 281/679 [05:44<08:07,  1.22s/it]\u001b[A\n","Iteration:  42% 282/679 [05:45<08:07,  1.23s/it]\u001b[A\n","Iteration:  42% 283/679 [05:46<08:05,  1.23s/it]\u001b[A\n","Iteration:  42% 284/679 [05:48<08:04,  1.23s/it]\u001b[A\n","Iteration:  42% 285/679 [05:49<08:03,  1.23s/it]\u001b[A\n","Iteration:  42% 286/679 [05:50<08:01,  1.23s/it]\u001b[A\n","Iteration:  42% 287/679 [05:51<08:00,  1.23s/it]\u001b[A\n","Iteration:  42% 288/679 [05:53<07:59,  1.23s/it]\u001b[A\n","Iteration:  43% 289/679 [05:54<07:57,  1.23s/it]\u001b[A\n","Iteration:  43% 290/679 [05:55<07:56,  1.22s/it]\u001b[A\n","Iteration:  43% 291/679 [05:56<07:55,  1.22s/it]\u001b[A\n","Iteration:  43% 292/679 [05:58<07:54,  1.23s/it]\u001b[A\n","Iteration:  43% 293/679 [05:59<07:52,  1.23s/it]\u001b[A\n","Iteration:  43% 294/679 [06:00<07:51,  1.22s/it]\u001b[A\n","Iteration:  43% 295/679 [06:01<07:50,  1.22s/it]\u001b[A\n","Iteration:  44% 296/679 [06:02<07:48,  1.22s/it]\u001b[A\n","Iteration:  44% 297/679 [06:04<07:48,  1.23s/it]\u001b[A\n","Iteration:  44% 298/679 [06:05<07:46,  1.23s/it]\u001b[A\n","Iteration:  44% 299/679 [06:06<07:45,  1.22s/it]\u001b[A\n","Iteration:  44% 300/679 [06:07<07:43,  1.22s/it]\u001b[A\n","Iteration:  44% 301/679 [06:09<07:42,  1.22s/it]\u001b[A\n","Iteration:  44% 302/679 [06:10<07:41,  1.23s/it]\u001b[A\n","Iteration:  45% 303/679 [06:11<07:40,  1.22s/it]\u001b[A\n","Iteration:  45% 304/679 [06:12<07:39,  1.22s/it]\u001b[A\n","Iteration:  45% 305/679 [06:13<07:38,  1.23s/it]\u001b[A\n","Iteration:  45% 306/679 [06:15<07:36,  1.23s/it]\u001b[A\n","Iteration:  45% 307/679 [06:16<07:35,  1.22s/it]\u001b[A\n","Iteration:  45% 308/679 [06:17<07:34,  1.22s/it]\u001b[A\n","Iteration:  46% 309/679 [06:18<07:33,  1.23s/it]\u001b[A\n","Iteration:  46% 310/679 [06:20<07:31,  1.22s/it]\u001b[A\n","Iteration:  46% 311/679 [06:21<07:30,  1.22s/it]\u001b[A\n","Iteration:  46% 312/679 [06:22<07:29,  1.22s/it]\u001b[A\n","Iteration:  46% 313/679 [06:23<07:28,  1.22s/it]\u001b[A\n","Iteration:  46% 314/679 [06:24<07:27,  1.23s/it]\u001b[A\n","Iteration:  46% 315/679 [06:26<07:25,  1.23s/it]\u001b[A\n","Iteration:  47% 316/679 [06:27<07:24,  1.22s/it]\u001b[A\n","Iteration:  47% 317/679 [06:28<07:23,  1.23s/it]\u001b[A\n","Iteration:  47% 318/679 [06:29<07:22,  1.23s/it]\u001b[A\n","Iteration:  47% 319/679 [06:31<07:20,  1.22s/it]\u001b[A\n","Iteration:  47% 320/679 [06:32<07:19,  1.22s/it]\u001b[A\n","Iteration:  47% 321/679 [06:33<07:18,  1.22s/it]\u001b[A\n","Iteration:  47% 322/679 [06:34<07:17,  1.23s/it]\u001b[A\n","Iteration:  48% 323/679 [06:35<07:16,  1.23s/it]\u001b[A\n","Iteration:  48% 324/679 [06:37<07:14,  1.23s/it]\u001b[A\n","Iteration:  48% 325/679 [06:38<07:13,  1.23s/it]\u001b[A\n","Iteration:  48% 326/679 [06:39<07:12,  1.23s/it]\u001b[A\n","Iteration:  48% 327/679 [06:40<07:11,  1.23s/it]\u001b[A\n","Iteration:  48% 328/679 [06:42<07:09,  1.22s/it]\u001b[A\n","Iteration:  48% 329/679 [06:43<07:08,  1.22s/it]\u001b[A\n","Iteration:  49% 330/679 [06:44<07:07,  1.23s/it]\u001b[A\n","Iteration:  49% 331/679 [06:45<07:06,  1.23s/it]\u001b[A\n","Iteration:  49% 332/679 [06:47<07:05,  1.23s/it]\u001b[A\n","Iteration:  49% 333/679 [06:48<07:04,  1.23s/it]\u001b[A\n","Iteration:  49% 334/679 [06:49<07:02,  1.23s/it]\u001b[A\n","Iteration:  49% 335/679 [06:50<07:01,  1.22s/it]\u001b[A\n","Iteration:  49% 336/679 [06:51<07:00,  1.22s/it]\u001b[A\n","Iteration:  50% 337/679 [06:53<06:59,  1.23s/it]\u001b[A\n","Iteration:  50% 338/679 [06:54<06:57,  1.23s/it]\u001b[A\n","Iteration:  50% 339/679 [06:55<06:56,  1.22s/it]\u001b[A\n","Iteration:  50% 340/679 [06:56<06:55,  1.23s/it]\u001b[A\n","Iteration:  50% 341/679 [06:58<06:54,  1.23s/it]\u001b[A\n","Iteration:  50% 342/679 [06:59<06:53,  1.23s/it]\u001b[A\n","Iteration:  51% 343/679 [07:00<06:52,  1.23s/it]\u001b[A\n","Iteration:  51% 344/679 [07:01<06:51,  1.23s/it]\u001b[A\n","Iteration:  51% 345/679 [07:02<06:49,  1.23s/it]\u001b[A\n","Iteration:  51% 346/679 [07:04<06:48,  1.23s/it]\u001b[A\n","Iteration:  51% 347/679 [07:05<06:46,  1.23s/it]\u001b[A\n","Iteration:  51% 348/679 [07:06<06:45,  1.22s/it]\u001b[A\n","Iteration:  51% 349/679 [07:07<06:44,  1.23s/it]\u001b[A\n","Iteration:  52% 350/679 [07:09<06:42,  1.22s/it]\u001b[A\n","Iteration:  52% 351/679 [07:10<06:41,  1.22s/it]\u001b[A\n","Iteration:  52% 352/679 [07:11<06:40,  1.23s/it]\u001b[A\n","Iteration:  52% 353/679 [07:12<06:39,  1.22s/it]\u001b[A\n","Iteration:  52% 354/679 [07:13<06:38,  1.22s/it]\u001b[A\n","Iteration:  52% 355/679 [07:15<06:36,  1.22s/it]\u001b[A\n","Iteration:  52% 356/679 [07:16<06:35,  1.22s/it]\u001b[A\n","Iteration:  53% 357/679 [07:17<06:34,  1.23s/it]\u001b[A\n","Iteration:  53% 358/679 [07:18<06:33,  1.23s/it]\u001b[A\n","Iteration:  53% 359/679 [07:20<06:31,  1.22s/it]\u001b[A\n","Iteration:  53% 360/679 [07:21<06:30,  1.22s/it]\u001b[A\n","Iteration:  53% 361/679 [07:22<06:29,  1.22s/it]\u001b[A\n","Iteration:  53% 362/679 [07:23<06:28,  1.22s/it]\u001b[A\n","Iteration:  53% 363/679 [07:24<06:26,  1.22s/it]\u001b[A\n","Iteration:  54% 364/679 [07:26<06:25,  1.22s/it]\u001b[A\n","Iteration:  54% 365/679 [07:27<06:24,  1.23s/it]\u001b[A\n","Iteration:  54% 366/679 [07:28<06:23,  1.23s/it]\u001b[A\n","Iteration:  54% 367/679 [07:29<06:22,  1.23s/it]\u001b[A\n","Iteration:  54% 368/679 [07:31<06:21,  1.23s/it]\u001b[A\n","Iteration:  54% 369/679 [07:32<06:19,  1.23s/it]\u001b[A\n","Iteration:  54% 370/679 [07:33<06:18,  1.22s/it]\u001b[A\n","Iteration:  55% 371/679 [07:34<06:17,  1.22s/it]\u001b[A\n","Iteration:  55% 372/679 [07:36<06:16,  1.23s/it]\u001b[A\n","Iteration:  55% 373/679 [07:37<06:15,  1.23s/it]\u001b[A\n","Iteration:  55% 374/679 [07:38<06:13,  1.23s/it]\u001b[A\n","Iteration:  55% 375/679 [07:39<06:12,  1.23s/it]\u001b[A\n","Iteration:  55% 376/679 [07:40<06:10,  1.22s/it]\u001b[A\n","Iteration:  56% 377/679 [07:42<06:10,  1.23s/it]\u001b[A\n","Iteration:  56% 378/679 [07:43<06:08,  1.22s/it]\u001b[A\n","Iteration:  56% 379/679 [07:44<06:07,  1.22s/it]\u001b[A\n","Iteration:  56% 380/679 [07:45<06:06,  1.22s/it]\u001b[A\n","Iteration:  56% 381/679 [07:47<06:05,  1.23s/it]\u001b[A\n","Iteration:  56% 382/679 [07:48<06:04,  1.23s/it]\u001b[A\n","Iteration:  56% 383/679 [07:49<06:03,  1.23s/it]\u001b[A\n","Iteration:  57% 384/679 [07:50<06:01,  1.23s/it]\u001b[A\n","Iteration:  57% 385/679 [07:51<06:00,  1.23s/it]\u001b[A\n","Iteration:  57% 386/679 [07:53<05:59,  1.23s/it]\u001b[A\n","Iteration:  57% 387/679 [07:54<05:57,  1.23s/it]\u001b[A\n","Iteration:  57% 388/679 [07:55<05:56,  1.23s/it]\u001b[A\n","Iteration:  57% 389/679 [07:56<05:55,  1.22s/it]\u001b[A\n","Iteration:  57% 390/679 [07:58<05:53,  1.22s/it]\u001b[A\n","Iteration:  58% 391/679 [07:59<05:52,  1.22s/it]\u001b[A\n","Iteration:  58% 392/679 [08:00<05:51,  1.23s/it]\u001b[A\n","Iteration:  58% 393/679 [08:01<05:50,  1.23s/it]\u001b[A\n","Iteration:  58% 394/679 [08:02<05:49,  1.23s/it]\u001b[A\n","Iteration:  58% 395/679 [08:04<05:48,  1.23s/it]\u001b[A\n","Iteration:  58% 396/679 [08:05<05:46,  1.23s/it]\u001b[A\n","Iteration:  58% 397/679 [08:06<05:46,  1.23s/it]\u001b[A\n","Iteration:  59% 398/679 [08:07<05:44,  1.23s/it]\u001b[A\n","Iteration:  59% 399/679 [08:09<05:43,  1.23s/it]\u001b[A\n","Iteration:  59% 400/679 [08:10<05:42,  1.23s/it]\u001b[A\n","Iteration:  59% 401/679 [08:11<05:40,  1.23s/it]\u001b[A\n","Iteration:  59% 402/679 [08:12<05:39,  1.23s/it]\u001b[A\n","Iteration:  59% 403/679 [08:14<05:38,  1.23s/it]\u001b[A\n","Iteration:  59% 404/679 [08:15<05:36,  1.22s/it]\u001b[A\n","Iteration:  60% 405/679 [08:16<05:35,  1.22s/it]\u001b[A\n","Iteration:  60% 406/679 [08:17<05:34,  1.22s/it]\u001b[A\n","Iteration:  60% 407/679 [08:18<05:33,  1.23s/it]\u001b[A\n","Iteration:  60% 408/679 [08:20<05:32,  1.23s/it]\u001b[A\n","Iteration:  60% 409/679 [08:21<05:30,  1.23s/it]\u001b[A\n","Iteration:  60% 410/679 [08:22<05:29,  1.23s/it]\u001b[A\n","Iteration:  61% 411/679 [08:23<05:28,  1.23s/it]\u001b[A\n","Iteration:  61% 412/679 [08:25<05:27,  1.23s/it]\u001b[A\n","Iteration:  61% 413/679 [08:26<05:26,  1.23s/it]\u001b[A\n","Iteration:  61% 414/679 [08:27<05:24,  1.23s/it]\u001b[A\n","Iteration:  61% 415/679 [08:28<05:23,  1.22s/it]\u001b[A\n","Iteration:  61% 416/679 [08:29<05:22,  1.22s/it]\u001b[A\n","Iteration:  61% 417/679 [08:31<05:21,  1.23s/it]\u001b[A\n","Iteration:  62% 418/679 [08:32<05:19,  1.22s/it]\u001b[A\n","Iteration:  62% 419/679 [08:33<05:18,  1.22s/it]\u001b[A\n","Iteration:  62% 420/679 [08:34<05:16,  1.22s/it]\u001b[A\n","Iteration:  62% 421/679 [08:36<05:15,  1.22s/it]\u001b[A\n","Iteration:  62% 422/679 [08:37<05:14,  1.23s/it]\u001b[A\n","Iteration:  62% 423/679 [08:38<05:13,  1.22s/it]\u001b[A\n","Iteration:  62% 424/679 [08:39<05:12,  1.22s/it]\u001b[A\n","Iteration:  63% 425/679 [08:40<05:11,  1.22s/it]\u001b[A\n","Iteration:  63% 426/679 [08:42<05:09,  1.22s/it]\u001b[A\n","Iteration:  63% 427/679 [08:43<05:08,  1.23s/it]\u001b[A\n","Iteration:  63% 428/679 [08:44<05:07,  1.23s/it]\u001b[A\n","Iteration:  63% 429/679 [08:45<05:06,  1.23s/it]\u001b[A\n","Iteration:  63% 430/679 [08:47<05:05,  1.23s/it]\u001b[A\n","Iteration:  63% 431/679 [08:48<05:03,  1.23s/it]\u001b[A\n","Iteration:  64% 432/679 [08:49<05:02,  1.23s/it]\u001b[A\n","Iteration:  64% 433/679 [08:50<05:01,  1.23s/it]\u001b[A\n","Iteration:  64% 434/679 [08:51<05:00,  1.23s/it]\u001b[A\n","Iteration:  64% 435/679 [08:53<04:59,  1.23s/it]\u001b[A\n","Iteration:  64% 436/679 [08:54<04:57,  1.23s/it]\u001b[A\n","Iteration:  64% 437/679 [08:55<04:56,  1.23s/it]\u001b[A\n","Iteration:  65% 438/679 [08:56<04:55,  1.23s/it]\u001b[A\n","Iteration:  65% 439/679 [08:58<04:54,  1.23s/it]\u001b[A\n","Iteration:  65% 440/679 [08:59<04:52,  1.22s/it]\u001b[A\n","Iteration:  65% 441/679 [09:00<04:51,  1.22s/it]\u001b[A\n","Iteration:  65% 442/679 [09:01<04:50,  1.22s/it]\u001b[A\n","Iteration:  65% 443/679 [09:03<04:49,  1.22s/it]\u001b[A\n","Iteration:  65% 444/679 [09:04<04:47,  1.22s/it]\u001b[A\n","Iteration:  66% 445/679 [09:05<04:46,  1.22s/it]\u001b[A\n","Iteration:  66% 446/679 [09:06<04:45,  1.22s/it]\u001b[A\n","Iteration:  66% 447/679 [09:07<04:44,  1.23s/it]\u001b[A\n","Iteration:  66% 448/679 [09:09<04:43,  1.23s/it]\u001b[A\n","Iteration:  66% 449/679 [09:10<04:42,  1.23s/it]\u001b[A\n","Iteration:  66% 450/679 [09:11<04:40,  1.23s/it]\u001b[A\n","Iteration:  66% 451/679 [09:12<04:39,  1.22s/it]\u001b[A\n","Iteration:  67% 452/679 [09:14<04:38,  1.23s/it]\u001b[A\n","Iteration:  67% 453/679 [09:15<04:37,  1.23s/it]\u001b[A\n","Iteration:  67% 454/679 [09:16<04:35,  1.22s/it]\u001b[A\n","Iteration:  67% 455/679 [09:17<04:34,  1.23s/it]\u001b[A\n","Iteration:  67% 456/679 [09:18<04:33,  1.23s/it]\u001b[A\n","Iteration:  67% 457/679 [09:20<04:32,  1.23s/it]\u001b[A\n","Iteration:  67% 458/679 [09:21<04:31,  1.23s/it]\u001b[A\n","Iteration:  68% 459/679 [09:22<04:29,  1.22s/it]\u001b[A\n","Iteration:  68% 460/679 [09:23<04:28,  1.22s/it]\u001b[A\n","Iteration:  68% 461/679 [09:25<04:26,  1.22s/it]\u001b[A\n","Iteration:  68% 462/679 [09:26<04:26,  1.23s/it]\u001b[A\n","Iteration:  68% 463/679 [09:27<04:24,  1.23s/it]\u001b[A\n","Iteration:  68% 464/679 [09:28<04:23,  1.22s/it]\u001b[A\n","Iteration:  68% 465/679 [09:29<04:22,  1.22s/it]\u001b[A\n","Iteration:  69% 466/679 [09:31<04:20,  1.22s/it]\u001b[A\n","Iteration:  69% 467/679 [09:32<04:19,  1.23s/it]\u001b[A\n","Iteration:  69% 468/679 [09:33<04:18,  1.23s/it]\u001b[A\n","Iteration:  69% 469/679 [09:34<04:17,  1.23s/it]\u001b[A\n","Iteration:  69% 470/679 [09:36<04:16,  1.23s/it]\u001b[A\n","Iteration:  69% 471/679 [09:37<04:14,  1.23s/it]\u001b[A\n","Iteration:  70% 472/679 [09:38<04:13,  1.23s/it]\u001b[A\n","Iteration:  70% 473/679 [09:39<04:12,  1.23s/it]\u001b[A\n","Iteration:  70% 474/679 [09:41<04:10,  1.22s/it]\u001b[A\n","Iteration:  70% 475/679 [09:42<04:09,  1.22s/it]\u001b[A\n","Iteration:  70% 476/679 [09:43<04:08,  1.22s/it]\u001b[A\n","Iteration:  70% 477/679 [09:44<04:07,  1.22s/it]\u001b[A\n","Iteration:  70% 478/679 [09:45<04:06,  1.23s/it]\u001b[A\n","Iteration:  71% 479/679 [09:47<04:05,  1.23s/it]\u001b[A\n","Iteration:  71% 480/679 [09:48<04:03,  1.22s/it]\u001b[A\n","Iteration:  71% 481/679 [09:49<04:02,  1.22s/it]\u001b[A\n","Iteration:  71% 482/679 [09:50<04:01,  1.23s/it]\u001b[A\n","Iteration:  71% 483/679 [09:52<04:00,  1.22s/it]\u001b[A\n","Iteration:  71% 484/679 [09:53<03:58,  1.23s/it]\u001b[A\n","Iteration:  71% 485/679 [09:54<03:57,  1.22s/it]\u001b[A\n","Iteration:  72% 486/679 [09:55<03:56,  1.22s/it]\u001b[A\n","Iteration:  72% 487/679 [09:56<03:55,  1.22s/it]\u001b[A\n","Iteration:  72% 488/679 [09:58<03:53,  1.22s/it]\u001b[A\n","Iteration:  72% 489/679 [09:59<03:52,  1.22s/it]\u001b[A\n","Iteration:  72% 490/679 [10:00<03:51,  1.22s/it]\u001b[A\n","Iteration:  72% 491/679 [10:01<03:50,  1.22s/it]\u001b[A\n","Iteration:  72% 492/679 [10:03<03:49,  1.23s/it]\u001b[A\n","Iteration:  73% 493/679 [10:04<03:47,  1.23s/it]\u001b[A\n","Iteration:  73% 494/679 [10:05<03:46,  1.22s/it]\u001b[A\n","Iteration:  73% 495/679 [10:06<03:45,  1.22s/it]\u001b[A\n","Iteration:  73% 496/679 [10:07<03:43,  1.22s/it]\u001b[A\n","Iteration:  73% 497/679 [10:09<03:42,  1.22s/it]\u001b[A\n","Iteration:  73% 498/679 [10:10<03:41,  1.22s/it]\u001b[A\n","Iteration:  73% 499/679 [10:11<03:40,  1.22s/it]\u001b[A\n","Iteration:  74% 500/679 [10:12<03:39,  1.22s/it]\u001b[A\n","Iteration:  74% 501/679 [10:14<03:37,  1.22s/it]\u001b[A\n","Iteration:  74% 502/679 [10:15<03:36,  1.23s/it]\u001b[A\n","Iteration:  74% 503/679 [10:16<03:35,  1.23s/it]\u001b[A\n","Iteration:  74% 504/679 [10:17<03:34,  1.23s/it]\u001b[A\n","Iteration:  74% 505/679 [10:18<03:33,  1.23s/it]\u001b[A\n","Iteration:  75% 506/679 [10:20<03:31,  1.22s/it]\u001b[A\n","Iteration:  75% 507/679 [10:21<03:30,  1.23s/it]\u001b[A\n","Iteration:  75% 508/679 [10:22<03:29,  1.23s/it]\u001b[A\n","Iteration:  75% 509/679 [10:23<03:28,  1.23s/it]\u001b[A\n","Iteration:  75% 510/679 [10:25<03:26,  1.22s/it]\u001b[A\n","Iteration:  75% 511/679 [10:26<03:25,  1.22s/it]\u001b[A\n","Iteration:  75% 512/679 [10:27<03:24,  1.22s/it]\u001b[A\n","Iteration:  76% 513/679 [10:28<03:23,  1.22s/it]\u001b[A\n","Iteration:  76% 514/679 [10:29<03:22,  1.22s/it]\u001b[A\n","Iteration:  76% 515/679 [10:31<03:20,  1.22s/it]\u001b[A\n","Iteration:  76% 516/679 [10:32<03:19,  1.22s/it]\u001b[A\n","Iteration:  76% 517/679 [10:33<03:18,  1.23s/it]\u001b[A\n","Iteration:  76% 518/679 [10:34<03:17,  1.23s/it]\u001b[A\n","Iteration:  76% 519/679 [10:36<03:16,  1.23s/it]\u001b[A\n","Iteration:  77% 520/679 [10:37<03:14,  1.22s/it]\u001b[A\n","Iteration:  77% 521/679 [10:38<03:13,  1.22s/it]\u001b[A\n","Iteration:  77% 522/679 [10:39<03:12,  1.23s/it]\u001b[A\n","Iteration:  77% 523/679 [10:41<03:11,  1.22s/it]\u001b[A\n","Iteration:  77% 524/679 [10:42<03:09,  1.22s/it]\u001b[A\n","Iteration:  77% 525/679 [10:43<03:08,  1.22s/it]\u001b[A\n","Iteration:  77% 526/679 [10:44<03:07,  1.22s/it]\u001b[A\n","Iteration:  78% 527/679 [10:45<03:06,  1.23s/it]\u001b[A\n","Iteration:  78% 528/679 [10:47<03:05,  1.23s/it]\u001b[A\n","Iteration:  78% 529/679 [10:48<03:03,  1.23s/it]\u001b[A\n","Iteration:  78% 530/679 [10:49<03:02,  1.23s/it]\u001b[A\n","Iteration:  78% 531/679 [10:50<03:01,  1.23s/it]\u001b[A\n","Iteration:  78% 532/679 [10:52<03:00,  1.23s/it]\u001b[A\n","Iteration:  78% 533/679 [10:53<02:58,  1.23s/it]\u001b[A\n","Iteration:  79% 534/679 [10:54<02:57,  1.23s/it]\u001b[A\n","Iteration:  79% 535/679 [10:55<02:56,  1.22s/it]\u001b[A\n","Iteration:  79% 536/679 [10:56<02:55,  1.22s/it]\u001b[A\n","Iteration:  79% 537/679 [10:58<02:54,  1.23s/it]\u001b[A\n","Iteration:  79% 538/679 [10:59<02:52,  1.23s/it]\u001b[A\n","Iteration:  79% 539/679 [11:00<02:51,  1.22s/it]\u001b[A\n","Iteration:  80% 540/679 [11:01<02:50,  1.22s/it]\u001b[A\n","Iteration:  80% 541/679 [11:03<02:48,  1.22s/it]\u001b[A\n","Iteration:  80% 542/679 [11:04<02:47,  1.23s/it]\u001b[A\n","Iteration:  80% 543/679 [11:05<02:46,  1.23s/it]\u001b[A\n","Iteration:  80% 544/679 [11:06<02:45,  1.23s/it]\u001b[A\n","Iteration:  80% 545/679 [11:07<02:44,  1.22s/it]\u001b[A\n","Iteration:  80% 546/679 [11:09<02:42,  1.22s/it]\u001b[A\n","Iteration:  81% 547/679 [11:10<02:41,  1.23s/it]\u001b[A\n","Iteration:  81% 548/679 [11:11<02:40,  1.23s/it]\u001b[A\n","Iteration:  81% 549/679 [11:12<02:39,  1.22s/it]\u001b[A\n","Iteration:  81% 550/679 [11:14<02:37,  1.22s/it]\u001b[A\n","Iteration:  81% 551/679 [11:15<02:36,  1.23s/it]\u001b[A\n","Iteration:  81% 552/679 [11:16<02:35,  1.23s/it]\u001b[A\n","Iteration:  81% 553/679 [11:17<02:34,  1.23s/it]\u001b[A\n","Iteration:  82% 554/679 [11:18<02:33,  1.23s/it]\u001b[A\n","Iteration:  82% 555/679 [11:20<02:31,  1.23s/it]\u001b[A\n","Iteration:  82% 556/679 [11:21<02:30,  1.22s/it]\u001b[A\n","Iteration:  82% 557/679 [11:22<02:29,  1.23s/it]\u001b[A\n","Iteration:  82% 558/679 [11:23<02:28,  1.22s/it]\u001b[A\n","Iteration:  82% 559/679 [11:25<02:27,  1.23s/it]\u001b[A\n","Iteration:  82% 560/679 [11:26<02:25,  1.23s/it]\u001b[A\n","Iteration:  83% 561/679 [11:27<02:24,  1.22s/it]\u001b[A\n","Iteration:  83% 562/679 [11:28<02:23,  1.23s/it]\u001b[A\n","Iteration:  83% 563/679 [11:30<02:22,  1.23s/it]\u001b[A\n","Iteration:  83% 564/679 [11:31<02:20,  1.23s/it]\u001b[A\n","Iteration:  83% 565/679 [11:32<02:19,  1.22s/it]\u001b[A\n","Iteration:  83% 566/679 [11:33<02:18,  1.22s/it]\u001b[A\n","Iteration:  84% 567/679 [11:34<02:17,  1.23s/it]\u001b[A\n","Iteration:  84% 568/679 [11:36<02:15,  1.23s/it]\u001b[A\n","Iteration:  84% 569/679 [11:37<02:14,  1.22s/it]\u001b[A\n","Iteration:  84% 570/679 [11:38<02:13,  1.22s/it]\u001b[A\n","Iteration:  84% 571/679 [11:39<02:12,  1.22s/it]\u001b[A\n","Iteration:  84% 572/679 [11:41<02:11,  1.23s/it]\u001b[A\n","Iteration:  84% 573/679 [11:42<02:09,  1.23s/it]\u001b[A\n","Iteration:  85% 574/679 [11:43<02:08,  1.23s/it]\u001b[A\n","Iteration:  85% 575/679 [11:44<02:07,  1.23s/it]\u001b[A\n","Iteration:  85% 576/679 [11:45<02:06,  1.22s/it]\u001b[A\n","Iteration:  85% 577/679 [11:47<02:04,  1.23s/it]\u001b[A\n","Iteration:  85% 578/679 [11:48<02:03,  1.22s/it]\u001b[A\n","Iteration:  85% 579/679 [11:49<02:02,  1.22s/it]\u001b[A\n","Iteration:  85% 580/679 [11:50<02:01,  1.22s/it]\u001b[A\n","Iteration:  86% 581/679 [11:52<01:59,  1.22s/it]\u001b[A\n","Iteration:  86% 582/679 [11:53<01:58,  1.23s/it]\u001b[A\n","Iteration:  86% 583/679 [11:54<01:57,  1.22s/it]\u001b[A\n","Iteration:  86% 584/679 [11:55<01:56,  1.23s/it]\u001b[A\n","Iteration:  86% 585/679 [11:56<01:55,  1.22s/it]\u001b[A\n","Iteration:  86% 586/679 [11:58<01:53,  1.22s/it]\u001b[A\n","Iteration:  86% 587/679 [11:59<01:52,  1.23s/it]\u001b[A\n","Iteration:  87% 588/679 [12:00<01:51,  1.22s/it]\u001b[A\n","Iteration:  87% 589/679 [12:01<01:50,  1.22s/it]\u001b[A\n","Iteration:  87% 590/679 [12:03<01:49,  1.22s/it]\u001b[A\n","Iteration:  87% 591/679 [12:04<01:47,  1.22s/it]\u001b[A\n","Iteration:  87% 592/679 [12:05<01:46,  1.22s/it]\u001b[A\n","Iteration:  87% 593/679 [12:06<01:45,  1.22s/it]\u001b[A\n","Iteration:  87% 594/679 [12:07<01:44,  1.22s/it]\u001b[A\n","Iteration:  88% 595/679 [12:09<01:42,  1.22s/it]\u001b[A\n","Iteration:  88% 596/679 [12:10<01:41,  1.22s/it]\u001b[A\n","Iteration:  88% 597/679 [12:11<01:40,  1.22s/it]\u001b[A\n","Iteration:  88% 598/679 [12:12<01:39,  1.22s/it]\u001b[A\n","Iteration:  88% 599/679 [12:14<01:37,  1.22s/it]\u001b[A\n","Iteration:  88% 600/679 [12:15<01:36,  1.22s/it]\u001b[A\n","Iteration:  89% 601/679 [12:16<01:35,  1.22s/it]\u001b[A\n","Iteration:  89% 602/679 [12:17<01:34,  1.22s/it]\u001b[A\n","Iteration:  89% 603/679 [12:19<01:32,  1.22s/it]\u001b[A\n","Iteration:  89% 604/679 [12:20<01:31,  1.22s/it]\u001b[A\n","Iteration:  89% 605/679 [12:21<01:30,  1.22s/it]\u001b[A\n","Iteration:  89% 606/679 [12:22<01:29,  1.22s/it]\u001b[A\n","Iteration:  89% 607/679 [12:23<01:28,  1.22s/it]\u001b[A\n","Iteration:  90% 608/679 [12:25<01:26,  1.22s/it]\u001b[A\n","Iteration:  90% 609/679 [12:26<01:25,  1.22s/it]\u001b[A\n","Iteration:  90% 610/679 [12:27<01:24,  1.22s/it]\u001b[A\n","Iteration:  90% 611/679 [12:28<01:23,  1.22s/it]\u001b[A\n","Iteration:  90% 612/679 [12:30<01:22,  1.22s/it]\u001b[A\n","Iteration:  90% 613/679 [12:31<01:20,  1.22s/it]\u001b[A\n","Iteration:  90% 614/679 [12:32<01:19,  1.22s/it]\u001b[A\n","Iteration:  91% 615/679 [12:33<01:18,  1.22s/it]\u001b[A\n","Iteration:  91% 616/679 [12:34<01:17,  1.22s/it]\u001b[A\n","Iteration:  91% 617/679 [12:36<01:15,  1.22s/it]\u001b[A\n","Iteration:  91% 618/679 [12:37<01:14,  1.22s/it]\u001b[A\n","Iteration:  91% 619/679 [12:38<01:13,  1.22s/it]\u001b[A\n","Iteration:  91% 620/679 [12:39<01:12,  1.22s/it]\u001b[A\n","Iteration:  91% 621/679 [12:41<01:10,  1.22s/it]\u001b[A\n","Iteration:  92% 622/679 [12:42<01:09,  1.22s/it]\u001b[A\n","Iteration:  92% 623/679 [12:43<01:08,  1.22s/it]\u001b[A\n","Iteration:  92% 624/679 [12:44<01:07,  1.22s/it]\u001b[A\n","Iteration:  92% 625/679 [12:45<01:06,  1.22s/it]\u001b[A\n","Iteration:  92% 626/679 [12:47<01:04,  1.22s/it]\u001b[A\n","Iteration:  92% 627/679 [12:48<01:03,  1.22s/it]\u001b[A\n","Iteration:  92% 628/679 [12:49<01:02,  1.22s/it]\u001b[A\n","Iteration:  93% 629/679 [12:50<01:01,  1.22s/it]\u001b[A\n","Iteration:  93% 630/679 [12:52<00:59,  1.22s/it]\u001b[A\n","Iteration:  93% 631/679 [12:53<00:58,  1.22s/it]\u001b[A\n","Iteration:  93% 632/679 [12:54<00:57,  1.22s/it]\u001b[A\n","Iteration:  93% 633/679 [12:55<00:56,  1.22s/it]\u001b[A\n","Iteration:  93% 634/679 [12:56<00:55,  1.22s/it]\u001b[A\n","Iteration:  94% 635/679 [12:58<00:53,  1.22s/it]\u001b[A\n","Iteration:  94% 636/679 [12:59<00:52,  1.22s/it]\u001b[A\n","Iteration:  94% 637/679 [13:00<00:51,  1.23s/it]\u001b[A\n","Iteration:  94% 638/679 [13:01<00:50,  1.22s/it]\u001b[A\n","Iteration:  94% 639/679 [13:03<00:48,  1.22s/it]\u001b[A\n","Iteration:  94% 640/679 [13:04<00:47,  1.22s/it]\u001b[A\n","Iteration:  94% 641/679 [13:05<00:46,  1.22s/it]\u001b[A\n","Iteration:  95% 642/679 [13:06<00:45,  1.22s/it]\u001b[A\n","Iteration:  95% 643/679 [13:07<00:44,  1.22s/it]\u001b[A\n","Iteration:  95% 644/679 [13:09<00:42,  1.22s/it]\u001b[A\n","Iteration:  95% 645/679 [13:10<00:41,  1.22s/it]\u001b[A\n","Iteration:  95% 646/679 [13:11<00:40,  1.22s/it]\u001b[A\n","Iteration:  95% 647/679 [13:12<00:39,  1.22s/it]\u001b[A\n","Iteration:  95% 648/679 [13:14<00:37,  1.22s/it]\u001b[A\n","Iteration:  96% 649/679 [13:15<00:36,  1.22s/it]\u001b[A\n","Iteration:  96% 650/679 [13:16<00:35,  1.22s/it]\u001b[A\n","Iteration:  96% 651/679 [13:17<00:34,  1.22s/it]\u001b[A\n","Iteration:  96% 652/679 [13:18<00:33,  1.23s/it]\u001b[A\n","Iteration:  96% 653/679 [13:20<00:31,  1.22s/it]\u001b[A\n","Iteration:  96% 654/679 [13:21<00:30,  1.22s/it]\u001b[A\n","Iteration:  96% 655/679 [13:22<00:29,  1.22s/it]\u001b[A\n","Iteration:  97% 656/679 [13:23<00:28,  1.22s/it]\u001b[A\n","Iteration:  97% 657/679 [13:25<00:26,  1.22s/it]\u001b[A\n","Iteration:  97% 658/679 [13:26<00:25,  1.22s/it]\u001b[A\n","Iteration:  97% 659/679 [13:27<00:24,  1.22s/it]\u001b[A\n","Iteration:  97% 660/679 [13:28<00:23,  1.22s/it]\u001b[A\n","Iteration:  97% 661/679 [13:30<00:22,  1.22s/it]\u001b[A\n","Iteration:  97% 662/679 [13:31<00:20,  1.22s/it]\u001b[A\n","Iteration:  98% 663/679 [13:32<00:19,  1.22s/it]\u001b[A\n","Iteration:  98% 664/679 [13:33<00:18,  1.22s/it]\u001b[A\n","Iteration:  98% 665/679 [13:34<00:17,  1.22s/it]\u001b[A\n","Iteration:  98% 666/679 [13:36<00:15,  1.23s/it]\u001b[A\n","Iteration:  98% 667/679 [13:37<00:14,  1.22s/it]\u001b[A\n","Iteration:  98% 668/679 [13:38<00:13,  1.22s/it]\u001b[A\n","Iteration:  99% 669/679 [13:39<00:12,  1.22s/it]\u001b[A\n","Iteration:  99% 670/679 [13:41<00:11,  1.22s/it]\u001b[A\n","Iteration:  99% 671/679 [13:42<00:09,  1.22s/it]\u001b[A\n","Iteration:  99% 672/679 [13:43<00:08,  1.22s/it]\u001b[A\n","Iteration:  99% 673/679 [13:44<00:07,  1.22s/it]\u001b[A\n","Iteration:  99% 674/679 [13:45<00:06,  1.22s/it]\u001b[A\n","Iteration:  99% 675/679 [13:47<00:04,  1.22s/it]\u001b[A\n","Iteration: 100% 676/679 [13:48<00:03,  1.22s/it]\u001b[A\n","Iteration: 100% 677/679 [13:49<00:02,  1.22s/it]\u001b[A\n","Iteration: 100% 678/679 [13:50<00:01,  1.22s/it]\u001b[A\n","Iteration: 100% 679/679 [13:51<00:00,  1.22s/it]\n","Epoch:  10% 1/10 [13:51<2:04:41, 831.32s/it]\n","Iteration:   0% 0/679 [00:00<?, ?it/s]\u001b[A\n","Iteration:   0% 1/679 [00:01<13:47,  1.22s/it]\u001b[A\n","Iteration:   0% 2/679 [00:02<13:47,  1.22s/it]\u001b[A\n","Iteration:   0% 3/679 [00:03<13:47,  1.22s/it]\u001b[A\n","Iteration:   1% 4/679 [00:04<13:46,  1.22s/it]\u001b[A\n","Iteration:   1% 5/679 [00:06<13:45,  1.22s/it]\u001b[A\n","Iteration:   1% 6/679 [00:07<13:44,  1.22s/it]\u001b[A\n","Iteration:   1% 7/679 [00:08<13:42,  1.22s/it]\u001b[A\n","Iteration:   1% 8/679 [00:09<13:41,  1.22s/it]\u001b[A\n","Iteration:   1% 9/679 [00:11<13:40,  1.22s/it]\u001b[A\n","Iteration:   1% 10/679 [00:12<13:38,  1.22s/it]\u001b[A\n","Iteration:   2% 11/679 [00:13<13:37,  1.22s/it]\u001b[A\n","Iteration:   2% 12/679 [00:14<13:36,  1.22s/it]\u001b[A\n","Iteration:   2% 13/679 [00:15<13:35,  1.22s/it]\u001b[A\n","Iteration:   2% 14/679 [00:17<13:34,  1.22s/it]\u001b[A\n","Iteration:   2% 15/679 [00:18<13:32,  1.22s/it]\u001b[A\n","Iteration:   2% 16/679 [00:19<13:31,  1.22s/it]\u001b[A\n","Iteration:   3% 17/679 [00:20<13:29,  1.22s/it]\u001b[A\n","Iteration:   3% 18/679 [00:22<13:28,  1.22s/it]\u001b[A\n","Iteration:   3% 19/679 [00:23<13:27,  1.22s/it]\u001b[A\n","Iteration:   3% 20/679 [00:24<13:26,  1.22s/it]\u001b[A\n","Iteration:   3% 21/679 [00:25<13:25,  1.22s/it]\u001b[A\n","Iteration:   3% 22/679 [00:26<13:24,  1.23s/it]\u001b[A\n","Iteration:   3% 23/679 [00:28<13:23,  1.22s/it]\u001b[A\n","Iteration:   4% 24/679 [00:29<13:21,  1.22s/it]\u001b[A\n","Iteration:   4% 25/679 [00:30<13:19,  1.22s/it]\u001b[A\n","Iteration:   4% 26/679 [00:31<13:18,  1.22s/it]\u001b[A\n","Iteration:   4% 27/679 [00:33<13:17,  1.22s/it]\u001b[A\n","Iteration:   4% 28/679 [00:34<13:16,  1.22s/it]\u001b[A\n","Iteration:   4% 29/679 [00:35<13:15,  1.22s/it]\u001b[A\n","Iteration:   4% 30/679 [00:36<13:14,  1.22s/it]\u001b[A\n","Iteration:   5% 31/679 [00:37<13:13,  1.22s/it]\u001b[A\n","Iteration:   5% 32/679 [00:39<13:12,  1.22s/it]\u001b[A\n","Iteration:   5% 33/679 [00:40<13:10,  1.22s/it]\u001b[A\n","Iteration:   5% 34/679 [00:41<13:09,  1.22s/it]\u001b[A\n","Iteration:   5% 35/679 [00:42<13:08,  1.22s/it]\u001b[A\n","Iteration:   5% 36/679 [00:44<13:06,  1.22s/it]\u001b[A\n","Iteration:   5% 37/679 [00:45<13:05,  1.22s/it]\u001b[A\n","Iteration:   6% 38/679 [00:46<13:04,  1.22s/it]\u001b[A\n","Iteration:   6% 39/679 [00:47<13:03,  1.22s/it]\u001b[A\n","Iteration:   6% 40/679 [00:48<13:02,  1.22s/it]\u001b[A\n","Iteration:   6% 41/679 [00:50<13:00,  1.22s/it]\u001b[A\n","Iteration:   6% 42/679 [00:51<13:00,  1.22s/it]\u001b[A\n","Iteration:   6% 43/679 [00:52<12:58,  1.22s/it]\u001b[A\n","Iteration:   6% 44/679 [00:53<12:57,  1.22s/it]\u001b[A\n","Iteration:   7% 45/679 [00:55<12:55,  1.22s/it]\u001b[A\n","Iteration:   7% 46/679 [00:56<12:54,  1.22s/it]\u001b[A\n","Iteration:   7% 47/679 [00:57<12:53,  1.22s/it]\u001b[A\n","Iteration:   7% 48/679 [00:58<12:52,  1.22s/it]\u001b[A\n","Iteration:   7% 49/679 [00:59<12:51,  1.22s/it]\u001b[A\n","Iteration:   7% 50/679 [01:01<12:49,  1.22s/it]\u001b[A\n","Iteration:   8% 51/679 [01:02<12:48,  1.22s/it]\u001b[A\n","Iteration:   8% 52/679 [01:03<12:47,  1.22s/it]\u001b[A\n","Iteration:   8% 53/679 [01:04<12:45,  1.22s/it]\u001b[A\n","Iteration:   8% 54/679 [01:06<12:45,  1.22s/it]\u001b[A\n","Iteration:   8% 55/679 [01:07<12:44,  1.22s/it]\u001b[A\n","Iteration:   8% 56/679 [01:08<12:42,  1.22s/it]\u001b[A\n","Iteration:   8% 57/679 [01:09<12:41,  1.22s/it]\u001b[A\n","Iteration:   9% 58/679 [01:10<12:40,  1.22s/it]\u001b[A\n","Iteration:   9% 59/679 [01:12<12:38,  1.22s/it]\u001b[A\n","Iteration:   9% 60/679 [01:13<12:37,  1.22s/it]\u001b[A\n","Iteration:   9% 61/679 [01:14<12:36,  1.22s/it]\u001b[A\n","Iteration:   9% 62/679 [01:15<12:35,  1.22s/it]\u001b[A\n","Iteration:   9% 63/679 [01:17<12:34,  1.22s/it]\u001b[A\n","Iteration:   9% 64/679 [01:18<12:32,  1.22s/it]\u001b[A\n","Iteration:  10% 65/679 [01:19<12:31,  1.22s/it]\u001b[A\n","Iteration:  10% 66/679 [01:20<12:30,  1.22s/it]\u001b[A\n","Iteration:  10% 67/679 [01:22<12:29,  1.22s/it]\u001b[A\n","Iteration:  10% 68/679 [01:23<12:28,  1.22s/it]\u001b[A\n","Iteration:  10% 69/679 [01:24<12:26,  1.22s/it]\u001b[A\n","Iteration:  10% 70/679 [01:25<12:25,  1.22s/it]\u001b[A\n","Iteration:  10% 71/679 [01:26<12:24,  1.22s/it]\u001b[A\n","Iteration:  11% 72/679 [01:28<12:23,  1.22s/it]\u001b[A\n","Iteration:  11% 73/679 [01:29<12:21,  1.22s/it]\u001b[A\n","Iteration:  11% 74/679 [01:30<12:20,  1.22s/it]\u001b[A\n","Iteration:  11% 75/679 [01:31<12:19,  1.22s/it]\u001b[A\n","Iteration:  11% 76/679 [01:33<12:18,  1.22s/it]\u001b[A\n","Iteration:  11% 77/679 [01:34<12:17,  1.22s/it]\u001b[A\n","Iteration:  11% 78/679 [01:35<12:15,  1.22s/it]\u001b[A\n","Iteration:  12% 79/679 [01:36<12:14,  1.22s/it]\u001b[A\n","Iteration:  12% 80/679 [01:37<12:12,  1.22s/it]\u001b[A\n","Iteration:  12% 81/679 [01:39<12:11,  1.22s/it]\u001b[A\n","Iteration:  12% 82/679 [01:40<12:10,  1.22s/it]\u001b[A\n","Iteration:  12% 83/679 [01:41<12:09,  1.22s/it]\u001b[A\n","Iteration:  12% 84/679 [01:42<12:08,  1.22s/it]\u001b[A\n","Iteration:  13% 85/679 [01:44<12:07,  1.23s/it]\u001b[A\n","Iteration:  13% 86/679 [01:45<12:06,  1.22s/it]\u001b[A\n","Iteration:  13% 87/679 [01:46<12:05,  1.22s/it]\u001b[A\n","Iteration:  13% 88/679 [01:47<12:03,  1.22s/it]\u001b[A\n","Iteration:  13% 89/679 [01:48<12:02,  1.22s/it]\u001b[A\n","Iteration:  13% 90/679 [01:50<12:01,  1.22s/it]\u001b[A\n","Iteration:  13% 91/679 [01:51<11:59,  1.22s/it]\u001b[A\n","Iteration:  14% 92/679 [01:52<11:58,  1.22s/it]\u001b[A\n","Iteration:  14% 93/679 [01:53<11:57,  1.22s/it]\u001b[A\n","Iteration:  14% 94/679 [01:55<11:55,  1.22s/it]\u001b[A\n","Iteration:  14% 95/679 [01:56<11:55,  1.22s/it]\u001b[A\n","Iteration:  14% 96/679 [01:57<11:53,  1.22s/it]\u001b[A\n","Iteration:  14% 97/679 [01:58<11:52,  1.22s/it]\u001b[A\n","Iteration:  14% 98/679 [01:59<11:51,  1.22s/it]\u001b[A\n","Iteration:  15% 99/679 [02:01<11:49,  1.22s/it]\u001b[A\n","Iteration:  15% 100/679 [02:02<11:48,  1.22s/it]\u001b[A\n","Iteration:  15% 101/679 [02:03<11:47,  1.22s/it]\u001b[A\n","Iteration:  15% 102/679 [02:04<11:45,  1.22s/it]\u001b[A\n","Iteration:  15% 103/679 [02:06<11:44,  1.22s/it]\u001b[A\n","Iteration:  15% 104/679 [02:07<11:43,  1.22s/it]\u001b[A\n","Iteration:  15% 105/679 [02:08<11:43,  1.22s/it]\u001b[A\n","Iteration:  16% 106/679 [02:09<11:41,  1.22s/it]\u001b[A\n","Iteration:  16% 107/679 [02:10<11:40,  1.22s/it]\u001b[A\n","Iteration:  16% 108/679 [02:12<11:38,  1.22s/it]\u001b[A\n","Iteration:  16% 109/679 [02:13<11:37,  1.22s/it]\u001b[A\n","Iteration:  16% 110/679 [02:14<11:36,  1.22s/it]\u001b[A\n","Iteration:  16% 111/679 [02:15<11:35,  1.22s/it]\u001b[A\n","Iteration:  16% 112/679 [02:17<11:34,  1.22s/it]\u001b[A\n","Iteration:  17% 113/679 [02:18<11:33,  1.22s/it]\u001b[A\n","Iteration:  17% 114/679 [02:19<11:31,  1.22s/it]\u001b[A\n","Iteration:  17% 115/679 [02:20<11:30,  1.22s/it]\u001b[A\n","Iteration:  17% 116/679 [02:22<11:29,  1.22s/it]\u001b[A\n","Iteration:  17% 117/679 [02:23<11:28,  1.22s/it]\u001b[A\n","Iteration:  17% 118/679 [02:24<11:26,  1.22s/it]\u001b[A\n","Iteration:  18% 119/679 [02:25<11:25,  1.22s/it]\u001b[A\n","Iteration:  18% 120/679 [02:26<11:24,  1.22s/it]\u001b[A\n","Iteration:  18% 121/679 [02:28<11:23,  1.22s/it]\u001b[A\n","Iteration:  18% 122/679 [02:29<11:21,  1.22s/it]\u001b[A\n","Iteration:  18% 123/679 [02:30<11:19,  1.22s/it]\u001b[A\n","Iteration:  18% 124/679 [02:31<11:18,  1.22s/it]\u001b[A\n","Iteration:  18% 125/679 [02:33<11:16,  1.22s/it]\u001b[A\n","Iteration:  19% 126/679 [02:34<11:16,  1.22s/it]\u001b[A\n","Iteration:  19% 127/679 [02:35<11:15,  1.22s/it]\u001b[A\n","Iteration:  19% 128/679 [02:36<11:13,  1.22s/it]\u001b[A\n","Iteration:  19% 129/679 [02:37<11:12,  1.22s/it]\u001b[A\n","Iteration:  19% 130/679 [02:39<11:11,  1.22s/it]\u001b[A\n","Iteration:  19% 131/679 [02:40<11:10,  1.22s/it]\u001b[A\n","Iteration:  19% 132/679 [02:41<11:09,  1.22s/it]\u001b[A\n","Iteration:  20% 133/679 [02:42<11:09,  1.23s/it]\u001b[A\n","Iteration:  20% 134/679 [02:44<11:08,  1.23s/it]\u001b[A\n","Iteration:  20% 135/679 [02:45<11:06,  1.23s/it]\u001b[A\n","Iteration:  20% 136/679 [02:46<11:04,  1.22s/it]\u001b[A\n","Iteration:  20% 137/679 [02:47<11:03,  1.22s/it]\u001b[A\n","Iteration:  20% 138/679 [02:48<11:02,  1.22s/it]\u001b[A\n","Iteration:  20% 139/679 [02:50<11:00,  1.22s/it]\u001b[A\n","Iteration:  21% 140/679 [02:51<10:59,  1.22s/it]\u001b[A\n","Iteration:  21% 141/679 [02:52<10:58,  1.22s/it]\u001b[A\n","Iteration:  21% 142/679 [02:53<10:57,  1.22s/it]\u001b[A\n","Iteration:  21% 143/679 [02:55<10:56,  1.22s/it]\u001b[A\n","Iteration:  21% 144/679 [02:56<10:54,  1.22s/it]\u001b[A\n","Iteration:  21% 145/679 [02:57<10:53,  1.22s/it]\u001b[A\n","Iteration:  22% 146/679 [02:58<10:52,  1.22s/it]\u001b[A\n","Iteration:  22% 147/679 [02:59<10:51,  1.22s/it]\u001b[A\n","Iteration:  22% 148/679 [03:01<10:49,  1.22s/it]\u001b[A\n","Iteration:  22% 149/679 [03:02<10:48,  1.22s/it]\u001b[A\n","Iteration:  22% 150/679 [03:03<10:47,  1.22s/it]\u001b[A\n","Iteration:  22% 151/679 [03:04<10:46,  1.22s/it]\u001b[A\n","Iteration:  22% 152/679 [03:06<10:45,  1.22s/it]\u001b[A\n","Iteration:  23% 153/679 [03:07<10:44,  1.23s/it]\u001b[A\n","Iteration:  23% 154/679 [03:08<10:43,  1.22s/it]\u001b[A\n","Iteration:  23% 155/679 [03:09<10:41,  1.22s/it]\u001b[A\n","Iteration:  23% 156/679 [03:10<10:40,  1.22s/it]\u001b[A\n","Iteration:  23% 157/679 [03:12<10:38,  1.22s/it]\u001b[A\n","Iteration:  23% 158/679 [03:13<10:37,  1.22s/it]\u001b[A\n","Iteration:  23% 159/679 [03:14<10:36,  1.22s/it]\u001b[A\n","Iteration:  24% 160/679 [03:15<10:35,  1.22s/it]\u001b[A\n","Iteration:  24% 161/679 [03:17<10:33,  1.22s/it]\u001b[A\n","Iteration:  24% 162/679 [03:18<10:32,  1.22s/it]\u001b[A\n","Iteration:  24% 163/679 [03:19<10:31,  1.22s/it]\u001b[A\n","Iteration:  24% 164/679 [03:20<10:29,  1.22s/it]\u001b[A\n","Iteration:  24% 165/679 [03:21<10:28,  1.22s/it]\u001b[A\n","Iteration:  24% 166/679 [03:23<10:27,  1.22s/it]\u001b[A\n","Iteration:  25% 167/679 [03:24<10:26,  1.22s/it]\u001b[A\n","Iteration:  25% 168/679 [03:25<10:24,  1.22s/it]\u001b[A\n","Iteration:  25% 169/679 [03:26<10:24,  1.22s/it]\u001b[A\n","Iteration:  25% 170/679 [03:28<10:23,  1.22s/it]\u001b[A\n","Iteration:  25% 171/679 [03:29<10:22,  1.22s/it]\u001b[A\n","Iteration:  25% 172/679 [03:30<10:20,  1.22s/it]\u001b[A\n","Iteration:  25% 173/679 [03:31<10:19,  1.22s/it]\u001b[A\n","Iteration:  26% 174/679 [03:32<10:18,  1.22s/it]\u001b[A\n","Iteration:  26% 175/679 [03:34<10:16,  1.22s/it]\u001b[A\n","Iteration:  26% 176/679 [03:35<10:15,  1.22s/it]\u001b[A\n","Iteration:  26% 177/679 [03:36<10:14,  1.22s/it]\u001b[A\n","Iteration:  26% 178/679 [03:37<10:13,  1.22s/it]\u001b[A\n","Iteration:  26% 179/679 [03:39<10:12,  1.22s/it]\u001b[A\n","Iteration:  27% 180/679 [03:40<10:10,  1.22s/it]\u001b[A\n","Iteration:  27% 181/679 [03:41<10:09,  1.22s/it]\u001b[A\n","Iteration:  27% 182/679 [03:42<10:08,  1.22s/it]\u001b[A\n","Iteration:  27% 183/679 [03:44<10:07,  1.22s/it]\u001b[A\n","Iteration:  27% 184/679 [03:45<10:06,  1.22s/it]\u001b[A\n","Iteration:  27% 185/679 [03:46<10:05,  1.23s/it]\u001b[A\n","Iteration:  27% 186/679 [03:47<10:04,  1.23s/it]\u001b[A\n","Iteration:  28% 187/679 [03:48<10:02,  1.23s/it]\u001b[A\n","Iteration:  28% 188/679 [03:50<10:01,  1.22s/it]\u001b[A\n","Iteration:  28% 189/679 [03:51<09:59,  1.22s/it]\u001b[A\n","Iteration:  28% 190/679 [03:52<09:58,  1.22s/it]\u001b[A\n","Iteration:  28% 191/679 [03:53<09:56,  1.22s/it]\u001b[A\n","Iteration:  28% 192/679 [03:55<09:55,  1.22s/it]\u001b[A\n","Iteration:  28% 193/679 [03:56<09:54,  1.22s/it]\u001b[A\n","Iteration:  29% 194/679 [03:57<09:53,  1.22s/it]\u001b[A\n","Iteration:  29% 195/679 [03:58<09:52,  1.22s/it]\u001b[A\n","Iteration:  29% 196/679 [03:59<09:51,  1.22s/it]\u001b[A\n","Iteration:  29% 197/679 [04:01<09:50,  1.23s/it]\u001b[A\n","Iteration:  29% 198/679 [04:02<09:49,  1.22s/it]\u001b[A\n","Iteration:  29% 199/679 [04:03<09:48,  1.23s/it]\u001b[A\n","Iteration:  29% 200/679 [04:04<09:46,  1.22s/it]\u001b[A\n","Iteration:  30% 201/679 [04:06<09:45,  1.22s/it]\u001b[A\n","Iteration:  30% 202/679 [04:07<09:43,  1.22s/it]\u001b[A\n","Iteration:  30% 203/679 [04:08<09:42,  1.22s/it]\u001b[A\n","Iteration:  30% 204/679 [04:09<09:41,  1.22s/it]\u001b[A\n","Iteration:  30% 205/679 [04:10<09:40,  1.22s/it]\u001b[A\n","Iteration:  30% 206/679 [04:12<09:39,  1.22s/it]\u001b[A\n","Iteration:  30% 207/679 [04:13<09:37,  1.22s/it]\u001b[A\n","Iteration:  31% 208/679 [04:14<09:36,  1.22s/it]\u001b[A\n","Iteration:  31% 209/679 [04:15<09:35,  1.22s/it]\u001b[A\n","Iteration:  31% 210/679 [04:17<09:33,  1.22s/it]\u001b[A\n","Iteration:  31% 211/679 [04:18<09:32,  1.22s/it]\u001b[A\n","Iteration:  31% 212/679 [04:19<09:31,  1.22s/it]\u001b[A\n","Iteration:  31% 213/679 [04:20<09:30,  1.22s/it]\u001b[A\n","Iteration:  32% 214/679 [04:21<09:29,  1.22s/it]\u001b[A\n","Iteration:  32% 215/679 [04:23<09:27,  1.22s/it]\u001b[A\n","Iteration:  32% 216/679 [04:24<09:26,  1.22s/it]\u001b[A\n","Iteration:  32% 217/679 [04:25<09:25,  1.22s/it]\u001b[A\n","Iteration:  32% 218/679 [04:26<09:23,  1.22s/it]\u001b[A\n","Iteration:  32% 219/679 [04:28<09:22,  1.22s/it]\u001b[A\n","Iteration:  32% 220/679 [04:29<09:21,  1.22s/it]\u001b[A\n","Iteration:  33% 221/679 [04:30<09:20,  1.22s/it]\u001b[A\n","Iteration:  33% 222/679 [04:31<09:19,  1.22s/it]\u001b[A\n","Iteration:  33% 223/679 [04:32<09:17,  1.22s/it]\u001b[A\n","Iteration:  33% 224/679 [04:34<09:16,  1.22s/it]\u001b[A\n","Iteration:  33% 225/679 [04:35<09:16,  1.22s/it]\u001b[A\n","Iteration:  33% 226/679 [04:36<09:15,  1.23s/it]\u001b[A\n","Iteration:  33% 227/679 [04:37<09:14,  1.23s/it]\u001b[A\n","Iteration:  34% 228/679 [04:39<09:12,  1.23s/it]\u001b[A\n","Iteration:  34% 229/679 [04:40<09:11,  1.23s/it]\u001b[A\n","Iteration:  34% 230/679 [04:41<09:10,  1.23s/it]\u001b[A\n","Iteration:  34% 231/679 [04:42<09:08,  1.23s/it]\u001b[A\n","Iteration:  34% 232/679 [04:43<09:07,  1.22s/it]\u001b[A\n","Iteration:  34% 233/679 [04:45<09:05,  1.22s/it]\u001b[A\n","Iteration:  34% 234/679 [04:46<09:04,  1.22s/it]\u001b[A\n","Iteration:  35% 235/679 [04:47<09:03,  1.22s/it]\u001b[A\n","Iteration:  35% 236/679 [04:48<09:02,  1.22s/it]\u001b[A\n","Iteration:  35% 237/679 [04:50<09:01,  1.22s/it]\u001b[A\n","Iteration:  35% 238/679 [04:51<08:59,  1.22s/it]\u001b[A\n","Iteration:  35% 239/679 [04:52<08:58,  1.22s/it]\u001b[A\n","Iteration:  35% 240/679 [04:53<08:57,  1.22s/it]\u001b[A\n","Iteration:  35% 241/679 [04:55<08:56,  1.22s/it]\u001b[A\n","Iteration:  36% 242/679 [04:56<08:54,  1.22s/it]\u001b[A\n","Iteration:  36% 243/679 [04:57<08:53,  1.22s/it]\u001b[A\n","Iteration:  36% 244/679 [04:58<08:52,  1.22s/it]\u001b[A\n","Iteration:  36% 245/679 [04:59<08:50,  1.22s/it]\u001b[A\n","Iteration:  36% 246/679 [05:01<08:50,  1.22s/it]\u001b[A\n","Iteration:  36% 247/679 [05:02<08:48,  1.22s/it]\u001b[A\n","Iteration:  37% 248/679 [05:03<08:47,  1.22s/it]\u001b[A\n","Iteration:  37% 249/679 [05:04<08:46,  1.22s/it]\u001b[A\n","Iteration:  37% 250/679 [05:06<08:45,  1.22s/it]\u001b[A\n","Iteration:  37% 251/679 [05:07<08:43,  1.22s/it]\u001b[A\n","Iteration:  37% 252/679 [05:08<08:42,  1.22s/it]\u001b[A\n","Iteration:  37% 253/679 [05:09<08:41,  1.22s/it]\u001b[A\n","Iteration:  37% 254/679 [05:10<08:40,  1.22s/it]\u001b[A\n","Iteration:  38% 255/679 [05:12<08:38,  1.22s/it]\u001b[A\n","Iteration:  38% 256/679 [05:13<08:37,  1.22s/it]\u001b[A\n","Iteration:  38% 257/679 [05:14<08:37,  1.23s/it]\u001b[A\n","Iteration:  38% 258/679 [05:15<08:35,  1.22s/it]\u001b[A\n","Iteration:  38% 259/679 [05:17<08:34,  1.23s/it]\u001b[A\n","Iteration:  38% 260/679 [05:18<08:33,  1.22s/it]\u001b[A\n","Iteration:  38% 261/679 [05:19<08:31,  1.22s/it]\u001b[A\n","Iteration:  39% 262/679 [05:20<08:30,  1.22s/it]\u001b[A\n","Iteration:  39% 263/679 [05:21<08:28,  1.22s/it]\u001b[A\n","Iteration:  39% 264/679 [05:23<08:27,  1.22s/it]\u001b[A\n","Iteration:  39% 265/679 [05:24<08:26,  1.22s/it]\u001b[A\n","Iteration:  39% 266/679 [05:25<08:25,  1.22s/it]\u001b[A\n","Iteration:  39% 267/679 [05:26<08:24,  1.22s/it]\u001b[A\n","Iteration:  39% 268/679 [05:28<08:23,  1.23s/it]\u001b[A\n","Iteration:  40% 269/679 [05:29<08:22,  1.23s/it]\u001b[A\n","Iteration:  40% 270/679 [05:30<08:20,  1.22s/it]\u001b[A\n","Iteration:  40% 271/679 [05:31<08:19,  1.22s/it]\u001b[A\n","Iteration:  40% 272/679 [05:32<08:18,  1.22s/it]\u001b[A\n","Iteration:  40% 273/679 [05:34<08:17,  1.23s/it]\u001b[A\n","Iteration:  40% 274/679 [05:35<08:16,  1.23s/it]\u001b[A\n","Iteration:  41% 275/679 [05:36<08:15,  1.23s/it]\u001b[A\n","Iteration:  41% 276/679 [05:37<08:13,  1.23s/it]\u001b[A\n","Iteration:  41% 277/679 [05:39<08:12,  1.23s/it]\u001b[A\n","Iteration:  41% 278/679 [05:40<08:11,  1.22s/it]\u001b[A\n","Iteration:  41% 279/679 [05:41<08:09,  1.22s/it]\u001b[A\n","Iteration:  41% 280/679 [05:42<08:08,  1.22s/it]\u001b[A\n","Iteration:  41% 281/679 [05:43<08:07,  1.22s/it]\u001b[A\n","Iteration:  42% 282/679 [05:45<08:05,  1.22s/it]\u001b[A\n","Iteration:  42% 283/679 [05:46<08:04,  1.22s/it]\u001b[A\n","Iteration:  42% 284/679 [05:47<08:03,  1.22s/it]\u001b[A\n","Iteration:  42% 285/679 [05:48<08:02,  1.22s/it]\u001b[A\n","Iteration:  42% 286/679 [05:50<08:00,  1.22s/it]\u001b[A\n","Iteration:  42% 287/679 [05:51<07:59,  1.22s/it]\u001b[A\n","Iteration:  42% 288/679 [05:52<07:58,  1.22s/it]\u001b[A\n","Iteration:  43% 289/679 [05:53<07:56,  1.22s/it]\u001b[A\n","Iteration:  43% 290/679 [05:55<07:56,  1.22s/it]\u001b[A\n","Iteration:  43% 291/679 [05:56<07:55,  1.22s/it]\u001b[A\n","Iteration:  43% 292/679 [05:57<07:53,  1.22s/it]\u001b[A\n","Iteration:  43% 293/679 [05:58<07:52,  1.22s/it]\u001b[A\n","Iteration:  43% 294/679 [05:59<07:51,  1.22s/it]\u001b[A\n","Iteration:  43% 295/679 [06:01<07:50,  1.23s/it]\u001b[A\n","Iteration:  44% 296/679 [06:02<07:49,  1.22s/it]\u001b[A\n","Iteration:  44% 297/679 [06:03<07:47,  1.22s/it]\u001b[A\n","Iteration:  44% 298/679 [06:04<07:46,  1.22s/it]\u001b[A\n","Iteration:  44% 299/679 [06:06<07:44,  1.22s/it]\u001b[A\n","Iteration:  44% 300/679 [06:07<07:43,  1.22s/it]\u001b[A\n","Iteration:  44% 301/679 [06:08<07:42,  1.22s/it]\u001b[A\n","Iteration:  44% 302/679 [06:09<07:41,  1.22s/it]\u001b[A\n","Iteration:  45% 303/679 [06:10<07:40,  1.22s/it]\u001b[A\n","Iteration:  45% 304/679 [06:12<07:39,  1.22s/it]\u001b[A\n","Iteration:  45% 305/679 [06:13<07:37,  1.22s/it]\u001b[A\n","Iteration:  45% 306/679 [06:14<07:36,  1.22s/it]\u001b[A\n","Iteration:  45% 307/679 [06:15<07:35,  1.22s/it]\u001b[A\n","Iteration:  45% 308/679 [06:17<07:34,  1.23s/it]\u001b[A\n","Iteration:  46% 309/679 [06:18<07:33,  1.22s/it]\u001b[A\n","Iteration:  46% 310/679 [06:19<07:31,  1.22s/it]\u001b[A\n","Iteration:  46% 311/679 [06:20<07:30,  1.22s/it]\u001b[A\n","Iteration:  46% 312/679 [06:21<07:29,  1.22s/it]\u001b[A\n","Iteration:  46% 313/679 [06:23<07:27,  1.22s/it]\u001b[A\n","Iteration:  46% 314/679 [06:24<07:26,  1.22s/it]\u001b[A\n","Iteration:  46% 315/679 [06:25<07:25,  1.23s/it]\u001b[A\n","Iteration:  47% 316/679 [06:26<07:24,  1.22s/it]\u001b[A\n","Iteration:  47% 317/679 [06:28<07:23,  1.22s/it]\u001b[A\n","Iteration:  47% 318/679 [06:29<07:22,  1.22s/it]\u001b[A\n","Iteration:  47% 319/679 [06:30<07:20,  1.22s/it]\u001b[A\n","Iteration:  47% 320/679 [06:31<07:19,  1.22s/it]\u001b[A12/14/2021 21:58:53 - INFO - __main__ -   ***** Running evaluation on dev dataset (1000 step) *****\n","12/14/2021 21:58:53 - INFO - __main__ -     Num examples = 5426\n","12/14/2021 21:58:53 - INFO - __main__ -     Eval Batch size = 32\n","\n","\n","Evaluating:   0% 0/170 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluating:   1% 1/170 [00:00<00:41,  4.03it/s]\u001b[A\u001b[A\n","\n","Evaluating:   1% 2/170 [00:00<00:41,  4.06it/s]\u001b[A\u001b[A\n","\n","Evaluating:   2% 3/170 [00:00<00:40,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:   2% 4/170 [00:00<00:40,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:   3% 5/170 [00:01<00:39,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:   4% 6/170 [00:01<00:39,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:   4% 7/170 [00:01<00:39,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:   5% 8/170 [00:01<00:39,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:   5% 9/170 [00:02<00:38,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:   6% 10/170 [00:02<00:38,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:   6% 11/170 [00:02<00:38,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:   7% 12/170 [00:02<00:38,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:   8% 13/170 [00:03<00:37,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:   8% 14/170 [00:03<00:37,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:   9% 15/170 [00:03<00:37,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:   9% 16/170 [00:03<00:36,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  10% 17/170 [00:04<00:36,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  11% 18/170 [00:04<00:36,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  11% 19/170 [00:04<00:36,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  12% 20/170 [00:04<00:35,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  12% 21/170 [00:05<00:35,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  13% 22/170 [00:05<00:35,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  14% 23/170 [00:05<00:35,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  14% 24/170 [00:05<00:35,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  15% 25/170 [00:06<00:34,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  15% 26/170 [00:06<00:34,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  16% 27/170 [00:06<00:34,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  16% 28/170 [00:06<00:34,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  17% 29/170 [00:06<00:33,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  18% 30/170 [00:07<00:33,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  18% 31/170 [00:07<00:33,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  19% 32/170 [00:07<00:33,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  19% 33/170 [00:07<00:32,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  20% 34/170 [00:08<00:32,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  21% 35/170 [00:08<00:32,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  21% 36/170 [00:08<00:32,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  22% 37/170 [00:08<00:32,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  22% 38/170 [00:09<00:31,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  23% 39/170 [00:09<00:31,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  24% 40/170 [00:09<00:31,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  24% 41/170 [00:09<00:30,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  25% 42/170 [00:10<00:30,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  25% 43/170 [00:10<00:30,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  26% 44/170 [00:10<00:30,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  26% 45/170 [00:10<00:30,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  27% 46/170 [00:11<00:29,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  28% 47/170 [00:11<00:29,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  28% 48/170 [00:11<00:29,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  29% 49/170 [00:11<00:29,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  29% 50/170 [00:12<00:28,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  30% 51/170 [00:12<00:28,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  31% 52/170 [00:12<00:28,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  31% 53/170 [00:12<00:28,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  32% 54/170 [00:12<00:27,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  32% 55/170 [00:13<00:27,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  33% 56/170 [00:13<00:27,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  34% 57/170 [00:13<00:27,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  34% 58/170 [00:13<00:26,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  35% 59/170 [00:14<00:26,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  35% 60/170 [00:14<00:26,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  36% 61/170 [00:14<00:26,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  36% 62/170 [00:14<00:25,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  37% 63/170 [00:15<00:25,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  38% 64/170 [00:15<00:25,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  38% 65/170 [00:15<00:25,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  39% 66/170 [00:15<00:25,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  39% 67/170 [00:16<00:24,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  40% 68/170 [00:16<00:24,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  41% 69/170 [00:16<00:24,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  41% 70/170 [00:16<00:23,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  42% 71/170 [00:17<00:23,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  42% 72/170 [00:17<00:23,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  43% 73/170 [00:17<00:23,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  44% 74/170 [00:17<00:23,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  44% 75/170 [00:18<00:22,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  45% 76/170 [00:18<00:22,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  45% 77/170 [00:18<00:22,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  46% 78/170 [00:18<00:22,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  46% 79/170 [00:19<00:21,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  47% 80/170 [00:19<00:21,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  48% 81/170 [00:19<00:21,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  48% 82/170 [00:19<00:21,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  49% 83/170 [00:19<00:20,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  49% 84/170 [00:20<00:20,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  50% 85/170 [00:20<00:20,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  51% 86/170 [00:20<00:20,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  51% 87/170 [00:20<00:20,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  52% 88/170 [00:21<00:19,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  52% 89/170 [00:21<00:19,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  53% 90/170 [00:21<00:19,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  54% 91/170 [00:21<00:19,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  54% 92/170 [00:22<00:18,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  55% 93/170 [00:22<00:18,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  55% 94/170 [00:22<00:18,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  56% 95/170 [00:22<00:18,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  56% 96/170 [00:23<00:17,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  57% 97/170 [00:23<00:17,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  58% 98/170 [00:23<00:17,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  58% 99/170 [00:23<00:17,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  59% 100/170 [00:24<00:16,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  59% 101/170 [00:24<00:16,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  60% 102/170 [00:24<00:16,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  61% 103/170 [00:24<00:16,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  61% 104/170 [00:25<00:15,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 105/170 [00:25<00:15,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 106/170 [00:25<00:15,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  63% 107/170 [00:25<00:15,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  64% 108/170 [00:25<00:14,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  64% 109/170 [00:26<00:14,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  65% 110/170 [00:26<00:14,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  65% 111/170 [00:26<00:14,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  66% 112/170 [00:26<00:13,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  66% 113/170 [00:27<00:13,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  67% 114/170 [00:27<00:13,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  68% 115/170 [00:27<00:13,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  68% 116/170 [00:27<00:12,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  69% 117/170 [00:28<00:12,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  69% 118/170 [00:28<00:12,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  70% 119/170 [00:28<00:12,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  71% 120/170 [00:28<00:12,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  71% 121/170 [00:29<00:11,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  72% 122/170 [00:29<00:11,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  72% 123/170 [00:29<00:11,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  73% 124/170 [00:29<00:11,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  74% 125/170 [00:30<00:10,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  74% 126/170 [00:30<00:10,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 127/170 [00:30<00:10,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 128/170 [00:30<00:10,  4.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  76% 129/170 [00:31<00:09,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  76% 130/170 [00:31<00:09,  4.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  77% 131/170 [00:31<00:09,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  78% 132/170 [00:31<00:09,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  78% 133/170 [00:32<00:08,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  79% 134/170 [00:32<00:08,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  79% 135/170 [00:32<00:08,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  80% 136/170 [00:32<00:08,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  81% 137/170 [00:32<00:07,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  81% 138/170 [00:33<00:07,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  82% 139/170 [00:33<00:07,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  82% 140/170 [00:33<00:07,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  83% 141/170 [00:33<00:06,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  84% 142/170 [00:34<00:06,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  84% 143/170 [00:34<00:06,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  85% 144/170 [00:34<00:06,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  85% 145/170 [00:34<00:06,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  86% 146/170 [00:35<00:05,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  86% 147/170 [00:35<00:05,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  87% 148/170 [00:35<00:05,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 149/170 [00:35<00:05,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 150/170 [00:36<00:04,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  89% 151/170 [00:36<00:04,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  89% 152/170 [00:36<00:04,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  90% 153/170 [00:36<00:04,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  91% 154/170 [00:37<00:03,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  91% 155/170 [00:37<00:03,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  92% 156/170 [00:37<00:03,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  92% 157/170 [00:37<00:03,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  93% 158/170 [00:38<00:02,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  94% 159/170 [00:38<00:02,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  94% 160/170 [00:38<00:02,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  95% 161/170 [00:38<00:02,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  95% 162/170 [00:38<00:01,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  96% 163/170 [00:39<00:01,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  96% 164/170 [00:39<00:01,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  97% 165/170 [00:39<00:01,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  98% 166/170 [00:39<00:00,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  98% 167/170 [00:40<00:00,  4.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  99% 168/170 [00:40<00:00,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  99% 169/170 [00:40<00:00,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating: 100% 170/170 [00:40<00:00,  4.16it/s]\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","12/14/2021 21:59:34 - INFO - __main__ -   ***** Eval results on dev dataset *****\n","12/14/2021 21:59:34 - INFO - __main__ -     accuracy = 0.3986361960928861\n","12/14/2021 21:59:34 - INFO - __main__ -     loss = 0.11530815069289768\n","12/14/2021 21:59:34 - INFO - __main__ -     macro_f1 = 0.19439160966106353\n","12/14/2021 21:59:34 - INFO - __main__ -     macro_precision = 0.2431397595357781\n","12/14/2021 21:59:34 - INFO - __main__ -     macro_recall = 0.19511614832395094\n","12/14/2021 21:59:34 - INFO - __main__ -     micro_f1 = 0.49230215179616454\n","12/14/2021 21:59:34 - INFO - __main__ -     micro_precision = 0.578379521895494\n","12/14/2021 21:59:34 - INFO - __main__ -     micro_recall = 0.42852664576802507\n","12/14/2021 21:59:34 - INFO - __main__ -     weighted_f1 = 0.3881311334480472\n","12/14/2021 21:59:34 - INFO - __main__ -     weighted_precision = 0.38696886491010035\n","12/14/2021 21:59:34 - INFO - __main__ -     weighted_recall = 0.42852664576802507\n","12/14/2021 21:59:34 - INFO - transformers.configuration_utils -   Configuration saved in ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/config.json\n","12/14/2021 21:59:35 - INFO - transformers.modeling_utils -   Model weights saved in ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000/pytorch_model.bin\n","12/14/2021 21:59:36 - INFO - __main__ -   Saving model checkpoint to ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-1000\n","\n","Iteration:  47% 321/679 [07:15<1:23:44, 14.04s/it]\u001b[A\n","Iteration:  47% 322/679 [07:16<1:00:37, 10.19s/it]\u001b[A\n","Iteration:  48% 323/679 [07:18<44:29,  7.50s/it]  \u001b[A\n","Iteration:  48% 324/679 [07:19<33:14,  5.62s/it]\u001b[A\n","Iteration:  48% 325/679 [07:20<25:21,  4.30s/it]\u001b[A\n","Iteration:  48% 326/679 [07:21<19:51,  3.38s/it]\u001b[A\n","Iteration:  48% 327/679 [07:22<16:01,  2.73s/it]\u001b[A\n","Iteration:  48% 328/679 [07:24<13:19,  2.28s/it]\u001b[A\n","Iteration:  48% 329/679 [07:25<11:26,  1.96s/it]\u001b[A\n","Iteration:  49% 330/679 [07:26<10:07,  1.74s/it]\u001b[A\n","Iteration:  49% 331/679 [07:27<09:11,  1.59s/it]\u001b[A\n","Iteration:  49% 332/679 [07:29<08:32,  1.48s/it]\u001b[A\n","Iteration:  49% 333/679 [07:30<08:04,  1.40s/it]\u001b[A\n","Iteration:  49% 334/679 [07:31<07:45,  1.35s/it]\u001b[A\n","Iteration:  49% 335/679 [07:32<07:30,  1.31s/it]\u001b[A\n","Iteration:  49% 336/679 [07:34<07:20,  1.29s/it]\u001b[A\n","Iteration:  50% 337/679 [07:35<07:13,  1.27s/it]\u001b[A\n","Iteration:  50% 338/679 [07:36<07:07,  1.25s/it]\u001b[A\n","Iteration:  50% 339/679 [07:37<07:03,  1.25s/it]\u001b[A\n","Iteration:  50% 340/679 [07:38<06:59,  1.24s/it]\u001b[A\n","Iteration:  50% 341/679 [07:40<06:57,  1.23s/it]\u001b[A\n","Iteration:  50% 342/679 [07:41<06:54,  1.23s/it]\u001b[A\n","Iteration:  51% 343/679 [07:42<06:52,  1.23s/it]\u001b[A\n","Iteration:  51% 344/679 [07:43<06:51,  1.23s/it]\u001b[A\n","Iteration:  51% 345/679 [07:45<06:49,  1.23s/it]\u001b[A\n","Iteration:  51% 346/679 [07:46<06:47,  1.22s/it]\u001b[A\n","Iteration:  51% 347/679 [07:47<06:46,  1.23s/it]\u001b[A\n","Iteration:  51% 348/679 [07:48<06:45,  1.22s/it]\u001b[A\n","Iteration:  51% 349/679 [07:49<06:44,  1.23s/it]\u001b[A\n","Iteration:  52% 350/679 [07:51<06:42,  1.22s/it]\u001b[A\n","Iteration:  52% 351/679 [07:52<06:41,  1.23s/it]\u001b[A\n","Iteration:  52% 352/679 [07:53<06:40,  1.23s/it]\u001b[A\n","Iteration:  52% 353/679 [07:54<06:39,  1.22s/it]\u001b[A\n","Iteration:  52% 354/679 [07:56<06:37,  1.22s/it]\u001b[A\n","Iteration:  52% 355/679 [07:57<06:36,  1.22s/it]\u001b[A\n","Iteration:  52% 356/679 [07:58<06:35,  1.22s/it]\u001b[A\n","Iteration:  53% 357/679 [07:59<06:34,  1.22s/it]\u001b[A\n","Iteration:  53% 358/679 [08:00<06:33,  1.23s/it]\u001b[A\n","Iteration:  53% 359/679 [08:02<06:32,  1.23s/it]\u001b[A\n","Iteration:  53% 360/679 [08:03<06:30,  1.23s/it]\u001b[A\n","Iteration:  53% 361/679 [08:04<06:29,  1.22s/it]\u001b[A\n","Iteration:  53% 362/679 [08:05<06:28,  1.23s/it]\u001b[A\n","Iteration:  53% 363/679 [08:07<06:26,  1.22s/it]\u001b[A\n","Iteration:  54% 364/679 [08:08<06:25,  1.22s/it]\u001b[A\n","Iteration:  54% 365/679 [08:09<06:24,  1.23s/it]\u001b[A\n","Iteration:  54% 366/679 [08:10<06:23,  1.22s/it]\u001b[A\n","Iteration:  54% 367/679 [08:11<06:22,  1.22s/it]\u001b[A\n","Iteration:  54% 368/679 [08:13<06:20,  1.22s/it]\u001b[A\n","Iteration:  54% 369/679 [08:14<06:19,  1.23s/it]\u001b[A\n","Iteration:  54% 370/679 [08:15<06:18,  1.23s/it]\u001b[A\n","Iteration:  55% 371/679 [08:16<06:17,  1.22s/it]\u001b[A\n","Iteration:  55% 372/679 [08:18<06:16,  1.22s/it]\u001b[A\n","Iteration:  55% 373/679 [08:19<06:14,  1.22s/it]\u001b[A\n","Iteration:  55% 374/679 [08:20<06:13,  1.23s/it]\u001b[A\n","Iteration:  55% 375/679 [08:21<06:12,  1.23s/it]\u001b[A\n","Iteration:  55% 376/679 [08:22<06:11,  1.23s/it]\u001b[A\n","Iteration:  56% 377/679 [08:24<06:09,  1.22s/it]\u001b[A\n","Iteration:  56% 378/679 [08:25<06:08,  1.22s/it]\u001b[A\n","Iteration:  56% 379/679 [08:26<06:07,  1.22s/it]\u001b[A\n","Iteration:  56% 380/679 [08:27<06:05,  1.22s/it]\u001b[A\n","Iteration:  56% 381/679 [08:29<06:04,  1.22s/it]\u001b[A\n","Iteration:  56% 382/679 [08:30<06:03,  1.22s/it]\u001b[A\n","Iteration:  56% 383/679 [08:31<06:02,  1.22s/it]\u001b[A\n","Iteration:  57% 384/679 [08:32<06:01,  1.22s/it]\u001b[A\n","Iteration:  57% 385/679 [08:34<05:59,  1.22s/it]\u001b[A\n","Iteration:  57% 386/679 [08:35<05:58,  1.22s/it]\u001b[A\n","Iteration:  57% 387/679 [08:36<05:57,  1.22s/it]\u001b[A\n","Iteration:  57% 388/679 [08:37<05:56,  1.22s/it]\u001b[A\n","Iteration:  57% 389/679 [08:38<05:54,  1.22s/it]\u001b[A\n","Iteration:  57% 390/679 [08:40<05:53,  1.22s/it]\u001b[A\n","Iteration:  58% 391/679 [08:41<05:52,  1.22s/it]\u001b[A\n","Iteration:  58% 392/679 [08:42<05:51,  1.22s/it]\u001b[A\n","Iteration:  58% 393/679 [08:43<05:49,  1.22s/it]\u001b[A\n","Iteration:  58% 394/679 [08:45<05:48,  1.22s/it]\u001b[A\n","Iteration:  58% 395/679 [08:46<05:47,  1.22s/it]\u001b[A\n","Iteration:  58% 396/679 [08:47<05:46,  1.23s/it]\u001b[A\n","Iteration:  58% 397/679 [08:48<05:45,  1.22s/it]\u001b[A\n","Iteration:  59% 398/679 [08:49<05:43,  1.22s/it]\u001b[A\n","Iteration:  59% 399/679 [08:51<05:42,  1.22s/it]\u001b[A\n","Iteration:  59% 400/679 [08:52<05:41,  1.22s/it]\u001b[A\n","Iteration:  59% 401/679 [08:53<05:40,  1.22s/it]\u001b[A\n","Iteration:  59% 402/679 [08:54<05:39,  1.22s/it]\u001b[A\n","Iteration:  59% 403/679 [08:56<05:37,  1.22s/it]\u001b[A\n","Iteration:  59% 404/679 [08:57<05:36,  1.22s/it]\u001b[A\n","Iteration:  60% 405/679 [08:58<05:35,  1.22s/it]\u001b[A\n","Iteration:  60% 406/679 [08:59<05:34,  1.22s/it]\u001b[A\n","Iteration:  60% 407/679 [09:00<05:33,  1.22s/it]\u001b[A\n","Iteration:  60% 408/679 [09:02<05:31,  1.22s/it]\u001b[A\n","Iteration:  60% 409/679 [09:03<05:30,  1.23s/it]\u001b[A\n","Iteration:  60% 410/679 [09:04<05:29,  1.23s/it]\u001b[A\n","Iteration:  61% 411/679 [09:05<05:28,  1.22s/it]\u001b[A\n","Iteration:  61% 412/679 [09:07<05:26,  1.22s/it]\u001b[A\n","Iteration:  61% 413/679 [09:08<05:25,  1.22s/it]\u001b[A\n","Iteration:  61% 414/679 [09:09<05:24,  1.22s/it]\u001b[A\n","Iteration:  61% 415/679 [09:10<05:23,  1.22s/it]\u001b[A\n","Iteration:  61% 416/679 [09:11<05:22,  1.22s/it]\u001b[A\n","Iteration:  61% 417/679 [09:13<05:20,  1.23s/it]\u001b[A\n","Iteration:  62% 418/679 [09:14<05:19,  1.22s/it]\u001b[A\n","Iteration:  62% 419/679 [09:15<05:18,  1.23s/it]\u001b[A\n","Iteration:  62% 420/679 [09:16<05:17,  1.23s/it]\u001b[A\n","Iteration:  62% 421/679 [09:18<05:15,  1.22s/it]\u001b[A\n","Iteration:  62% 422/679 [09:19<05:15,  1.23s/it]\u001b[A\n","Iteration:  62% 423/679 [09:20<05:13,  1.23s/it]\u001b[A\n","Iteration:  62% 424/679 [09:21<05:12,  1.23s/it]\u001b[A\n","Iteration:  63% 425/679 [09:22<05:11,  1.22s/it]\u001b[A\n","Iteration:  63% 426/679 [09:24<05:09,  1.22s/it]\u001b[A\n","Iteration:  63% 427/679 [09:25<05:08,  1.22s/it]\u001b[A\n","Iteration:  63% 428/679 [09:26<05:07,  1.22s/it]\u001b[A\n","Iteration:  63% 429/679 [09:27<05:06,  1.22s/it]\u001b[A\n","Iteration:  63% 430/679 [09:29<05:04,  1.22s/it]\u001b[A\n","Iteration:  63% 431/679 [09:30<05:03,  1.22s/it]\u001b[A\n","Iteration:  64% 432/679 [09:31<05:02,  1.22s/it]\u001b[A\n","Iteration:  64% 433/679 [09:32<05:01,  1.22s/it]\u001b[A\n","Iteration:  64% 434/679 [09:34<04:59,  1.22s/it]\u001b[A\n","Iteration:  64% 435/679 [09:35<04:58,  1.22s/it]\u001b[A\n","Iteration:  64% 436/679 [09:36<04:57,  1.22s/it]\u001b[A\n","Iteration:  64% 437/679 [09:37<04:55,  1.22s/it]\u001b[A\n","Iteration:  65% 438/679 [09:38<04:54,  1.22s/it]\u001b[A\n","Iteration:  65% 439/679 [09:40<04:53,  1.22s/it]\u001b[A\n","Iteration:  65% 440/679 [09:41<04:52,  1.22s/it]\u001b[A\n","Iteration:  65% 441/679 [09:42<04:51,  1.22s/it]\u001b[A\n","Iteration:  65% 442/679 [09:43<04:50,  1.22s/it]\u001b[A\n","Iteration:  65% 443/679 [09:45<04:49,  1.23s/it]\u001b[A\n","Iteration:  65% 444/679 [09:46<04:47,  1.23s/it]\u001b[A\n","Iteration:  66% 445/679 [09:47<04:46,  1.23s/it]\u001b[A\n","Iteration:  66% 446/679 [09:48<04:45,  1.23s/it]\u001b[A\n","Iteration:  66% 447/679 [09:49<04:44,  1.23s/it]\u001b[A\n","Iteration:  66% 448/679 [09:51<04:42,  1.22s/it]\u001b[A\n","Iteration:  66% 449/679 [09:52<04:41,  1.22s/it]\u001b[A\n","Iteration:  66% 450/679 [09:53<04:40,  1.22s/it]\u001b[A\n","Iteration:  66% 451/679 [09:54<04:39,  1.22s/it]\u001b[A\n","Iteration:  67% 452/679 [09:56<04:38,  1.22s/it]\u001b[A\n","Iteration:  67% 453/679 [09:57<04:36,  1.22s/it]\u001b[A\n","Iteration:  67% 454/679 [09:58<04:35,  1.22s/it]\u001b[A\n","Iteration:  67% 455/679 [09:59<04:34,  1.22s/it]\u001b[A\n","Iteration:  67% 456/679 [10:00<04:33,  1.22s/it]\u001b[A\n","Iteration:  67% 457/679 [10:02<04:31,  1.22s/it]\u001b[A\n","Iteration:  67% 458/679 [10:03<04:30,  1.22s/it]\u001b[A\n","Iteration:  68% 459/679 [10:04<04:29,  1.22s/it]\u001b[A\n","Iteration:  68% 460/679 [10:05<04:28,  1.22s/it]\u001b[A\n","Iteration:  68% 461/679 [10:07<04:27,  1.22s/it]\u001b[A\n","Iteration:  68% 462/679 [10:08<04:25,  1.22s/it]\u001b[A\n","Iteration:  68% 463/679 [10:09<04:24,  1.23s/it]\u001b[A\n","Iteration:  68% 464/679 [10:10<04:23,  1.23s/it]\u001b[A\n","Iteration:  68% 465/679 [10:11<04:22,  1.22s/it]\u001b[A\n","Iteration:  69% 466/679 [10:13<04:21,  1.23s/it]\u001b[A\n","Iteration:  69% 467/679 [10:14<04:19,  1.22s/it]\u001b[A\n","Iteration:  69% 468/679 [10:15<04:18,  1.23s/it]\u001b[A\n","Iteration:  69% 469/679 [10:16<04:17,  1.22s/it]\u001b[A\n","Iteration:  69% 470/679 [10:18<04:15,  1.22s/it]\u001b[A\n","Iteration:  69% 471/679 [10:19<04:14,  1.22s/it]\u001b[A\n","Iteration:  70% 472/679 [10:20<04:13,  1.23s/it]\u001b[A\n","Iteration:  70% 473/679 [10:21<04:12,  1.22s/it]\u001b[A\n","Iteration:  70% 474/679 [10:22<04:11,  1.23s/it]\u001b[A\n","Iteration:  70% 475/679 [10:24<04:09,  1.22s/it]\u001b[A\n","Iteration:  70% 476/679 [10:25<04:08,  1.22s/it]\u001b[A\n","Iteration:  70% 477/679 [10:26<04:06,  1.22s/it]\u001b[A\n","Iteration:  70% 478/679 [10:27<04:05,  1.22s/it]\u001b[A\n","Iteration:  71% 479/679 [10:29<04:04,  1.22s/it]\u001b[A\n","Iteration:  71% 480/679 [10:30<04:03,  1.23s/it]\u001b[A\n","Iteration:  71% 481/679 [10:31<04:02,  1.22s/it]\u001b[A\n","Iteration:  71% 482/679 [10:32<04:01,  1.23s/it]\u001b[A\n","Iteration:  71% 483/679 [10:34<04:00,  1.22s/it]\u001b[A\n","Iteration:  71% 484/679 [10:35<03:58,  1.23s/it]\u001b[A\n","Iteration:  71% 485/679 [10:36<03:57,  1.23s/it]\u001b[A\n","Iteration:  72% 486/679 [10:37<03:56,  1.22s/it]\u001b[A\n","Iteration:  72% 487/679 [10:38<03:55,  1.22s/it]\u001b[A\n","Iteration:  72% 488/679 [10:40<03:53,  1.22s/it]\u001b[A\n","Iteration:  72% 489/679 [10:41<03:52,  1.22s/it]\u001b[A\n","Iteration:  72% 490/679 [10:42<03:51,  1.22s/it]\u001b[A\n","Iteration:  72% 491/679 [10:43<03:50,  1.22s/it]\u001b[A\n","Iteration:  72% 492/679 [10:45<03:48,  1.22s/it]\u001b[A\n","Iteration:  73% 493/679 [10:46<03:47,  1.22s/it]\u001b[A\n","Iteration:  73% 494/679 [10:47<03:46,  1.22s/it]\u001b[A\n","Iteration:  73% 495/679 [10:48<03:45,  1.22s/it]\u001b[A\n","Iteration:  73% 496/679 [10:49<03:43,  1.22s/it]\u001b[A\n","Iteration:  73% 497/679 [10:51<03:42,  1.22s/it]\u001b[A\n","Iteration:  73% 498/679 [10:52<03:41,  1.22s/it]\u001b[A\n","Iteration:  73% 499/679 [10:53<03:40,  1.22s/it]\u001b[A\n","Iteration:  74% 500/679 [10:54<03:39,  1.22s/it]\u001b[A\n","Iteration:  74% 501/679 [10:56<03:37,  1.22s/it]\u001b[A\n","Iteration:  74% 502/679 [10:57<03:36,  1.22s/it]\u001b[A\n","Iteration:  74% 503/679 [10:58<03:35,  1.22s/it]\u001b[A\n","Iteration:  74% 504/679 [10:59<03:34,  1.22s/it]\u001b[A\n","Iteration:  74% 505/679 [11:00<03:32,  1.22s/it]\u001b[A\n","Iteration:  75% 506/679 [11:02<03:31,  1.22s/it]\u001b[A\n","Iteration:  75% 507/679 [11:03<03:30,  1.22s/it]\u001b[A\n","Iteration:  75% 508/679 [11:04<03:29,  1.22s/it]\u001b[A\n","Iteration:  75% 509/679 [11:05<03:27,  1.22s/it]\u001b[A\n","Iteration:  75% 510/679 [11:07<03:26,  1.22s/it]\u001b[A\n","Iteration:  75% 511/679 [11:08<03:25,  1.22s/it]\u001b[A\n","Iteration:  75% 512/679 [11:09<03:24,  1.22s/it]\u001b[A\n","Iteration:  76% 513/679 [11:10<03:23,  1.22s/it]\u001b[A\n","Iteration:  76% 514/679 [11:11<03:21,  1.22s/it]\u001b[A\n","Iteration:  76% 515/679 [11:13<03:20,  1.22s/it]\u001b[A\n","Iteration:  76% 516/679 [11:14<03:19,  1.22s/it]\u001b[A\n","Iteration:  76% 517/679 [11:15<03:18,  1.22s/it]\u001b[A\n","Iteration:  76% 518/679 [11:16<03:16,  1.22s/it]\u001b[A\n","Iteration:  76% 519/679 [11:18<03:15,  1.22s/it]\u001b[A\n","Iteration:  77% 520/679 [11:19<03:14,  1.22s/it]\u001b[A\n","Iteration:  77% 521/679 [11:20<03:13,  1.22s/it]\u001b[A\n","Iteration:  77% 522/679 [11:21<03:12,  1.22s/it]\u001b[A\n","Iteration:  77% 523/679 [11:22<03:10,  1.22s/it]\u001b[A\n","Iteration:  77% 524/679 [11:24<03:09,  1.22s/it]\u001b[A\n","Iteration:  77% 525/679 [11:25<03:08,  1.22s/it]\u001b[A\n","Iteration:  77% 526/679 [11:26<03:07,  1.23s/it]\u001b[A\n","Iteration:  78% 527/679 [11:27<03:06,  1.23s/it]\u001b[A\n","Iteration:  78% 528/679 [11:29<03:04,  1.22s/it]\u001b[A\n","Iteration:  78% 529/679 [11:30<03:03,  1.22s/it]\u001b[A\n","Iteration:  78% 530/679 [11:31<03:02,  1.22s/it]\u001b[A\n","Iteration:  78% 531/679 [11:32<03:01,  1.22s/it]\u001b[A\n","Iteration:  78% 532/679 [11:33<02:59,  1.22s/it]\u001b[A\n","Iteration:  78% 533/679 [11:35<02:58,  1.22s/it]\u001b[A\n","Iteration:  79% 534/679 [11:36<02:57,  1.22s/it]\u001b[A\n","Iteration:  79% 535/679 [11:37<02:56,  1.22s/it]\u001b[A\n","Iteration:  79% 536/679 [11:38<02:55,  1.22s/it]\u001b[A\n","Iteration:  79% 537/679 [11:40<02:53,  1.22s/it]\u001b[A\n","Iteration:  79% 538/679 [11:41<02:52,  1.22s/it]\u001b[A\n","Iteration:  79% 539/679 [11:42<02:51,  1.22s/it]\u001b[A\n","Iteration:  80% 540/679 [11:43<02:50,  1.22s/it]\u001b[A\n","Iteration:  80% 541/679 [11:44<02:48,  1.22s/it]\u001b[A\n","Iteration:  80% 542/679 [11:46<02:47,  1.22s/it]\u001b[A\n","Iteration:  80% 543/679 [11:47<02:46,  1.22s/it]\u001b[A\n","Iteration:  80% 544/679 [11:48<02:45,  1.22s/it]\u001b[A\n","Iteration:  80% 545/679 [11:49<02:44,  1.22s/it]\u001b[A\n","Iteration:  80% 546/679 [11:51<02:42,  1.22s/it]\u001b[A\n","Iteration:  81% 547/679 [11:52<02:41,  1.22s/it]\u001b[A\n","Iteration:  81% 548/679 [11:53<02:40,  1.22s/it]\u001b[A\n","Iteration:  81% 549/679 [11:54<02:39,  1.22s/it]\u001b[A\n","Iteration:  81% 550/679 [11:56<02:37,  1.22s/it]\u001b[A\n","Iteration:  81% 551/679 [11:57<02:36,  1.22s/it]\u001b[A\n","Iteration:  81% 552/679 [11:58<02:35,  1.22s/it]\u001b[A\n","Iteration:  81% 553/679 [11:59<02:34,  1.22s/it]\u001b[A\n","Iteration:  82% 554/679 [12:00<02:32,  1.22s/it]\u001b[A\n","Iteration:  82% 555/679 [12:02<02:31,  1.22s/it]\u001b[A\n","Iteration:  82% 556/679 [12:03<02:30,  1.22s/it]\u001b[A\n","Iteration:  82% 557/679 [12:04<02:29,  1.22s/it]\u001b[A\n","Iteration:  82% 558/679 [12:05<02:28,  1.22s/it]\u001b[A\n","Iteration:  82% 559/679 [12:07<02:26,  1.22s/it]\u001b[A\n","Iteration:  82% 560/679 [12:08<02:25,  1.22s/it]\u001b[A\n","Iteration:  83% 561/679 [12:09<02:24,  1.22s/it]\u001b[A\n","Iteration:  83% 562/679 [12:10<02:23,  1.22s/it]\u001b[A\n","Iteration:  83% 563/679 [12:11<02:22,  1.22s/it]\u001b[A\n","Iteration:  83% 564/679 [12:13<02:20,  1.22s/it]\u001b[A\n","Iteration:  83% 565/679 [12:14<02:19,  1.22s/it]\u001b[A\n","Iteration:  83% 566/679 [12:15<02:18,  1.22s/it]\u001b[A\n","Iteration:  84% 567/679 [12:16<02:16,  1.22s/it]\u001b[A\n","Iteration:  84% 568/679 [12:18<02:15,  1.22s/it]\u001b[A\n","Iteration:  84% 569/679 [12:19<02:14,  1.22s/it]\u001b[A\n","Iteration:  84% 570/679 [12:20<02:13,  1.22s/it]\u001b[A\n","Iteration:  84% 571/679 [12:21<02:12,  1.22s/it]\u001b[A\n","Iteration:  84% 572/679 [12:22<02:10,  1.22s/it]\u001b[A\n","Iteration:  84% 573/679 [12:24<02:09,  1.22s/it]\u001b[A\n","Iteration:  85% 574/679 [12:25<02:08,  1.22s/it]\u001b[A\n","Iteration:  85% 575/679 [12:26<02:07,  1.22s/it]\u001b[A\n","Iteration:  85% 576/679 [12:27<02:06,  1.22s/it]\u001b[A\n","Iteration:  85% 577/679 [12:29<02:04,  1.22s/it]\u001b[A\n","Iteration:  85% 578/679 [12:30<02:03,  1.22s/it]\u001b[A\n","Iteration:  85% 579/679 [12:31<02:02,  1.22s/it]\u001b[A\n","Iteration:  85% 580/679 [12:32<02:01,  1.22s/it]\u001b[A\n","Iteration:  86% 581/679 [12:33<01:59,  1.22s/it]\u001b[A\n","Iteration:  86% 582/679 [12:35<01:58,  1.22s/it]\u001b[A\n","Iteration:  86% 583/679 [12:36<01:57,  1.22s/it]\u001b[A\n","Iteration:  86% 584/679 [12:37<01:56,  1.22s/it]\u001b[A\n","Iteration:  86% 585/679 [12:38<01:55,  1.22s/it]\u001b[A\n","Iteration:  86% 586/679 [12:40<01:53,  1.22s/it]\u001b[A\n","Iteration:  86% 587/679 [12:41<01:52,  1.22s/it]\u001b[A\n","Iteration:  87% 588/679 [12:42<01:51,  1.23s/it]\u001b[A\n","Iteration:  87% 589/679 [12:43<01:50,  1.22s/it]\u001b[A\n","Iteration:  87% 590/679 [12:44<01:48,  1.22s/it]\u001b[A\n","Iteration:  87% 591/679 [12:46<01:47,  1.22s/it]\u001b[A\n","Iteration:  87% 592/679 [12:47<01:46,  1.22s/it]\u001b[A\n","Iteration:  87% 593/679 [12:48<01:45,  1.22s/it]\u001b[A\n","Iteration:  87% 594/679 [12:49<01:43,  1.22s/it]\u001b[A\n","Iteration:  88% 595/679 [12:51<01:42,  1.22s/it]\u001b[A\n","Iteration:  88% 596/679 [12:52<01:41,  1.22s/it]\u001b[A\n","Iteration:  88% 597/679 [12:53<01:40,  1.22s/it]\u001b[A\n","Iteration:  88% 598/679 [12:54<01:39,  1.22s/it]\u001b[A\n","Iteration:  88% 599/679 [12:55<01:37,  1.22s/it]\u001b[A\n","Iteration:  88% 600/679 [12:57<01:36,  1.22s/it]\u001b[A\n","Iteration:  89% 601/679 [12:58<01:35,  1.22s/it]\u001b[A\n","Iteration:  89% 602/679 [12:59<01:34,  1.22s/it]\u001b[A\n","Iteration:  89% 603/679 [13:00<01:33,  1.22s/it]\u001b[A\n","Iteration:  89% 604/679 [13:02<01:31,  1.22s/it]\u001b[A\n","Iteration:  89% 605/679 [13:03<01:30,  1.22s/it]\u001b[A\n","Iteration:  89% 606/679 [13:04<01:29,  1.22s/it]\u001b[A\n","Iteration:  89% 607/679 [13:05<01:28,  1.22s/it]\u001b[A\n","Iteration:  90% 608/679 [13:06<01:26,  1.22s/it]\u001b[A\n","Iteration:  90% 609/679 [13:08<01:25,  1.22s/it]\u001b[A\n","Iteration:  90% 610/679 [13:09<01:24,  1.22s/it]\u001b[A\n","Iteration:  90% 611/679 [13:10<01:23,  1.22s/it]\u001b[A\n","Iteration:  90% 612/679 [13:11<01:22,  1.22s/it]\u001b[A\n","Iteration:  90% 613/679 [13:13<01:20,  1.22s/it]\u001b[A\n","Iteration:  90% 614/679 [13:14<01:19,  1.22s/it]\u001b[A\n","Iteration:  91% 615/679 [13:15<01:18,  1.22s/it]\u001b[A\n","Iteration:  91% 616/679 [13:16<01:17,  1.22s/it]\u001b[A\n","Iteration:  91% 617/679 [13:17<01:15,  1.22s/it]\u001b[A\n","Iteration:  91% 618/679 [13:19<01:14,  1.22s/it]\u001b[A\n","Iteration:  91% 619/679 [13:20<01:13,  1.22s/it]\u001b[A\n","Iteration:  91% 620/679 [13:21<01:12,  1.22s/it]\u001b[A\n","Iteration:  91% 621/679 [13:22<01:10,  1.22s/it]\u001b[A\n","Iteration:  92% 622/679 [13:24<01:09,  1.22s/it]\u001b[A\n","Iteration:  92% 623/679 [13:25<01:08,  1.22s/it]\u001b[A\n","Iteration:  92% 624/679 [13:26<01:07,  1.22s/it]\u001b[A\n","Iteration:  92% 625/679 [13:27<01:06,  1.22s/it]\u001b[A\n","Iteration:  92% 626/679 [13:29<01:04,  1.22s/it]\u001b[A\n","Iteration:  92% 627/679 [13:30<01:03,  1.22s/it]\u001b[A\n","Iteration:  92% 628/679 [13:31<01:02,  1.22s/it]\u001b[A\n","Iteration:  93% 629/679 [13:32<01:01,  1.22s/it]\u001b[A\n","Iteration:  93% 630/679 [13:33<00:59,  1.22s/it]\u001b[A\n","Iteration:  93% 631/679 [13:35<00:58,  1.22s/it]\u001b[A\n","Iteration:  93% 632/679 [13:36<00:57,  1.22s/it]\u001b[A\n","Iteration:  93% 633/679 [13:37<00:56,  1.22s/it]\u001b[A\n","Iteration:  93% 634/679 [13:38<00:55,  1.22s/it]\u001b[A\n","Iteration:  94% 635/679 [13:40<00:53,  1.23s/it]\u001b[A\n","Iteration:  94% 636/679 [13:41<00:52,  1.22s/it]\u001b[A\n","Iteration:  94% 637/679 [13:42<00:51,  1.22s/it]\u001b[A\n","Iteration:  94% 638/679 [13:43<00:50,  1.22s/it]\u001b[A\n","Iteration:  94% 639/679 [13:44<00:48,  1.22s/it]\u001b[A\n","Iteration:  94% 640/679 [13:46<00:47,  1.22s/it]\u001b[A\n","Iteration:  94% 641/679 [13:47<00:46,  1.23s/it]\u001b[A\n","Iteration:  95% 642/679 [13:48<00:45,  1.22s/it]\u001b[A\n","Iteration:  95% 643/679 [13:49<00:44,  1.22s/it]\u001b[A\n","Iteration:  95% 644/679 [13:51<00:42,  1.22s/it]\u001b[A\n","Iteration:  95% 645/679 [13:52<00:41,  1.22s/it]\u001b[A\n","Iteration:  95% 646/679 [13:53<00:40,  1.22s/it]\u001b[A\n","Iteration:  95% 647/679 [13:54<00:39,  1.22s/it]\u001b[A\n","Iteration:  95% 648/679 [13:55<00:37,  1.22s/it]\u001b[A\n","Iteration:  96% 649/679 [13:57<00:36,  1.22s/it]\u001b[A\n","Iteration:  96% 650/679 [13:58<00:35,  1.22s/it]\u001b[A\n","Iteration:  96% 651/679 [13:59<00:34,  1.22s/it]\u001b[A\n","Iteration:  96% 652/679 [14:00<00:33,  1.22s/it]\u001b[A\n","Iteration:  96% 653/679 [14:02<00:31,  1.22s/it]\u001b[A\n","Iteration:  96% 654/679 [14:03<00:30,  1.23s/it]\u001b[A\n","Iteration:  96% 655/679 [14:04<00:29,  1.23s/it]\u001b[A\n","Iteration:  97% 656/679 [14:05<00:28,  1.23s/it]\u001b[A\n","Iteration:  97% 657/679 [14:06<00:26,  1.23s/it]\u001b[A\n","Iteration:  97% 658/679 [14:08<00:25,  1.23s/it]\u001b[A\n","Iteration:  97% 659/679 [14:09<00:24,  1.23s/it]\u001b[A\n","Iteration:  97% 660/679 [14:10<00:23,  1.22s/it]\u001b[A\n","Iteration:  97% 661/679 [14:11<00:22,  1.22s/it]\u001b[A\n","Iteration:  97% 662/679 [14:13<00:20,  1.22s/it]\u001b[A\n","Iteration:  98% 663/679 [14:14<00:19,  1.22s/it]\u001b[A\n","Iteration:  98% 664/679 [14:15<00:18,  1.22s/it]\u001b[A\n","Iteration:  98% 665/679 [14:16<00:17,  1.22s/it]\u001b[A\n","Iteration:  98% 666/679 [14:17<00:15,  1.22s/it]\u001b[A\n","Iteration:  98% 667/679 [14:19<00:14,  1.22s/it]\u001b[A\n","Iteration:  98% 668/679 [14:20<00:13,  1.22s/it]\u001b[A\n","Iteration:  99% 669/679 [14:21<00:12,  1.23s/it]\u001b[A\n","Iteration:  99% 670/679 [14:22<00:11,  1.23s/it]\u001b[A\n","Iteration:  99% 671/679 [14:24<00:09,  1.23s/it]\u001b[A\n","Iteration:  99% 672/679 [14:25<00:08,  1.23s/it]\u001b[A\n","Iteration:  99% 673/679 [14:26<00:07,  1.23s/it]\u001b[A\n","Iteration:  99% 674/679 [14:27<00:06,  1.23s/it]\u001b[A\n","Iteration:  99% 675/679 [14:29<00:04,  1.23s/it]\u001b[A\n","Iteration: 100% 676/679 [14:30<00:03,  1.22s/it]\u001b[A\n","Iteration: 100% 677/679 [14:31<00:02,  1.22s/it]\u001b[A\n","Iteration: 100% 678/679 [14:32<00:01,  1.22s/it]\u001b[A\n","Iteration: 100% 679/679 [14:33<00:00,  1.29s/it]\n","Epoch:  20% 2/10 [28:24<1:54:07, 855.95s/it]\n","Iteration:   0% 0/679 [00:00<?, ?it/s]\u001b[A\n","Iteration:   0% 1/679 [00:01<13:49,  1.22s/it]\u001b[A\n","Iteration:   0% 2/679 [00:02<13:48,  1.22s/it]\u001b[A\n","Iteration:   0% 3/679 [00:03<13:47,  1.22s/it]\u001b[A\n","Iteration:   1% 4/679 [00:04<13:46,  1.22s/it]\u001b[A\n","Iteration:   1% 5/679 [00:06<13:45,  1.22s/it]\u001b[A\n","Iteration:   1% 6/679 [00:07<13:44,  1.22s/it]\u001b[A\n","Iteration:   1% 7/679 [00:08<13:42,  1.22s/it]\u001b[A\n","Iteration:   1% 8/679 [00:09<13:41,  1.22s/it]\u001b[A\n","Iteration:   1% 9/679 [00:11<13:41,  1.23s/it]\u001b[A\n","Iteration:   1% 10/679 [00:12<13:39,  1.23s/it]\u001b[A\n","Iteration:   2% 11/679 [00:13<13:38,  1.23s/it]\u001b[A\n","Iteration:   2% 12/679 [00:14<13:37,  1.23s/it]\u001b[A\n","Iteration:   2% 13/679 [00:15<13:35,  1.22s/it]\u001b[A\n","Iteration:   2% 14/679 [00:17<13:34,  1.22s/it]\u001b[A\n","Iteration:   2% 15/679 [00:18<13:33,  1.22s/it]\u001b[A\n","Iteration:   2% 16/679 [00:19<13:32,  1.22s/it]\u001b[A\n","Iteration:   3% 17/679 [00:20<13:30,  1.22s/it]\u001b[A\n","Iteration:   3% 18/679 [00:22<13:29,  1.22s/it]\u001b[A\n","Iteration:   3% 19/679 [00:23<13:28,  1.22s/it]\u001b[A\n","Iteration:   3% 20/679 [00:24<13:27,  1.22s/it]\u001b[A\n","Iteration:   3% 21/679 [00:25<13:25,  1.22s/it]\u001b[A\n","Iteration:   3% 22/679 [00:26<13:23,  1.22s/it]\u001b[A\n","Iteration:   3% 23/679 [00:28<13:22,  1.22s/it]\u001b[A\n","Iteration:   4% 24/679 [00:29<13:22,  1.22s/it]\u001b[A\n","Iteration:   4% 25/679 [00:30<13:20,  1.22s/it]\u001b[A\n","Iteration:   4% 26/679 [00:31<13:19,  1.22s/it]\u001b[A\n","Iteration:   4% 27/679 [00:33<13:18,  1.22s/it]\u001b[A\n","Iteration:   4% 28/679 [00:34<13:17,  1.22s/it]\u001b[A\n","Iteration:   4% 29/679 [00:35<13:15,  1.22s/it]\u001b[A\n","Iteration:   4% 30/679 [00:36<13:14,  1.22s/it]\u001b[A\n","Iteration:   5% 31/679 [00:37<13:13,  1.22s/it]\u001b[A\n","Iteration:   5% 32/679 [00:39<13:12,  1.22s/it]\u001b[A\n","Iteration:   5% 33/679 [00:40<13:10,  1.22s/it]\u001b[A\n","Iteration:   5% 34/679 [00:41<13:09,  1.22s/it]\u001b[A\n","Iteration:   5% 35/679 [00:42<13:08,  1.22s/it]\u001b[A\n","Iteration:   5% 36/679 [00:44<13:07,  1.22s/it]\u001b[A\n","Iteration:   5% 37/679 [00:45<13:05,  1.22s/it]\u001b[A\n","Iteration:   6% 38/679 [00:46<13:04,  1.22s/it]\u001b[A\n","Iteration:   6% 39/679 [00:47<13:02,  1.22s/it]\u001b[A\n","Iteration:   6% 40/679 [00:48<13:01,  1.22s/it]\u001b[A\n","Iteration:   6% 41/679 [00:50<13:00,  1.22s/it]\u001b[A\n","Iteration:   6% 42/679 [00:51<12:58,  1.22s/it]\u001b[A\n","Iteration:   6% 43/679 [00:52<12:57,  1.22s/it]\u001b[A\n","Iteration:   6% 44/679 [00:53<12:56,  1.22s/it]\u001b[A\n","Iteration:   7% 45/679 [00:55<12:56,  1.22s/it]\u001b[A\n","Iteration:   7% 46/679 [00:56<12:54,  1.22s/it]\u001b[A\n","Iteration:   7% 47/679 [00:57<12:53,  1.22s/it]\u001b[A\n","Iteration:   7% 48/679 [00:58<12:53,  1.23s/it]\u001b[A\n","Iteration:   7% 49/679 [00:59<12:51,  1.22s/it]\u001b[A\n","Iteration:   7% 50/679 [01:01<12:49,  1.22s/it]\u001b[A\n","Iteration:   8% 51/679 [01:02<12:48,  1.22s/it]\u001b[A\n","Iteration:   8% 52/679 [01:03<12:47,  1.22s/it]\u001b[A\n","Iteration:   8% 53/679 [01:04<12:46,  1.22s/it]\u001b[A\n","Iteration:   8% 54/679 [01:06<12:45,  1.22s/it]\u001b[A\n","Iteration:   8% 55/679 [01:07<12:43,  1.22s/it]\u001b[A\n","Iteration:   8% 56/679 [01:08<12:42,  1.22s/it]\u001b[A\n","Iteration:   8% 57/679 [01:09<12:41,  1.22s/it]\u001b[A\n","Iteration:   9% 58/679 [01:11<12:40,  1.22s/it]\u001b[A\n","Iteration:   9% 59/679 [01:12<12:39,  1.23s/it]\u001b[A\n","Iteration:   9% 60/679 [01:13<12:38,  1.23s/it]\u001b[A\n","Iteration:   9% 61/679 [01:14<12:36,  1.22s/it]\u001b[A\n","Iteration:   9% 62/679 [01:15<12:35,  1.22s/it]\u001b[A\n","Iteration:   9% 63/679 [01:17<12:33,  1.22s/it]\u001b[A\n","Iteration:   9% 64/679 [01:18<12:32,  1.22s/it]\u001b[A\n","Iteration:  10% 65/679 [01:19<12:31,  1.22s/it]\u001b[A\n","Iteration:  10% 66/679 [01:20<12:30,  1.22s/it]\u001b[A\n","Iteration:  10% 67/679 [01:22<12:28,  1.22s/it]\u001b[A\n","Iteration:  10% 68/679 [01:23<12:27,  1.22s/it]\u001b[A\n","Iteration:  10% 69/679 [01:24<12:26,  1.22s/it]\u001b[A\n","Iteration:  10% 70/679 [01:25<12:25,  1.22s/it]\u001b[A\n","Iteration:  10% 71/679 [01:26<12:24,  1.22s/it]\u001b[A\n","Iteration:  11% 72/679 [01:28<12:22,  1.22s/it]\u001b[A\n","Iteration:  11% 73/679 [01:29<12:21,  1.22s/it]\u001b[A\n","Iteration:  11% 74/679 [01:30<12:21,  1.23s/it]\u001b[A\n","Iteration:  11% 75/679 [01:31<12:20,  1.23s/it]\u001b[A\n","Iteration:  11% 76/679 [01:33<12:18,  1.22s/it]\u001b[A\n","Iteration:  11% 77/679 [01:34<12:16,  1.22s/it]\u001b[A\n","Iteration:  11% 78/679 [01:35<12:15,  1.22s/it]\u001b[A\n","Iteration:  12% 79/679 [01:36<12:15,  1.23s/it]\u001b[A\n","Iteration:  12% 80/679 [01:37<12:13,  1.23s/it]\u001b[A\n","Iteration:  12% 81/679 [01:39<12:12,  1.22s/it]\u001b[A\n","Iteration:  12% 82/679 [01:40<12:11,  1.23s/it]\u001b[A\n","Iteration:  12% 83/679 [01:41<12:09,  1.22s/it]\u001b[A\n","Iteration:  12% 84/679 [01:42<12:09,  1.23s/it]\u001b[A\n","Iteration:  13% 85/679 [01:44<12:08,  1.23s/it]\u001b[A\n","Iteration:  13% 86/679 [01:45<12:06,  1.22s/it]\u001b[A\n","Iteration:  13% 87/679 [01:46<12:04,  1.22s/it]\u001b[A\n","Iteration:  13% 88/679 [01:47<12:03,  1.22s/it]\u001b[A\n","Iteration:  13% 89/679 [01:48<12:03,  1.23s/it]\u001b[A\n","Iteration:  13% 90/679 [01:50<12:02,  1.23s/it]\u001b[A\n","Iteration:  13% 91/679 [01:51<12:00,  1.22s/it]\u001b[A\n","Iteration:  14% 92/679 [01:52<11:58,  1.22s/it]\u001b[A\n","Iteration:  14% 93/679 [01:53<11:57,  1.22s/it]\u001b[A\n","Iteration:  14% 94/679 [01:55<11:56,  1.22s/it]\u001b[A\n","Iteration:  14% 95/679 [01:56<11:55,  1.22s/it]\u001b[A\n","Iteration:  14% 96/679 [01:57<11:53,  1.22s/it]\u001b[A\n","Iteration:  14% 97/679 [01:58<11:52,  1.22s/it]\u001b[A\n","Iteration:  14% 98/679 [01:59<11:50,  1.22s/it]\u001b[A\n","Iteration:  15% 99/679 [02:01<11:49,  1.22s/it]\u001b[A\n","Iteration:  15% 100/679 [02:02<11:48,  1.22s/it]\u001b[A\n","Iteration:  15% 101/679 [02:03<11:46,  1.22s/it]\u001b[A\n","Iteration:  15% 102/679 [02:04<11:45,  1.22s/it]\u001b[A\n","Iteration:  15% 103/679 [02:06<11:44,  1.22s/it]\u001b[A\n","Iteration:  15% 104/679 [02:07<11:43,  1.22s/it]\u001b[A\n","Iteration:  15% 105/679 [02:08<11:41,  1.22s/it]\u001b[A\n","Iteration:  16% 106/679 [02:09<11:39,  1.22s/it]\u001b[A\n","Iteration:  16% 107/679 [02:10<11:38,  1.22s/it]\u001b[A\n","Iteration:  16% 108/679 [02:12<11:38,  1.22s/it]\u001b[A\n","Iteration:  16% 109/679 [02:13<11:37,  1.22s/it]\u001b[A\n","Iteration:  16% 110/679 [02:14<11:36,  1.22s/it]\u001b[A\n","Iteration:  16% 111/679 [02:15<11:34,  1.22s/it]\u001b[A\n","Iteration:  16% 112/679 [02:17<11:33,  1.22s/it]\u001b[A\n","Iteration:  17% 113/679 [02:18<11:32,  1.22s/it]\u001b[A\n","Iteration:  17% 114/679 [02:19<11:31,  1.22s/it]\u001b[A\n","Iteration:  17% 115/679 [02:20<11:30,  1.22s/it]\u001b[A\n","Iteration:  17% 116/679 [02:21<11:28,  1.22s/it]\u001b[A\n","Iteration:  17% 117/679 [02:23<11:27,  1.22s/it]\u001b[A\n","Iteration:  17% 118/679 [02:24<11:27,  1.22s/it]\u001b[A\n","Iteration:  18% 119/679 [02:25<11:25,  1.22s/it]\u001b[A\n","Iteration:  18% 120/679 [02:26<11:24,  1.22s/it]\u001b[A\n","Iteration:  18% 121/679 [02:28<11:22,  1.22s/it]\u001b[A\n","Iteration:  18% 122/679 [02:29<11:21,  1.22s/it]\u001b[A\n","Iteration:  18% 123/679 [02:30<11:20,  1.22s/it]\u001b[A\n","Iteration:  18% 124/679 [02:31<11:19,  1.22s/it]\u001b[A\n","Iteration:  18% 125/679 [02:33<11:18,  1.22s/it]\u001b[A\n","Iteration:  19% 126/679 [02:34<11:16,  1.22s/it]\u001b[A\n","Iteration:  19% 127/679 [02:35<11:15,  1.22s/it]\u001b[A\n","Iteration:  19% 128/679 [02:36<11:14,  1.22s/it]\u001b[A\n","Iteration:  19% 129/679 [02:37<11:13,  1.22s/it]\u001b[A\n","Iteration:  19% 130/679 [02:39<11:11,  1.22s/it]\u001b[A\n","Iteration:  19% 131/679 [02:40<11:10,  1.22s/it]\u001b[A\n","Iteration:  19% 132/679 [02:41<11:09,  1.22s/it]\u001b[A\n","Iteration:  20% 133/679 [02:42<11:08,  1.22s/it]\u001b[A\n","Iteration:  20% 134/679 [02:44<11:06,  1.22s/it]\u001b[A\n","Iteration:  20% 135/679 [02:45<11:06,  1.22s/it]\u001b[A\n","Iteration:  20% 136/679 [02:46<11:04,  1.22s/it]\u001b[A\n","Iteration:  20% 137/679 [02:47<11:03,  1.22s/it]\u001b[A\n","Iteration:  20% 138/679 [02:48<11:02,  1.22s/it]\u001b[A\n","Iteration:  20% 139/679 [02:50<11:00,  1.22s/it]\u001b[A\n","Iteration:  21% 140/679 [02:51<10:59,  1.22s/it]\u001b[A\n","Iteration:  21% 141/679 [02:52<10:58,  1.22s/it]\u001b[A\n","Iteration:  21% 142/679 [02:53<10:56,  1.22s/it]\u001b[A\n","Iteration:  21% 143/679 [02:55<10:55,  1.22s/it]\u001b[A\n","Iteration:  21% 144/679 [02:56<10:54,  1.22s/it]\u001b[A\n","Iteration:  21% 145/679 [02:57<10:54,  1.22s/it]\u001b[A\n","Iteration:  22% 146/679 [02:58<10:52,  1.22s/it]\u001b[A\n","Iteration:  22% 147/679 [02:59<10:51,  1.22s/it]\u001b[A\n","Iteration:  22% 148/679 [03:01<10:50,  1.22s/it]\u001b[A\n","Iteration:  22% 149/679 [03:02<10:48,  1.22s/it]\u001b[A\n","Iteration:  22% 150/679 [03:03<10:47,  1.22s/it]\u001b[A\n","Iteration:  22% 151/679 [03:04<10:46,  1.22s/it]\u001b[A\n","Iteration:  22% 152/679 [03:06<10:45,  1.22s/it]\u001b[A\n","Iteration:  23% 153/679 [03:07<10:43,  1.22s/it]\u001b[A\n","Iteration:  23% 154/679 [03:08<10:41,  1.22s/it]\u001b[A\n","Iteration:  23% 155/679 [03:09<10:41,  1.22s/it]\u001b[A\n","Iteration:  23% 156/679 [03:10<10:39,  1.22s/it]\u001b[A\n","Iteration:  23% 157/679 [03:12<10:38,  1.22s/it]\u001b[A\n","Iteration:  23% 158/679 [03:13<10:37,  1.22s/it]\u001b[A\n","Iteration:  23% 159/679 [03:14<10:35,  1.22s/it]\u001b[A\n","Iteration:  24% 160/679 [03:15<10:34,  1.22s/it]\u001b[A\n","Iteration:  24% 161/679 [03:17<10:32,  1.22s/it]\u001b[A\n","Iteration:  24% 162/679 [03:18<10:31,  1.22s/it]\u001b[A\n","Iteration:  24% 163/679 [03:19<10:30,  1.22s/it]\u001b[A\n","Iteration:  24% 164/679 [03:20<10:29,  1.22s/it]\u001b[A\n","Iteration:  24% 165/679 [03:21<10:28,  1.22s/it]\u001b[A\n","Iteration:  24% 166/679 [03:23<10:27,  1.22s/it]\u001b[A\n","Iteration:  25% 167/679 [03:24<10:26,  1.22s/it]\u001b[A\n","Iteration:  25% 168/679 [03:25<10:25,  1.22s/it]\u001b[A\n","Iteration:  25% 169/679 [03:26<10:23,  1.22s/it]\u001b[A\n","Iteration:  25% 170/679 [03:28<10:22,  1.22s/it]\u001b[A\n","Iteration:  25% 171/679 [03:29<10:21,  1.22s/it]\u001b[A\n","Iteration:  25% 172/679 [03:30<10:19,  1.22s/it]\u001b[A\n","Iteration:  25% 173/679 [03:31<10:18,  1.22s/it]\u001b[A\n","Iteration:  26% 174/679 [03:32<10:17,  1.22s/it]\u001b[A\n","Iteration:  26% 175/679 [03:34<10:16,  1.22s/it]\u001b[A\n","Iteration:  26% 176/679 [03:35<10:15,  1.22s/it]\u001b[A\n","Iteration:  26% 177/679 [03:36<10:14,  1.22s/it]\u001b[A\n","Iteration:  26% 178/679 [03:37<10:12,  1.22s/it]\u001b[A\n","Iteration:  26% 179/679 [03:39<10:12,  1.22s/it]\u001b[A\n","Iteration:  27% 180/679 [03:40<10:10,  1.22s/it]\u001b[A\n","Iteration:  27% 181/679 [03:41<10:08,  1.22s/it]\u001b[A\n","Iteration:  27% 182/679 [03:42<10:07,  1.22s/it]\u001b[A\n","Iteration:  27% 183/679 [03:43<10:06,  1.22s/it]\u001b[A\n","Iteration:  27% 184/679 [03:45<10:05,  1.22s/it]\u001b[A\n","Iteration:  27% 185/679 [03:46<10:04,  1.22s/it]\u001b[A\n","Iteration:  27% 186/679 [03:47<10:03,  1.22s/it]\u001b[A\n","Iteration:  28% 187/679 [03:48<10:01,  1.22s/it]\u001b[A\n","Iteration:  28% 188/679 [03:50<10:00,  1.22s/it]\u001b[A\n","Iteration:  28% 189/679 [03:51<09:59,  1.22s/it]\u001b[A\n","Iteration:  28% 190/679 [03:52<09:58,  1.22s/it]\u001b[A\n","Iteration:  28% 191/679 [03:53<09:56,  1.22s/it]\u001b[A\n","Iteration:  28% 192/679 [03:54<09:56,  1.22s/it]\u001b[A\n","Iteration:  28% 193/679 [03:56<09:55,  1.22s/it]\u001b[A\n","Iteration:  29% 194/679 [03:57<09:53,  1.22s/it]\u001b[A\n","Iteration:  29% 195/679 [03:58<09:52,  1.22s/it]\u001b[A\n","Iteration:  29% 196/679 [03:59<09:51,  1.22s/it]\u001b[A\n","Iteration:  29% 197/679 [04:01<09:49,  1.22s/it]\u001b[A\n","Iteration:  29% 198/679 [04:02<09:48,  1.22s/it]\u001b[A\n","Iteration:  29% 199/679 [04:03<09:47,  1.22s/it]\u001b[A\n","Iteration:  29% 200/679 [04:04<09:46,  1.22s/it]\u001b[A\n","Iteration:  30% 201/679 [04:05<09:45,  1.22s/it]\u001b[A\n","Iteration:  30% 202/679 [04:07<09:43,  1.22s/it]\u001b[A\n","Iteration:  30% 203/679 [04:08<09:42,  1.22s/it]\u001b[A\n","Iteration:  30% 204/679 [04:09<09:41,  1.22s/it]\u001b[A\n","Iteration:  30% 205/679 [04:10<09:40,  1.22s/it]\u001b[A\n","Iteration:  30% 206/679 [04:12<09:38,  1.22s/it]\u001b[A\n","Iteration:  30% 207/679 [04:13<09:37,  1.22s/it]\u001b[A\n","Iteration:  31% 208/679 [04:14<09:36,  1.22s/it]\u001b[A\n","Iteration:  31% 209/679 [04:15<09:35,  1.22s/it]\u001b[A\n","Iteration:  31% 210/679 [04:17<09:34,  1.22s/it]\u001b[A\n","Iteration:  31% 211/679 [04:18<09:32,  1.22s/it]\u001b[A\n","Iteration:  31% 212/679 [04:19<09:32,  1.23s/it]\u001b[A\n","Iteration:  31% 213/679 [04:20<09:30,  1.22s/it]\u001b[A\n","Iteration:  32% 214/679 [04:21<09:29,  1.22s/it]\u001b[A\n","Iteration:  32% 215/679 [04:23<09:28,  1.23s/it]\u001b[A\n","Iteration:  32% 216/679 [04:24<09:27,  1.23s/it]\u001b[A\n","Iteration:  32% 217/679 [04:25<09:25,  1.22s/it]\u001b[A\n","Iteration:  32% 218/679 [04:26<09:24,  1.22s/it]\u001b[A\n","Iteration:  32% 219/679 [04:28<09:23,  1.22s/it]\u001b[A\n","Iteration:  32% 220/679 [04:29<09:22,  1.22s/it]\u001b[A\n","Iteration:  33% 221/679 [04:30<09:20,  1.22s/it]\u001b[A\n","Iteration:  33% 222/679 [04:31<09:20,  1.23s/it]\u001b[A\n","Iteration:  33% 223/679 [04:32<09:18,  1.22s/it]\u001b[A\n","Iteration:  33% 224/679 [04:34<09:17,  1.22s/it]\u001b[A\n","Iteration:  33% 225/679 [04:35<09:16,  1.23s/it]\u001b[A\n","Iteration:  33% 226/679 [04:36<09:14,  1.23s/it]\u001b[A\n","Iteration:  33% 227/679 [04:37<09:13,  1.22s/it]\u001b[A\n","Iteration:  34% 228/679 [04:39<09:12,  1.22s/it]\u001b[A\n","Iteration:  34% 229/679 [04:40<09:11,  1.22s/it]\u001b[A\n","Iteration:  34% 230/679 [04:41<09:10,  1.23s/it]\u001b[A\n","Iteration:  34% 231/679 [04:42<09:08,  1.22s/it]\u001b[A\n","Iteration:  34% 232/679 [04:43<09:07,  1.22s/it]\u001b[A\n","Iteration:  34% 233/679 [04:45<09:05,  1.22s/it]\u001b[A\n","Iteration:  34% 234/679 [04:46<09:04,  1.22s/it]\u001b[A\n","Iteration:  35% 235/679 [04:47<09:04,  1.23s/it]\u001b[A\n","Iteration:  35% 236/679 [04:48<09:02,  1.23s/it]\u001b[A\n","Iteration:  35% 237/679 [04:50<09:01,  1.22s/it]\u001b[A\n","Iteration:  35% 238/679 [04:51<08:59,  1.22s/it]\u001b[A\n","Iteration:  35% 239/679 [04:52<08:57,  1.22s/it]\u001b[A\n","Iteration:  35% 240/679 [04:53<08:57,  1.22s/it]\u001b[A\n","Iteration:  35% 241/679 [04:54<08:56,  1.22s/it]\u001b[A\n","Iteration:  36% 242/679 [04:56<08:54,  1.22s/it]\u001b[A\n","Iteration:  36% 243/679 [04:57<08:53,  1.22s/it]\u001b[A\n","Iteration:  36% 244/679 [04:58<08:52,  1.22s/it]\u001b[A\n","Iteration:  36% 245/679 [04:59<08:51,  1.22s/it]\u001b[A\n","Iteration:  36% 246/679 [05:01<08:50,  1.22s/it]\u001b[A\n","Iteration:  36% 247/679 [05:02<08:49,  1.23s/it]\u001b[A\n","Iteration:  37% 248/679 [05:03<08:47,  1.22s/it]\u001b[A\n","Iteration:  37% 249/679 [05:04<08:46,  1.22s/it]\u001b[A\n","Iteration:  37% 250/679 [05:05<08:44,  1.22s/it]\u001b[A\n","Iteration:  37% 251/679 [05:07<08:43,  1.22s/it]\u001b[A\n","Iteration:  37% 252/679 [05:08<08:43,  1.22s/it]\u001b[A\n","Iteration:  37% 253/679 [05:09<08:41,  1.22s/it]\u001b[A\n","Iteration:  37% 254/679 [05:10<08:40,  1.22s/it]\u001b[A\n","Iteration:  38% 255/679 [05:12<08:38,  1.22s/it]\u001b[A\n","Iteration:  38% 256/679 [05:13<08:37,  1.22s/it]\u001b[A\n","Iteration:  38% 257/679 [05:14<08:36,  1.22s/it]\u001b[A\n","Iteration:  38% 258/679 [05:15<08:35,  1.22s/it]\u001b[A\n","Iteration:  38% 259/679 [05:17<08:33,  1.22s/it]\u001b[A\n","Iteration:  38% 260/679 [05:18<08:33,  1.22s/it]\u001b[A\n","Iteration:  38% 261/679 [05:19<08:31,  1.22s/it]\u001b[A\n","Iteration:  39% 262/679 [05:20<08:31,  1.23s/it]\u001b[A\n","Iteration:  39% 263/679 [05:21<08:29,  1.22s/it]\u001b[A\n","Iteration:  39% 264/679 [05:23<08:27,  1.22s/it]\u001b[A\n","Iteration:  39% 265/679 [05:24<08:26,  1.22s/it]\u001b[A\n","Iteration:  39% 266/679 [05:25<08:25,  1.22s/it]\u001b[A\n","Iteration:  39% 267/679 [05:26<08:24,  1.22s/it]\u001b[A\n","Iteration:  39% 268/679 [05:28<08:23,  1.22s/it]\u001b[A\n","Iteration:  40% 269/679 [05:29<08:21,  1.22s/it]\u001b[A\n","Iteration:  40% 270/679 [05:30<08:21,  1.23s/it]\u001b[A\n","Iteration:  40% 271/679 [05:31<08:20,  1.23s/it]\u001b[A\n","Iteration:  40% 272/679 [05:32<08:18,  1.23s/it]\u001b[A\n","Iteration:  40% 273/679 [05:34<08:17,  1.23s/it]\u001b[A\n","Iteration:  40% 274/679 [05:35<08:15,  1.22s/it]\u001b[A\n","Iteration:  41% 275/679 [05:36<08:15,  1.23s/it]\u001b[A\n","Iteration:  41% 276/679 [05:37<08:13,  1.22s/it]\u001b[A\n","Iteration:  41% 277/679 [05:39<08:11,  1.22s/it]\u001b[A\n","Iteration:  41% 278/679 [05:40<08:10,  1.22s/it]\u001b[A\n","Iteration:  41% 279/679 [05:41<08:10,  1.23s/it]\u001b[A\n","Iteration:  41% 280/679 [05:42<08:09,  1.23s/it]\u001b[A\n","Iteration:  41% 281/679 [05:43<08:07,  1.22s/it]\u001b[A\n","Iteration:  42% 282/679 [05:45<08:05,  1.22s/it]\u001b[A\n","Iteration:  42% 283/679 [05:46<08:04,  1.22s/it]\u001b[A\n","Iteration:  42% 284/679 [05:47<08:03,  1.22s/it]\u001b[A\n","Iteration:  42% 285/679 [05:48<08:02,  1.23s/it]\u001b[A\n","Iteration:  42% 286/679 [05:50<08:01,  1.23s/it]\u001b[A\n","Iteration:  42% 287/679 [05:51<08:00,  1.23s/it]\u001b[A\n","Iteration:  42% 288/679 [05:52<07:59,  1.23s/it]\u001b[A\n","Iteration:  43% 289/679 [05:53<07:58,  1.23s/it]\u001b[A\n","Iteration:  43% 290/679 [05:54<07:57,  1.23s/it]\u001b[A\n","Iteration:  43% 291/679 [05:56<07:55,  1.23s/it]\u001b[A\n","Iteration:  43% 292/679 [05:57<07:54,  1.23s/it]\u001b[A\n","Iteration:  43% 293/679 [05:58<07:53,  1.23s/it]\u001b[A\n","Iteration:  43% 294/679 [05:59<07:51,  1.22s/it]\u001b[A\n","Iteration:  43% 295/679 [06:01<07:51,  1.23s/it]\u001b[A\n","Iteration:  44% 296/679 [06:02<07:49,  1.23s/it]\u001b[A\n","Iteration:  44% 297/679 [06:03<07:47,  1.22s/it]\u001b[A\n","Iteration:  44% 298/679 [06:04<07:46,  1.22s/it]\u001b[A\n","Iteration:  44% 299/679 [06:06<07:44,  1.22s/it]\u001b[A\n","Iteration:  44% 300/679 [06:07<07:44,  1.22s/it]\u001b[A\n","Iteration:  44% 301/679 [06:08<07:43,  1.23s/it]\u001b[A\n","Iteration:  44% 302/679 [06:09<07:41,  1.22s/it]\u001b[A\n","Iteration:  45% 303/679 [06:10<07:40,  1.23s/it]\u001b[A\n","Iteration:  45% 304/679 [06:12<07:39,  1.22s/it]\u001b[A\n","Iteration:  45% 305/679 [06:13<07:37,  1.22s/it]\u001b[A\n","Iteration:  45% 306/679 [06:14<07:36,  1.22s/it]\u001b[A\n","Iteration:  45% 307/679 [06:15<07:35,  1.22s/it]\u001b[A\n","Iteration:  45% 308/679 [06:17<07:34,  1.22s/it]\u001b[A\n","Iteration:  46% 309/679 [06:18<07:33,  1.22s/it]\u001b[A\n","Iteration:  46% 310/679 [06:19<07:31,  1.22s/it]\u001b[A\n","Iteration:  46% 311/679 [06:20<07:30,  1.22s/it]\u001b[A\n","Iteration:  46% 312/679 [06:21<07:29,  1.22s/it]\u001b[A\n","Iteration:  46% 313/679 [06:23<07:27,  1.22s/it]\u001b[A\n","Iteration:  46% 314/679 [06:24<07:27,  1.22s/it]\u001b[A\n","Iteration:  46% 315/679 [06:25<07:25,  1.22s/it]\u001b[A\n","Iteration:  47% 316/679 [06:26<07:24,  1.22s/it]\u001b[A\n","Iteration:  47% 317/679 [06:28<07:23,  1.23s/it]\u001b[A\n","Iteration:  47% 318/679 [06:29<07:22,  1.23s/it]\u001b[A\n","Iteration:  47% 319/679 [06:30<07:20,  1.22s/it]\u001b[A\n","Iteration:  47% 320/679 [06:31<07:19,  1.22s/it]\u001b[A\n","Iteration:  47% 321/679 [06:32<07:18,  1.22s/it]\u001b[A\n","Iteration:  47% 322/679 [06:34<07:17,  1.22s/it]\u001b[A\n","Iteration:  48% 323/679 [06:35<07:15,  1.22s/it]\u001b[A\n","Iteration:  48% 324/679 [06:36<07:14,  1.22s/it]\u001b[A\n","Iteration:  48% 325/679 [06:37<07:13,  1.22s/it]\u001b[A\n","Iteration:  48% 326/679 [06:39<07:12,  1.22s/it]\u001b[A\n","Iteration:  48% 327/679 [06:40<07:11,  1.22s/it]\u001b[A\n","Iteration:  48% 328/679 [06:41<07:09,  1.22s/it]\u001b[A\n","Iteration:  48% 329/679 [06:42<07:08,  1.23s/it]\u001b[A\n","Iteration:  49% 330/679 [06:43<07:07,  1.23s/it]\u001b[A\n","Iteration:  49% 331/679 [06:45<07:06,  1.23s/it]\u001b[A\n","Iteration:  49% 332/679 [06:46<07:05,  1.23s/it]\u001b[A\n","Iteration:  49% 333/679 [06:47<07:03,  1.22s/it]\u001b[A\n","Iteration:  49% 334/679 [06:48<07:02,  1.22s/it]\u001b[A\n","Iteration:  49% 335/679 [06:50<07:01,  1.22s/it]\u001b[A\n","Iteration:  49% 336/679 [06:51<07:00,  1.22s/it]\u001b[A\n","Iteration:  50% 337/679 [06:52<06:58,  1.23s/it]\u001b[A\n","Iteration:  50% 338/679 [06:53<06:57,  1.23s/it]\u001b[A\n","Iteration:  50% 339/679 [06:54<06:56,  1.23s/it]\u001b[A\n","Iteration:  50% 340/679 [06:56<06:55,  1.23s/it]\u001b[A\n","Iteration:  50% 341/679 [06:57<06:54,  1.23s/it]\u001b[A\n","Iteration:  50% 342/679 [06:58<06:53,  1.23s/it]\u001b[A\n","Iteration:  51% 343/679 [06:59<06:51,  1.22s/it]\u001b[A\n","Iteration:  51% 344/679 [07:01<06:50,  1.22s/it]\u001b[A\n","Iteration:  51% 345/679 [07:02<06:48,  1.22s/it]\u001b[A\n","Iteration:  51% 346/679 [07:03<06:47,  1.22s/it]\u001b[A\n","Iteration:  51% 347/679 [07:04<06:46,  1.22s/it]\u001b[A\n","Iteration:  51% 348/679 [07:06<06:45,  1.22s/it]\u001b[A\n","Iteration:  51% 349/679 [07:07<06:44,  1.22s/it]\u001b[A\n","Iteration:  52% 350/679 [07:08<06:42,  1.22s/it]\u001b[A\n","Iteration:  52% 351/679 [07:09<06:41,  1.23s/it]\u001b[A\n","Iteration:  52% 352/679 [07:10<06:40,  1.22s/it]\u001b[A\n","Iteration:  52% 353/679 [07:12<06:39,  1.22s/it]\u001b[A\n","Iteration:  52% 354/679 [07:13<06:37,  1.22s/it]\u001b[A\n","Iteration:  52% 355/679 [07:14<06:36,  1.22s/it]\u001b[A\n","Iteration:  52% 356/679 [07:15<06:35,  1.22s/it]\u001b[A\n","Iteration:  53% 357/679 [07:17<06:33,  1.22s/it]\u001b[A\n","Iteration:  53% 358/679 [07:18<06:32,  1.22s/it]\u001b[A\n","Iteration:  53% 359/679 [07:19<06:31,  1.22s/it]\u001b[A\n","Iteration:  53% 360/679 [07:20<06:30,  1.22s/it]\u001b[A\n","Iteration:  53% 361/679 [07:21<06:29,  1.22s/it]\u001b[A\n","Iteration:  53% 362/679 [07:23<06:28,  1.22s/it]\u001b[A\n","Iteration:  53% 363/679 [07:24<06:26,  1.22s/it]\u001b[A\n","Iteration:  54% 364/679 [07:25<06:25,  1.22s/it]\u001b[A\n","Iteration:  54% 365/679 [07:26<06:24,  1.23s/it]\u001b[A\n","Iteration:  54% 366/679 [07:28<06:23,  1.22s/it]\u001b[A\n","Iteration:  54% 367/679 [07:29<06:22,  1.22s/it]\u001b[A\n","Iteration:  54% 368/679 [07:30<06:20,  1.22s/it]\u001b[A\n","Iteration:  54% 369/679 [07:31<06:19,  1.22s/it]\u001b[A\n","Iteration:  54% 370/679 [07:32<06:18,  1.22s/it]\u001b[A\n","Iteration:  55% 371/679 [07:34<06:16,  1.22s/it]\u001b[A\n","Iteration:  55% 372/679 [07:35<06:15,  1.22s/it]\u001b[A\n","Iteration:  55% 373/679 [07:36<06:14,  1.22s/it]\u001b[A\n","Iteration:  55% 374/679 [07:37<06:13,  1.23s/it]\u001b[A\n","Iteration:  55% 375/679 [07:39<06:12,  1.22s/it]\u001b[A\n","Iteration:  55% 376/679 [07:40<06:11,  1.22s/it]\u001b[A\n","Iteration:  56% 377/679 [07:41<06:09,  1.22s/it]\u001b[A\n","Iteration:  56% 378/679 [07:42<06:08,  1.22s/it]\u001b[A\n","Iteration:  56% 379/679 [07:43<06:07,  1.22s/it]\u001b[A\n","Iteration:  56% 380/679 [07:45<06:06,  1.22s/it]\u001b[A\n","Iteration:  56% 381/679 [07:46<06:04,  1.22s/it]\u001b[A\n","Iteration:  56% 382/679 [07:47<06:03,  1.22s/it]\u001b[A\n","Iteration:  56% 383/679 [07:48<06:02,  1.22s/it]\u001b[A\n","Iteration:  57% 384/679 [07:50<06:01,  1.22s/it]\u001b[A\n","Iteration:  57% 385/679 [07:51<05:59,  1.22s/it]\u001b[A\n","Iteration:  57% 386/679 [07:52<05:58,  1.22s/it]\u001b[A\n","Iteration:  57% 387/679 [07:53<05:57,  1.22s/it]\u001b[A\n","Iteration:  57% 388/679 [07:54<05:55,  1.22s/it]\u001b[A\n","Iteration:  57% 389/679 [07:56<05:54,  1.22s/it]\u001b[A\n","Iteration:  57% 390/679 [07:57<05:53,  1.22s/it]\u001b[A\n","Iteration:  58% 391/679 [07:58<05:52,  1.22s/it]\u001b[A\n","Iteration:  58% 392/679 [07:59<05:51,  1.22s/it]\u001b[A\n","Iteration:  58% 393/679 [08:01<05:50,  1.22s/it]\u001b[A\n","Iteration:  58% 394/679 [08:02<05:48,  1.22s/it]\u001b[A\n","Iteration:  58% 395/679 [08:03<05:47,  1.22s/it]\u001b[A\n","Iteration:  58% 396/679 [08:04<05:46,  1.22s/it]\u001b[A\n","Iteration:  58% 397/679 [08:05<05:44,  1.22s/it]\u001b[A\n","Iteration:  59% 398/679 [08:07<05:43,  1.22s/it]\u001b[A\n","Iteration:  59% 399/679 [08:08<05:42,  1.22s/it]\u001b[A\n","Iteration:  59% 400/679 [08:09<05:41,  1.22s/it]\u001b[A\n","Iteration:  59% 401/679 [08:10<05:40,  1.22s/it]\u001b[A\n","Iteration:  59% 402/679 [08:12<05:38,  1.22s/it]\u001b[A\n","Iteration:  59% 403/679 [08:13<05:37,  1.22s/it]\u001b[A\n","Iteration:  59% 404/679 [08:14<05:36,  1.22s/it]\u001b[A\n","Iteration:  60% 405/679 [08:15<05:35,  1.23s/it]\u001b[A\n","Iteration:  60% 406/679 [08:17<05:34,  1.22s/it]\u001b[A\n","Iteration:  60% 407/679 [08:18<05:32,  1.22s/it]\u001b[A\n","Iteration:  60% 408/679 [08:19<05:31,  1.22s/it]\u001b[A\n","Iteration:  60% 409/679 [08:20<05:30,  1.22s/it]\u001b[A\n","Iteration:  60% 410/679 [08:21<05:29,  1.22s/it]\u001b[A\n","Iteration:  61% 411/679 [08:23<05:27,  1.22s/it]\u001b[A\n","Iteration:  61% 412/679 [08:24<05:26,  1.22s/it]\u001b[A\n","Iteration:  61% 413/679 [08:25<05:25,  1.23s/it]\u001b[A\n","Iteration:  61% 414/679 [08:26<05:24,  1.22s/it]\u001b[A\n","Iteration:  61% 415/679 [08:28<05:23,  1.22s/it]\u001b[A\n","Iteration:  61% 416/679 [08:29<05:21,  1.22s/it]\u001b[A\n","Iteration:  61% 417/679 [08:30<05:20,  1.22s/it]\u001b[A\n","Iteration:  62% 418/679 [08:31<05:19,  1.22s/it]\u001b[A\n","Iteration:  62% 419/679 [08:32<05:18,  1.22s/it]\u001b[A\n","Iteration:  62% 420/679 [08:34<05:17,  1.22s/it]\u001b[A\n","Iteration:  62% 421/679 [08:35<05:15,  1.22s/it]\u001b[A\n","Iteration:  62% 422/679 [08:36<05:14,  1.22s/it]\u001b[A\n","Iteration:  62% 423/679 [08:37<05:13,  1.22s/it]\u001b[A\n","Iteration:  62% 424/679 [08:39<05:12,  1.22s/it]\u001b[A\n","Iteration:  63% 425/679 [08:40<05:10,  1.22s/it]\u001b[A\n","Iteration:  63% 426/679 [08:41<05:09,  1.22s/it]\u001b[A\n","Iteration:  63% 427/679 [08:42<05:08,  1.22s/it]\u001b[A\n","Iteration:  63% 428/679 [08:43<05:07,  1.22s/it]\u001b[A\n","Iteration:  63% 429/679 [08:45<05:06,  1.22s/it]\u001b[A\n","Iteration:  63% 430/679 [08:46<05:04,  1.22s/it]\u001b[A\n","Iteration:  63% 431/679 [08:47<05:03,  1.22s/it]\u001b[A\n","Iteration:  64% 432/679 [08:48<05:01,  1.22s/it]\u001b[A\n","Iteration:  64% 433/679 [08:50<05:00,  1.22s/it]\u001b[A\n","Iteration:  64% 434/679 [08:51<04:59,  1.22s/it]\u001b[A\n","Iteration:  64% 435/679 [08:52<04:58,  1.22s/it]\u001b[A\n","Iteration:  64% 436/679 [08:53<04:57,  1.22s/it]\u001b[A\n","Iteration:  64% 437/679 [08:54<04:55,  1.22s/it]\u001b[A\n","Iteration:  65% 438/679 [08:56<04:54,  1.22s/it]\u001b[A\n","Iteration:  65% 439/679 [08:57<04:53,  1.22s/it]\u001b[A\n","Iteration:  65% 440/679 [08:58<04:52,  1.22s/it]\u001b[A\n","Iteration:  65% 441/679 [08:59<04:51,  1.22s/it]\u001b[A\n","Iteration:  65% 442/679 [09:01<04:50,  1.22s/it]\u001b[A\n","Iteration:  65% 443/679 [09:02<04:48,  1.22s/it]\u001b[A\n","Iteration:  65% 444/679 [09:03<04:47,  1.22s/it]\u001b[A\n","Iteration:  66% 445/679 [09:04<04:46,  1.22s/it]\u001b[A\n","Iteration:  66% 446/679 [09:05<04:45,  1.22s/it]\u001b[A\n","Iteration:  66% 447/679 [09:07<04:43,  1.22s/it]\u001b[A\n","Iteration:  66% 448/679 [09:08<04:42,  1.22s/it]\u001b[A\n","Iteration:  66% 449/679 [09:09<04:41,  1.22s/it]\u001b[A\n","Iteration:  66% 450/679 [09:10<04:40,  1.22s/it]\u001b[A\n","Iteration:  66% 451/679 [09:12<04:39,  1.22s/it]\u001b[A\n","Iteration:  67% 452/679 [09:13<04:37,  1.22s/it]\u001b[A\n","Iteration:  67% 453/679 [09:14<04:36,  1.22s/it]\u001b[A\n","Iteration:  67% 454/679 [09:15<04:35,  1.22s/it]\u001b[A\n","Iteration:  67% 455/679 [09:16<04:33,  1.22s/it]\u001b[A\n","Iteration:  67% 456/679 [09:18<04:32,  1.22s/it]\u001b[A\n","Iteration:  67% 457/679 [09:19<04:31,  1.22s/it]\u001b[A\n","Iteration:  67% 458/679 [09:20<04:30,  1.22s/it]\u001b[A\n","Iteration:  68% 459/679 [09:21<04:29,  1.22s/it]\u001b[A\n","Iteration:  68% 460/679 [09:23<04:28,  1.22s/it]\u001b[A\n","Iteration:  68% 461/679 [09:24<04:26,  1.22s/it]\u001b[A\n","Iteration:  68% 462/679 [09:25<04:25,  1.22s/it]\u001b[A\n","Iteration:  68% 463/679 [09:26<04:24,  1.23s/it]\u001b[A\n","Iteration:  68% 464/679 [09:28<04:23,  1.22s/it]\u001b[A\n","Iteration:  68% 465/679 [09:29<04:22,  1.23s/it]\u001b[A\n","Iteration:  69% 466/679 [09:30<04:20,  1.22s/it]\u001b[A\n","Iteration:  69% 467/679 [09:31<04:19,  1.22s/it]\u001b[A\n","Iteration:  69% 468/679 [09:32<04:18,  1.22s/it]\u001b[A\n","Iteration:  69% 469/679 [09:34<04:17,  1.23s/it]\u001b[A\n","Iteration:  69% 470/679 [09:35<04:16,  1.23s/it]\u001b[A\n","Iteration:  69% 471/679 [09:36<04:14,  1.22s/it]\u001b[A\n","Iteration:  70% 472/679 [09:37<04:13,  1.22s/it]\u001b[A\n","Iteration:  70% 473/679 [09:39<04:12,  1.22s/it]\u001b[A\n","Iteration:  70% 474/679 [09:40<04:11,  1.22s/it]\u001b[A\n","Iteration:  70% 475/679 [09:41<04:09,  1.22s/it]\u001b[A\n","Iteration:  70% 476/679 [09:42<04:08,  1.23s/it]\u001b[A\n","Iteration:  70% 477/679 [09:43<04:07,  1.23s/it]\u001b[A\n","Iteration:  70% 478/679 [09:45<04:06,  1.23s/it]\u001b[A\n","Iteration:  71% 479/679 [09:46<04:05,  1.23s/it]\u001b[A\n","Iteration:  71% 480/679 [09:47<04:03,  1.23s/it]\u001b[A\n","Iteration:  71% 481/679 [09:48<04:02,  1.23s/it]\u001b[A\n","Iteration:  71% 482/679 [09:50<04:01,  1.22s/it]\u001b[A\n","Iteration:  71% 483/679 [09:51<03:59,  1.22s/it]\u001b[A\n","Iteration:  71% 484/679 [09:52<03:58,  1.22s/it]\u001b[A\n","Iteration:  71% 485/679 [09:53<03:57,  1.22s/it]\u001b[A\n","Iteration:  72% 486/679 [09:54<03:56,  1.22s/it]\u001b[A\n","Iteration:  72% 487/679 [09:56<03:55,  1.22s/it]\u001b[A\n","Iteration:  72% 488/679 [09:57<03:53,  1.22s/it]\u001b[A\n","Iteration:  72% 489/679 [09:58<03:52,  1.22s/it]\u001b[A\n","Iteration:  72% 490/679 [09:59<03:51,  1.23s/it]\u001b[A\n","Iteration:  72% 491/679 [10:01<03:50,  1.22s/it]\u001b[A\n","Iteration:  72% 492/679 [10:02<03:49,  1.22s/it]\u001b[A\n","Iteration:  73% 493/679 [10:03<03:47,  1.23s/it]\u001b[A\n","Iteration:  73% 494/679 [10:04<03:46,  1.23s/it]\u001b[A\n","Iteration:  73% 495/679 [10:05<03:45,  1.23s/it]\u001b[A\n","Iteration:  73% 496/679 [10:07<03:44,  1.22s/it]\u001b[A\n","Iteration:  73% 497/679 [10:08<03:42,  1.22s/it]\u001b[A\n","Iteration:  73% 498/679 [10:09<03:41,  1.22s/it]\u001b[A\n","Iteration:  73% 499/679 [10:10<03:40,  1.22s/it]\u001b[A\n","Iteration:  74% 500/679 [10:12<03:39,  1.22s/it]\u001b[A\n","Iteration:  74% 501/679 [10:13<03:37,  1.22s/it]\u001b[A\n","Iteration:  74% 502/679 [10:14<03:36,  1.22s/it]\u001b[A\n","Iteration:  74% 503/679 [10:15<03:35,  1.22s/it]\u001b[A\n","Iteration:  74% 504/679 [10:16<03:34,  1.22s/it]\u001b[A\n","Iteration:  74% 505/679 [10:18<03:32,  1.22s/it]\u001b[A\n","Iteration:  75% 506/679 [10:19<03:31,  1.23s/it]\u001b[A\n","Iteration:  75% 507/679 [10:20<03:30,  1.23s/it]\u001b[A\n","Iteration:  75% 508/679 [10:21<03:29,  1.23s/it]\u001b[A\n","Iteration:  75% 509/679 [10:23<03:28,  1.23s/it]\u001b[A\n","Iteration:  75% 510/679 [10:24<03:27,  1.23s/it]\u001b[A\n","Iteration:  75% 511/679 [10:25<03:25,  1.22s/it]\u001b[A\n","Iteration:  75% 512/679 [10:26<03:24,  1.22s/it]\u001b[A\n","Iteration:  76% 513/679 [10:28<03:23,  1.22s/it]\u001b[A\n","Iteration:  76% 514/679 [10:29<03:22,  1.22s/it]\u001b[A\n","Iteration:  76% 515/679 [10:30<03:20,  1.22s/it]\u001b[A\n","Iteration:  76% 516/679 [10:31<03:19,  1.22s/it]\u001b[A\n","Iteration:  76% 517/679 [10:32<03:18,  1.22s/it]\u001b[A\n","Iteration:  76% 518/679 [10:34<03:17,  1.22s/it]\u001b[A\n","Iteration:  76% 519/679 [10:35<03:15,  1.22s/it]\u001b[A\n","Iteration:  77% 520/679 [10:36<03:14,  1.22s/it]\u001b[A\n","Iteration:  77% 521/679 [10:37<03:13,  1.22s/it]\u001b[A\n","Iteration:  77% 522/679 [10:39<03:12,  1.22s/it]\u001b[A\n","Iteration:  77% 523/679 [10:40<03:11,  1.23s/it]\u001b[A\n","Iteration:  77% 524/679 [10:41<03:09,  1.22s/it]\u001b[A\n","Iteration:  77% 525/679 [10:42<03:08,  1.22s/it]\u001b[A\n","Iteration:  77% 526/679 [10:43<03:07,  1.22s/it]\u001b[A\n","Iteration:  78% 527/679 [10:45<03:05,  1.22s/it]\u001b[A\n","Iteration:  78% 528/679 [10:46<03:04,  1.22s/it]\u001b[A\n","Iteration:  78% 529/679 [10:47<03:03,  1.22s/it]\u001b[A\n","Iteration:  78% 530/679 [10:48<03:02,  1.22s/it]\u001b[A\n","Iteration:  78% 531/679 [10:50<03:01,  1.22s/it]\u001b[A\n","Iteration:  78% 532/679 [10:51<03:00,  1.23s/it]\u001b[A\n","Iteration:  78% 533/679 [10:52<02:58,  1.22s/it]\u001b[A\n","Iteration:  79% 534/679 [10:53<02:57,  1.22s/it]\u001b[A\n","Iteration:  79% 535/679 [10:54<02:56,  1.23s/it]\u001b[A\n","Iteration:  79% 536/679 [10:56<02:55,  1.23s/it]\u001b[A\n","Iteration:  79% 537/679 [10:57<02:53,  1.23s/it]\u001b[A\n","Iteration:  79% 538/679 [10:58<02:52,  1.22s/it]\u001b[A\n","Iteration:  79% 539/679 [10:59<02:51,  1.22s/it]\u001b[A\n","Iteration:  80% 540/679 [11:01<02:50,  1.22s/it]\u001b[A\n","Iteration:  80% 541/679 [11:02<02:48,  1.22s/it]\u001b[A\n","Iteration:  80% 542/679 [11:03<02:47,  1.22s/it]\u001b[A\n","Iteration:  80% 543/679 [11:04<02:46,  1.22s/it]\u001b[A\n","Iteration:  80% 544/679 [11:05<02:45,  1.22s/it]\u001b[A\n","Iteration:  80% 545/679 [11:07<02:44,  1.22s/it]\u001b[A\n","Iteration:  80% 546/679 [11:08<02:42,  1.23s/it]\u001b[A\n","Iteration:  81% 547/679 [11:09<02:41,  1.23s/it]\u001b[A\n","Iteration:  81% 548/679 [11:10<02:40,  1.22s/it]\u001b[A\n","Iteration:  81% 549/679 [11:12<02:39,  1.22s/it]\u001b[A\n","Iteration:  81% 550/679 [11:13<02:37,  1.22s/it]\u001b[A\n","Iteration:  81% 551/679 [11:14<02:36,  1.22s/it]\u001b[A\n","Iteration:  81% 552/679 [11:15<02:35,  1.22s/it]\u001b[A\n","Iteration:  81% 553/679 [11:16<02:34,  1.22s/it]\u001b[A\n","Iteration:  82% 554/679 [11:18<02:33,  1.22s/it]\u001b[A\n","Iteration:  82% 555/679 [11:19<02:31,  1.22s/it]\u001b[A\n","Iteration:  82% 556/679 [11:20<02:30,  1.22s/it]\u001b[A\n","Iteration:  82% 557/679 [11:21<02:29,  1.23s/it]\u001b[A\n","Iteration:  82% 558/679 [11:23<02:28,  1.23s/it]\u001b[A\n","Iteration:  82% 559/679 [11:24<02:27,  1.23s/it]\u001b[A\n","Iteration:  82% 560/679 [11:25<02:25,  1.22s/it]\u001b[A\n","Iteration:  83% 561/679 [11:26<02:24,  1.22s/it]\u001b[A\n","Iteration:  83% 562/679 [11:28<02:23,  1.22s/it]\u001b[A\n","Iteration:  83% 563/679 [11:29<02:21,  1.22s/it]\u001b[A\n","Iteration:  83% 564/679 [11:30<02:20,  1.22s/it]\u001b[A\n","Iteration:  83% 565/679 [11:31<02:19,  1.23s/it]\u001b[A\n","Iteration:  83% 566/679 [11:32<02:18,  1.23s/it]\u001b[A\n","Iteration:  84% 567/679 [11:34<02:17,  1.23s/it]\u001b[A\n","Iteration:  84% 568/679 [11:35<02:15,  1.22s/it]\u001b[A\n","Iteration:  84% 569/679 [11:36<02:14,  1.23s/it]\u001b[A\n","Iteration:  84% 570/679 [11:37<02:13,  1.22s/it]\u001b[A\n","Iteration:  84% 571/679 [11:39<02:12,  1.23s/it]\u001b[A\n","Iteration:  84% 572/679 [11:40<02:11,  1.23s/it]\u001b[A\n","Iteration:  84% 573/679 [11:41<02:09,  1.23s/it]\u001b[A\n","Iteration:  85% 574/679 [11:42<02:08,  1.22s/it]\u001b[A\n","Iteration:  85% 575/679 [11:43<02:07,  1.22s/it]\u001b[A\n","Iteration:  85% 576/679 [11:45<02:06,  1.22s/it]\u001b[A\n","Iteration:  85% 577/679 [11:46<02:04,  1.22s/it]\u001b[A\n","Iteration:  85% 578/679 [11:47<02:03,  1.23s/it]\u001b[A\n","Iteration:  85% 579/679 [11:48<02:02,  1.23s/it]\u001b[A\n","Iteration:  85% 580/679 [11:50<02:01,  1.22s/it]\u001b[A\n","Iteration:  86% 581/679 [11:51<01:59,  1.22s/it]\u001b[A\n","Iteration:  86% 582/679 [11:52<01:58,  1.22s/it]\u001b[A\n","Iteration:  86% 583/679 [11:53<01:57,  1.22s/it]\u001b[A\n","Iteration:  86% 584/679 [11:54<01:56,  1.23s/it]\u001b[A\n","Iteration:  86% 585/679 [11:56<01:55,  1.23s/it]\u001b[A\n","Iteration:  86% 586/679 [11:57<01:54,  1.23s/it]\u001b[A\n","Iteration:  86% 587/679 [11:58<01:52,  1.23s/it]\u001b[A\n","Iteration:  87% 588/679 [11:59<01:51,  1.22s/it]\u001b[A\n","Iteration:  87% 589/679 [12:01<01:50,  1.22s/it]\u001b[A\n","Iteration:  87% 590/679 [12:02<01:48,  1.22s/it]\u001b[A\n","Iteration:  87% 591/679 [12:03<01:47,  1.22s/it]\u001b[A\n","Iteration:  87% 592/679 [12:04<01:46,  1.22s/it]\u001b[A\n","Iteration:  87% 593/679 [12:05<01:45,  1.22s/it]\u001b[A\n","Iteration:  87% 594/679 [12:07<01:44,  1.22s/it]\u001b[A\n","Iteration:  88% 595/679 [12:08<01:42,  1.22s/it]\u001b[A\n","Iteration:  88% 596/679 [12:09<01:41,  1.22s/it]\u001b[A\n","Iteration:  88% 597/679 [12:10<01:40,  1.22s/it]\u001b[A\n","Iteration:  88% 598/679 [12:12<01:39,  1.22s/it]\u001b[A\n","Iteration:  88% 599/679 [12:13<01:37,  1.22s/it]\u001b[A\n","Iteration:  88% 600/679 [12:14<01:36,  1.22s/it]\u001b[A\n","Iteration:  89% 601/679 [12:15<01:35,  1.22s/it]\u001b[A\n","Iteration:  89% 602/679 [12:16<01:34,  1.22s/it]\u001b[A\n","Iteration:  89% 603/679 [12:18<01:32,  1.22s/it]\u001b[A\n","Iteration:  89% 604/679 [12:19<01:31,  1.22s/it]\u001b[A\n","Iteration:  89% 605/679 [12:20<01:30,  1.22s/it]\u001b[A\n","Iteration:  89% 606/679 [12:21<01:29,  1.22s/it]\u001b[A\n","Iteration:  89% 607/679 [12:23<01:28,  1.22s/it]\u001b[A\n","Iteration:  90% 608/679 [12:24<01:26,  1.23s/it]\u001b[A\n","Iteration:  90% 609/679 [12:25<01:25,  1.22s/it]\u001b[A\n","Iteration:  90% 610/679 [12:26<01:24,  1.22s/it]\u001b[A\n","Iteration:  90% 611/679 [12:28<01:23,  1.22s/it]\u001b[A\n","Iteration:  90% 612/679 [12:29<01:22,  1.22s/it]\u001b[A\n","Iteration:  90% 613/679 [12:30<01:20,  1.22s/it]\u001b[A\n","Iteration:  90% 614/679 [12:31<01:19,  1.22s/it]\u001b[A\n","Iteration:  91% 615/679 [12:32<01:18,  1.22s/it]\u001b[A\n","Iteration:  91% 616/679 [12:34<01:17,  1.22s/it]\u001b[A\n","Iteration:  91% 617/679 [12:35<01:15,  1.22s/it]\u001b[A\n","Iteration:  91% 618/679 [12:36<01:14,  1.22s/it]\u001b[A\n","Iteration:  91% 619/679 [12:37<01:13,  1.22s/it]\u001b[A\n","Iteration:  91% 620/679 [12:39<01:12,  1.22s/it]\u001b[A\n","Iteration:  91% 621/679 [12:40<01:11,  1.23s/it]\u001b[A\n","Iteration:  92% 622/679 [12:41<01:09,  1.23s/it]\u001b[A\n","Iteration:  92% 623/679 [12:42<01:08,  1.22s/it]\u001b[A\n","Iteration:  92% 624/679 [12:43<01:07,  1.22s/it]\u001b[A\n","Iteration:  92% 625/679 [12:45<01:06,  1.22s/it]\u001b[A\n","Iteration:  92% 626/679 [12:46<01:04,  1.23s/it]\u001b[A\n","Iteration:  92% 627/679 [12:47<01:03,  1.23s/it]\u001b[A\n","Iteration:  92% 628/679 [12:48<01:02,  1.23s/it]\u001b[A\n","Iteration:  93% 629/679 [12:50<01:01,  1.23s/it]\u001b[A\n","Iteration:  93% 630/679 [12:51<01:00,  1.22s/it]\u001b[A\n","Iteration:  93% 631/679 [12:52<00:58,  1.22s/it]\u001b[A\n","Iteration:  93% 632/679 [12:53<00:57,  1.22s/it]\u001b[A\n","Iteration:  93% 633/679 [12:54<00:56,  1.22s/it]\u001b[A\n","Iteration:  93% 634/679 [12:56<00:55,  1.22s/it]\u001b[A\n","Iteration:  94% 635/679 [12:57<00:53,  1.22s/it]\u001b[A\n","Iteration:  94% 636/679 [12:58<00:52,  1.22s/it]\u001b[A\n","Iteration:  94% 637/679 [12:59<00:51,  1.22s/it]\u001b[A\n","Iteration:  94% 638/679 [13:01<00:50,  1.22s/it]\u001b[A\n","Iteration:  94% 639/679 [13:02<00:48,  1.22s/it]\u001b[A\n","Iteration:  94% 640/679 [13:03<00:47,  1.22s/it]\u001b[A\n","Iteration:  94% 641/679 [13:04<00:46,  1.22s/it]\u001b[A12/14/2021 22:19:59 - INFO - __main__ -   ***** Running evaluation on dev dataset (2000 step) *****\n","12/14/2021 22:19:59 - INFO - __main__ -     Num examples = 5426\n","12/14/2021 22:19:59 - INFO - __main__ -     Eval Batch size = 32\n","\n","\n","Evaluating:   0% 0/170 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluating:   1% 1/170 [00:00<00:41,  4.06it/s]\u001b[A\u001b[A\n","\n","Evaluating:   1% 2/170 [00:00<00:40,  4.12it/s]\u001b[A\u001b[A\n","\n","Evaluating:   2% 3/170 [00:00<00:40,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:   2% 4/170 [00:00<00:40,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:   3% 5/170 [00:01<00:39,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:   4% 6/170 [00:01<00:39,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:   4% 7/170 [00:01<00:38,  4.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:   5% 8/170 [00:01<00:38,  4.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:   5% 9/170 [00:02<00:38,  4.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:   6% 10/170 [00:02<00:38,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:   6% 11/170 [00:02<00:38,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:   7% 12/170 [00:02<00:37,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:   8% 13/170 [00:03<00:37,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:   8% 14/170 [00:03<00:37,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:   9% 15/170 [00:03<00:37,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:   9% 16/170 [00:03<00:36,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  10% 17/170 [00:04<00:36,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  11% 18/170 [00:04<00:36,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  11% 19/170 [00:04<00:36,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  12% 20/170 [00:04<00:36,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  12% 21/170 [00:05<00:36,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  13% 22/170 [00:05<00:35,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  14% 23/170 [00:05<00:35,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  14% 24/170 [00:05<00:35,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  15% 25/170 [00:06<00:34,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  15% 26/170 [00:06<00:34,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  16% 27/170 [00:06<00:34,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  16% 28/170 [00:06<00:34,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  17% 29/170 [00:06<00:33,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  18% 30/170 [00:07<00:33,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  18% 31/170 [00:07<00:33,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  19% 32/170 [00:07<00:33,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  19% 33/170 [00:07<00:32,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  20% 34/170 [00:08<00:32,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  21% 35/170 [00:08<00:32,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  21% 36/170 [00:08<00:32,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  22% 37/170 [00:08<00:31,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  22% 38/170 [00:09<00:31,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  23% 39/170 [00:09<00:31,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  24% 40/170 [00:09<00:31,  4.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  24% 41/170 [00:09<00:30,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  25% 42/170 [00:10<00:30,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  25% 43/170 [00:10<00:30,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  26% 44/170 [00:10<00:30,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  26% 45/170 [00:10<00:30,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  27% 46/170 [00:11<00:29,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  28% 47/170 [00:11<00:29,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  28% 48/170 [00:11<00:29,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  29% 49/170 [00:11<00:29,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  29% 50/170 [00:12<00:28,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  30% 51/170 [00:12<00:28,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  31% 52/170 [00:12<00:28,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  31% 53/170 [00:12<00:28,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  32% 54/170 [00:12<00:27,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  32% 55/170 [00:13<00:27,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  33% 56/170 [00:13<00:27,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  34% 57/170 [00:13<00:27,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  34% 58/170 [00:13<00:26,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  35% 59/170 [00:14<00:26,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  35% 60/170 [00:14<00:26,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  36% 61/170 [00:14<00:26,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  36% 62/170 [00:14<00:26,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  37% 63/170 [00:15<00:25,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  38% 64/170 [00:15<00:25,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  38% 65/170 [00:15<00:25,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  39% 66/170 [00:15<00:25,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  39% 67/170 [00:16<00:24,  4.12it/s]\u001b[A\u001b[A\n","\n","Evaluating:  40% 68/170 [00:16<00:24,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  41% 69/170 [00:16<00:24,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  41% 70/170 [00:16<00:24,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  42% 71/170 [00:17<00:23,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  42% 72/170 [00:17<00:23,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  43% 73/170 [00:17<00:23,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  44% 74/170 [00:17<00:23,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  44% 75/170 [00:18<00:22,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  45% 76/170 [00:18<00:22,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  45% 77/170 [00:18<00:22,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  46% 78/170 [00:18<00:22,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  46% 79/170 [00:19<00:22,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  47% 80/170 [00:19<00:21,  4.12it/s]\u001b[A\u001b[A\n","\n","Evaluating:  48% 81/170 [00:19<00:21,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  48% 82/170 [00:19<00:21,  4.12it/s]\u001b[A\u001b[A\n","\n","Evaluating:  49% 83/170 [00:19<00:21,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  49% 84/170 [00:20<00:20,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  50% 85/170 [00:20<00:20,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  51% 86/170 [00:20<00:20,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  51% 87/170 [00:20<00:19,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  52% 88/170 [00:21<00:19,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  52% 89/170 [00:21<00:19,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  53% 90/170 [00:21<00:19,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  54% 91/170 [00:21<00:19,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  54% 92/170 [00:22<00:18,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  55% 93/170 [00:22<00:18,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  55% 94/170 [00:22<00:18,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  56% 95/170 [00:22<00:18,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  56% 96/170 [00:23<00:17,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  57% 97/170 [00:23<00:17,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  58% 98/170 [00:23<00:17,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  58% 99/170 [00:23<00:17,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  59% 100/170 [00:24<00:16,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  59% 101/170 [00:24<00:16,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  60% 102/170 [00:24<00:16,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  61% 103/170 [00:24<00:16,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  61% 104/170 [00:25<00:15,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 105/170 [00:25<00:15,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 106/170 [00:25<00:15,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  63% 107/170 [00:25<00:15,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  64% 108/170 [00:26<00:14,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  64% 109/170 [00:26<00:14,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  65% 110/170 [00:26<00:14,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  65% 111/170 [00:26<00:14,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  66% 112/170 [00:26<00:13,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  66% 113/170 [00:27<00:13,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  67% 114/170 [00:27<00:13,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  68% 115/170 [00:27<00:13,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  68% 116/170 [00:27<00:12,  4.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  69% 117/170 [00:28<00:12,  4.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  69% 118/170 [00:28<00:12,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  70% 119/170 [00:28<00:12,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  71% 120/170 [00:28<00:12,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  71% 121/170 [00:29<00:11,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  72% 122/170 [00:29<00:11,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  72% 123/170 [00:29<00:11,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  73% 124/170 [00:29<00:11,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  74% 125/170 [00:30<00:10,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  74% 126/170 [00:30<00:10,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 127/170 [00:30<00:10,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 128/170 [00:30<00:10,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  76% 129/170 [00:31<00:09,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  76% 130/170 [00:31<00:09,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  77% 131/170 [00:31<00:09,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  78% 132/170 [00:31<00:09,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  78% 133/170 [00:32<00:08,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  79% 134/170 [00:32<00:08,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  79% 135/170 [00:32<00:08,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  80% 136/170 [00:32<00:08,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  81% 137/170 [00:33<00:07,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  81% 138/170 [00:33<00:07,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  82% 139/170 [00:33<00:07,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  82% 140/170 [00:33<00:07,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  83% 141/170 [00:33<00:06,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  84% 142/170 [00:34<00:06,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  84% 143/170 [00:34<00:06,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  85% 144/170 [00:34<00:06,  4.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  85% 145/170 [00:34<00:05,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  86% 146/170 [00:35<00:05,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  86% 147/170 [00:35<00:05,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  87% 148/170 [00:35<00:05,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 149/170 [00:35<00:05,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 150/170 [00:36<00:04,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  89% 151/170 [00:36<00:04,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  89% 152/170 [00:36<00:04,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  90% 153/170 [00:36<00:04,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  91% 154/170 [00:37<00:03,  4.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  91% 155/170 [00:37<00:03,  4.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  92% 156/170 [00:37<00:03,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  92% 157/170 [00:37<00:03,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  93% 158/170 [00:38<00:02,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  94% 159/170 [00:38<00:02,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  94% 160/170 [00:38<00:02,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  95% 161/170 [00:38<00:02,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  95% 162/170 [00:39<00:01,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  96% 163/170 [00:39<00:01,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  96% 164/170 [00:39<00:01,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  97% 165/170 [00:39<00:01,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  98% 166/170 [00:39<00:00,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  98% 167/170 [00:40<00:00,  4.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  99% 168/170 [00:40<00:00,  4.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  99% 169/170 [00:40<00:00,  4.13it/s]\u001b[A\u001b[A\n","\n","Evaluating: 100% 170/170 [00:40<00:00,  4.16it/s]\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","12/14/2021 22:20:40 - INFO - __main__ -   ***** Eval results on dev dataset *****\n","12/14/2021 22:20:40 - INFO - __main__ -     accuracy = 0.4157758938444526\n","12/14/2021 22:20:40 - INFO - __main__ -     loss = 0.1008066330324201\n","12/14/2021 22:20:40 - INFO - __main__ -     macro_f1 = 0.3433528571448649\n","12/14/2021 22:20:40 - INFO - __main__ -     macro_precision = 0.44426150376336626\n","12/14/2021 22:20:40 - INFO - __main__ -     macro_recall = 0.32055774888296507\n","12/14/2021 22:20:40 - INFO - __main__ -     micro_f1 = 0.5402828017099638\n","12/14/2021 22:20:40 - INFO - __main__ -     micro_precision = 0.568118948824343\n","12/14/2021 22:20:40 - INFO - __main__ -     micro_recall = 0.5150470219435737\n","12/14/2021 22:20:40 - INFO - __main__ -     weighted_f1 = 0.49489733289644994\n","12/14/2021 22:20:40 - INFO - __main__ -     weighted_precision = 0.5291997046101267\n","12/14/2021 22:20:40 - INFO - __main__ -     weighted_recall = 0.5150470219435737\n","12/14/2021 22:20:40 - INFO - transformers.configuration_utils -   Configuration saved in ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/config.json\n","12/14/2021 22:20:41 - INFO - transformers.modeling_utils -   Model weights saved in ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000/pytorch_model.bin\n","12/14/2021 22:20:41 - INFO - __main__ -   Saving model checkpoint to ckpt/original/drive/MyDrive/EECS595 Final Project/roberta/checkpoint-2000\n","\n","Iteration:  95% 642/679 [13:48<08:34, 13.90s/it]\u001b[A\n","Iteration:  95% 643/679 [13:49<06:03, 10.10s/it]\u001b[A\n","Iteration:  95% 644/679 [13:50<04:20,  7.44s/it]\u001b[A\n","Iteration:  95% 645/679 [13:51<03:09,  5.57s/it]\u001b[A\n","Iteration:  95% 646/679 [13:53<02:20,  4.27s/it]\u001b[A\n","Iteration:  95% 647/679 [13:54<01:47,  3.35s/it]\u001b[A\n","Iteration:  95% 648/679 [13:55<01:24,  2.72s/it]\u001b[A\n","Iteration:  96% 649/679 [13:56<01:08,  2.27s/it]\u001b[A\n","Iteration:  96% 650/679 [13:58<00:56,  1.95s/it]\u001b[A\n","Iteration:  96% 651/679 [13:59<00:48,  1.74s/it]\u001b[A\n","Iteration:  96% 652/679 [14:00<00:42,  1.58s/it]\u001b[A\n","Iteration:  96% 653/679 [14:01<00:38,  1.47s/it]\u001b[A\n","Iteration:  96% 654/679 [14:02<00:34,  1.40s/it]\u001b[A\n","Iteration:  96% 655/679 [14:04<00:32,  1.35s/it]\u001b[A\n","Iteration:  97% 656/679 [14:05<00:30,  1.31s/it]\u001b[A\n","Iteration:  97% 657/679 [14:06<00:28,  1.28s/it]\u001b[A\n","Iteration:  97% 658/679 [14:07<00:26,  1.27s/it]\u001b[A\n","Iteration:  97% 659/679 [14:09<00:25,  1.25s/it]\u001b[A\n","Iteration:  97% 660/679 [14:10<00:23,  1.24s/it]\u001b[A\n","Iteration:  97% 661/679 [14:11<00:22,  1.24s/it]\u001b[A\n","Iteration:  97% 662/679 [14:12<00:20,  1.23s/it]\u001b[A\n","Iteration:  98% 663/679 [14:13<00:19,  1.23s/it]\u001b[A\n","Iteration:  98% 664/679 [14:15<00:18,  1.23s/it]\u001b[A\n","Iteration:  98% 665/679 [14:16<00:17,  1.23s/it]\u001b[A\n","Iteration:  98% 666/679 [14:17<00:15,  1.23s/it]\u001b[A\n","Iteration:  98% 667/679 [14:18<00:14,  1.23s/it]\u001b[A\n","Iteration:  98% 668/679 [14:20<00:13,  1.23s/it]\u001b[A\n","Iteration:  99% 669/679 [14:21<00:12,  1.22s/it]\u001b[A\n","Iteration:  99% 670/679 [14:22<00:11,  1.22s/it]\u001b[A\n","Iteration:  99% 671/679 [14:23<00:09,  1.22s/it]\u001b[A\n","Iteration:  99% 672/679 [14:24<00:08,  1.22s/it]\u001b[A\n","Iteration:  99% 673/679 [14:26<00:07,  1.23s/it]\u001b[A\n","Iteration:  99% 674/679 [14:27<00:06,  1.23s/it]\u001b[A\n","Iteration:  99% 675/679 [14:28<00:04,  1.22s/it]\u001b[A\n","Iteration: 100% 676/679 [14:29<00:03,  1.22s/it]\u001b[A\n","Iteration: 100% 677/679 [14:31<00:02,  1.23s/it]\u001b[A\n","Iteration: 100% 678/679 [14:32<00:01,  1.23s/it]\u001b[A\n","Iteration: 100% 679/679 [14:32<00:00,  1.29s/it]\n","Epoch:  30% 3/10 [42:57<1:40:45, 863.64s/it]\n","Iteration:   0% 0/679 [00:00<?, ?it/s]\u001b[A\n","Iteration:   0% 1/679 [00:01<13:50,  1.22s/it]\u001b[A\n","Iteration:   0% 2/679 [00:02<13:48,  1.22s/it]\u001b[A\n","Iteration:   0% 3/679 [00:03<13:48,  1.23s/it]\u001b[A\n","Iteration:   1% 4/679 [00:04<13:48,  1.23s/it]\u001b[A\n","Iteration:   1% 5/679 [00:06<13:46,  1.23s/it]\u001b[A\n","Iteration:   1% 6/679 [00:07<13:44,  1.23s/it]\u001b[A\n","Iteration:   1% 7/679 [00:08<13:42,  1.22s/it]\u001b[A\n","Iteration:   1% 8/679 [00:09<13:42,  1.23s/it]\u001b[A\n","Iteration:   1% 9/679 [00:11<13:41,  1.23s/it]\u001b[A\n","Iteration:   1% 10/679 [00:12<13:39,  1.23s/it]\u001b[A\n","Iteration:   2% 11/679 [00:13<13:38,  1.23s/it]\u001b[A\n","Iteration:   2% 12/679 [00:14<13:36,  1.22s/it]\u001b[A\n","Iteration:   2% 13/679 [00:15<13:35,  1.22s/it]\u001b[A\n","Iteration:   2% 14/679 [00:17<13:33,  1.22s/it]\u001b[A\n","Iteration:   2% 15/679 [00:18<13:32,  1.22s/it]\u001b[A\n","Iteration:   2% 16/679 [00:19<13:32,  1.23s/it]\u001b[A\n","Iteration:   3% 17/679 [00:20<13:31,  1.23s/it]\u001b[A\n","Iteration:   3% 18/679 [00:22<13:30,  1.23s/it]\u001b[A\n","Iteration:   3% 19/679 [00:23<13:30,  1.23s/it]\u001b[A\n","Iteration:   3% 20/679 [00:24<13:27,  1.23s/it]\u001b[A\n","Iteration:   3% 21/679 [00:25<13:25,  1.22s/it]\u001b[A\n","Iteration:   3% 22/679 [00:26<13:25,  1.23s/it]\u001b[A\n","Iteration:   3% 23/679 [00:28<13:23,  1.23s/it]\u001b[A\n","Iteration:   4% 24/679 [00:29<13:22,  1.23s/it]\u001b[A\n","Iteration:   4% 25/679 [00:30<13:21,  1.23s/it]\u001b[A\n","Iteration:   4% 26/679 [00:31<13:19,  1.22s/it]\u001b[A\n","Iteration:   4% 27/679 [00:33<13:18,  1.22s/it]\u001b[A\n","Iteration:   4% 28/679 [00:34<13:17,  1.22s/it]\u001b[A\n","Iteration:   4% 29/679 [00:35<13:15,  1.22s/it]\u001b[A\n","Iteration:   4% 30/679 [00:36<13:15,  1.22s/it]\u001b[A\n","Iteration:   5% 31/679 [00:37<13:13,  1.23s/it]\u001b[A\n","Iteration:   5% 32/679 [00:39<13:12,  1.22s/it]\u001b[A\n","Iteration:   5% 33/679 [00:40<13:10,  1.22s/it]\u001b[A\n","Iteration:   5% 34/679 [00:41<13:09,  1.22s/it]\u001b[A\n","Iteration:   5% 35/679 [00:42<13:08,  1.22s/it]\u001b[A\n","Iteration:   5% 36/679 [00:44<13:07,  1.22s/it]\u001b[A\n","Iteration:   5% 37/679 [00:45<13:05,  1.22s/it]\u001b[A\n","Iteration:   6% 38/679 [00:46<13:05,  1.22s/it]\u001b[A\n","Iteration:   6% 39/679 [00:47<13:03,  1.22s/it]\u001b[A\n","Iteration:   6% 40/679 [00:48<13:02,  1.22s/it]\u001b[A\n","Iteration:   6% 41/679 [00:50<13:01,  1.22s/it]\u001b[A\n","Iteration:   6% 42/679 [00:51<12:59,  1.22s/it]\u001b[A\n","Iteration:   6% 43/679 [00:52<12:58,  1.22s/it]\u001b[A\n","Iteration:   6% 44/679 [00:53<12:57,  1.22s/it]\u001b[A\n","Iteration:   7% 45/679 [00:55<12:56,  1.22s/it]\u001b[A\n","Iteration:   7% 46/679 [00:56<12:55,  1.22s/it]\u001b[A\n","Iteration:   7% 47/679 [00:57<12:54,  1.23s/it]\u001b[A\n","Iteration:   7% 48/679 [00:58<12:52,  1.22s/it]\u001b[A\n","Iteration:   7% 49/679 [01:00<12:51,  1.22s/it]\u001b[A\n","Iteration:   7% 50/679 [01:01<12:50,  1.22s/it]\u001b[A\n","Iteration:   8% 51/679 [01:02<12:49,  1.22s/it]\u001b[A\n","Iteration:   8% 52/679 [01:03<12:47,  1.22s/it]\u001b[A\n","Iteration:   8% 53/679 [01:04<12:46,  1.22s/it]\u001b[A\n","Iteration:   8% 54/679 [01:06<12:44,  1.22s/it]\u001b[A\n","Iteration:   8% 55/679 [01:07<12:44,  1.22s/it]\u001b[A\n","Iteration:   8% 56/679 [01:08<12:42,  1.22s/it]\u001b[A\n","Iteration:   8% 57/679 [01:09<12:41,  1.22s/it]\u001b[A\n","Iteration:   9% 58/679 [01:11<12:40,  1.22s/it]\u001b[A\n","Iteration:   9% 59/679 [01:12<12:39,  1.22s/it]\u001b[A\n","Iteration:   9% 60/679 [01:13<12:38,  1.22s/it]\u001b[A\n","Iteration:   9% 61/679 [01:14<12:36,  1.22s/it]\u001b[A\n","Iteration:   9% 62/679 [01:15<12:35,  1.22s/it]\u001b[A\n","Iteration:   9% 63/679 [01:17<12:34,  1.22s/it]\u001b[A\n","Iteration:   9% 64/679 [01:18<12:33,  1.22s/it]\u001b[A\n","Iteration:  10% 65/679 [01:19<12:31,  1.22s/it]\u001b[A\n","Iteration:  10% 66/679 [01:20<12:30,  1.22s/it]\u001b[A\n","Iteration:  10% 67/679 [01:22<12:29,  1.22s/it]\u001b[A\n","Iteration:  10% 68/679 [01:23<12:27,  1.22s/it]\u001b[A\n","Iteration:  10% 69/679 [01:24<12:27,  1.22s/it]\u001b[A\n","Iteration:  10% 70/679 [01:25<12:25,  1.22s/it]\u001b[A\n","Iteration:  10% 71/679 [01:26<12:24,  1.22s/it]\u001b[A\n","Iteration:  11% 72/679 [01:28<12:23,  1.22s/it]\u001b[A\n","Iteration:  11% 73/679 [01:29<12:21,  1.22s/it]\u001b[A\n","Iteration:  11% 74/679 [01:30<12:20,  1.22s/it]\u001b[A\n","Iteration:  11% 75/679 [01:31<12:18,  1.22s/it]\u001b[A\n","Iteration:  11% 76/679 [01:33<12:18,  1.22s/it]\u001b[A\n","Iteration:  11% 77/679 [01:34<12:17,  1.22s/it]\u001b[A\n","Iteration:  11% 78/679 [01:35<12:16,  1.22s/it]\u001b[A\n","Iteration:  12% 79/679 [01:36<12:14,  1.22s/it]\u001b[A\n","Iteration:  12% 80/679 [01:37<12:13,  1.22s/it]\u001b[A\n","Iteration:  12% 81/679 [01:39<12:12,  1.23s/it]\u001b[A\n","Iteration:  12% 82/679 [01:40<12:11,  1.23s/it]\u001b[A\n","Iteration:  12% 83/679 [01:41<12:10,  1.23s/it]\u001b[A\n","Iteration:  12% 84/679 [01:42<12:08,  1.22s/it]\u001b[A\n","Iteration:  13% 85/679 [01:44<12:07,  1.22s/it]\u001b[A\n","Iteration:  13% 86/679 [01:45<12:05,  1.22s/it]\u001b[A\n","Iteration:  13% 87/679 [01:46<12:04,  1.22s/it]\u001b[A\n","Iteration:  13% 88/679 [01:47<12:03,  1.22s/it]\u001b[A\n","Iteration:  13% 89/679 [01:48<12:02,  1.22s/it]\u001b[A\n","Iteration:  13% 90/679 [01:50<12:00,  1.22s/it]\u001b[A\n","Iteration:  13% 91/679 [01:51<11:59,  1.22s/it]\u001b[A\n","Iteration:  14% 92/679 [01:52<11:58,  1.22s/it]\u001b[A\n","Iteration:  14% 93/679 [01:53<11:57,  1.22s/it]\u001b[A\n","Iteration:  14% 94/679 [01:55<11:56,  1.22s/it]\u001b[A\n","Iteration:  14% 95/679 [01:56<11:55,  1.22s/it]\u001b[A\n","Iteration:  14% 96/679 [01:57<11:53,  1.22s/it]\u001b[A\n","Iteration:  14% 97/679 [01:58<11:52,  1.22s/it]\u001b[A\n","Iteration:  14% 98/679 [02:00<11:51,  1.22s/it]\u001b[A\n","Iteration:  15% 99/679 [02:01<11:50,  1.22s/it]\u001b[A\n","Iteration:  15% 100/679 [02:02<11:49,  1.22s/it]\u001b[A\n","Iteration:  15% 101/679 [02:03<11:47,  1.22s/it]\u001b[A\n","Iteration:  15% 102/679 [02:04<11:46,  1.22s/it]\u001b[A\n","Iteration:  15% 103/679 [02:06<11:45,  1.22s/it]\u001b[A\n","Iteration:  15% 104/679 [02:07<11:44,  1.23s/it]\u001b[A\n","Iteration:  15% 105/679 [02:08<11:42,  1.22s/it]\u001b[A\n","Iteration:  16% 106/679 [02:09<11:41,  1.22s/it]\u001b[A\n","Iteration:  16% 107/679 [02:11<11:39,  1.22s/it]\u001b[A\n","Iteration:  16% 108/679 [02:12<11:38,  1.22s/it]\u001b[A\n","Iteration:  16% 109/679 [02:13<11:37,  1.22s/it]\u001b[A\n","Iteration:  16% 110/679 [02:14<11:36,  1.22s/it]\u001b[A\n","Iteration:  16% 111/679 [02:15<11:35,  1.22s/it]\u001b[A\n","Iteration:  16% 112/679 [02:17<11:34,  1.23s/it]\u001b[A\n","Iteration:  17% 113/679 [02:18<11:33,  1.23s/it]\u001b[A\n","Iteration:  17% 114/679 [02:19<11:32,  1.23s/it]\u001b[A\n","Iteration:  17% 115/679 [02:20<11:31,  1.23s/it]\u001b[A\n","Iteration:  17% 116/679 [02:22<11:29,  1.23s/it]\u001b[A\n","Iteration:  17% 117/679 [02:23<11:28,  1.22s/it]\u001b[A\n","Iteration:  17% 118/679 [02:24<11:26,  1.22s/it]\u001b[A\n","Iteration:  18% 119/679 [02:25<11:25,  1.22s/it]\u001b[A\n","Iteration:  18% 120/679 [02:26<11:23,  1.22s/it]\u001b[A\n","Iteration:  18% 121/679 [02:28<11:23,  1.22s/it]\u001b[A\n","Iteration:  18% 122/679 [02:29<11:22,  1.22s/it]\u001b[A\n","Iteration:  18% 123/679 [02:30<11:20,  1.22s/it]\u001b[A\n","Iteration:  18% 124/679 [02:31<11:19,  1.22s/it]\u001b[A\n","Iteration:  18% 125/679 [02:33<11:18,  1.22s/it]\u001b[A\n","Iteration:  19% 126/679 [02:34<11:17,  1.22s/it]\u001b[A\n","Iteration:  19% 127/679 [02:35<11:15,  1.22s/it]\u001b[A\n","Iteration:  19% 128/679 [02:36<11:14,  1.22s/it]\u001b[A\n","Iteration:  19% 129/679 [02:37<11:13,  1.23s/it]\u001b[A\n","Iteration:  19% 130/679 [02:39<11:12,  1.22s/it]\u001b[A\n","Iteration:  19% 131/679 [02:40<11:11,  1.23s/it]\u001b[A\n","Iteration:  19% 132/679 [02:41<11:10,  1.23s/it]\u001b[A\n","Iteration:  20% 133/679 [02:42<11:09,  1.23s/it]\u001b[A\n","Iteration:  20% 134/679 [02:44<11:07,  1.23s/it]\u001b[A\n","Iteration:  20% 135/679 [02:45<11:06,  1.22s/it]\u001b[A\n","Iteration:  20% 136/679 [02:46<11:04,  1.22s/it]\u001b[A\n","Iteration:  20% 137/679 [02:47<11:03,  1.22s/it]\u001b[A\n","Iteration:  20% 138/679 [02:48<11:02,  1.22s/it]\u001b[A\n","Iteration:  20% 139/679 [02:50<11:01,  1.23s/it]\u001b[A\n","Iteration:  21% 140/679 [02:51<11:00,  1.23s/it]\u001b[A\n","Iteration:  21% 141/679 [02:52<10:59,  1.23s/it]\u001b[A\n","Iteration:  21% 142/679 [02:53<10:58,  1.23s/it]\u001b[A\n","Iteration:  21% 143/679 [02:55<10:56,  1.23s/it]\u001b[A\n","Iteration:  21% 144/679 [02:56<10:55,  1.23s/it]\u001b[A\n","Iteration:  21% 145/679 [02:57<10:53,  1.22s/it]\u001b[A\n","Iteration:  22% 146/679 [02:58<10:52,  1.22s/it]\u001b[A\n","Iteration:  22% 147/679 [03:00<10:51,  1.23s/it]\u001b[A\n","Iteration:  22% 148/679 [03:01<10:50,  1.23s/it]\u001b[A\n","Iteration:  22% 149/679 [03:02<10:51,  1.23s/it]\u001b[A\n","Iteration:  22% 150/679 [03:03<10:49,  1.23s/it]\u001b[A\n","Iteration:  22% 151/679 [03:04<10:47,  1.23s/it]\u001b[A\n","Iteration:  22% 152/679 [03:06<10:46,  1.23s/it]\u001b[A\n","Iteration:  23% 153/679 [03:07<10:45,  1.23s/it]\u001b[A\n","Iteration:  23% 154/679 [03:08<10:43,  1.23s/it]\u001b[A\n","Iteration:  23% 155/679 [03:09<10:42,  1.23s/it]\u001b[A\n","Iteration:  23% 156/679 [03:11<10:40,  1.22s/it]\u001b[A\n","Iteration:  23% 157/679 [03:12<10:39,  1.22s/it]\u001b[A\n","Iteration:  23% 158/679 [03:13<10:37,  1.22s/it]\u001b[A\n","Iteration:  23% 159/679 [03:14<10:36,  1.22s/it]\u001b[A\n","Iteration:  24% 160/679 [03:15<10:35,  1.22s/it]\u001b[A\n","Iteration:  24% 161/679 [03:17<10:34,  1.22s/it]\u001b[A\n","Iteration:  24% 162/679 [03:18<10:32,  1.22s/it]\u001b[A\n","Iteration:  24% 163/679 [03:19<10:31,  1.22s/it]\u001b[A\n","Iteration:  24% 164/679 [03:20<10:30,  1.22s/it]\u001b[A\n","Iteration:  24% 165/679 [03:22<10:29,  1.22s/it]\u001b[A\n","Iteration:  24% 166/679 [03:23<10:28,  1.22s/it]\u001b[A\n","Iteration:  25% 167/679 [03:24<10:26,  1.22s/it]\u001b[A\n","Iteration:  25% 168/679 [03:25<10:25,  1.22s/it]\u001b[A\n","Iteration:  25% 169/679 [03:26<10:24,  1.23s/it]\u001b[A\n","Iteration:  25% 170/679 [03:28<10:23,  1.22s/it]\u001b[A\n","Iteration:  25% 171/679 [03:29<10:22,  1.23s/it]\u001b[A\n","Iteration:  25% 172/679 [03:30<10:21,  1.23s/it]\u001b[A\n","Iteration:  25% 173/679 [03:31<10:19,  1.22s/it]\u001b[A\n","Iteration:  26% 174/679 [03:33<10:18,  1.22s/it]\u001b[A\n","Iteration:  26% 175/679 [03:34<10:17,  1.23s/it]\u001b[A\n","Iteration:  26% 176/679 [03:35<10:16,  1.23s/it]\u001b[A\n","Iteration:  26% 177/679 [03:36<10:14,  1.22s/it]\u001b[A\n","Iteration:  26% 178/679 [03:38<10:13,  1.22s/it]\u001b[A\n","Iteration:  26% 179/679 [03:39<10:11,  1.22s/it]\u001b[A\n","Iteration:  27% 180/679 [03:40<10:10,  1.22s/it]\u001b[A\n","Iteration:  27% 181/679 [03:41<10:09,  1.22s/it]\u001b[A\n","Iteration:  27% 182/679 [03:42<10:08,  1.22s/it]\u001b[A\n","Iteration:  27% 183/679 [03:44<10:07,  1.22s/it]\u001b[A\n","Iteration:  27% 184/679 [03:45<10:06,  1.22s/it]\u001b[A\n","Iteration:  27% 185/679 [03:46<10:04,  1.22s/it]\u001b[A\n","Iteration:  27% 186/679 [03:47<10:03,  1.22s/it]\u001b[A\n","Iteration:  28% 187/679 [03:49<10:02,  1.22s/it]\u001b[A\n","Iteration:  28% 188/679 [03:50<10:00,  1.22s/it]\u001b[A\n","Iteration:  28% 189/679 [03:51<10:00,  1.22s/it]\u001b[A\n","Iteration:  28% 190/679 [03:52<09:58,  1.22s/it]\u001b[A\n","Iteration:  28% 191/679 [03:53<09:57,  1.22s/it]\u001b[A\n","Iteration:  28% 192/679 [03:55<09:56,  1.22s/it]\u001b[A\n","Iteration:  28% 193/679 [03:56<09:54,  1.22s/it]\u001b[A\n","Iteration:  29% 194/679 [03:57<09:53,  1.22s/it]\u001b[A\n","Iteration:  29% 195/679 [03:58<09:52,  1.22s/it]\u001b[A\n","Iteration:  29% 196/679 [04:00<09:51,  1.22s/it]\u001b[A\n","Iteration:  29% 197/679 [04:01<09:49,  1.22s/it]\u001b[A\n","Iteration:  29% 198/679 [04:02<09:48,  1.22s/it]\u001b[A\n","Iteration:  29% 199/679 [04:03<09:47,  1.22s/it]\u001b[A\n","Iteration:  29% 200/679 [04:04<09:46,  1.22s/it]\u001b[A\n","Iteration:  30% 201/679 [04:06<09:45,  1.22s/it]\u001b[A\n","Iteration:  30% 202/679 [04:07<09:43,  1.22s/it]\u001b[A\n","Iteration:  30% 203/679 [04:08<09:42,  1.22s/it]\u001b[A\n","Iteration:  30% 204/679 [04:09<09:41,  1.22s/it]\u001b[A\n","Iteration:  30% 205/679 [04:11<09:40,  1.22s/it]\u001b[A\n","Iteration:  30% 206/679 [04:12<09:39,  1.22s/it]\u001b[A\n","Iteration:  30% 207/679 [04:13<09:37,  1.22s/it]\u001b[A\n","Iteration:  31% 208/679 [04:14<09:37,  1.23s/it]\u001b[A\n","Iteration:  31% 209/679 [04:15<09:35,  1.23s/it]\u001b[A\n","Iteration:  31% 210/679 [04:17<09:34,  1.23s/it]\u001b[A\n","Iteration:  31% 211/679 [04:18<09:33,  1.23s/it]\u001b[A\n","Iteration:  31% 212/679 [04:19<09:32,  1.23s/it]\u001b[A\n","Iteration:  31% 213/679 [04:20<09:31,  1.23s/it]\u001b[A\n","Iteration:  32% 214/679 [04:22<09:29,  1.23s/it]\u001b[A\n","Iteration:  32% 215/679 [04:23<09:28,  1.22s/it]\u001b[A\n","Iteration:  32% 216/679 [04:24<09:27,  1.23s/it]\u001b[A\n","Iteration:  32% 217/679 [04:25<09:26,  1.23s/it]\u001b[A\n","Iteration:  32% 218/679 [04:26<09:24,  1.23s/it]\u001b[A\n","Iteration:  32% 219/679 [04:28<09:23,  1.22s/it]\u001b[A\n","Iteration:  32% 220/679 [04:29<09:22,  1.22s/it]\u001b[A\n","Iteration:  33% 221/679 [04:30<09:21,  1.23s/it]\u001b[A\n","Iteration:  33% 222/679 [04:31<09:20,  1.23s/it]\u001b[A\n","Iteration:  33% 223/679 [04:33<09:18,  1.23s/it]\u001b[A\n","Iteration:  33% 224/679 [04:34<09:17,  1.23s/it]\u001b[A\n","Iteration:  33% 225/679 [04:35<09:16,  1.23s/it]\u001b[A\n","Iteration:  33% 226/679 [04:36<09:14,  1.22s/it]\u001b[A\n","Iteration:  33% 227/679 [04:38<09:13,  1.22s/it]\u001b[A\n","Iteration:  34% 228/679 [04:39<09:11,  1.22s/it]\u001b[A\n","Iteration:  34% 229/679 [04:40<09:10,  1.22s/it]\u001b[A\n","Iteration:  34% 230/679 [04:41<09:09,  1.22s/it]\u001b[A\n","Iteration:  34% 231/679 [04:42<09:08,  1.22s/it]\u001b[A\n","Iteration:  34% 232/679 [04:44<09:07,  1.22s/it]\u001b[A\n","Iteration:  34% 233/679 [04:45<09:06,  1.22s/it]\u001b[A\n","Iteration:  34% 234/679 [04:46<09:04,  1.22s/it]\u001b[A\n","Iteration:  35% 235/679 [04:47<09:03,  1.22s/it]\u001b[A\n","Iteration:  35% 236/679 [04:49<09:02,  1.22s/it]\u001b[A\n","Iteration:  35% 237/679 [04:50<09:01,  1.22s/it]\u001b[A\n","Iteration:  35% 238/679 [04:51<08:59,  1.22s/it]\u001b[A\n","Iteration:  35% 239/679 [04:52<08:57,  1.22s/it]\u001b[A\n","Iteration:  35% 240/679 [04:53<08:57,  1.22s/it]\u001b[A\n","Iteration:  35% 241/679 [04:55<08:55,  1.22s/it]\u001b[A\n","Iteration:  36% 242/679 [04:56<08:54,  1.22s/it]\u001b[A\n","Iteration:  36% 243/679 [04:57<08:53,  1.22s/it]\u001b[A\n","Iteration:  36% 244/679 [04:58<08:52,  1.22s/it]\u001b[A\n","Iteration:  36% 245/679 [05:00<08:51,  1.22s/it]\u001b[A\n","Iteration:  36% 246/679 [05:01<08:50,  1.22s/it]\u001b[A\n","Iteration:  36% 247/679 [05:02<08:48,  1.22s/it]\u001b[A\n","Iteration:  37% 248/679 [05:03<08:47,  1.22s/it]\u001b[A\n","Iteration:  37% 249/679 [05:04<08:46,  1.22s/it]\u001b[A\n","Iteration:  37% 250/679 [05:06<08:45,  1.22s/it]\u001b[A\n","Iteration:  37% 251/679 [05:07<08:44,  1.22s/it]\u001b[A\n","Iteration:  37% 252/679 [05:08<08:42,  1.22s/it]\u001b[A\n","Iteration:  37% 253/679 [05:09<08:41,  1.22s/it]\u001b[A\n","Iteration:  37% 254/679 [05:11<08:40,  1.22s/it]\u001b[A\n","Iteration:  38% 255/679 [05:12<08:39,  1.22s/it]\u001b[A\n","Iteration:  38% 256/679 [05:13<08:37,  1.22s/it]\u001b[A\n","Iteration:  38% 257/679 [05:14<08:36,  1.22s/it]\u001b[A\n","Iteration:  38% 258/679 [05:15<08:35,  1.22s/it]\u001b[A\n","Iteration:  38% 259/679 [05:17<08:33,  1.22s/it]\u001b[A\n","Iteration:  38% 260/679 [05:18<08:32,  1.22s/it]\u001b[A\n","Iteration:  38% 261/679 [05:19<08:31,  1.22s/it]\u001b[A\n","Iteration:  39% 262/679 [05:20<08:30,  1.22s/it]\u001b[A\n","Iteration:  39% 263/679 [05:22<08:29,  1.22s/it]\u001b[A\n","Iteration:  39% 264/679 [05:23<08:27,  1.22s/it]\u001b[A\n","Iteration:  39% 265/679 [05:24<08:26,  1.22s/it]\u001b[A\n","Iteration:  39% 266/679 [05:25<08:25,  1.22s/it]\u001b[A\n","Iteration:  39% 267/679 [05:26<08:24,  1.22s/it]\u001b[A\n","Iteration:  39% 268/679 [05:28<08:23,  1.22s/it]\u001b[A\n","Iteration:  40% 269/679 [05:29<08:21,  1.22s/it]\u001b[A\n","Iteration:  40% 270/679 [05:30<08:20,  1.22s/it]\u001b[A\n","Iteration:  40% 271/679 [05:31<08:19,  1.22s/it]\u001b[A\n","Iteration:  40% 272/679 [05:33<08:18,  1.22s/it]\u001b[A\n","Iteration:  40% 273/679 [05:34<08:17,  1.22s/it]\u001b[A\n","Iteration:  40% 274/679 [05:35<08:15,  1.22s/it]\u001b[A\n","Iteration:  41% 275/679 [05:36<08:14,  1.22s/it]\u001b[A\n","Iteration:  41% 276/679 [05:37<08:13,  1.23s/it]\u001b[A\n","Iteration:  41% 277/679 [05:39<08:12,  1.22s/it]\u001b[A\n","Iteration:  41% 278/679 [05:40<08:10,  1.22s/it]\u001b[A\n","Iteration:  41% 279/679 [05:41<08:09,  1.22s/it]\u001b[A\n","Iteration:  41% 280/679 [05:42<08:08,  1.22s/it]\u001b[A\n","Iteration:  41% 281/679 [05:44<08:07,  1.22s/it]\u001b[A\n","Iteration:  42% 282/679 [05:45<08:06,  1.23s/it]\u001b[A\n","Iteration:  42% 283/679 [05:46<08:05,  1.23s/it]\u001b[A\n","Iteration:  42% 284/679 [05:47<08:04,  1.23s/it]\u001b[A\n","Iteration:  42% 285/679 [05:49<08:02,  1.23s/it]\u001b[A\n","Iteration:  42% 286/679 [05:50<08:01,  1.22s/it]\u001b[A\n","Iteration:  42% 287/679 [05:51<08:00,  1.22s/it]\u001b[A\n","Iteration:  42% 288/679 [05:52<07:58,  1.22s/it]\u001b[A\n","Iteration:  43% 289/679 [05:53<07:57,  1.22s/it]\u001b[A\n","Iteration:  43% 290/679 [05:55<07:56,  1.22s/it]\u001b[A\n","Iteration:  43% 291/679 [05:56<07:55,  1.22s/it]\u001b[A\n","Iteration:  43% 292/679 [05:57<07:53,  1.22s/it]\u001b[A\n","Iteration:  43% 293/679 [05:58<07:52,  1.22s/it]\u001b[A\n","Iteration:  43% 294/679 [06:00<07:51,  1.22s/it]\u001b[A\n","Iteration:  43% 295/679 [06:01<07:49,  1.22s/it]\u001b[A\n","Iteration:  44% 296/679 [06:02<07:48,  1.22s/it]\u001b[A\n","Iteration:  44% 297/679 [06:03<07:47,  1.22s/it]\u001b[A\n","Iteration:  44% 298/679 [06:04<07:46,  1.22s/it]\u001b[A\n","Iteration:  44% 299/679 [06:06<07:44,  1.22s/it]\u001b[A\n","Iteration:  44% 300/679 [06:07<07:43,  1.22s/it]\u001b[A\n","Iteration:  44% 301/679 [06:08<07:42,  1.22s/it]\u001b[A\n","Iteration:  44% 302/679 [06:09<07:41,  1.22s/it]\u001b[A\n","Iteration:  45% 303/679 [06:11<07:39,  1.22s/it]\u001b[A\n","Iteration:  45% 304/679 [06:12<07:38,  1.22s/it]\u001b[A\n","Iteration:  45% 305/679 [06:13<07:37,  1.22s/it]\u001b[A\n","Iteration:  45% 306/679 [06:14<07:36,  1.22s/it]\u001b[A\n","Iteration:  45% 307/679 [06:15<07:35,  1.22s/it]\u001b[A\n","Iteration:  45% 308/679 [06:17<07:34,  1.22s/it]\u001b[A\n","Iteration:  46% 309/679 [06:18<07:33,  1.23s/it]\u001b[A\n","Iteration:  46% 310/679 [06:19<07:32,  1.23s/it]\u001b[A\n","Iteration:  46% 311/679 [06:20<07:30,  1.22s/it]\u001b[A\n","Iteration:  46% 312/679 [06:22<07:29,  1.22s/it]\u001b[A\n","Iteration:  46% 313/679 [06:23<07:28,  1.22s/it]\u001b[A\n","Iteration:  46% 314/679 [06:24<07:26,  1.22s/it]\u001b[A\n","Iteration:  46% 315/679 [06:25<07:25,  1.22s/it]\u001b[A\n","Iteration:  47% 316/679 [06:26<07:24,  1.22s/it]\u001b[A\n","Iteration:  47% 317/679 [06:28<07:23,  1.22s/it]\u001b[A\n","Iteration:  47% 318/679 [06:29<07:22,  1.23s/it]\u001b[A\n","Iteration:  47% 319/679 [06:30<07:21,  1.23s/it]\u001b[A\n","Iteration:  47% 320/679 [06:31<07:19,  1.23s/it]\u001b[A\n","Iteration:  47% 321/679 [06:33<07:18,  1.22s/it]\u001b[A\n","Iteration:  47% 322/679 [06:34<07:17,  1.22s/it]\u001b[A\n","Iteration:  48% 323/679 [06:35<07:15,  1.22s/it]\u001b[A\n","Iteration:  48% 324/679 [06:36<07:14,  1.23s/it]\u001b[A\n","Iteration:  48% 325/679 [06:37<07:13,  1.22s/it]\u001b[A\n","Iteration:  48% 326/679 [06:39<07:12,  1.22s/it]\u001b[A\n","Iteration:  48% 327/679 [06:40<07:11,  1.22s/it]\u001b[A\n","Iteration:  48% 328/679 [06:41<07:09,  1.22s/it]\u001b[A\n","Iteration:  48% 329/679 [06:42<07:08,  1.22s/it]\u001b[A\n","Iteration:  49% 330/679 [06:44<07:07,  1.23s/it]\u001b[A\n","Iteration:  49% 331/679 [06:45<07:06,  1.22s/it]\u001b[A\n","Iteration:  49% 332/679 [06:46<07:04,  1.22s/it]\u001b[A\n","Iteration:  49% 333/679 [06:47<07:03,  1.22s/it]\u001b[A\n","Iteration:  49% 334/679 [06:49<07:02,  1.22s/it]\u001b[A\n","Iteration:  49% 335/679 [06:50<07:00,  1.22s/it]\u001b[A\n","Iteration:  49% 336/679 [06:51<06:59,  1.22s/it]\u001b[A\n","Iteration:  50% 337/679 [06:52<06:58,  1.23s/it]\u001b[A\n","Iteration:  50% 338/679 [06:53<06:57,  1.22s/it]\u001b[A\n","Iteration:  50% 339/679 [06:55<06:56,  1.22s/it]\u001b[A\n","Iteration:  50% 340/679 [06:56<06:55,  1.22s/it]\u001b[A\n","Iteration:  50% 341/679 [06:57<06:53,  1.22s/it]\u001b[A\n","Iteration:  50% 342/679 [06:58<06:52,  1.22s/it]\u001b[A\n","Iteration:  51% 343/679 [07:00<06:51,  1.23s/it]\u001b[A\n","Iteration:  51% 344/679 [07:01<06:50,  1.22s/it]\u001b[A\n","Iteration:  51% 345/679 [07:02<06:49,  1.23s/it]\u001b[A\n","Iteration:  51% 346/679 [07:03<06:48,  1.23s/it]\u001b[A\n","Iteration:  51% 347/679 [07:04<06:46,  1.23s/it]\u001b[A\n","Iteration:  51% 348/679 [07:06<06:45,  1.23s/it]\u001b[A\n","Iteration:  51% 349/679 [07:07<06:44,  1.22s/it]\u001b[A\n","Iteration:  52% 350/679 [07:08<06:42,  1.22s/it]\u001b[A\n","Iteration:  52% 351/679 [07:09<06:41,  1.22s/it]\u001b[A\n","Iteration:  52% 352/679 [07:11<06:40,  1.22s/it]\u001b[A\n","Iteration:  52% 353/679 [07:12<06:39,  1.23s/it]\u001b[A\n","Iteration:  52% 354/679 [07:13<06:38,  1.23s/it]\u001b[A\n","Iteration:  52% 355/679 [07:14<06:36,  1.23s/it]\u001b[A\n","Iteration:  52% 356/679 [07:15<06:35,  1.22s/it]\u001b[A\n","Iteration:  53% 357/679 [07:17<06:34,  1.22s/it]\u001b[A\n","Iteration:  53% 358/679 [07:18<06:33,  1.22s/it]\u001b[A\n","Iteration:  53% 359/679 [07:19<06:31,  1.22s/it]\u001b[A\n","Iteration:  53% 360/679 [07:20<06:30,  1.22s/it]\u001b[A\n","Iteration:  53% 361/679 [07:22<06:29,  1.22s/it]\u001b[A\n","Iteration:  53% 362/679 [07:23<06:27,  1.22s/it]\u001b[A\n","Iteration:  53% 363/679 [07:24<06:26,  1.22s/it]\u001b[A\n","Iteration:  54% 364/679 [07:25<06:25,  1.22s/it]\u001b[A\n","Iteration:  54% 365/679 [07:26<06:24,  1.22s/it]\u001b[A\n","Iteration:  54% 366/679 [07:28<06:23,  1.22s/it]\u001b[A\n","Iteration:  54% 367/679 [07:29<06:21,  1.22s/it]\u001b[A\n","Iteration:  54% 368/679 [07:30<06:20,  1.22s/it]\u001b[A\n","Iteration:  54% 369/679 [07:31<06:19,  1.22s/it]\u001b[A\n","Iteration:  54% 370/679 [07:33<06:18,  1.22s/it]\u001b[A\n","Iteration:  55% 371/679 [07:34<06:17,  1.22s/it]\u001b[A\n","Iteration:  55% 372/679 [07:35<06:15,  1.22s/it]\u001b[A\n","Iteration:  55% 373/679 [07:36<06:14,  1.22s/it]\u001b[A\n","Iteration:  55% 374/679 [07:37<06:13,  1.22s/it]\u001b[A\n","Iteration:  55% 375/679 [07:39<06:12,  1.22s/it]\u001b[A\n","Iteration:  55% 376/679 [07:40<06:10,  1.22s/it]\u001b[A\n","Iteration:  56% 377/679 [07:41<06:09,  1.22s/it]\u001b[A\n","Iteration:  56% 378/679 [07:42<06:08,  1.22s/it]\u001b[A\n","Iteration:  56% 379/679 [07:44<06:07,  1.22s/it]\u001b[A\n","Iteration:  56% 380/679 [07:45<06:06,  1.23s/it]\u001b[A\n","Iteration:  56% 381/679 [07:46<06:04,  1.22s/it]\u001b[A\n","Iteration:  56% 382/679 [07:47<06:03,  1.22s/it]\u001b[A\n","Iteration:  56% 383/679 [07:49<06:02,  1.22s/it]\u001b[A\n","Iteration:  57% 384/679 [07:50<06:01,  1.22s/it]\u001b[A\n","Iteration:  57% 385/679 [07:51<06:00,  1.23s/it]\u001b[A\n","Iteration:  57% 386/679 [07:53<05:59,  1.23s/it]\n","Epoch:  30% 3/10 [50:51<1:58:39, 1017.03s/it]\n","Traceback (most recent call last):\n","  File \"run_goemotions.py\", line 384, in <module>\n","    main(cli_args)\n","  File \"run_goemotions.py\", line 349, in main\n","    global_step, tr_loss = train(args, model, tokenizer, train_dataset, dev_dataset, test_dataset)\n","  File \"run_goemotions.py\", line 127, in train\n","    loss.backward()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 195, in backward\n","    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 99, in backward\n","    allow_unreachable=True)  # allow_unreachable flag\n","KeyboardInterrupt\n"]}],"source":["!python3 run_goemotions.py --taxonomy original-roberta  # train"]},{"cell_type":"code","source":["!python3 run_goemotions.py --taxonomy original-roberta  # train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y9N7iS5fHLdg","outputId":"139d78cc-0d64-4cc9-f9da-a2b4e93cf5d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["12/16/2021 03:47:27 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-2000/config.json\n","12/16/2021 03:47:27 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMultiLabelClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": \"goemotions\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"admiration\",\n","    \"1\": \"amusement\",\n","    \"10\": \"disapproval\",\n","    \"11\": \"disgust\",\n","    \"12\": \"embarrassment\",\n","    \"13\": \"excitement\",\n","    \"14\": \"fear\",\n","    \"15\": \"gratitude\",\n","    \"16\": \"grief\",\n","    \"17\": \"joy\",\n","    \"18\": \"love\",\n","    \"19\": \"nervousness\",\n","    \"2\": \"anger\",\n","    \"20\": \"optimism\",\n","    \"21\": \"pride\",\n","    \"22\": \"realization\",\n","    \"23\": \"relief\",\n","    \"24\": \"remorse\",\n","    \"25\": \"sadness\",\n","    \"26\": \"surprise\",\n","    \"27\": \"neutral\",\n","    \"3\": \"annoyance\",\n","    \"4\": \"approval\",\n","    \"5\": \"caring\",\n","    \"6\": \"confusion\",\n","    \"7\": \"curiosity\",\n","    \"8\": \"desire\",\n","    \"9\": \"disappointment\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"admiration\": 0,\n","    \"amusement\": 1,\n","    \"anger\": 2,\n","    \"annoyance\": 3,\n","    \"approval\": 4,\n","    \"caring\": 5,\n","    \"confusion\": 6,\n","    \"curiosity\": 7,\n","    \"desire\": 8,\n","    \"disappointment\": 9,\n","    \"disapproval\": 10,\n","    \"disgust\": 11,\n","    \"embarrassment\": 12,\n","    \"excitement\": 13,\n","    \"fear\": 14,\n","    \"gratitude\": 15,\n","    \"grief\": 16,\n","    \"joy\": 17,\n","    \"love\": 18,\n","    \"nervousness\": 19,\n","    \"neutral\": 27,\n","    \"optimism\": 20,\n","    \"pride\": 21,\n","    \"realization\": 22,\n","    \"relief\": 23,\n","    \"remorse\": 24,\n","    \"sadness\": 25,\n","    \"surprise\": 26\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","helllo i am done\n","12/16/2021 03:47:27 - INFO - transformers.modeling_utils -   loading weights file /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-2000/pytorch_model.bin\n","12/16/2021 03:47:39 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp8mbjbls9\n","Downloading: 100% 899k/899k [00:00<00:00, 5.07MB/s]\n","12/16/2021 03:47:39 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json in cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","12/16/2021 03:47:39 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","12/16/2021 03:47:39 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpf2oxux2y\n","Downloading: 100% 456k/456k [00:00<00:00, 3.05MB/s]\n","12/16/2021 03:47:40 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt in cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","12/16/2021 03:47:40 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","12/16/2021 03:47:40 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","12/16/2021 03:47:40 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","12/16/2021 03:47:40 - INFO - data_loader -   Creating features from dataset file at data/original\n","12/16/2021 03:47:40 - INFO - data_loader -   LOOKING AT data/original/train.tsv\n","12/16/2021 03:47:40 - INFO - data_loader -   My favourite food is anything I didn't have to cook myself.\t27\teebbqej\n","12/16/2021 03:47:40 - INFO - data_loader -   What’s that extra B for?\t6,7\tedo4lm1\n","12/16/2021 03:47:40 - INFO - data_loader -   Quick... there's a boot somewhere that you haven't licked today yet!\t27\tedoblwt\n","12/16/2021 03:47:40 - INFO - data_loader -   I'm so gay I can't even drive straight - a bumper sticker older than most redditors\t19\tedfval6\n","12/16/2021 03:47:40 - INFO - data_loader -   I don't know\t27\ted98qh1\n","12/16/2021 03:47:40 - INFO - data_loader -   Broom him fast.\t27\tedket23\n","12/16/2021 03:47:40 - INFO - data_loader -   The balance above the base fee gets put somewhere else. Education, healthcare, etc. Voila, police aren't biased, people are proportionally fined. \t27\teepn62z\n","12/16/2021 03:47:40 - INFO - data_loader -   Hi [NAME], I love you, that is all. Can't wait to see you in Worcester in February!\t17,18\tee8wndy\n","12/16/2021 03:47:40 - INFO - data_loader -   I mean it sucks but that man looks deaded\t11,22\ted917ws\n","12/16/2021 03:47:48 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:48 - INFO - data_loader -   guid: train-0\n","12/16/2021 03:47:48 - INFO - data_loader -   sentence: My favourite food is anything I didn't have to cook myself.\n","12/16/2021 03:47:48 - INFO - data_loader -   tokens: My Ġfavourite Ġfood Ġis Ġanything ĠI Ġdidn 't Ġhave Ġto Ġcook Ġmyself .\n","12/16/2021 03:47:48 - INFO - data_loader -   input_ids: 0 1308 5548 689 16 932 38 399 75 33 7 7142 2185 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:48 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:48 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/16/2021 03:47:48 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:48 - INFO - data_loader -   guid: train-1\n","12/16/2021 03:47:48 - INFO - data_loader -   sentence: Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead\n","12/16/2021 03:47:48 - INFO - data_loader -   tokens: Now Ġif Ġhe Ġdoes Ġoff Ġhimself , Ġeveryone Ġwill Ġthink Ġhes Ġhaving Ġa Ġlaugh Ġscrew ing Ġwith Ġpeople Ġinstead Ġof Ġactually Ġdead\n","12/16/2021 03:47:48 - INFO - data_loader -   input_ids: 0 978 114 37 473 160 1003 6 961 40 206 36279 519 10 7923 21927 154 19 82 1386 9 888 1462 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:48 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:48 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/16/2021 03:47:48 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:48 - INFO - data_loader -   guid: train-2\n","12/16/2021 03:47:48 - INFO - data_loader -   sentence: WHY THE FUCK IS BAYLESS ISOING\n","12/16/2021 03:47:48 - INFO - data_loader -   tokens: WH Y ĠTHE ĠFUCK ĠIS ĠB AY LESS ĠISO ING\n","12/16/2021 03:47:48 - INFO - data_loader -   input_ids: 0 34912 1941 46997 3703 163 2547 43023 26553 1862 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:48 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:48 - INFO - data_loader -   label: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:48 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:48 - INFO - data_loader -   guid: train-3\n","12/16/2021 03:47:48 - INFO - data_loader -   sentence: To make her feel threatened\n","12/16/2021 03:47:48 - INFO - data_loader -   tokens: To Ġmake Ġher Ġfeel Ġthreatened\n","12/16/2021 03:47:48 - INFO - data_loader -   input_ids: 0 598 146 69 619 3711 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:48 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:48 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:48 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:48 - INFO - data_loader -   guid: train-4\n","12/16/2021 03:47:48 - INFO - data_loader -   sentence: Dirty Southern Wankers\n","12/16/2021 03:47:48 - INFO - data_loader -   tokens: D irty ĠSouthern ĠW ank ers\n","12/16/2021 03:47:48 - INFO - data_loader -   input_ids: 0 30375 2944 305 3153 268 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:48 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:48 - INFO - data_loader -   label: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:48 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:48 - INFO - data_loader -   guid: train-5\n","12/16/2021 03:47:48 - INFO - data_loader -   sentence: OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe PlAyOfFs! Dumbass Broncos fans circa December 2015.\n","12/16/2021 03:47:48 - INFO - data_loader -   tokens: O m G Ġp Ey To N Ġi Sn ' T Ġg O o D Ġe No U g H Ġt O Ġh El P Ġu S Ġi N Ġt He ĠPl Ay Of Fs ! ĠDumb ass ĠBroncos Ġfans Ġcirca ĠDecember Ġ2015 .\n","12/16/2021 03:47:48 - INFO - data_loader -   input_ids: 0 13292 534 181 43431 3972 487 939 37790 108 565 821 673 139 495 364 3084 791 571 725 326 673 1368 9682 510 1717 104 939 487 326 894 3037 41585 10643 34417 328 37098 2401 7609 841 33570 719 570 4 2 1 1 1 1 1\n","12/16/2021 03:47:48 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n","12/16/2021 03:47:48 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n","12/16/2021 03:47:48 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:48 - INFO - data_loader -   guid: train-6\n","12/16/2021 03:47:48 - INFO - data_loader -   sentence: Yes I heard abt the f bombs! That has to be why. Thanks for your reply:) until then hubby and I will anxiously wait 😝\n","12/16/2021 03:47:48 - INFO - data_loader -   tokens: Yes ĠI Ġheard Ġab t Ġthe Ġf Ġbombs ! ĠThat Ġhas Ġto Ġbe Ġwhy . ĠThanks Ġfor Ġyour Ġreply : ) Ġuntil Ġthen Ġhub by Ġand ĠI Ġwill Ġanx iously Ġwait ĠðŁĺ Ŀ\n","12/16/2021 03:47:48 - INFO - data_loader -   input_ids: 0 3216 38 1317 4091 90 5 856 10834 328 280 34 7 28 596 4 4557 13 110 10418 35 43 454 172 6756 1409 8 38 40 27442 9997 2067 17841 46 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:48 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:48 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:48 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:48 - INFO - data_loader -   guid: train-7\n","12/16/2021 03:47:48 - INFO - data_loader -   sentence: We need more boards and to create a bit more space for [NAME]. Then we’ll be good.\n","12/16/2021 03:47:48 - INFO - data_loader -   tokens: We Ġneed Ġmore Ġboards Ġand Ġto Ġcreate Ġa Ġbit Ġmore Ġspace Ġfor Ġ[ NAME ]. ĠThen Ġwe âĢ Ļ ll Ġbe Ġgood .\n","12/16/2021 03:47:48 - INFO - data_loader -   input_ids: 0 166 240 55 6904 8 7 1045 10 828 55 980 13 646 48307 8174 1892 52 17 27 890 28 205 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:48 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:48 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n","12/16/2021 03:47:48 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:48 - INFO - data_loader -   guid: train-8\n","12/16/2021 03:47:48 - INFO - data_loader -   sentence: Damn youtube and outrage drama is super lucrative for reddit\n","12/16/2021 03:47:48 - INFO - data_loader -   tokens: Damn Ġyoutube Ġand Ġoutrage Ġdrama Ġis Ġsuper Ġlucrative Ġfor Ġreddit\n","12/16/2021 03:47:48 - INFO - data_loader -   input_ids: 0 41163 44736 8 10618 4149 16 2422 11874 13 44014 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:48 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:48 - INFO - data_loader -   label: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:48 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:48 - INFO - data_loader -   guid: train-9\n","12/16/2021 03:47:48 - INFO - data_loader -   sentence: It might be linked to the trust factor of your friend.\n","12/16/2021 03:47:48 - INFO - data_loader -   tokens: It Ġmight Ġbe Ġlinked Ġto Ġthe Ġtrust Ġfactor Ġof Ġyour Ġfriend .\n","12/16/2021 03:47:48 - INFO - data_loader -   input_ids: 0 85 429 28 3307 7 5 2416 3724 9 110 1441 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:48 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:48 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/16/2021 03:47:48 - INFO - data_loader -   Saving features into cached file data/original/cached_goemotions_checkpoint-2000_50_train\n","12/16/2021 03:47:51 - INFO - data_loader -   Creating features from dataset file at data/original\n","12/16/2021 03:47:51 - INFO - data_loader -   LOOKING AT data/original/dev.tsv\n","12/16/2021 03:47:51 - INFO - data_loader -   Is this in New Orleans?? I really feel like this is New Orleans.\t27\tedgurhb\n","12/16/2021 03:47:51 - INFO - data_loader -   [NAME] is vastly overrated. Much bette4 [RELIGION] delis in the outer Burroughs\t4\tedc0amo\n","12/16/2021 03:47:52 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:52 - INFO - data_loader -   guid: dev-0\n","12/16/2021 03:47:52 - INFO - data_loader -   sentence: Is this in New Orleans?? I really feel like this is New Orleans.\n","12/16/2021 03:47:52 - INFO - data_loader -   tokens: Is Ġthis Ġin ĠNew ĠOrleans ?? ĠI Ġreally Ġfeel Ġlike Ġthis Ġis ĠNew ĠOrleans .\n","12/16/2021 03:47:52 - INFO - data_loader -   input_ids: 0 1534 42 11 188 4942 28749 38 269 619 101 42 16 188 4942 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:52 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:52 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/16/2021 03:47:52 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:52 - INFO - data_loader -   guid: dev-1\n","12/16/2021 03:47:52 - INFO - data_loader -   sentence: You know the answer man, you are programmed to capture those codes they send you, don’t avoid them!\n","12/16/2021 03:47:52 - INFO - data_loader -   tokens: You Ġknow Ġthe Ġanswer Ġman , Ġyou Ġare Ġprogrammed Ġto Ġcapture Ġthose Ġcodes Ġthey Ġsend Ġyou , Ġdon âĢ Ļ t Ġavoid Ġthem !\n","12/16/2021 03:47:52 - INFO - data_loader -   input_ids: 0 370 216 5 1948 313 6 47 32 30825 7 5604 167 14284 51 2142 47 6 218 17 27 90 1877 106 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:52 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:52 - INFO - data_loader -   label: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/16/2021 03:47:52 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:52 - INFO - data_loader -   guid: dev-2\n","12/16/2021 03:47:52 - INFO - data_loader -   sentence: I've never been this sad in my life!\n","12/16/2021 03:47:52 - INFO - data_loader -   tokens: I 've Ġnever Ġbeen Ġthis Ġsad Ġin Ġmy Ġlife !\n","12/16/2021 03:47:52 - INFO - data_loader -   input_ids: 0 38 348 393 57 42 5074 11 127 301 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:52 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:52 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n","12/16/2021 03:47:52 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:52 - INFO - data_loader -   guid: dev-3\n","12/16/2021 03:47:52 - INFO - data_loader -   sentence: The economy is heavily controlled and subsidized by the government. In any case, I was poking at the lack of nuance in US politics today\n","12/16/2021 03:47:52 - INFO - data_loader -   tokens: The Ġeconomy Ġis Ġheavily Ġcontrolled Ġand Ġsubsidized Ġby Ġthe Ġgovernment . ĠIn Ġany Ġcase , ĠI Ġwas Ġpoking Ġat Ġthe Ġlack Ġof Ġnuance Ġin ĠUS Ġpolitics Ġtoday\n","12/16/2021 03:47:52 - INFO - data_loader -   input_ids: 0 20 866 16 4008 4875 8 28397 30 5 168 4 96 143 403 6 38 21 34552 23 5 1762 9 37784 11 382 2302 452 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:52 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:52 - INFO - data_loader -   label: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/16/2021 03:47:52 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:52 - INFO - data_loader -   guid: dev-4\n","12/16/2021 03:47:52 - INFO - data_loader -   sentence: He could have easily taken a real camera from a legitimate source and change the price in Word/Photoshop and then print it out.\n","12/16/2021 03:47:52 - INFO - data_loader -   tokens: He Ġcould Ġhave Ġeasily Ġtaken Ġa Ġreal Ġcamera Ġfrom Ġa Ġlegitimate Ġsource Ġand Ġchange Ġthe Ġprice Ġin ĠWord / Phot oshop Ġand Ġthen Ġprint Ġit Ġout .\n","12/16/2021 03:47:52 - INFO - data_loader -   input_ids: 0 91 115 33 2773 551 10 588 2280 31 10 8134 1300 8 464 5 425 11 15690 73 41612 46491 8 172 5780 24 66 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:52 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:52 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n","12/16/2021 03:47:52 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:52 - INFO - data_loader -   guid: dev-5\n","12/16/2021 03:47:52 - INFO - data_loader -   sentence: Thank you for your vote of confidence, but we statistically can't get to 10 wins.\n","12/16/2021 03:47:52 - INFO - data_loader -   tokens: Thank Ġyou Ġfor Ġyour Ġvote Ġof Ġconfidence , Ġbut Ġwe Ġstatistically Ġcan 't Ġget Ġto Ġ10 Ġwins .\n","12/16/2021 03:47:52 - INFO - data_loader -   input_ids: 0 3837 47 13 110 900 9 2123 6 53 52 27697 64 75 120 7 158 2693 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:52 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:52 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:52 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:52 - INFO - data_loader -   guid: dev-6\n","12/16/2021 03:47:52 - INFO - data_loader -   sentence: Wah Mum other people call me on my bullshit and I can't ban them , Go out side son.\n","12/16/2021 03:47:52 - INFO - data_loader -   tokens: W ah ĠMum Ġother Ġpeople Ġcall Ġme Ġon Ġmy Ġbullshit Ġand ĠI Ġcan 't Ġban Ġthem Ġ, ĠGo Ġout Ġside Ġson .\n","12/16/2021 03:47:52 - INFO - data_loader -   input_ids: 0 19478 20675 97 82 486 162 15 127 37568 8 38 64 75 2020 106 2156 2381 66 526 979 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:52 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:52 - INFO - data_loader -   label: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:52 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:52 - INFO - data_loader -   guid: dev-7\n","12/16/2021 03:47:52 - INFO - data_loader -   sentence: There it is!\n","12/16/2021 03:47:52 - INFO - data_loader -   tokens: There Ġit Ġis !\n","12/16/2021 03:47:52 - INFO - data_loader -   input_ids: 0 345 24 16 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:52 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:52 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/16/2021 03:47:52 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:52 - INFO - data_loader -   guid: dev-8\n","12/16/2021 03:47:52 - INFO - data_loader -   sentence: At least now [NAME] has more time to gain his confidence\n","12/16/2021 03:47:52 - INFO - data_loader -   tokens: At Ġleast Ġnow Ġ[ NAME ] Ġhas Ġmore Ġtime Ġto Ġgain Ġhis Ġconfidence\n","12/16/2021 03:47:52 - INFO - data_loader -   input_ids: 0 497 513 122 646 48307 742 34 55 86 7 2364 39 2123 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:52 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:52 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n","12/16/2021 03:47:52 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:52 - INFO - data_loader -   guid: dev-9\n","12/16/2021 03:47:52 - INFO - data_loader -   sentence: Good. We don't want more thrash liberal offspring in this world.\n","12/16/2021 03:47:52 - INFO - data_loader -   tokens: Good . ĠWe Ġdon 't Ġwant Ġmore Ġthr ash Ġliberal Ġoffspring Ġin Ġthis Ġworld .\n","12/16/2021 03:47:52 - INFO - data_loader -   input_ids: 0 2497 4 166 218 75 236 55 10161 1671 6176 28491 11 42 232 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:52 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:52 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:52 - INFO - data_loader -   Saving features into cached file data/original/cached_goemotions_checkpoint-2000_50_dev\n","12/16/2021 03:47:53 - INFO - data_loader -   Creating features from dataset file at data/original\n","12/16/2021 03:47:53 - INFO - data_loader -   LOOKING AT data/original/test.tsv\n","12/16/2021 03:47:53 - INFO - data_loader -   I’m really sorry about your situation :( Although I love the names Sapphira, Cirilla, and Scarlett!\t25\teecwqtt\n","12/16/2021 03:47:53 - INFO - data_loader -   Well I am a lady, so that would probably just freak them out. Oh, Reddit. Everyone is a man haha. \t1\teez3kgr\n","12/16/2021 03:47:53 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:53 - INFO - data_loader -   guid: test-0\n","12/16/2021 03:47:53 - INFO - data_loader -   sentence: I’m really sorry about your situation :( Although I love the names Sapphira, Cirilla, and Scarlett!\n","12/16/2021 03:47:53 - INFO - data_loader -   tokens: I âĢ Ļ m Ġreally Ġsorry Ġabout Ġyour Ġsituation Ġ:( ĠAlthough ĠI Ġlove Ġthe Ġnames ĠSapp h ira , ĠCir illa , Ġand ĠScarlett !\n","12/16/2021 03:47:53 - INFO - data_loader -   input_ids: 0 38 17 27 119 269 6661 59 110 1068 46225 2223 38 657 5 2523 37151 298 3578 6 24223 4699 6 8 27473 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:53 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:53 - INFO - data_loader -   guid: test-1\n","12/16/2021 03:47:53 - INFO - data_loader -   sentence: It's wonderful because it's awful. At not with.\n","12/16/2021 03:47:53 - INFO - data_loader -   tokens: It 's Ġwonderful Ġbecause Ġit 's Ġawful . ĠAt Ġnot Ġwith .\n","12/16/2021 03:47:53 - INFO - data_loader -   input_ids: 0 85 18 4613 142 24 18 11522 4 497 45 19 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:53 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   label: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:53 - INFO - data_loader -   guid: test-2\n","12/16/2021 03:47:53 - INFO - data_loader -   sentence: Kings fan here, good luck to you guys! Will be an interesting game to watch! \n","12/16/2021 03:47:53 - INFO - data_loader -   tokens: Kings Ġfan Ġhere , Ġgood Ġluck Ġto Ġyou Ġguys ! ĠWill Ġbe Ġan Ġinteresting Ġgame Ġto Ġwatch !\n","12/16/2021 03:47:53 - INFO - data_loader -   input_ids: 0 5414 2378 259 6 205 6620 7 47 1669 328 2290 28 41 2679 177 7 1183 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:53 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:53 - INFO - data_loader -   guid: test-3\n","12/16/2021 03:47:53 - INFO - data_loader -   sentence: I didn't know that, thank you for teaching me something today!\n","12/16/2021 03:47:53 - INFO - data_loader -   tokens: I Ġdidn 't Ġknow Ġthat , Ġthank Ġyou Ġfor Ġteaching Ġme Ġsomething Ġtoday !\n","12/16/2021 03:47:53 - INFO - data_loader -   input_ids: 0 38 399 75 216 14 6 3392 47 13 5307 162 402 452 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:53 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:53 - INFO - data_loader -   guid: test-4\n","12/16/2021 03:47:53 - INFO - data_loader -   sentence: They got bored from haunting earth for thousands of years and ultimately moved on to the afterlife.\n","12/16/2021 03:47:53 - INFO - data_loader -   tokens: They Ġgot Ġbored Ġfrom Ġhaunting Ġearth Ġfor Ġthousands Ġof Ġyears Ġand Ġultimately Ġmoved Ġon Ġto Ġthe Ġafterlife .\n","12/16/2021 03:47:53 - INFO - data_loader -   input_ids: 0 252 300 23809 31 29475 6872 13 1583 9 107 8 3284 1410 15 7 5 42873 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:53 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/16/2021 03:47:53 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:53 - INFO - data_loader -   guid: test-5\n","12/16/2021 03:47:53 - INFO - data_loader -   sentence: Thank you for asking questions and recognizing that there may be things that you don’t know or understand about police tactics. Seriously. Thank you.\n","12/16/2021 03:47:53 - INFO - data_loader -   tokens: Thank Ġyou Ġfor Ġasking Ġquestions Ġand Ġrecognizing Ġthat Ġthere Ġmay Ġbe Ġthings Ġthat Ġyou Ġdon âĢ Ļ t Ġknow Ġor Ġunderstand Ġabout Ġpolice Ġtactics . ĠSeriously . ĠThank Ġyou .\n","12/16/2021 03:47:53 - INFO - data_loader -   input_ids: 0 3837 47 13 1996 1142 8 16257 14 89 189 28 383 14 47 218 17 27 90 216 50 1346 59 249 8893 4 29945 4 3837 47 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:53 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:53 - INFO - data_loader -   guid: test-6\n","12/16/2021 03:47:53 - INFO - data_loader -   sentence: You’re welcome\n","12/16/2021 03:47:53 - INFO - data_loader -   tokens: You âĢ Ļ re Ġwelcome\n","12/16/2021 03:47:53 - INFO - data_loader -   input_ids: 0 370 17 27 241 2814 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:53 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:53 - INFO - data_loader -   guid: test-7\n","12/16/2021 03:47:53 - INFO - data_loader -   sentence: 100%! Congrats on your job too!\n","12/16/2021 03:47:53 - INFO - data_loader -   tokens: 100 % ! ĠCong rats Ġon Ġyour Ġjob Ġtoo !\n","12/16/2021 03:47:53 - INFO - data_loader -   input_ids: 0 727 207 328 12249 28814 15 110 633 350 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:53 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:53 - INFO - data_loader -   guid: test-8\n","12/16/2021 03:47:53 - INFO - data_loader -   sentence: I’m sorry to hear that friend :(. It’s for the best most likely if she didn’t accept you for who you are\n","12/16/2021 03:47:53 - INFO - data_loader -   tokens: I âĢ Ļ m Ġsorry Ġto Ġhear Ġthat Ġfriend Ġ:( . ĠIt âĢ Ļ s Ġfor Ġthe Ġbest Ġmost Ġlikely Ġif Ġshe Ġdidn âĢ Ļ t Ġaccept Ġyou Ġfor Ġwho Ġyou Ġare\n","12/16/2021 03:47:53 - INFO - data_loader -   input_ids: 0 38 17 27 119 6661 7 1798 14 1441 46225 4 85 17 27 29 13 5 275 144 533 114 79 399 17 27 90 3264 47 13 54 47 32 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:53 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   *** Example ***\n","12/16/2021 03:47:53 - INFO - data_loader -   guid: test-9\n","12/16/2021 03:47:53 - INFO - data_loader -   sentence: Girlfriend weak as well, that jump was pathetic.\n","12/16/2021 03:47:53 - INFO - data_loader -   tokens: G irlfriend Ġweak Ġas Ġwell , Ġthat Ġjump Ġwas Ġpathetic .\n","12/16/2021 03:47:53 - INFO - data_loader -   input_ids: 0 272 38883 3953 25 157 6 14 3704 21 31790 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/16/2021 03:47:53 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n","12/16/2021 03:47:53 - INFO - data_loader -   Saving features into cached file data/original/cached_goemotions_checkpoint-2000_50_test\n","12/16/2021 03:47:54 - INFO - __main__ -   ***** Running training *****\n","12/16/2021 03:47:54 - INFO - __main__ -     Num examples = 43410\n","12/16/2021 03:47:54 - INFO - __main__ -     Num Epochs = 10\n","12/16/2021 03:47:54 - INFO - __main__ -     Total train batch size = 64\n","12/16/2021 03:47:54 - INFO - __main__ -     Gradient Accumulation steps = 1\n","12/16/2021 03:47:54 - INFO - __main__ -     Total optimization steps = 6790\n","12/16/2021 03:47:54 - INFO - __main__ -     Logging steps = 1000\n","12/16/2021 03:47:54 - INFO - __main__ -     Save steps = 1000\n","Epoch:   0% 0/10 [00:00<?, ?it/s]\n","Iteration:   0% 0/679 [00:00<?, ?it/s]\u001b[A\n","Iteration:   0% 1/679 [00:33<6:18:35, 33.50s/it]\u001b[A\n","Iteration:   0% 2/679 [01:07<6:19:31, 33.64s/it]\u001b[A\n","Iteration:   0% 3/679 [01:39<6:10:03, 32.85s/it]\u001b[A\n","Iteration:   1% 4/679 [02:11<6:05:37, 32.50s/it]\u001b[A\n","Iteration:   1% 5/679 [02:43<6:03:35, 32.37s/it]\u001b[A\n","Iteration:   1% 6/679 [03:15<6:02:01, 32.28s/it]\u001b[A"]}]},{"cell_type":"code","source":["!python3 run_goemotions.py --taxonomy original-roberta  # train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5zNFy1rUYjJs","executionInfo":{"status":"ok","timestamp":1639636268892,"user_tz":300,"elapsed":7837581,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"}},"outputId":"bc53596b-cb1a-4c63-8d45-30782ce994da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","\n","Evaluating:  55% 94/170 [00:18<00:14,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  56% 95/170 [00:18<00:14,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  56% 96/170 [00:18<00:14,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  57% 97/170 [00:18<00:13,  5.23it/s]\u001b[A\u001b[A\n","\n","Evaluating:  58% 98/170 [00:18<00:13,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  58% 99/170 [00:19<00:13,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  59% 100/170 [00:19<00:13,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  59% 101/170 [00:19<00:13,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  60% 102/170 [00:19<00:13,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  61% 103/170 [00:19<00:12,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  61% 104/170 [00:20<00:12,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 105/170 [00:20<00:12,  5.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 106/170 [00:20<00:12,  5.12it/s]\u001b[A\u001b[A\n","\n","Evaluating:  63% 107/170 [00:20<00:12,  5.11it/s]\u001b[A\u001b[A\n","\n","Evaluating:  64% 108/170 [00:20<00:12,  5.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  64% 109/170 [00:21<00:11,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  65% 110/170 [00:21<00:11,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  65% 111/170 [00:21<00:11,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  66% 112/170 [00:21<00:11,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  66% 113/170 [00:21<00:11,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  67% 114/170 [00:21<00:10,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  68% 115/170 [00:22<00:10,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  68% 116/170 [00:22<00:10,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  69% 117/170 [00:22<00:10,  5.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  69% 118/170 [00:22<00:10,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  70% 119/170 [00:22<00:09,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  71% 120/170 [00:23<00:09,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  71% 121/170 [00:23<00:09,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  72% 122/170 [00:23<00:09,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  72% 123/170 [00:23<00:08,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  73% 124/170 [00:23<00:08,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  74% 125/170 [00:24<00:08,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  74% 126/170 [00:24<00:08,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 127/170 [00:24<00:08,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 128/170 [00:24<00:08,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  76% 129/170 [00:24<00:07,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  76% 130/170 [00:25<00:07,  5.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  77% 131/170 [00:25<00:07,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  78% 132/170 [00:25<00:07,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  78% 133/170 [00:25<00:07,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  79% 134/170 [00:25<00:06,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  79% 135/170 [00:26<00:06,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  80% 136/170 [00:26<00:06,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  81% 137/170 [00:26<00:06,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  81% 138/170 [00:26<00:06,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  82% 139/170 [00:26<00:06,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  82% 140/170 [00:26<00:05,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  83% 141/170 [00:27<00:05,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  84% 142/170 [00:27<00:05,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  84% 143/170 [00:27<00:05,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  85% 144/170 [00:27<00:05,  5.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  85% 145/170 [00:27<00:04,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  86% 146/170 [00:28<00:04,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  86% 147/170 [00:28<00:04,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  87% 148/170 [00:28<00:04,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 149/170 [00:28<00:04,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 150/170 [00:28<00:03,  5.23it/s]\u001b[A\u001b[A\n","\n","Evaluating:  89% 151/170 [00:29<00:03,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  89% 152/170 [00:29<00:03,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  90% 153/170 [00:29<00:03,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  91% 154/170 [00:29<00:03,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  91% 155/170 [00:29<00:02,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  92% 156/170 [00:30<00:02,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  92% 157/170 [00:30<00:02,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  93% 158/170 [00:30<00:02,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  94% 159/170 [00:30<00:02,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  94% 160/170 [00:30<00:01,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  95% 161/170 [00:31<00:01,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  95% 162/170 [00:31<00:01,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  96% 163/170 [00:31<00:01,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  96% 164/170 [00:31<00:01,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  97% 165/170 [00:31<00:00,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  98% 166/170 [00:31<00:00,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  98% 167/170 [00:32<00:00,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  99% 168/170 [00:32<00:00,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  99% 169/170 [00:32<00:00,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating: 100% 170/170 [00:32<00:00,  5.20it/s]\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","12/16/2021 05:53:19 - INFO - __main__ -   ***** Eval results on dev dataset *****\n","12/16/2021 05:53:19 - INFO - __main__ -     accuracy = 0.3783634353114633\n","12/16/2021 05:53:19 - INFO - __main__ -     loss = 0.14312715999343817\n","12/16/2021 05:53:19 - INFO - __main__ -     macro_f1 = 0.3943665750482966\n","12/16/2021 05:53:19 - INFO - __main__ -     macro_precision = 0.421710599693756\n","12/16/2021 05:53:19 - INFO - __main__ -     macro_recall = 0.401931726591264\n","12/16/2021 05:53:19 - INFO - __main__ -     micro_f1 = 0.5026248687565622\n","12/16/2021 05:53:19 - INFO - __main__ -     micro_precision = 0.4818809318377912\n","12/16/2021 05:53:19 - INFO - __main__ -     micro_recall = 0.5252351097178684\n","12/16/2021 05:53:19 - INFO - __main__ -     weighted_f1 = 0.48968373248589847\n","12/16/2021 05:53:19 - INFO - __main__ -     weighted_precision = 0.4694513721206823\n","12/16/2021 05:53:19 - INFO - __main__ -     weighted_recall = 0.5252351097178684\n","12/16/2021 05:53:19 - INFO - transformers.configuration_utils -   Configuration saved in drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-9000/config.json\n","12/16/2021 05:53:21 - INFO - transformers.modeling_utils -   Model weights saved in drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-9000/pytorch_model.bin\n","12/16/2021 05:53:21 - INFO - __main__ -   Saving model checkpoint to drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-9000\n","\n","Iteration:  63% 858/1357 [08:53<1:32:13, 11.09s/it]\u001b[A\n","Iteration:  63% 859/1357 [08:54<1:05:49,  7.93s/it]\u001b[A\n","Iteration:  63% 860/1357 [08:55<47:25,  5.73s/it]  \u001b[A\n","Iteration:  63% 861/1357 [08:55<34:33,  4.18s/it]\u001b[A\n","Iteration:  64% 862/1357 [08:56<25:35,  3.10s/it]\u001b[A\n","Iteration:  64% 863/1357 [08:56<19:18,  2.34s/it]\u001b[A\n","Iteration:  64% 864/1357 [08:57<14:55,  1.82s/it]\u001b[A\n","Iteration:  64% 865/1357 [08:57<11:49,  1.44s/it]\u001b[A\n","Iteration:  64% 866/1357 [08:58<09:40,  1.18s/it]\u001b[A\n","Iteration:  64% 867/1357 [08:59<08:12,  1.00s/it]\u001b[A\n","Iteration:  64% 868/1357 [08:59<07:09,  1.14it/s]\u001b[A\n","Iteration:  64% 869/1357 [09:00<06:24,  1.27it/s]\u001b[A\n","Iteration:  64% 870/1357 [09:00<05:53,  1.38it/s]\u001b[A\n","Iteration:  64% 871/1357 [09:01<05:31,  1.47it/s]\u001b[A\n","Iteration:  64% 872/1357 [09:02<05:15,  1.54it/s]\u001b[A\n","Iteration:  64% 873/1357 [09:02<05:04,  1.59it/s]\u001b[A\n","Iteration:  64% 874/1357 [09:03<05:00,  1.61it/s]\u001b[A\n","Iteration:  64% 875/1357 [09:03<04:54,  1.64it/s]\u001b[A\n","Iteration:  65% 876/1357 [09:04<04:49,  1.66it/s]\u001b[A\n","Iteration:  65% 877/1357 [09:04<04:47,  1.67it/s]\u001b[A\n","Iteration:  65% 878/1357 [09:05<04:44,  1.68it/s]\u001b[A\n","Iteration:  65% 879/1357 [09:06<04:43,  1.69it/s]\u001b[A\n","Iteration:  65% 880/1357 [09:06<04:43,  1.68it/s]\u001b[A\n","Iteration:  65% 881/1357 [09:07<04:41,  1.69it/s]\u001b[A\n","Iteration:  65% 882/1357 [09:07<04:43,  1.68it/s]\u001b[A\n","Iteration:  65% 883/1357 [09:08<04:40,  1.69it/s]\u001b[A\n","Iteration:  65% 884/1357 [09:09<04:37,  1.71it/s]\u001b[A\n","Iteration:  65% 885/1357 [09:09<04:36,  1.70it/s]\u001b[A\n","Iteration:  65% 886/1357 [09:10<04:35,  1.71it/s]\u001b[A\n","Iteration:  65% 887/1357 [09:10<04:33,  1.72it/s]\u001b[A\n","Iteration:  65% 888/1357 [09:11<04:32,  1.72it/s]\u001b[A\n","Iteration:  66% 889/1357 [09:12<04:32,  1.72it/s]\u001b[A\n","Iteration:  66% 890/1357 [09:12<04:31,  1.72it/s]\u001b[A\n","Iteration:  66% 891/1357 [09:13<04:31,  1.71it/s]\u001b[A\n","Iteration:  66% 892/1357 [09:13<04:31,  1.71it/s]\u001b[A\n","Iteration:  66% 893/1357 [09:14<04:30,  1.72it/s]\u001b[A\n","Iteration:  66% 894/1357 [09:14<04:29,  1.72it/s]\u001b[A\n","Iteration:  66% 895/1357 [09:15<04:28,  1.72it/s]\u001b[A\n","Iteration:  66% 896/1357 [09:16<04:28,  1.72it/s]\u001b[A\n","Iteration:  66% 897/1357 [09:16<04:27,  1.72it/s]\u001b[A\n","Iteration:  66% 898/1357 [09:17<04:26,  1.72it/s]\u001b[A\n","Iteration:  66% 899/1357 [09:17<04:26,  1.72it/s]\u001b[A\n","Iteration:  66% 900/1357 [09:18<04:25,  1.72it/s]\u001b[A\n","Iteration:  66% 901/1357 [09:18<04:24,  1.72it/s]\u001b[A\n","Iteration:  66% 902/1357 [09:19<04:23,  1.73it/s]\u001b[A\n","Iteration:  67% 903/1357 [09:20<04:22,  1.73it/s]\u001b[A\n","Iteration:  67% 904/1357 [09:20<04:22,  1.73it/s]\u001b[A\n","Iteration:  67% 905/1357 [09:21<04:21,  1.73it/s]\u001b[A\n","Iteration:  67% 906/1357 [09:21<04:19,  1.74it/s]\u001b[A\n","Iteration:  67% 907/1357 [09:22<04:20,  1.73it/s]\u001b[A\n","Iteration:  67% 908/1357 [09:23<04:21,  1.72it/s]\u001b[A\n","Iteration:  67% 909/1357 [09:23<04:21,  1.71it/s]\u001b[A\n","Iteration:  67% 910/1357 [09:24<04:21,  1.71it/s]\u001b[A\n","Iteration:  67% 911/1357 [09:24<04:19,  1.72it/s]\u001b[A\n","Iteration:  67% 912/1357 [09:25<04:18,  1.72it/s]\u001b[A\n","Iteration:  67% 913/1357 [09:25<04:19,  1.71it/s]\u001b[A\n","Iteration:  67% 914/1357 [09:26<04:18,  1.71it/s]\u001b[A\n","Iteration:  67% 915/1357 [09:27<04:17,  1.72it/s]\u001b[A\n","Iteration:  68% 916/1357 [09:27<04:16,  1.72it/s]\u001b[A\n","Iteration:  68% 917/1357 [09:28<04:15,  1.72it/s]\u001b[A\n","Iteration:  68% 918/1357 [09:28<04:15,  1.72it/s]\u001b[A\n","Iteration:  68% 919/1357 [09:29<04:16,  1.71it/s]\u001b[A\n","Iteration:  68% 920/1357 [09:30<04:16,  1.71it/s]\u001b[A\n","Iteration:  68% 921/1357 [09:30<04:14,  1.72it/s]\u001b[A\n","Iteration:  68% 922/1357 [09:31<04:13,  1.71it/s]\u001b[A\n","Iteration:  68% 923/1357 [09:31<04:13,  1.71it/s]\u001b[A\n","Iteration:  68% 924/1357 [09:32<04:14,  1.70it/s]\u001b[A\n","Iteration:  68% 925/1357 [09:32<04:13,  1.71it/s]\u001b[A\n","Iteration:  68% 926/1357 [09:33<04:11,  1.72it/s]\u001b[A\n","Iteration:  68% 927/1357 [09:34<04:11,  1.71it/s]\u001b[A\n","Iteration:  68% 928/1357 [09:34<04:10,  1.72it/s]\u001b[A\n","Iteration:  68% 929/1357 [09:35<04:09,  1.71it/s]\u001b[A\n","Iteration:  69% 930/1357 [09:35<04:08,  1.72it/s]\u001b[A\n","Iteration:  69% 931/1357 [09:36<04:08,  1.71it/s]\u001b[A\n","Iteration:  69% 932/1357 [09:37<04:06,  1.72it/s]\u001b[A\n","Iteration:  69% 933/1357 [09:37<04:06,  1.72it/s]\u001b[A\n","Iteration:  69% 934/1357 [09:38<04:06,  1.71it/s]\u001b[A\n","Iteration:  69% 935/1357 [09:38<04:05,  1.72it/s]\u001b[A\n","Iteration:  69% 936/1357 [09:39<04:04,  1.72it/s]\u001b[A\n","Iteration:  69% 937/1357 [09:39<04:05,  1.71it/s]\u001b[A\n","Iteration:  69% 938/1357 [09:40<04:03,  1.72it/s]\u001b[A\n","Iteration:  69% 939/1357 [09:41<04:02,  1.73it/s]\u001b[A\n","Iteration:  69% 940/1357 [09:41<04:02,  1.72it/s]\u001b[A\n","Iteration:  69% 941/1357 [09:42<04:02,  1.72it/s]\u001b[A\n","Iteration:  69% 942/1357 [09:42<04:01,  1.72it/s]\u001b[A\n","Iteration:  69% 943/1357 [09:43<04:01,  1.72it/s]\u001b[A\n","Iteration:  70% 944/1357 [09:44<04:00,  1.72it/s]\u001b[A\n","Iteration:  70% 945/1357 [09:44<03:58,  1.73it/s]\u001b[A\n","Iteration:  70% 946/1357 [09:45<03:58,  1.72it/s]\u001b[A\n","Iteration:  70% 947/1357 [09:45<03:57,  1.72it/s]\u001b[A\n","Iteration:  70% 948/1357 [09:46<03:57,  1.72it/s]\u001b[A\n","Iteration:  70% 949/1357 [09:46<03:56,  1.72it/s]\u001b[A\n","Iteration:  70% 950/1357 [09:47<03:58,  1.71it/s]\u001b[A\n","Iteration:  70% 951/1357 [09:48<03:56,  1.72it/s]\u001b[A\n","Iteration:  70% 952/1357 [09:48<03:55,  1.72it/s]\u001b[A\n","Iteration:  70% 953/1357 [09:49<03:55,  1.72it/s]\u001b[A\n","Iteration:  70% 954/1357 [09:49<03:54,  1.72it/s]\u001b[A\n","Iteration:  70% 955/1357 [09:50<03:54,  1.72it/s]\u001b[A\n","Iteration:  70% 956/1357 [09:51<03:53,  1.71it/s]\u001b[A\n","Iteration:  71% 957/1357 [09:51<03:53,  1.71it/s]\u001b[A\n","Iteration:  71% 958/1357 [09:52<03:52,  1.72it/s]\u001b[A\n","Iteration:  71% 959/1357 [09:52<03:51,  1.72it/s]\u001b[A\n","Iteration:  71% 960/1357 [09:53<03:50,  1.73it/s]\u001b[A\n","Iteration:  71% 961/1357 [09:53<03:48,  1.73it/s]\u001b[A\n","Iteration:  71% 962/1357 [09:54<03:48,  1.73it/s]\u001b[A\n","Iteration:  71% 963/1357 [09:55<03:48,  1.72it/s]\u001b[A\n","Iteration:  71% 964/1357 [09:55<03:48,  1.72it/s]\u001b[A\n","Iteration:  71% 965/1357 [09:56<03:48,  1.71it/s]\u001b[A\n","Iteration:  71% 966/1357 [09:56<03:47,  1.72it/s]\u001b[A\n","Iteration:  71% 967/1357 [09:57<03:45,  1.73it/s]\u001b[A\n","Iteration:  71% 968/1357 [09:57<03:45,  1.72it/s]\u001b[A\n","Iteration:  71% 969/1357 [09:58<03:45,  1.72it/s]\u001b[A\n","Iteration:  71% 970/1357 [09:59<03:44,  1.72it/s]\u001b[A\n","Iteration:  72% 971/1357 [09:59<03:43,  1.72it/s]\u001b[A\n","Iteration:  72% 972/1357 [10:00<03:43,  1.72it/s]\u001b[A\n","Iteration:  72% 973/1357 [10:00<03:42,  1.73it/s]\u001b[A\n","Iteration:  72% 974/1357 [10:01<03:41,  1.73it/s]\u001b[A\n","Iteration:  72% 975/1357 [10:02<03:41,  1.72it/s]\u001b[A\n","Iteration:  72% 976/1357 [10:02<03:41,  1.72it/s]\u001b[A\n","Iteration:  72% 977/1357 [10:03<03:41,  1.72it/s]\u001b[A\n","Iteration:  72% 978/1357 [10:03<03:41,  1.71it/s]\u001b[A\n","Iteration:  72% 979/1357 [10:04<03:40,  1.72it/s]\u001b[A\n","Iteration:  72% 980/1357 [10:04<03:39,  1.72it/s]\u001b[A\n","Iteration:  72% 981/1357 [10:05<03:38,  1.72it/s]\u001b[A\n","Iteration:  72% 982/1357 [10:06<03:38,  1.72it/s]\u001b[A\n","Iteration:  72% 983/1357 [10:06<03:37,  1.72it/s]\u001b[A\n","Iteration:  73% 984/1357 [10:07<03:38,  1.71it/s]\u001b[A\n","Iteration:  73% 985/1357 [10:07<03:37,  1.71it/s]\u001b[A\n","Iteration:  73% 986/1357 [10:08<03:37,  1.71it/s]\u001b[A\n","Iteration:  73% 987/1357 [10:09<03:35,  1.71it/s]\u001b[A\n","Iteration:  73% 988/1357 [10:09<03:34,  1.72it/s]\u001b[A\n","Iteration:  73% 989/1357 [10:10<03:34,  1.72it/s]\u001b[A\n","Iteration:  73% 990/1357 [10:10<03:34,  1.71it/s]\u001b[A\n","Iteration:  73% 991/1357 [10:11<03:34,  1.71it/s]\u001b[A\n","Iteration:  73% 992/1357 [10:11<03:32,  1.72it/s]\u001b[A\n","Iteration:  73% 993/1357 [10:12<03:31,  1.72it/s]\u001b[A\n","Iteration:  73% 994/1357 [10:13<03:30,  1.72it/s]\u001b[A\n","Iteration:  73% 995/1357 [10:13<03:30,  1.72it/s]\u001b[A\n","Iteration:  73% 996/1357 [10:14<03:29,  1.72it/s]\u001b[A\n","Iteration:  73% 997/1357 [10:14<03:29,  1.72it/s]\u001b[A\n","Iteration:  74% 998/1357 [10:15<03:28,  1.72it/s]\u001b[A\n","Iteration:  74% 999/1357 [10:16<03:28,  1.71it/s]\u001b[A\n","Iteration:  74% 1000/1357 [10:16<03:27,  1.72it/s]\u001b[A\n","Iteration:  74% 1001/1357 [10:17<03:27,  1.72it/s]\u001b[A\n","Iteration:  74% 1002/1357 [10:17<03:26,  1.72it/s]\u001b[A\n","Iteration:  74% 1003/1357 [10:18<03:27,  1.71it/s]\u001b[A\n","Iteration:  74% 1004/1357 [10:18<03:26,  1.71it/s]\u001b[A\n","Iteration:  74% 1005/1357 [10:19<03:26,  1.71it/s]\u001b[A\n","Iteration:  74% 1006/1357 [10:20<03:24,  1.72it/s]\u001b[A\n","Iteration:  74% 1007/1357 [10:20<03:23,  1.72it/s]\u001b[A\n","Iteration:  74% 1008/1357 [10:21<03:23,  1.71it/s]\u001b[A\n","Iteration:  74% 1009/1357 [10:21<03:23,  1.71it/s]\u001b[A\n","Iteration:  74% 1010/1357 [10:22<03:22,  1.71it/s]\u001b[A\n","Iteration:  75% 1011/1357 [10:23<03:22,  1.71it/s]\u001b[A\n","Iteration:  75% 1012/1357 [10:23<03:20,  1.72it/s]\u001b[A\n","Iteration:  75% 1013/1357 [10:24<03:19,  1.72it/s]\u001b[A\n","Iteration:  75% 1014/1357 [10:24<03:19,  1.72it/s]\u001b[A\n","Iteration:  75% 1015/1357 [10:25<03:19,  1.71it/s]\u001b[A\n","Iteration:  75% 1016/1357 [10:25<03:18,  1.72it/s]\u001b[A\n","Iteration:  75% 1017/1357 [10:26<03:17,  1.72it/s]\u001b[A\n","Iteration:  75% 1018/1357 [10:27<03:16,  1.72it/s]\u001b[A\n","Iteration:  75% 1019/1357 [10:27<03:16,  1.72it/s]\u001b[A\n","Iteration:  75% 1020/1357 [10:28<03:17,  1.71it/s]\u001b[A\n","Iteration:  75% 1021/1357 [10:28<03:15,  1.72it/s]\u001b[A\n","Iteration:  75% 1022/1357 [10:29<03:14,  1.73it/s]\u001b[A\n","Iteration:  75% 1023/1357 [10:30<03:14,  1.72it/s]\u001b[A\n","Iteration:  75% 1024/1357 [10:30<03:14,  1.71it/s]\u001b[A\n","Iteration:  76% 1025/1357 [10:31<03:13,  1.71it/s]\u001b[A\n","Iteration:  76% 1026/1357 [10:31<03:12,  1.72it/s]\u001b[A\n","Iteration:  76% 1027/1357 [10:32<03:11,  1.72it/s]\u001b[A\n","Iteration:  76% 1028/1357 [10:32<03:10,  1.73it/s]\u001b[A\n","Iteration:  76% 1029/1357 [10:33<03:09,  1.73it/s]\u001b[A\n","Iteration:  76% 1030/1357 [10:34<03:09,  1.73it/s]\u001b[A\n","Iteration:  76% 1031/1357 [10:34<03:08,  1.73it/s]\u001b[A\n","Iteration:  76% 1032/1357 [10:35<03:09,  1.71it/s]\u001b[A\n","Iteration:  76% 1033/1357 [10:35<03:09,  1.71it/s]\u001b[A\n","Iteration:  76% 1034/1357 [10:36<03:08,  1.72it/s]\u001b[A\n","Iteration:  76% 1035/1357 [10:36<03:07,  1.72it/s]\u001b[A\n","Iteration:  76% 1036/1357 [10:37<03:07,  1.71it/s]\u001b[A\n","Iteration:  76% 1037/1357 [10:38<03:06,  1.71it/s]\u001b[A\n","Iteration:  76% 1038/1357 [10:38<03:05,  1.72it/s]\u001b[A\n","Iteration:  77% 1039/1357 [10:39<03:05,  1.71it/s]\u001b[A\n","Iteration:  77% 1040/1357 [10:39<03:03,  1.72it/s]\u001b[A\n","Iteration:  77% 1041/1357 [10:40<03:03,  1.73it/s]\u001b[A\n","Iteration:  77% 1042/1357 [10:41<03:02,  1.73it/s]\u001b[A\n","Iteration:  77% 1043/1357 [10:41<03:02,  1.72it/s]\u001b[A\n","Iteration:  77% 1044/1357 [10:42<03:02,  1.72it/s]\u001b[A\n","Iteration:  77% 1045/1357 [10:42<03:02,  1.71it/s]\u001b[A\n","Iteration:  77% 1046/1357 [10:43<03:01,  1.72it/s]\u001b[A\n","Iteration:  77% 1047/1357 [10:43<03:00,  1.72it/s]\u001b[A\n","Iteration:  77% 1048/1357 [10:44<03:00,  1.72it/s]\u001b[A\n","Iteration:  77% 1049/1357 [10:45<02:58,  1.72it/s]\u001b[A\n","Iteration:  77% 1050/1357 [10:45<02:58,  1.72it/s]\u001b[A\n","Iteration:  77% 1051/1357 [10:46<02:57,  1.72it/s]\u001b[A\n","Iteration:  78% 1052/1357 [10:46<02:57,  1.72it/s]\u001b[A\n","Iteration:  78% 1053/1357 [10:47<02:56,  1.72it/s]\u001b[A\n","Iteration:  78% 1054/1357 [10:48<02:55,  1.72it/s]\u001b[A\n","Iteration:  78% 1055/1357 [10:48<02:55,  1.72it/s]\u001b[A\n","Iteration:  78% 1056/1357 [10:49<02:54,  1.72it/s]\u001b[A\n","Iteration:  78% 1057/1357 [10:49<02:54,  1.72it/s]\u001b[A\n","Iteration:  78% 1058/1357 [10:50<02:54,  1.72it/s]\u001b[A\n","Iteration:  78% 1059/1357 [10:50<02:52,  1.72it/s]\u001b[A\n","Iteration:  78% 1060/1357 [10:51<02:52,  1.72it/s]\u001b[A\n","Iteration:  78% 1061/1357 [10:52<02:52,  1.71it/s]\u001b[A\n","Iteration:  78% 1062/1357 [10:52<02:51,  1.72it/s]\u001b[A\n","Iteration:  78% 1063/1357 [10:53<02:51,  1.72it/s]\u001b[A\n","Iteration:  78% 1064/1357 [10:53<02:50,  1.72it/s]\u001b[A\n","Iteration:  78% 1065/1357 [10:54<02:49,  1.72it/s]\u001b[A\n","Iteration:  79% 1066/1357 [10:55<02:49,  1.72it/s]\u001b[A\n","Iteration:  79% 1067/1357 [10:55<02:48,  1.72it/s]\u001b[A\n","Iteration:  79% 1068/1357 [10:56<02:47,  1.72it/s]\u001b[A\n","Iteration:  79% 1069/1357 [10:56<02:47,  1.72it/s]\u001b[A\n","Iteration:  79% 1070/1357 [10:57<02:47,  1.71it/s]\u001b[A\n","Iteration:  79% 1071/1357 [10:57<02:46,  1.71it/s]\u001b[A\n","Iteration:  79% 1072/1357 [10:58<02:46,  1.72it/s]\u001b[A\n","Iteration:  79% 1073/1357 [10:59<02:45,  1.71it/s]\u001b[A\n","Iteration:  79% 1074/1357 [10:59<02:44,  1.72it/s]\u001b[A\n","Iteration:  79% 1075/1357 [11:00<02:43,  1.73it/s]\u001b[A\n","Iteration:  79% 1076/1357 [11:00<02:43,  1.72it/s]\u001b[A\n","Iteration:  79% 1077/1357 [11:01<02:42,  1.73it/s]\u001b[A\n","Iteration:  79% 1078/1357 [11:01<02:42,  1.72it/s]\u001b[A\n","Iteration:  80% 1079/1357 [11:02<02:41,  1.72it/s]\u001b[A\n","Iteration:  80% 1080/1357 [11:03<02:41,  1.72it/s]\u001b[A\n","Iteration:  80% 1081/1357 [11:03<02:40,  1.72it/s]\u001b[A\n","Iteration:  80% 1082/1357 [11:04<02:40,  1.71it/s]\u001b[A\n","Iteration:  80% 1083/1357 [11:04<02:38,  1.72it/s]\u001b[A\n","Iteration:  80% 1084/1357 [11:05<02:37,  1.73it/s]\u001b[A\n","Iteration:  80% 1085/1357 [11:06<02:37,  1.73it/s]\u001b[A\n","Iteration:  80% 1086/1357 [11:06<02:37,  1.72it/s]\u001b[A\n","Iteration:  80% 1087/1357 [11:07<02:36,  1.72it/s]\u001b[A\n","Iteration:  80% 1088/1357 [11:07<02:36,  1.72it/s]\u001b[A\n","Iteration:  80% 1089/1357 [11:08<02:35,  1.72it/s]\u001b[A\n","Iteration:  80% 1090/1357 [11:08<02:34,  1.73it/s]\u001b[A\n","Iteration:  80% 1091/1357 [11:09<02:34,  1.72it/s]\u001b[A\n","Iteration:  80% 1092/1357 [11:10<02:33,  1.72it/s]\u001b[A\n","Iteration:  81% 1093/1357 [11:10<02:33,  1.72it/s]\u001b[A\n","Iteration:  81% 1094/1357 [11:11<02:33,  1.72it/s]\u001b[A\n","Iteration:  81% 1095/1357 [11:11<02:32,  1.72it/s]\u001b[A\n","Iteration:  81% 1096/1357 [11:12<02:32,  1.71it/s]\u001b[A\n","Iteration:  81% 1097/1357 [11:13<02:32,  1.71it/s]\u001b[A\n","Iteration:  81% 1098/1357 [11:13<02:31,  1.71it/s]\u001b[A\n","Iteration:  81% 1099/1357 [11:14<02:30,  1.71it/s]\u001b[A\n","Iteration:  81% 1100/1357 [11:14<02:30,  1.71it/s]\u001b[A\n","Iteration:  81% 1101/1357 [11:15<02:29,  1.71it/s]\u001b[A\n","Iteration:  81% 1102/1357 [11:15<02:29,  1.71it/s]\u001b[A\n","Iteration:  81% 1103/1357 [11:16<02:28,  1.71it/s]\u001b[A\n","Iteration:  81% 1104/1357 [11:17<02:28,  1.71it/s]\u001b[A\n","Iteration:  81% 1105/1357 [11:17<02:26,  1.72it/s]\u001b[A\n","Iteration:  82% 1106/1357 [11:18<02:26,  1.72it/s]\u001b[A\n","Iteration:  82% 1107/1357 [11:18<02:25,  1.71it/s]\u001b[A\n","Iteration:  82% 1108/1357 [11:19<02:25,  1.71it/s]\u001b[A\n","Iteration:  82% 1109/1357 [11:20<02:24,  1.72it/s]\u001b[A\n","Iteration:  82% 1110/1357 [11:20<02:23,  1.72it/s]\u001b[A\n","Iteration:  82% 1111/1357 [11:21<02:22,  1.73it/s]\u001b[A\n","Iteration:  82% 1112/1357 [11:21<02:21,  1.73it/s]\u001b[A\n","Iteration:  82% 1113/1357 [11:22<02:21,  1.73it/s]\u001b[A\n","Iteration:  82% 1114/1357 [11:22<02:20,  1.72it/s]\u001b[A\n","Iteration:  82% 1115/1357 [11:23<02:20,  1.72it/s]\u001b[A\n","Iteration:  82% 1116/1357 [11:24<02:20,  1.72it/s]\u001b[A\n","Iteration:  82% 1117/1357 [11:24<02:18,  1.73it/s]\u001b[A\n","Iteration:  82% 1118/1357 [11:25<02:17,  1.73it/s]\u001b[A\n","Iteration:  82% 1119/1357 [11:25<02:18,  1.71it/s]\u001b[A\n","Iteration:  83% 1120/1357 [11:26<02:18,  1.72it/s]\u001b[A\n","Iteration:  83% 1121/1357 [11:27<02:17,  1.71it/s]\u001b[A\n","Iteration:  83% 1122/1357 [11:27<02:17,  1.71it/s]\u001b[A\n","Iteration:  83% 1123/1357 [11:28<02:16,  1.72it/s]\u001b[A\n","Iteration:  83% 1124/1357 [11:28<02:14,  1.73it/s]\u001b[A\n","Iteration:  83% 1125/1357 [11:29<02:14,  1.72it/s]\u001b[A\n","Iteration:  83% 1126/1357 [11:29<02:14,  1.72it/s]\u001b[A\n","Iteration:  83% 1127/1357 [11:30<02:13,  1.72it/s]\u001b[A\n","Iteration:  83% 1128/1357 [11:31<02:12,  1.72it/s]\u001b[A\n","Iteration:  83% 1129/1357 [11:31<02:12,  1.72it/s]\u001b[A\n","Iteration:  83% 1130/1357 [11:32<02:11,  1.72it/s]\u001b[A\n","Iteration:  83% 1131/1357 [11:32<02:11,  1.72it/s]\u001b[A\n","Iteration:  83% 1132/1357 [11:33<02:10,  1.72it/s]\u001b[A\n","Iteration:  83% 1133/1357 [11:33<02:10,  1.72it/s]\u001b[A\n","Iteration:  84% 1134/1357 [11:34<02:09,  1.72it/s]\u001b[A\n","Iteration:  84% 1135/1357 [11:35<02:10,  1.71it/s]\u001b[A\n","Iteration:  84% 1136/1357 [11:35<02:08,  1.72it/s]\u001b[A\n","Iteration:  84% 1137/1357 [11:36<02:07,  1.72it/s]\u001b[A\n","Iteration:  84% 1138/1357 [11:36<02:07,  1.72it/s]\u001b[A\n","Iteration:  84% 1139/1357 [11:37<02:05,  1.73it/s]\u001b[A\n","Iteration:  84% 1140/1357 [11:38<02:05,  1.72it/s]\u001b[A\n","Iteration:  84% 1141/1357 [11:38<02:05,  1.72it/s]\u001b[A\n","Iteration:  84% 1142/1357 [11:39<02:05,  1.72it/s]\u001b[A\n","Iteration:  84% 1143/1357 [11:39<02:04,  1.72it/s]\u001b[A\n","Iteration:  84% 1144/1357 [11:40<02:03,  1.72it/s]\u001b[A\n","Iteration:  84% 1145/1357 [11:40<02:02,  1.73it/s]\u001b[A\n","Iteration:  84% 1146/1357 [11:41<02:02,  1.72it/s]\u001b[A\n","Iteration:  85% 1147/1357 [11:42<02:02,  1.72it/s]\u001b[A\n","Iteration:  85% 1148/1357 [11:42<02:01,  1.72it/s]\u001b[A\n","Iteration:  85% 1149/1357 [11:43<02:01,  1.71it/s]\u001b[A\n","Iteration:  85% 1150/1357 [11:43<02:00,  1.71it/s]\u001b[A\n","Iteration:  85% 1151/1357 [11:44<02:00,  1.71it/s]\u001b[A\n","Iteration:  85% 1152/1357 [11:45<01:59,  1.72it/s]\u001b[A\n","Iteration:  85% 1153/1357 [11:45<01:58,  1.72it/s]\u001b[A\n","Iteration:  85% 1154/1357 [11:46<01:58,  1.71it/s]\u001b[A\n","Iteration:  85% 1155/1357 [11:46<01:57,  1.72it/s]\u001b[A\n","Iteration:  85% 1156/1357 [11:47<01:57,  1.71it/s]\u001b[A\n","Iteration:  85% 1157/1357 [11:47<01:56,  1.72it/s]\u001b[A\n","Iteration:  85% 1158/1357 [11:48<01:56,  1.71it/s]\u001b[A\n","Iteration:  85% 1159/1357 [11:49<01:55,  1.71it/s]\u001b[A\n","Iteration:  85% 1160/1357 [11:49<01:55,  1.71it/s]\u001b[A\n","Iteration:  86% 1161/1357 [11:50<01:54,  1.71it/s]\u001b[A\n","Iteration:  86% 1162/1357 [11:50<01:53,  1.71it/s]\u001b[A\n","Iteration:  86% 1163/1357 [11:51<01:53,  1.71it/s]\u001b[A\n","Iteration:  86% 1164/1357 [11:52<01:52,  1.72it/s]\u001b[A\n","Iteration:  86% 1165/1357 [11:52<01:51,  1.72it/s]\u001b[A\n","Iteration:  86% 1166/1357 [11:53<01:50,  1.73it/s]\u001b[A\n","Iteration:  86% 1167/1357 [11:53<01:49,  1.74it/s]\u001b[A\n","Iteration:  86% 1168/1357 [11:54<01:49,  1.73it/s]\u001b[A\n","Iteration:  86% 1169/1357 [11:54<01:49,  1.72it/s]\u001b[A\n","Iteration:  86% 1170/1357 [11:55<01:48,  1.72it/s]\u001b[A\n","Iteration:  86% 1171/1357 [11:56<01:49,  1.70it/s]\u001b[A\n","Iteration:  86% 1172/1357 [11:56<01:48,  1.71it/s]\u001b[A\n","Iteration:  86% 1173/1357 [11:57<01:47,  1.71it/s]\u001b[A\n","Iteration:  87% 1174/1357 [11:57<01:46,  1.72it/s]\u001b[A\n","Iteration:  87% 1175/1357 [11:58<01:46,  1.71it/s]\u001b[A\n","Iteration:  87% 1176/1357 [11:59<01:45,  1.72it/s]\u001b[A\n","Iteration:  87% 1177/1357 [11:59<01:44,  1.72it/s]\u001b[A\n","Iteration:  87% 1178/1357 [12:00<01:43,  1.72it/s]\u001b[A\n","Iteration:  87% 1179/1357 [12:00<01:42,  1.73it/s]\u001b[A\n","Iteration:  87% 1180/1357 [12:01<01:41,  1.74it/s]\u001b[A\n","Iteration:  87% 1181/1357 [12:01<01:41,  1.73it/s]\u001b[A\n","Iteration:  87% 1182/1357 [12:02<01:41,  1.73it/s]\u001b[A\n","Iteration:  87% 1183/1357 [12:03<01:41,  1.72it/s]\u001b[A\n","Iteration:  87% 1184/1357 [12:03<01:40,  1.72it/s]\u001b[A\n","Iteration:  87% 1185/1357 [12:04<01:40,  1.72it/s]\u001b[A\n","Iteration:  87% 1186/1357 [12:04<01:39,  1.72it/s]\u001b[A\n","Iteration:  87% 1187/1357 [12:05<01:38,  1.72it/s]\u001b[A\n","Iteration:  88% 1188/1357 [12:05<01:38,  1.71it/s]\u001b[A\n","Iteration:  88% 1189/1357 [12:06<01:37,  1.72it/s]\u001b[A\n","Iteration:  88% 1190/1357 [12:07<01:37,  1.71it/s]\u001b[A\n","Iteration:  88% 1191/1357 [12:07<01:36,  1.72it/s]\u001b[A\n","Iteration:  88% 1192/1357 [12:08<01:36,  1.71it/s]\u001b[A\n","Iteration:  88% 1193/1357 [12:08<01:36,  1.70it/s]\u001b[A\n","Iteration:  88% 1194/1357 [12:09<01:34,  1.72it/s]\u001b[A\n","Iteration:  88% 1195/1357 [12:10<01:34,  1.72it/s]\u001b[A\n","Iteration:  88% 1196/1357 [12:10<01:33,  1.72it/s]\u001b[A\n","Iteration:  88% 1197/1357 [12:11<01:32,  1.72it/s]\u001b[A\n","Iteration:  88% 1198/1357 [12:11<01:32,  1.72it/s]\u001b[A\n","Iteration:  88% 1199/1357 [12:12<01:32,  1.71it/s]\u001b[A\n","Iteration:  88% 1200/1357 [12:12<01:31,  1.72it/s]\u001b[A\n","Iteration:  89% 1201/1357 [12:13<01:30,  1.72it/s]\u001b[A\n","Iteration:  89% 1202/1357 [12:14<01:30,  1.72it/s]\u001b[A\n","Iteration:  89% 1203/1357 [12:14<01:29,  1.72it/s]\u001b[A\n","Iteration:  89% 1204/1357 [12:15<01:29,  1.70it/s]\u001b[A\n","Iteration:  89% 1205/1357 [12:15<01:29,  1.70it/s]\u001b[A\n","Iteration:  89% 1206/1357 [12:16<01:28,  1.70it/s]\u001b[A\n","Iteration:  89% 1207/1357 [12:17<01:27,  1.72it/s]\u001b[A\n","Iteration:  89% 1208/1357 [12:17<01:26,  1.72it/s]\u001b[A\n","Iteration:  89% 1209/1357 [12:18<01:26,  1.71it/s]\u001b[A\n","Iteration:  89% 1210/1357 [12:18<01:26,  1.71it/s]\u001b[A\n","Iteration:  89% 1211/1357 [12:19<01:25,  1.70it/s]\u001b[A\n","Iteration:  89% 1212/1357 [12:19<01:24,  1.71it/s]\u001b[A\n","Iteration:  89% 1213/1357 [12:20<01:23,  1.72it/s]\u001b[A\n","Iteration:  89% 1214/1357 [12:21<01:23,  1.71it/s]\u001b[A\n","Iteration:  90% 1215/1357 [12:21<01:22,  1.72it/s]\u001b[A\n","Iteration:  90% 1216/1357 [12:22<01:21,  1.72it/s]\u001b[A\n","Iteration:  90% 1217/1357 [12:22<01:21,  1.72it/s]\u001b[A\n","Iteration:  90% 1218/1357 [12:23<01:20,  1.72it/s]\u001b[A\n","Iteration:  90% 1219/1357 [12:24<01:20,  1.72it/s]\u001b[A\n","Iteration:  90% 1220/1357 [12:24<01:19,  1.72it/s]\u001b[A\n","Iteration:  90% 1221/1357 [12:25<01:19,  1.71it/s]\u001b[A\n","Iteration:  90% 1222/1357 [12:25<01:18,  1.72it/s]\u001b[A\n","Iteration:  90% 1223/1357 [12:26<01:17,  1.72it/s]\u001b[A\n","Iteration:  90% 1224/1357 [12:26<01:17,  1.72it/s]\u001b[A\n","Iteration:  90% 1225/1357 [12:27<01:17,  1.71it/s]\u001b[A\n","Iteration:  90% 1226/1357 [12:28<01:16,  1.71it/s]\u001b[A\n","Iteration:  90% 1227/1357 [12:28<01:16,  1.71it/s]\u001b[A\n","Iteration:  90% 1228/1357 [12:29<01:14,  1.72it/s]\u001b[A\n","Iteration:  91% 1229/1357 [12:29<01:14,  1.72it/s]\u001b[A\n","Iteration:  91% 1230/1357 [12:30<01:13,  1.72it/s]\u001b[A\n","Iteration:  91% 1231/1357 [12:31<01:13,  1.72it/s]\u001b[A\n","Iteration:  91% 1232/1357 [12:31<01:12,  1.72it/s]\u001b[A\n","Iteration:  91% 1233/1357 [12:32<01:12,  1.71it/s]\u001b[A\n","Iteration:  91% 1234/1357 [12:32<01:11,  1.72it/s]\u001b[A\n","Iteration:  91% 1235/1357 [12:33<01:10,  1.72it/s]\u001b[A\n","Iteration:  91% 1236/1357 [12:33<01:10,  1.72it/s]\u001b[A\n","Iteration:  91% 1237/1357 [12:34<01:10,  1.71it/s]\u001b[A\n","Iteration:  91% 1238/1357 [12:35<01:09,  1.71it/s]\u001b[A\n","Iteration:  91% 1239/1357 [12:35<01:08,  1.71it/s]\u001b[A\n","Iteration:  91% 1240/1357 [12:36<01:08,  1.72it/s]\u001b[A\n","Iteration:  91% 1241/1357 [12:36<01:07,  1.71it/s]\u001b[A\n","Iteration:  92% 1242/1357 [12:37<01:07,  1.71it/s]\u001b[A\n","Iteration:  92% 1243/1357 [12:38<01:06,  1.72it/s]\u001b[A\n","Iteration:  92% 1244/1357 [12:38<01:06,  1.70it/s]\u001b[A\n","Iteration:  92% 1245/1357 [12:39<01:05,  1.71it/s]\u001b[A\n","Iteration:  92% 1246/1357 [12:39<01:04,  1.72it/s]\u001b[A\n","Iteration:  92% 1247/1357 [12:40<01:03,  1.72it/s]\u001b[A\n","Iteration:  92% 1248/1357 [12:40<01:03,  1.72it/s]\u001b[A\n","Iteration:  92% 1249/1357 [12:41<01:02,  1.72it/s]\u001b[A\n","Iteration:  92% 1250/1357 [12:42<01:02,  1.72it/s]\u001b[A\n","Iteration:  92% 1251/1357 [12:42<01:02,  1.71it/s]\u001b[A\n","Iteration:  92% 1252/1357 [12:43<01:01,  1.71it/s]\u001b[A\n","Iteration:  92% 1253/1357 [12:43<01:00,  1.72it/s]\u001b[A\n","Iteration:  92% 1254/1357 [12:44<00:59,  1.72it/s]\u001b[A\n","Iteration:  92% 1255/1357 [12:45<00:59,  1.72it/s]\u001b[A\n","Iteration:  93% 1256/1357 [12:45<00:58,  1.72it/s]\u001b[A\n","Iteration:  93% 1257/1357 [12:46<00:58,  1.72it/s]\u001b[A\n","Iteration:  93% 1258/1357 [12:46<00:57,  1.72it/s]\u001b[A\n","Iteration:  93% 1259/1357 [12:47<00:56,  1.72it/s]\u001b[A\n","Iteration:  93% 1260/1357 [12:47<00:56,  1.72it/s]\u001b[A\n","Iteration:  93% 1261/1357 [12:48<00:55,  1.73it/s]\u001b[A\n","Iteration:  93% 1262/1357 [12:49<00:55,  1.72it/s]\u001b[A\n","Iteration:  93% 1263/1357 [12:49<00:54,  1.72it/s]\u001b[A\n","Iteration:  93% 1264/1357 [12:50<00:54,  1.72it/s]\u001b[A\n","Iteration:  93% 1265/1357 [12:50<00:53,  1.72it/s]\u001b[A\n","Iteration:  93% 1266/1357 [12:51<00:52,  1.72it/s]\u001b[A\n","Iteration:  93% 1267/1357 [12:52<00:52,  1.72it/s]\u001b[A\n","Iteration:  93% 1268/1357 [12:52<00:51,  1.72it/s]\u001b[A\n","Iteration:  94% 1269/1357 [12:53<00:51,  1.72it/s]\u001b[A\n","Iteration:  94% 1270/1357 [12:53<00:50,  1.72it/s]\u001b[A\n","Iteration:  94% 1271/1357 [12:54<00:49,  1.72it/s]\u001b[A\n","Iteration:  94% 1272/1357 [12:54<00:49,  1.71it/s]\u001b[A\n","Iteration:  94% 1273/1357 [12:55<00:48,  1.72it/s]\u001b[A\n","Iteration:  94% 1274/1357 [12:56<00:48,  1.72it/s]\u001b[A\n","Iteration:  94% 1275/1357 [12:56<00:47,  1.72it/s]\u001b[A\n","Iteration:  94% 1276/1357 [12:57<00:47,  1.72it/s]\u001b[A\n","Iteration:  94% 1277/1357 [12:57<00:46,  1.72it/s]\u001b[A\n","Iteration:  94% 1278/1357 [12:58<00:45,  1.72it/s]\u001b[A\n","Iteration:  94% 1279/1357 [12:58<00:45,  1.72it/s]\u001b[A\n","Iteration:  94% 1280/1357 [12:59<00:44,  1.72it/s]\u001b[A\n","Iteration:  94% 1281/1357 [13:00<00:44,  1.71it/s]\u001b[A\n","Iteration:  94% 1282/1357 [13:00<00:43,  1.72it/s]\u001b[A\n","Iteration:  95% 1283/1357 [13:01<00:42,  1.73it/s]\u001b[A\n","Iteration:  95% 1284/1357 [13:01<00:42,  1.73it/s]\u001b[A\n","Iteration:  95% 1285/1357 [13:02<00:41,  1.72it/s]\u001b[A\n","Iteration:  95% 1286/1357 [13:03<00:41,  1.72it/s]\u001b[A\n","Iteration:  95% 1287/1357 [13:03<00:40,  1.72it/s]\u001b[A\n","Iteration:  95% 1288/1357 [13:04<00:40,  1.72it/s]\u001b[A\n","Iteration:  95% 1289/1357 [13:04<00:39,  1.73it/s]\u001b[A\n","Iteration:  95% 1290/1357 [13:05<00:38,  1.73it/s]\u001b[A\n","Iteration:  95% 1291/1357 [13:05<00:38,  1.72it/s]\u001b[A\n","Iteration:  95% 1292/1357 [13:06<00:37,  1.71it/s]\u001b[A\n","Iteration:  95% 1293/1357 [13:07<00:37,  1.71it/s]\u001b[A\n","Iteration:  95% 1294/1357 [13:07<00:36,  1.70it/s]\u001b[A\n","Iteration:  95% 1295/1357 [13:08<00:36,  1.71it/s]\u001b[A\n","Iteration:  96% 1296/1357 [13:08<00:35,  1.72it/s]\u001b[A\n","Iteration:  96% 1297/1357 [13:09<00:34,  1.72it/s]\u001b[A\n","Iteration:  96% 1298/1357 [13:10<00:34,  1.71it/s]\u001b[A\n","Iteration:  96% 1299/1357 [13:10<00:33,  1.72it/s]\u001b[A\n","Iteration:  96% 1300/1357 [13:11<00:33,  1.71it/s]\u001b[A\n","Iteration:  96% 1301/1357 [13:11<00:32,  1.72it/s]\u001b[A\n","Iteration:  96% 1302/1357 [13:12<00:31,  1.72it/s]\u001b[A\n","Iteration:  96% 1303/1357 [13:12<00:31,  1.72it/s]\u001b[A\n","Iteration:  96% 1304/1357 [13:13<00:30,  1.71it/s]\u001b[A\n","Iteration:  96% 1305/1357 [13:14<00:30,  1.71it/s]\u001b[A\n","Iteration:  96% 1306/1357 [13:14<00:29,  1.71it/s]\u001b[A\n","Iteration:  96% 1307/1357 [13:15<00:29,  1.72it/s]\u001b[A\n","Iteration:  96% 1308/1357 [13:15<00:28,  1.72it/s]\u001b[A\n","Iteration:  96% 1309/1357 [13:16<00:27,  1.72it/s]\u001b[A\n","Iteration:  97% 1310/1357 [13:17<00:27,  1.72it/s]\u001b[A\n","Iteration:  97% 1311/1357 [13:17<00:26,  1.72it/s]\u001b[A\n","Iteration:  97% 1312/1357 [13:18<00:26,  1.72it/s]\u001b[A\n","Iteration:  97% 1313/1357 [13:18<00:25,  1.72it/s]\u001b[A\n","Iteration:  97% 1314/1357 [13:19<00:24,  1.73it/s]\u001b[A\n","Iteration:  97% 1315/1357 [13:19<00:24,  1.72it/s]\u001b[A\n","Iteration:  97% 1316/1357 [13:20<00:23,  1.72it/s]\u001b[A\n","Iteration:  97% 1317/1357 [13:21<00:23,  1.72it/s]\u001b[A\n","Iteration:  97% 1318/1357 [13:21<00:22,  1.72it/s]\u001b[A\n","Iteration:  97% 1319/1357 [13:22<00:22,  1.71it/s]\u001b[A\n","Iteration:  97% 1320/1357 [13:22<00:21,  1.71it/s]\u001b[A\n","Iteration:  97% 1321/1357 [13:23<00:20,  1.72it/s]\u001b[A\n","Iteration:  97% 1322/1357 [13:24<00:20,  1.72it/s]\u001b[A\n","Iteration:  97% 1323/1357 [13:24<00:19,  1.73it/s]\u001b[A\n","Iteration:  98% 1324/1357 [13:25<00:19,  1.72it/s]\u001b[A\n","Iteration:  98% 1325/1357 [13:25<00:18,  1.72it/s]\u001b[A\n","Iteration:  98% 1326/1357 [13:26<00:18,  1.72it/s]\u001b[A\n","Iteration:  98% 1327/1357 [13:26<00:17,  1.72it/s]\u001b[A\n","Iteration:  98% 1328/1357 [13:27<00:16,  1.72it/s]\u001b[A\n","Iteration:  98% 1329/1357 [13:28<00:16,  1.72it/s]\u001b[A\n","Iteration:  98% 1330/1357 [13:28<00:15,  1.72it/s]\u001b[A\n","Iteration:  98% 1331/1357 [13:29<00:15,  1.72it/s]\u001b[A\n","Iteration:  98% 1332/1357 [13:29<00:14,  1.71it/s]\u001b[A\n","Iteration:  98% 1333/1357 [13:30<00:13,  1.72it/s]\u001b[A\n","Iteration:  98% 1334/1357 [13:30<00:13,  1.72it/s]\u001b[A\n","Iteration:  98% 1335/1357 [13:31<00:12,  1.72it/s]\u001b[A\n","Iteration:  98% 1336/1357 [13:32<00:12,  1.72it/s]\u001b[A\n","Iteration:  99% 1337/1357 [13:32<00:11,  1.72it/s]\u001b[A\n","Iteration:  99% 1338/1357 [13:33<00:11,  1.71it/s]\u001b[A\n","Iteration:  99% 1339/1357 [13:33<00:10,  1.71it/s]\u001b[A\n","Iteration:  99% 1340/1357 [13:34<00:09,  1.71it/s]\u001b[A\n","Iteration:  99% 1341/1357 [13:35<00:09,  1.72it/s]\u001b[A\n","Iteration:  99% 1342/1357 [13:35<00:08,  1.72it/s]\u001b[A\n","Iteration:  99% 1343/1357 [13:36<00:08,  1.71it/s]\u001b[A\n","Iteration:  99% 1344/1357 [13:36<00:07,  1.71it/s]\u001b[A\n","Iteration:  99% 1345/1357 [13:37<00:06,  1.72it/s]\u001b[A\n","Iteration:  99% 1346/1357 [13:37<00:06,  1.72it/s]\u001b[A\n","Iteration:  99% 1347/1357 [13:38<00:05,  1.73it/s]\u001b[A\n","Iteration:  99% 1348/1357 [13:39<00:05,  1.72it/s]\u001b[A\n","Iteration:  99% 1349/1357 [13:39<00:04,  1.72it/s]\u001b[A\n","Iteration:  99% 1350/1357 [13:40<00:04,  1.73it/s]\u001b[A\n","Iteration: 100% 1351/1357 [13:40<00:03,  1.73it/s]\u001b[A\n","Iteration: 100% 1352/1357 [13:41<00:02,  1.73it/s]\u001b[A\n","Iteration: 100% 1353/1357 [13:42<00:02,  1.72it/s]\u001b[A\n","Iteration: 100% 1354/1357 [13:42<00:01,  1.72it/s]\u001b[A\n","Iteration: 100% 1355/1357 [13:43<00:01,  1.72it/s]\u001b[A\n","Iteration: 100% 1356/1357 [13:43<00:00,  1.72it/s]\u001b[A\n","Iteration: 100% 1357/1357 [13:44<00:00,  1.65it/s]\n","Epoch:  70% 7/10 [1:37:28<41:46, 835.66s/it]\n","Iteration:   0% 0/1357 [00:00<?, ?it/s]\u001b[A\n","Iteration:   0% 1/1357 [00:00<13:08,  1.72it/s]\u001b[A\n","Iteration:   0% 2/1357 [00:01<13:03,  1.73it/s]\u001b[A\n","Iteration:   0% 3/1357 [00:01<13:01,  1.73it/s]\u001b[A\n","Iteration:   0% 4/1357 [00:02<13:02,  1.73it/s]\u001b[A\n","Iteration:   0% 5/1357 [00:02<13:04,  1.72it/s]\u001b[A\n","Iteration:   0% 6/1357 [00:03<13:05,  1.72it/s]\u001b[A\n","Iteration:   1% 7/1357 [00:04<13:06,  1.72it/s]\u001b[A\n","Iteration:   1% 8/1357 [00:04<13:05,  1.72it/s]\u001b[A\n","Iteration:   1% 9/1357 [00:05<13:03,  1.72it/s]\u001b[A\n","Iteration:   1% 10/1357 [00:05<13:03,  1.72it/s]\u001b[A\n","Iteration:   1% 11/1357 [00:06<13:04,  1.72it/s]\u001b[A\n","Iteration:   1% 12/1357 [00:06<13:04,  1.72it/s]\u001b[A\n","Iteration:   1% 13/1357 [00:07<13:02,  1.72it/s]\u001b[A\n","Iteration:   1% 14/1357 [00:08<13:02,  1.72it/s]\u001b[A\n","Iteration:   1% 15/1357 [00:08<13:00,  1.72it/s]\u001b[A\n","Iteration:   1% 16/1357 [00:09<13:00,  1.72it/s]\u001b[A\n","Iteration:   1% 17/1357 [00:09<12:56,  1.73it/s]\u001b[A\n","Iteration:   1% 18/1357 [00:10<12:54,  1.73it/s]\u001b[A\n","Iteration:   1% 19/1357 [00:11<12:55,  1.73it/s]\u001b[A\n","Iteration:   1% 20/1357 [00:11<12:56,  1.72it/s]\u001b[A\n","Iteration:   2% 21/1357 [00:12<12:53,  1.73it/s]\u001b[A\n","Iteration:   2% 22/1357 [00:12<12:52,  1.73it/s]\u001b[A\n","Iteration:   2% 23/1357 [00:13<12:54,  1.72it/s]\u001b[A\n","Iteration:   2% 24/1357 [00:13<12:51,  1.73it/s]\u001b[A\n","Iteration:   2% 25/1357 [00:14<12:53,  1.72it/s]\u001b[A\n","Iteration:   2% 26/1357 [00:15<12:52,  1.72it/s]\u001b[A\n","Iteration:   2% 27/1357 [00:15<12:50,  1.73it/s]\u001b[A\n","Iteration:   2% 28/1357 [00:16<12:56,  1.71it/s]\u001b[A\n","Iteration:   2% 29/1357 [00:16<12:53,  1.72it/s]\u001b[A\n","Iteration:   2% 30/1357 [00:17<12:55,  1.71it/s]\u001b[A\n","Iteration:   2% 31/1357 [00:18<12:51,  1.72it/s]\u001b[A\n","Iteration:   2% 32/1357 [00:18<12:51,  1.72it/s]\u001b[A\n","Iteration:   2% 33/1357 [00:19<12:50,  1.72it/s]\u001b[A\n","Iteration:   3% 34/1357 [00:19<12:50,  1.72it/s]\u001b[A\n","Iteration:   3% 35/1357 [00:20<12:51,  1.71it/s]\u001b[A\n","Iteration:   3% 36/1357 [00:20<12:48,  1.72it/s]\u001b[A\n","Iteration:   3% 37/1357 [00:21<12:48,  1.72it/s]\u001b[A\n","Iteration:   3% 38/1357 [00:22<12:48,  1.72it/s]\u001b[A\n","Iteration:   3% 39/1357 [00:22<12:49,  1.71it/s]\u001b[A\n","Iteration:   3% 40/1357 [00:23<12:49,  1.71it/s]\u001b[A\n","Iteration:   3% 41/1357 [00:23<12:48,  1.71it/s]\u001b[A\n","Iteration:   3% 42/1357 [00:24<12:45,  1.72it/s]\u001b[A\n","Iteration:   3% 43/1357 [00:25<12:42,  1.72it/s]\u001b[A\n","Iteration:   3% 44/1357 [00:25<12:43,  1.72it/s]\u001b[A\n","Iteration:   3% 45/1357 [00:26<12:39,  1.73it/s]\u001b[A\n","Iteration:   3% 46/1357 [00:26<12:37,  1.73it/s]\u001b[A\n","Iteration:   3% 47/1357 [00:27<12:38,  1.73it/s]\u001b[A\n","Iteration:   4% 48/1357 [00:27<12:40,  1.72it/s]\u001b[A\n","Iteration:   4% 49/1357 [00:28<12:39,  1.72it/s]\u001b[A\n","Iteration:   4% 50/1357 [00:29<12:38,  1.72it/s]\u001b[A\n","Iteration:   4% 51/1357 [00:29<12:37,  1.72it/s]\u001b[A\n","Iteration:   4% 52/1357 [00:30<12:34,  1.73it/s]\u001b[A\n","Iteration:   4% 53/1357 [00:30<12:33,  1.73it/s]\u001b[A\n","Iteration:   4% 54/1357 [00:31<12:36,  1.72it/s]\u001b[A\n","Iteration:   4% 55/1357 [00:31<12:36,  1.72it/s]\u001b[A\n","Iteration:   4% 56/1357 [00:32<12:35,  1.72it/s]\u001b[A\n","Iteration:   4% 57/1357 [00:33<12:37,  1.72it/s]\u001b[A\n","Iteration:   4% 58/1357 [00:33<12:30,  1.73it/s]\u001b[A\n","Iteration:   4% 59/1357 [00:34<12:30,  1.73it/s]\u001b[A\n","Iteration:   4% 60/1357 [00:34<12:32,  1.72it/s]\u001b[A\n","Iteration:   4% 61/1357 [00:35<12:33,  1.72it/s]\u001b[A\n","Iteration:   5% 62/1357 [00:36<12:33,  1.72it/s]\u001b[A\n","Iteration:   5% 63/1357 [00:36<12:35,  1.71it/s]\u001b[A\n","Iteration:   5% 64/1357 [00:37<12:30,  1.72it/s]\u001b[A\n","Iteration:   5% 65/1357 [00:37<12:30,  1.72it/s]\u001b[A\n","Iteration:   5% 66/1357 [00:38<12:29,  1.72it/s]\u001b[A\n","Iteration:   5% 67/1357 [00:38<12:28,  1.72it/s]\u001b[A\n","Iteration:   5% 68/1357 [00:39<12:28,  1.72it/s]\u001b[A\n","Iteration:   5% 69/1357 [00:40<12:27,  1.72it/s]\u001b[A\n","Iteration:   5% 70/1357 [00:40<12:26,  1.72it/s]\u001b[A\n","Iteration:   5% 71/1357 [00:41<12:25,  1.72it/s]\u001b[A\n","Iteration:   5% 72/1357 [00:41<12:27,  1.72it/s]\u001b[A\n","Iteration:   5% 73/1357 [00:42<12:23,  1.73it/s]\u001b[A\n","Iteration:   5% 74/1357 [00:42<12:21,  1.73it/s]\u001b[A\n","Iteration:   6% 75/1357 [00:43<12:20,  1.73it/s]\u001b[A\n","Iteration:   6% 76/1357 [00:44<12:23,  1.72it/s]\u001b[A\n","Iteration:   6% 77/1357 [00:44<12:21,  1.73it/s]\u001b[A\n","Iteration:   6% 78/1357 [00:45<12:19,  1.73it/s]\u001b[A\n","Iteration:   6% 79/1357 [00:45<12:19,  1.73it/s]\u001b[A\n","Iteration:   6% 80/1357 [00:46<12:19,  1.73it/s]\u001b[A\n","Iteration:   6% 81/1357 [00:47<12:17,  1.73it/s]\u001b[A\n","Iteration:   6% 82/1357 [00:47<12:17,  1.73it/s]\u001b[A\n","Iteration:   6% 83/1357 [00:48<12:18,  1.73it/s]\u001b[A\n","Iteration:   6% 84/1357 [00:48<12:22,  1.71it/s]\u001b[A\n","Iteration:   6% 85/1357 [00:49<12:23,  1.71it/s]\u001b[A\n","Iteration:   6% 86/1357 [00:49<12:18,  1.72it/s]\u001b[A\n","Iteration:   6% 87/1357 [00:50<12:17,  1.72it/s]\u001b[A\n","Iteration:   6% 88/1357 [00:51<12:17,  1.72it/s]\u001b[A\n","Iteration:   7% 89/1357 [00:51<12:18,  1.72it/s]\u001b[A\n","Iteration:   7% 90/1357 [00:52<12:18,  1.71it/s]\u001b[A\n","Iteration:   7% 91/1357 [00:52<12:17,  1.72it/s]\u001b[A\n","Iteration:   7% 92/1357 [00:53<12:14,  1.72it/s]\u001b[A\n","Iteration:   7% 93/1357 [00:54<12:12,  1.73it/s]\u001b[A\n","Iteration:   7% 94/1357 [00:54<12:13,  1.72it/s]\u001b[A\n","Iteration:   7% 95/1357 [00:55<12:14,  1.72it/s]\u001b[A\n","Iteration:   7% 96/1357 [00:55<12:12,  1.72it/s]\u001b[A\n","Iteration:   7% 97/1357 [00:56<12:10,  1.72it/s]\u001b[A\n","Iteration:   7% 98/1357 [00:56<12:14,  1.71it/s]\u001b[A\n","Iteration:   7% 99/1357 [00:57<12:12,  1.72it/s]\u001b[A\n","Iteration:   7% 100/1357 [00:58<12:16,  1.71it/s]\u001b[A\n","Iteration:   7% 101/1357 [00:58<12:15,  1.71it/s]\u001b[A\n","Iteration:   8% 102/1357 [00:59<12:12,  1.71it/s]\u001b[A\n","Iteration:   8% 103/1357 [00:59<12:12,  1.71it/s]\u001b[A\n","Iteration:   8% 104/1357 [01:00<12:08,  1.72it/s]\u001b[A\n","Iteration:   8% 105/1357 [01:01<12:07,  1.72it/s]\u001b[A\n","Iteration:   8% 106/1357 [01:01<12:10,  1.71it/s]\u001b[A\n","Iteration:   8% 107/1357 [01:02<12:05,  1.72it/s]\u001b[A\n","Iteration:   8% 108/1357 [01:02<12:03,  1.73it/s]\u001b[A\n","Iteration:   8% 109/1357 [01:03<12:04,  1.72it/s]\u001b[A\n","Iteration:   8% 110/1357 [01:03<12:06,  1.72it/s]\u001b[A\n","Iteration:   8% 111/1357 [01:04<12:02,  1.72it/s]\u001b[A\n","Iteration:   8% 112/1357 [01:05<12:01,  1.73it/s]\u001b[A\n","Iteration:   8% 113/1357 [01:05<12:03,  1.72it/s]\u001b[A\n","Iteration:   8% 114/1357 [01:06<11:59,  1.73it/s]\u001b[A\n","Iteration:   8% 115/1357 [01:06<11:58,  1.73it/s]\u001b[A\n","Iteration:   9% 116/1357 [01:07<11:58,  1.73it/s]\u001b[A\n","Iteration:   9% 117/1357 [01:07<12:00,  1.72it/s]\u001b[A\n","Iteration:   9% 118/1357 [01:08<12:01,  1.72it/s]\u001b[A\n","Iteration:   9% 119/1357 [01:09<12:01,  1.72it/s]\u001b[A\n","Iteration:   9% 120/1357 [01:09<11:58,  1.72it/s]\u001b[A\n","Iteration:   9% 121/1357 [01:10<11:56,  1.72it/s]\u001b[A\n","Iteration:   9% 122/1357 [01:10<11:57,  1.72it/s]\u001b[A\n","Iteration:   9% 123/1357 [01:11<11:58,  1.72it/s]\u001b[A\n","Iteration:   9% 124/1357 [01:12<11:56,  1.72it/s]\u001b[A\n","Iteration:   9% 125/1357 [01:12<11:55,  1.72it/s]\u001b[A\n","Iteration:   9% 126/1357 [01:13<11:52,  1.73it/s]\u001b[A\n","Iteration:   9% 127/1357 [01:13<11:51,  1.73it/s]\u001b[A\n","Iteration:   9% 128/1357 [01:14<11:52,  1.73it/s]\u001b[A\n","Iteration:  10% 129/1357 [01:14<11:55,  1.72it/s]\u001b[A\n","Iteration:  10% 130/1357 [01:15<11:57,  1.71it/s]\u001b[A\n","Iteration:  10% 131/1357 [01:16<11:56,  1.71it/s]\u001b[A\n","Iteration:  10% 132/1357 [01:16<11:56,  1.71it/s]\u001b[A\n","Iteration:  10% 133/1357 [01:17<11:52,  1.72it/s]\u001b[A\n","Iteration:  10% 134/1357 [01:17<11:54,  1.71it/s]\u001b[A\n","Iteration:  10% 135/1357 [01:18<11:50,  1.72it/s]\u001b[A\n","Iteration:  10% 136/1357 [01:19<11:48,  1.72it/s]\u001b[A\n","Iteration:  10% 137/1357 [01:19<11:49,  1.72it/s]\u001b[A\n","Iteration:  10% 138/1357 [01:20<11:50,  1.71it/s]\u001b[A\n","Iteration:  10% 139/1357 [01:20<11:47,  1.72it/s]\u001b[A\n","Iteration:  10% 140/1357 [01:21<11:46,  1.72it/s]\u001b[A\n","Iteration:  10% 141/1357 [01:21<11:45,  1.72it/s]\u001b[A\n","Iteration:  10% 142/1357 [01:22<11:41,  1.73it/s]\u001b[A\n","Iteration:  11% 143/1357 [01:23<11:41,  1.73it/s]\u001b[A\n","Iteration:  11% 144/1357 [01:23<11:41,  1.73it/s]\u001b[A\n","Iteration:  11% 145/1357 [01:24<11:42,  1.72it/s]\u001b[A\n","Iteration:  11% 146/1357 [01:24<11:41,  1.73it/s]\u001b[A\n","Iteration:  11% 147/1357 [01:25<11:43,  1.72it/s]\u001b[A\n","Iteration:  11% 148/1357 [01:25<11:40,  1.73it/s]\u001b[A\n","Iteration:  11% 149/1357 [01:26<11:36,  1.73it/s]\u001b[A\n","Iteration:  11% 150/1357 [01:27<11:38,  1.73it/s]\u001b[A\n","Iteration:  11% 151/1357 [01:27<11:40,  1.72it/s]\u001b[A\n","Iteration:  11% 152/1357 [01:28<11:39,  1.72it/s]\u001b[A\n","Iteration:  11% 153/1357 [01:28<11:39,  1.72it/s]\u001b[A\n","Iteration:  11% 154/1357 [01:29<11:36,  1.73it/s]\u001b[A\n","Iteration:  11% 155/1357 [01:30<11:38,  1.72it/s]\u001b[A\n","Iteration:  11% 156/1357 [01:30<11:38,  1.72it/s]\u001b[A\n","Iteration:  12% 157/1357 [01:31<11:38,  1.72it/s]\u001b[A\n","Iteration:  12% 158/1357 [01:31<11:36,  1.72it/s]\u001b[A\n","Iteration:  12% 159/1357 [01:32<11:36,  1.72it/s]\u001b[A\n","Iteration:  12% 160/1357 [01:32<11:36,  1.72it/s]\u001b[A\n","Iteration:  12% 161/1357 [01:33<11:33,  1.73it/s]\u001b[A\n","Iteration:  12% 162/1357 [01:34<11:34,  1.72it/s]\u001b[A\n","Iteration:  12% 163/1357 [01:34<11:33,  1.72it/s]\u001b[A\n","Iteration:  12% 164/1357 [01:35<11:36,  1.71it/s]\u001b[A\n","Iteration:  12% 165/1357 [01:35<11:34,  1.72it/s]\u001b[A\n","Iteration:  12% 166/1357 [01:36<11:35,  1.71it/s]\u001b[A\n","Iteration:  12% 167/1357 [01:37<11:33,  1.72it/s]\u001b[A\n","Iteration:  12% 168/1357 [01:37<11:30,  1.72it/s]\u001b[A\n","Iteration:  12% 169/1357 [01:38<11:30,  1.72it/s]\u001b[A\n","Iteration:  13% 170/1357 [01:38<11:26,  1.73it/s]\u001b[A\n","Iteration:  13% 171/1357 [01:39<11:26,  1.73it/s]\u001b[A\n","Iteration:  13% 172/1357 [01:39<11:26,  1.73it/s]\u001b[A\n","Iteration:  13% 173/1357 [01:40<11:26,  1.72it/s]\u001b[A\n","Iteration:  13% 174/1357 [01:41<11:26,  1.72it/s]\u001b[A\n","Iteration:  13% 175/1357 [01:41<11:27,  1.72it/s]\u001b[A\n","Iteration:  13% 176/1357 [01:42<11:24,  1.72it/s]\u001b[A\n","Iteration:  13% 177/1357 [01:42<11:22,  1.73it/s]\u001b[A\n","Iteration:  13% 178/1357 [01:43<11:24,  1.72it/s]\u001b[A\n","Iteration:  13% 179/1357 [01:43<11:25,  1.72it/s]\u001b[A\n","Iteration:  13% 180/1357 [01:44<11:27,  1.71it/s]\u001b[A\n","Iteration:  13% 181/1357 [01:45<11:25,  1.71it/s]\u001b[A\n","Iteration:  13% 182/1357 [01:45<11:23,  1.72it/s]\u001b[A\n","Iteration:  13% 183/1357 [01:46<11:21,  1.72it/s]\u001b[A\n","Iteration:  14% 184/1357 [01:46<11:21,  1.72it/s]\u001b[A\n","Iteration:  14% 185/1357 [01:47<11:23,  1.72it/s]\u001b[A\n","Iteration:  14% 186/1357 [01:48<11:22,  1.72it/s]\u001b[A\n","Iteration:  14% 187/1357 [01:48<11:20,  1.72it/s]\u001b[A\n","Iteration:  14% 188/1357 [01:49<11:20,  1.72it/s]\u001b[A\n","Iteration:  14% 189/1357 [01:49<11:18,  1.72it/s]\u001b[A\n","Iteration:  14% 190/1357 [01:50<11:19,  1.72it/s]\u001b[A\n","Iteration:  14% 191/1357 [01:50<11:16,  1.72it/s]\u001b[A\n","Iteration:  14% 192/1357 [01:51<11:12,  1.73it/s]\u001b[A\n","Iteration:  14% 193/1357 [01:52<11:15,  1.72it/s]\u001b[A\n","Iteration:  14% 194/1357 [01:52<11:17,  1.72it/s]\u001b[A\n","Iteration:  14% 195/1357 [01:53<11:15,  1.72it/s]\u001b[A\n","Iteration:  14% 196/1357 [01:53<11:14,  1.72it/s]\u001b[A\n","Iteration:  15% 197/1357 [01:54<11:14,  1.72it/s]\u001b[A\n","Iteration:  15% 198/1357 [01:55<11:11,  1.73it/s]\u001b[A\n","Iteration:  15% 199/1357 [01:55<11:10,  1.73it/s]\u001b[A\n","Iteration:  15% 200/1357 [01:56<11:11,  1.72it/s]\u001b[A\n","Iteration:  15% 201/1357 [01:56<11:13,  1.72it/s]\u001b[A\n","Iteration:  15% 202/1357 [01:57<11:13,  1.72it/s]\u001b[A\n","Iteration:  15% 203/1357 [01:57<11:13,  1.71it/s]\u001b[A\n","Iteration:  15% 204/1357 [01:58<11:09,  1.72it/s]\u001b[A\n","Iteration:  15% 205/1357 [01:59<11:06,  1.73it/s]\u001b[A\n","Iteration:  15% 206/1357 [01:59<11:07,  1.72it/s]\u001b[A\n","Iteration:  15% 207/1357 [02:00<11:08,  1.72it/s]\u001b[A\n","Iteration:  15% 208/1357 [02:00<11:08,  1.72it/s]\u001b[A\n","Iteration:  15% 209/1357 [02:01<11:07,  1.72it/s]\u001b[A\n","Iteration:  15% 210/1357 [02:01<11:04,  1.73it/s]\u001b[A\n","Iteration:  16% 211/1357 [02:02<11:01,  1.73it/s]\u001b[A\n","Iteration:  16% 212/1357 [02:03<11:03,  1.73it/s]\u001b[A\n","Iteration:  16% 213/1357 [02:03<11:04,  1.72it/s]\u001b[A\n","Iteration:  16% 214/1357 [02:04<11:03,  1.72it/s]\u001b[A\n","Iteration:  16% 215/1357 [02:04<11:02,  1.72it/s]\u001b[A\n","Iteration:  16% 216/1357 [02:05<11:03,  1.72it/s]\u001b[A\n","Iteration:  16% 217/1357 [02:06<11:00,  1.73it/s]\u001b[A\n","Iteration:  16% 218/1357 [02:06<11:00,  1.72it/s]\u001b[A\n","Iteration:  16% 219/1357 [02:07<10:58,  1.73it/s]\u001b[A\n","Iteration:  16% 220/1357 [02:07<10:59,  1.72it/s]\u001b[A\n","Iteration:  16% 221/1357 [02:08<10:59,  1.72it/s]\u001b[A\n","Iteration:  16% 222/1357 [02:08<11:00,  1.72it/s]\u001b[A\n","Iteration:  16% 223/1357 [02:09<10:59,  1.72it/s]\u001b[A\n","Iteration:  17% 224/1357 [02:10<11:00,  1.71it/s]\u001b[A\n","Iteration:  17% 225/1357 [02:10<10:59,  1.72it/s]\u001b[A\n","Iteration:  17% 226/1357 [02:11<10:56,  1.72it/s]\u001b[A\n","Iteration:  17% 227/1357 [02:11<10:57,  1.72it/s]\u001b[A\n","Iteration:  17% 228/1357 [02:12<10:56,  1.72it/s]\u001b[A\n","Iteration:  17% 229/1357 [02:13<10:55,  1.72it/s]\u001b[A\n","Iteration:  17% 230/1357 [02:13<10:55,  1.72it/s]\u001b[A\n","Iteration:  17% 231/1357 [02:14<10:54,  1.72it/s]\u001b[A\n","Iteration:  17% 232/1357 [02:14<10:51,  1.73it/s]\u001b[A\n","Iteration:  17% 233/1357 [02:15<10:51,  1.73it/s]\u001b[A\n","Iteration:  17% 234/1357 [02:15<10:51,  1.72it/s]\u001b[A\n","Iteration:  17% 235/1357 [02:16<10:53,  1.72it/s]\u001b[A\n","Iteration:  17% 236/1357 [02:17<10:52,  1.72it/s]\u001b[A\n","Iteration:  17% 237/1357 [02:17<10:50,  1.72it/s]\u001b[A\n","Iteration:  18% 238/1357 [02:18<10:49,  1.72it/s]\u001b[A\n","Iteration:  18% 239/1357 [02:18<10:47,  1.73it/s]\u001b[A\n","Iteration:  18% 240/1357 [02:19<10:47,  1.72it/s]\u001b[A\n","Iteration:  18% 241/1357 [02:20<10:48,  1.72it/s]\u001b[A\n","Iteration:  18% 242/1357 [02:20<10:47,  1.72it/s]\u001b[A\n","Iteration:  18% 243/1357 [02:21<10:48,  1.72it/s]\u001b[A\n","Iteration:  18% 244/1357 [02:21<10:47,  1.72it/s]\u001b[A\n","Iteration:  18% 245/1357 [02:22<10:46,  1.72it/s]\u001b[A\n","Iteration:  18% 246/1357 [02:22<10:46,  1.72it/s]\u001b[A\n","Iteration:  18% 247/1357 [02:23<10:46,  1.72it/s]\u001b[A\n","Iteration:  18% 248/1357 [02:24<10:52,  1.70it/s]\u001b[A\n","Iteration:  18% 249/1357 [02:24<10:46,  1.71it/s]\u001b[A\n","Iteration:  18% 250/1357 [02:25<10:46,  1.71it/s]\u001b[A\n","Iteration:  18% 251/1357 [02:25<10:43,  1.72it/s]\u001b[A\n","Iteration:  19% 252/1357 [02:26<10:42,  1.72it/s]\u001b[A\n","Iteration:  19% 253/1357 [02:26<10:42,  1.72it/s]\u001b[A\n","Iteration:  19% 254/1357 [02:27<10:41,  1.72it/s]\u001b[A\n","Iteration:  19% 255/1357 [02:28<10:39,  1.72it/s]\u001b[A\n","Iteration:  19% 256/1357 [02:28<10:39,  1.72it/s]\u001b[A\n","Iteration:  19% 257/1357 [02:29<10:38,  1.72it/s]\u001b[A\n","Iteration:  19% 258/1357 [02:29<10:41,  1.71it/s]\u001b[A\n","Iteration:  19% 259/1357 [02:30<10:40,  1.71it/s]\u001b[A\n","Iteration:  19% 260/1357 [02:31<10:37,  1.72it/s]\u001b[A\n","Iteration:  19% 261/1357 [02:31<10:35,  1.72it/s]\u001b[A\n","Iteration:  19% 262/1357 [02:32<10:35,  1.72it/s]\u001b[A\n","Iteration:  19% 263/1357 [02:32<10:35,  1.72it/s]\u001b[A\n","Iteration:  19% 264/1357 [02:33<10:38,  1.71it/s]\u001b[A\n","Iteration:  20% 265/1357 [02:33<10:38,  1.71it/s]\u001b[A\n","Iteration:  20% 266/1357 [02:34<10:34,  1.72it/s]\u001b[A\n","Iteration:  20% 267/1357 [02:35<10:31,  1.73it/s]\u001b[A\n","Iteration:  20% 268/1357 [02:35<10:33,  1.72it/s]\u001b[A\n","Iteration:  20% 269/1357 [02:36<10:33,  1.72it/s]\u001b[A\n","Iteration:  20% 270/1357 [02:36<10:33,  1.71it/s]\u001b[A\n","Iteration:  20% 271/1357 [02:37<10:32,  1.72it/s]\u001b[A\n","Iteration:  20% 272/1357 [02:38<10:30,  1.72it/s]\u001b[A\n","Iteration:  20% 273/1357 [02:38<10:29,  1.72it/s]\u001b[A\n","Iteration:  20% 274/1357 [02:39<10:30,  1.72it/s]\u001b[A\n","Iteration:  20% 275/1357 [02:39<10:31,  1.71it/s]\u001b[A\n","Iteration:  20% 276/1357 [02:40<10:29,  1.72it/s]\u001b[A\n","Iteration:  20% 277/1357 [02:40<10:26,  1.72it/s]\u001b[A\n","Iteration:  20% 278/1357 [02:41<10:26,  1.72it/s]\u001b[A\n","Iteration:  21% 279/1357 [02:42<10:24,  1.73it/s]\u001b[A\n","Iteration:  21% 280/1357 [02:42<10:25,  1.72it/s]\u001b[A\n","Iteration:  21% 281/1357 [02:43<10:24,  1.72it/s]\u001b[A\n","Iteration:  21% 282/1357 [02:43<10:22,  1.73it/s]\u001b[A\n","Iteration:  21% 283/1357 [02:44<10:22,  1.73it/s]\u001b[A\n","Iteration:  21% 284/1357 [02:45<10:23,  1.72it/s]\u001b[A\n","Iteration:  21% 285/1357 [02:45<10:23,  1.72it/s]\u001b[A\n","Iteration:  21% 286/1357 [02:46<10:21,  1.72it/s]\u001b[A\n","Iteration:  21% 287/1357 [02:46<10:21,  1.72it/s]\u001b[A\n","Iteration:  21% 288/1357 [02:47<10:20,  1.72it/s]\u001b[A\n","Iteration:  21% 289/1357 [02:47<10:17,  1.73it/s]\u001b[A\n","Iteration:  21% 290/1357 [02:48<10:17,  1.73it/s]\u001b[A\n","Iteration:  21% 291/1357 [02:49<10:15,  1.73it/s]\u001b[A\n","Iteration:  22% 292/1357 [02:49<10:15,  1.73it/s]\u001b[A\n","Iteration:  22% 293/1357 [02:50<10:15,  1.73it/s]\u001b[A\n","Iteration:  22% 294/1357 [02:50<10:14,  1.73it/s]\u001b[A\n","Iteration:  22% 295/1357 [02:51<10:11,  1.74it/s]\u001b[A\n","Iteration:  22% 296/1357 [02:51<10:13,  1.73it/s]\u001b[A\n","Iteration:  22% 297/1357 [02:52<10:15,  1.72it/s]\u001b[A\n","Iteration:  22% 298/1357 [02:53<10:14,  1.72it/s]\u001b[A\n","Iteration:  22% 299/1357 [02:53<10:13,  1.72it/s]\u001b[A\n","Iteration:  22% 300/1357 [02:54<10:14,  1.72it/s]\u001b[A\n","Iteration:  22% 301/1357 [02:54<10:12,  1.72it/s]\u001b[A\n","Iteration:  22% 302/1357 [02:55<10:12,  1.72it/s]\u001b[A\n","Iteration:  22% 303/1357 [02:56<10:11,  1.72it/s]\u001b[A\n","Iteration:  22% 304/1357 [02:56<10:11,  1.72it/s]\u001b[A\n","Iteration:  22% 305/1357 [02:57<10:11,  1.72it/s]\u001b[A\n","Iteration:  23% 306/1357 [02:57<10:11,  1.72it/s]\u001b[A\n","Iteration:  23% 307/1357 [02:58<10:08,  1.73it/s]\u001b[A\n","Iteration:  23% 308/1357 [02:58<10:06,  1.73it/s]\u001b[A\n","Iteration:  23% 309/1357 [02:59<10:07,  1.73it/s]\u001b[A\n","Iteration:  23% 310/1357 [03:00<10:06,  1.73it/s]\u001b[A\n","Iteration:  23% 311/1357 [03:00<10:05,  1.73it/s]\u001b[A\n","Iteration:  23% 312/1357 [03:01<10:06,  1.72it/s]\u001b[A\n","Iteration:  23% 313/1357 [03:01<10:05,  1.72it/s]\u001b[A\n","Iteration:  23% 314/1357 [03:02<10:07,  1.72it/s]\u001b[A\n","Iteration:  23% 315/1357 [03:02<10:07,  1.72it/s]\u001b[A\n","Iteration:  23% 316/1357 [03:03<10:04,  1.72it/s]\u001b[A\n","Iteration:  23% 317/1357 [03:04<10:02,  1.73it/s]\u001b[A\n","Iteration:  23% 318/1357 [03:04<10:03,  1.72it/s]\u001b[A\n","Iteration:  24% 319/1357 [03:05<10:05,  1.72it/s]\u001b[A\n","Iteration:  24% 320/1357 [03:05<10:03,  1.72it/s]\u001b[A\n","Iteration:  24% 321/1357 [03:06<10:04,  1.71it/s]\u001b[A\n","Iteration:  24% 322/1357 [03:07<10:00,  1.72it/s]\u001b[A\n","Iteration:  24% 323/1357 [03:07<09:58,  1.73it/s]\u001b[A\n","Iteration:  24% 324/1357 [03:08<09:56,  1.73it/s]\u001b[A\n","Iteration:  24% 325/1357 [03:08<09:57,  1.73it/s]\u001b[A\n","Iteration:  24% 326/1357 [03:09<09:57,  1.73it/s]\u001b[A\n","Iteration:  24% 327/1357 [03:09<09:57,  1.72it/s]\u001b[A\n","Iteration:  24% 328/1357 [03:10<09:59,  1.72it/s]\u001b[A\n","Iteration:  24% 329/1357 [03:11<09:57,  1.72it/s]\u001b[A\n","Iteration:  24% 330/1357 [03:11<09:55,  1.72it/s]\u001b[A\n","Iteration:  24% 331/1357 [03:12<09:55,  1.72it/s]\u001b[A\n","Iteration:  24% 332/1357 [03:12<09:57,  1.71it/s]\u001b[A\n","Iteration:  25% 333/1357 [03:13<09:57,  1.71it/s]\u001b[A\n","Iteration:  25% 334/1357 [03:14<09:58,  1.71it/s]\u001b[A\n","Iteration:  25% 335/1357 [03:14<09:55,  1.72it/s]\u001b[A\n","Iteration:  25% 336/1357 [03:15<09:53,  1.72it/s]\u001b[A\n","Iteration:  25% 337/1357 [03:15<09:52,  1.72it/s]\u001b[A\n","Iteration:  25% 338/1357 [03:16<09:53,  1.72it/s]\u001b[A\n","Iteration:  25% 339/1357 [03:16<09:52,  1.72it/s]\u001b[A\n","Iteration:  25% 340/1357 [03:17<09:52,  1.72it/s]\u001b[A\n","Iteration:  25% 341/1357 [03:18<09:50,  1.72it/s]\u001b[A\n","Iteration:  25% 342/1357 [03:18<09:49,  1.72it/s]\u001b[A\n","Iteration:  25% 343/1357 [03:19<09:50,  1.72it/s]\u001b[A\n","Iteration:  25% 344/1357 [03:19<09:46,  1.73it/s]\u001b[A\n","Iteration:  25% 345/1357 [03:20<09:44,  1.73it/s]\u001b[A\n","Iteration:  25% 346/1357 [03:21<09:47,  1.72it/s]\u001b[A\n","Iteration:  26% 347/1357 [03:21<09:48,  1.72it/s]\u001b[A\n","Iteration:  26% 348/1357 [03:22<09:45,  1.72it/s]\u001b[A\n","Iteration:  26% 349/1357 [03:22<09:47,  1.72it/s]\u001b[A\n","Iteration:  26% 350/1357 [03:23<09:45,  1.72it/s]\u001b[A\n","Iteration:  26% 351/1357 [03:23<09:42,  1.73it/s]\u001b[A\n","Iteration:  26% 352/1357 [03:24<09:43,  1.72it/s]\u001b[A\n","Iteration:  26% 353/1357 [03:25<09:44,  1.72it/s]\u001b[A\n","Iteration:  26% 354/1357 [03:25<09:42,  1.72it/s]\u001b[A\n","Iteration:  26% 355/1357 [03:26<09:41,  1.72it/s]\u001b[A\n","Iteration:  26% 356/1357 [03:26<09:42,  1.72it/s]\u001b[A\n","Iteration:  26% 357/1357 [03:27<09:39,  1.73it/s]\u001b[A\n","Iteration:  26% 358/1357 [03:27<09:38,  1.73it/s]\u001b[A\n","Iteration:  26% 359/1357 [03:28<09:39,  1.72it/s]\u001b[A\n","Iteration:  27% 360/1357 [03:29<09:42,  1.71it/s]\u001b[A\n","Iteration:  27% 361/1357 [03:29<09:41,  1.71it/s]\u001b[A\n","Iteration:  27% 362/1357 [03:30<09:41,  1.71it/s]\u001b[A\n","Iteration:  27% 363/1357 [03:30<09:39,  1.72it/s]\u001b[A\n","Iteration:  27% 364/1357 [03:31<09:37,  1.72it/s]\u001b[A\n","Iteration:  27% 365/1357 [03:32<09:36,  1.72it/s]\u001b[A\n","Iteration:  27% 366/1357 [03:32<09:36,  1.72it/s]\u001b[A\n","Iteration:  27% 367/1357 [03:33<09:39,  1.71it/s]\u001b[A\n","Iteration:  27% 368/1357 [03:33<09:38,  1.71it/s]\u001b[A\n","Iteration:  27% 369/1357 [03:34<09:36,  1.71it/s]\u001b[A\n","Iteration:  27% 370/1357 [03:34<09:37,  1.71it/s]\u001b[A\n","Iteration:  27% 371/1357 [03:35<09:34,  1.72it/s]\u001b[A\n","Iteration:  27% 372/1357 [03:36<09:30,  1.73it/s]\u001b[A\n","Iteration:  27% 373/1357 [03:36<09:31,  1.72it/s]\u001b[A\n","Iteration:  28% 374/1357 [03:37<09:30,  1.72it/s]\u001b[A\n","Iteration:  28% 375/1357 [03:37<09:30,  1.72it/s]\u001b[A\n","Iteration:  28% 376/1357 [03:38<09:32,  1.71it/s]\u001b[A\n","Iteration:  28% 377/1357 [03:39<09:32,  1.71it/s]\u001b[A\n","Iteration:  28% 378/1357 [03:39<09:29,  1.72it/s]\u001b[A\n","Iteration:  28% 379/1357 [03:40<09:28,  1.72it/s]\u001b[A\n","Iteration:  28% 380/1357 [03:40<09:27,  1.72it/s]\u001b[A\n","Iteration:  28% 381/1357 [03:41<09:28,  1.72it/s]\u001b[A\n","Iteration:  28% 382/1357 [03:41<09:26,  1.72it/s]\u001b[A\n","Iteration:  28% 383/1357 [03:42<09:26,  1.72it/s]\u001b[A\n","Iteration:  28% 384/1357 [03:43<09:24,  1.72it/s]\u001b[A\n","Iteration:  28% 385/1357 [03:43<09:23,  1.72it/s]\u001b[A\n","Iteration:  28% 386/1357 [03:44<09:22,  1.73it/s]\u001b[A\n","Iteration:  29% 387/1357 [03:44<09:24,  1.72it/s]\u001b[A\n","Iteration:  29% 388/1357 [03:45<09:28,  1.71it/s]\u001b[A\n","Iteration:  29% 389/1357 [03:46<09:25,  1.71it/s]\u001b[A\n","Iteration:  29% 390/1357 [03:46<09:23,  1.72it/s]\u001b[A\n","Iteration:  29% 391/1357 [03:47<09:25,  1.71it/s]\u001b[A\n","Iteration:  29% 392/1357 [03:47<09:24,  1.71it/s]\u001b[A\n","Iteration:  29% 393/1357 [03:48<09:24,  1.71it/s]\u001b[A\n","Iteration:  29% 394/1357 [03:48<09:22,  1.71it/s]\u001b[A\n","Iteration:  29% 395/1357 [03:49<09:21,  1.71it/s]\u001b[A\n","Iteration:  29% 396/1357 [03:50<09:19,  1.72it/s]\u001b[A\n","Iteration:  29% 397/1357 [03:50<09:16,  1.72it/s]\u001b[A\n","Iteration:  29% 398/1357 [03:51<09:17,  1.72it/s]\u001b[A\n","Iteration:  29% 399/1357 [03:51<09:13,  1.73it/s]\u001b[A\n","Iteration:  29% 400/1357 [03:52<09:13,  1.73it/s]\u001b[A\n","Iteration:  30% 401/1357 [03:53<09:14,  1.72it/s]\u001b[A\n","Iteration:  30% 402/1357 [03:53<09:17,  1.71it/s]\u001b[A\n","Iteration:  30% 403/1357 [03:54<09:16,  1.72it/s]\u001b[A\n","Iteration:  30% 404/1357 [03:54<09:14,  1.72it/s]\u001b[A\n","Iteration:  30% 405/1357 [03:55<09:15,  1.71it/s]\u001b[A\n","Iteration:  30% 406/1357 [03:55<09:10,  1.73it/s]\u001b[A\n","Iteration:  30% 407/1357 [03:56<09:14,  1.71it/s]\u001b[A\n","Iteration:  30% 408/1357 [03:57<09:14,  1.71it/s]\u001b[A\n","Iteration:  30% 409/1357 [03:57<09:11,  1.72it/s]\u001b[A\n","Iteration:  30% 410/1357 [03:58<09:13,  1.71it/s]\u001b[A\n","Iteration:  30% 411/1357 [03:58<09:12,  1.71it/s]\u001b[A\n","Iteration:  30% 412/1357 [03:59<09:09,  1.72it/s]\u001b[A\n","Iteration:  30% 413/1357 [04:00<09:07,  1.72it/s]\u001b[A\n","Iteration:  31% 414/1357 [04:00<09:07,  1.72it/s]\u001b[A\n","Iteration:  31% 415/1357 [04:01<09:07,  1.72it/s]\u001b[A\n","Iteration:  31% 416/1357 [04:01<09:06,  1.72it/s]\u001b[A\n","Iteration:  31% 417/1357 [04:02<09:06,  1.72it/s]\u001b[A\n","Iteration:  31% 418/1357 [04:02<09:04,  1.73it/s]\u001b[A\n","Iteration:  31% 419/1357 [04:03<09:03,  1.72it/s]\u001b[A\n","Iteration:  31% 420/1357 [04:04<09:04,  1.72it/s]\u001b[A\n","Iteration:  31% 421/1357 [04:04<09:04,  1.72it/s]\u001b[A\n","Iteration:  31% 422/1357 [04:05<09:05,  1.71it/s]\u001b[A\n","Iteration:  31% 423/1357 [04:05<09:04,  1.72it/s]\u001b[A\n","Iteration:  31% 424/1357 [04:06<09:00,  1.73it/s]\u001b[A\n","Iteration:  31% 425/1357 [04:06<09:00,  1.72it/s]\u001b[A\n","Iteration:  31% 426/1357 [04:07<09:00,  1.72it/s]\u001b[A\n","Iteration:  31% 427/1357 [04:08<09:01,  1.72it/s]\u001b[A\n","Iteration:  32% 428/1357 [04:08<09:02,  1.71it/s]\u001b[A\n","Iteration:  32% 429/1357 [04:09<09:00,  1.72it/s]\u001b[A\n","Iteration:  32% 430/1357 [04:09<08:58,  1.72it/s]\u001b[A\n","Iteration:  32% 431/1357 [04:10<08:57,  1.72it/s]\u001b[A\n","Iteration:  32% 432/1357 [04:11<08:57,  1.72it/s]\u001b[A\n","Iteration:  32% 433/1357 [04:11<08:58,  1.72it/s]\u001b[A\n","Iteration:  32% 434/1357 [04:12<08:54,  1.73it/s]\u001b[A\n","Iteration:  32% 435/1357 [04:12<08:55,  1.72it/s]\u001b[A\n","Iteration:  32% 436/1357 [04:13<08:56,  1.72it/s]\u001b[A\n","Iteration:  32% 437/1357 [04:13<08:54,  1.72it/s]\u001b[A\n","Iteration:  32% 438/1357 [04:14<08:54,  1.72it/s]\u001b[A\n","Iteration:  32% 439/1357 [04:15<08:54,  1.72it/s]\u001b[A\n","Iteration:  32% 440/1357 [04:15<08:53,  1.72it/s]\u001b[A\n","Iteration:  32% 441/1357 [04:16<08:52,  1.72it/s]\u001b[A\n","Iteration:  33% 442/1357 [04:16<08:51,  1.72it/s]\u001b[A\n","Iteration:  33% 443/1357 [04:17<08:51,  1.72it/s]\u001b[A\n","Iteration:  33% 444/1357 [04:18<08:50,  1.72it/s]\u001b[A\n","Iteration:  33% 445/1357 [04:18<08:50,  1.72it/s]\u001b[A\n","Iteration:  33% 446/1357 [04:19<08:50,  1.72it/s]\u001b[A\n","Iteration:  33% 447/1357 [04:19<08:47,  1.72it/s]\u001b[A\n","Iteration:  33% 448/1357 [04:20<08:49,  1.72it/s]\u001b[A\n","Iteration:  33% 449/1357 [04:20<08:49,  1.72it/s]\u001b[A\n","Iteration:  33% 450/1357 [04:21<08:49,  1.71it/s]\u001b[A\n","Iteration:  33% 451/1357 [04:22<08:48,  1.72it/s]\u001b[A\n","Iteration:  33% 452/1357 [04:22<08:44,  1.72it/s]\u001b[A\n","Iteration:  33% 453/1357 [04:23<08:43,  1.73it/s]\u001b[A\n","Iteration:  33% 454/1357 [04:23<08:43,  1.72it/s]\u001b[A\n","Iteration:  34% 455/1357 [04:24<08:44,  1.72it/s]\u001b[A\n","Iteration:  34% 456/1357 [04:25<08:43,  1.72it/s]\u001b[A\n","Iteration:  34% 457/1357 [04:25<08:42,  1.72it/s]\u001b[A\n","Iteration:  34% 458/1357 [04:26<08:41,  1.72it/s]\u001b[A\n","Iteration:  34% 459/1357 [04:26<08:43,  1.72it/s]\u001b[A\n","Iteration:  34% 460/1357 [04:27<08:43,  1.71it/s]\u001b[A\n","Iteration:  34% 461/1357 [04:27<08:39,  1.72it/s]\u001b[A\n","Iteration:  34% 462/1357 [04:28<08:38,  1.73it/s]\u001b[A\n","Iteration:  34% 463/1357 [04:29<08:38,  1.72it/s]\u001b[A\n","Iteration:  34% 464/1357 [04:29<08:40,  1.72it/s]\u001b[A\n","Iteration:  34% 465/1357 [04:30<08:41,  1.71it/s]\u001b[A\n","Iteration:  34% 466/1357 [04:30<08:40,  1.71it/s]\u001b[A\n","Iteration:  34% 467/1357 [04:31<08:37,  1.72it/s]\u001b[A\n","Iteration:  34% 468/1357 [04:31<08:35,  1.73it/s]\u001b[A\n","Iteration:  35% 469/1357 [04:32<08:35,  1.72it/s]\u001b[A\n","Iteration:  35% 470/1357 [04:33<08:39,  1.71it/s]\u001b[A\n","Iteration:  35% 471/1357 [04:33<08:36,  1.72it/s]\u001b[A\n","Iteration:  35% 472/1357 [04:34<08:35,  1.72it/s]\u001b[A\n","Iteration:  35% 473/1357 [04:34<08:34,  1.72it/s]\u001b[A\n","Iteration:  35% 474/1357 [04:35<08:32,  1.72it/s]\u001b[A\n","Iteration:  35% 475/1357 [04:36<08:32,  1.72it/s]\u001b[A\n","Iteration:  35% 476/1357 [04:36<08:36,  1.71it/s]\u001b[A\n","Iteration:  35% 477/1357 [04:37<08:34,  1.71it/s]\u001b[A\n","Iteration:  35% 478/1357 [04:37<08:32,  1.71it/s]\u001b[A\n","Iteration:  35% 479/1357 [04:38<08:32,  1.71it/s]\u001b[A\n","Iteration:  35% 480/1357 [04:38<08:32,  1.71it/s]\u001b[A\n","Iteration:  35% 481/1357 [04:39<08:31,  1.71it/s]\u001b[A\n","Iteration:  36% 482/1357 [04:40<08:30,  1.71it/s]\u001b[A\n","Iteration:  36% 483/1357 [04:40<08:30,  1.71it/s]\u001b[A\n","Iteration:  36% 484/1357 [04:41<08:28,  1.72it/s]\u001b[A\n","Iteration:  36% 485/1357 [04:41<08:28,  1.71it/s]\u001b[A\n","Iteration:  36% 486/1357 [04:42<08:26,  1.72it/s]\u001b[A\n","Iteration:  36% 487/1357 [04:43<08:25,  1.72it/s]\u001b[A\n","Iteration:  36% 488/1357 [04:43<08:24,  1.72it/s]\u001b[A\n","Iteration:  36% 489/1357 [04:44<08:25,  1.72it/s]\u001b[A\n","Iteration:  36% 490/1357 [04:44<08:25,  1.71it/s]\u001b[A\n","Iteration:  36% 491/1357 [04:45<08:25,  1.71it/s]\u001b[A\n","Iteration:  36% 492/1357 [04:45<08:23,  1.72it/s]\u001b[A\n","Iteration:  36% 493/1357 [04:46<08:22,  1.72it/s]\u001b[A\n","Iteration:  36% 494/1357 [04:47<08:21,  1.72it/s]\u001b[A\n","Iteration:  36% 495/1357 [04:47<08:19,  1.73it/s]\u001b[A\n","Iteration:  37% 496/1357 [04:48<08:18,  1.73it/s]\u001b[A\n","Iteration:  37% 497/1357 [04:48<08:17,  1.73it/s]\u001b[A\n","Iteration:  37% 498/1357 [04:49<08:18,  1.72it/s]\u001b[A\n","Iteration:  37% 499/1357 [04:50<08:18,  1.72it/s]\u001b[A\n","Iteration:  37% 500/1357 [04:50<08:19,  1.72it/s]\u001b[A12/16/2021 06:03:03 - INFO - __main__ -   ***** Running evaluation on dev dataset (10000 step) *****\n","12/16/2021 06:03:03 - INFO - __main__ -     Num examples = 5426\n","12/16/2021 06:03:03 - INFO - __main__ -     Eval Batch size = 32\n","\n","\n","Evaluating:   0% 0/170 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluating:   1% 1/170 [00:00<00:31,  5.34it/s]\u001b[A\u001b[A\n","\n","Evaluating:   1% 2/170 [00:00<00:31,  5.39it/s]\u001b[A\u001b[A\n","\n","Evaluating:   2% 3/170 [00:00<00:32,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:   2% 4/170 [00:00<00:32,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:   3% 5/170 [00:00<00:31,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:   4% 6/170 [00:01<00:31,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:   4% 7/170 [00:01<00:31,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:   5% 8/170 [00:01<00:31,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:   5% 9/170 [00:01<00:31,  5.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:   6% 10/170 [00:01<00:30,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:   6% 11/170 [00:02<00:30,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:   7% 12/170 [00:02<00:30,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:   8% 13/170 [00:02<00:30,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:   8% 14/170 [00:02<00:30,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:   9% 15/170 [00:02<00:29,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:   9% 16/170 [00:03<00:29,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  10% 17/170 [00:03<00:29,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  11% 18/170 [00:03<00:29,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  11% 19/170 [00:03<00:29,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  12% 20/170 [00:03<00:29,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  12% 21/170 [00:04<00:28,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  13% 22/170 [00:04<00:28,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  14% 23/170 [00:04<00:28,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  14% 24/170 [00:04<00:28,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  15% 25/170 [00:04<00:27,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  15% 26/170 [00:05<00:27,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  16% 27/170 [00:05<00:27,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  16% 28/170 [00:05<00:27,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  17% 29/170 [00:05<00:27,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  18% 30/170 [00:05<00:26,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  18% 31/170 [00:05<00:26,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  19% 32/170 [00:06<00:26,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  19% 33/170 [00:06<00:26,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  20% 34/170 [00:06<00:26,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  21% 35/170 [00:06<00:25,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  21% 36/170 [00:06<00:25,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  22% 37/170 [00:07<00:25,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  22% 38/170 [00:07<00:25,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  23% 39/170 [00:07<00:25,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  24% 40/170 [00:07<00:25,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  24% 41/170 [00:07<00:24,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  25% 42/170 [00:08<00:24,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  25% 43/170 [00:08<00:24,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  26% 44/170 [00:08<00:24,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  26% 45/170 [00:08<00:24,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  27% 46/170 [00:08<00:24,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  28% 47/170 [00:09<00:23,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  28% 48/170 [00:09<00:23,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  29% 49/170 [00:09<00:23,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  29% 50/170 [00:09<00:23,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  30% 51/170 [00:09<00:22,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  31% 52/170 [00:10<00:22,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  31% 53/170 [00:10<00:22,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  32% 54/170 [00:10<00:22,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  32% 55/170 [00:10<00:22,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  33% 56/170 [00:10<00:21,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  34% 57/170 [00:10<00:21,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  34% 58/170 [00:11<00:21,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  35% 59/170 [00:11<00:21,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  35% 60/170 [00:11<00:21,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  36% 61/170 [00:11<00:21,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  36% 62/170 [00:11<00:20,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  37% 63/170 [00:12<00:20,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  38% 64/170 [00:12<00:20,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  38% 65/170 [00:12<00:20,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  39% 66/170 [00:12<00:20,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  39% 67/170 [00:12<00:19,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  40% 68/170 [00:13<00:19,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  41% 69/170 [00:13<00:19,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  41% 70/170 [00:13<00:19,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  42% 71/170 [00:13<00:19,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  42% 72/170 [00:13<00:19,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  43% 73/170 [00:14<00:18,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  44% 74/170 [00:14<00:18,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  44% 75/170 [00:14<00:18,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  45% 76/170 [00:14<00:18,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  45% 77/170 [00:14<00:17,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  46% 78/170 [00:15<00:17,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  46% 79/170 [00:15<00:17,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  47% 80/170 [00:15<00:17,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  48% 81/170 [00:15<00:17,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  48% 82/170 [00:15<00:16,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  49% 83/170 [00:16<00:16,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  49% 84/170 [00:16<00:16,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  50% 85/170 [00:16<00:16,  5.12it/s]\u001b[A\u001b[A\n","\n","Evaluating:  51% 86/170 [00:16<00:16,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  51% 87/170 [00:16<00:15,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  52% 88/170 [00:16<00:15,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  52% 89/170 [00:17<00:15,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  53% 90/170 [00:17<00:15,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  54% 91/170 [00:17<00:15,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  54% 92/170 [00:17<00:15,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  55% 93/170 [00:17<00:14,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  55% 94/170 [00:18<00:14,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  56% 95/170 [00:18<00:14,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  56% 96/170 [00:18<00:14,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  57% 97/170 [00:18<00:14,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  58% 98/170 [00:18<00:13,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  58% 99/170 [00:19<00:13,  5.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  59% 100/170 [00:19<00:13,  5.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  59% 101/170 [00:19<00:13,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  60% 102/170 [00:19<00:13,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  61% 103/170 [00:19<00:12,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  61% 104/170 [00:20<00:12,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 105/170 [00:20<00:12,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 106/170 [00:20<00:12,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  63% 107/170 [00:20<00:12,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  64% 108/170 [00:20<00:11,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  64% 109/170 [00:21<00:11,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  65% 110/170 [00:21<00:11,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  65% 111/170 [00:21<00:11,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  66% 112/170 [00:21<00:11,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  66% 113/170 [00:21<00:10,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  67% 114/170 [00:21<00:10,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  68% 115/170 [00:22<00:10,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  68% 116/170 [00:22<00:10,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  69% 117/170 [00:22<00:10,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  69% 118/170 [00:22<00:10,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  70% 119/170 [00:22<00:09,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  71% 120/170 [00:23<00:09,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  71% 121/170 [00:23<00:09,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  72% 122/170 [00:23<00:09,  5.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  72% 123/170 [00:23<00:09,  5.12it/s]\u001b[A\u001b[A\n","\n","Evaluating:  73% 124/170 [00:23<00:08,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  74% 125/170 [00:24<00:08,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  74% 126/170 [00:24<00:08,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 127/170 [00:24<00:08,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 128/170 [00:24<00:08,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  76% 129/170 [00:24<00:07,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  76% 130/170 [00:25<00:07,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  77% 131/170 [00:25<00:07,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  78% 132/170 [00:25<00:07,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  78% 133/170 [00:25<00:07,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  79% 134/170 [00:25<00:06,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  79% 135/170 [00:26<00:06,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  80% 136/170 [00:26<00:06,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  81% 137/170 [00:26<00:06,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  81% 138/170 [00:26<00:06,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  82% 139/170 [00:26<00:05,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  82% 140/170 [00:27<00:05,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  83% 141/170 [00:27<00:05,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  84% 142/170 [00:27<00:05,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  84% 143/170 [00:27<00:05,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  85% 144/170 [00:27<00:04,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  85% 145/170 [00:27<00:04,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  86% 146/170 [00:28<00:04,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  86% 147/170 [00:28<00:04,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  87% 148/170 [00:28<00:04,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 149/170 [00:28<00:04,  5.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 150/170 [00:28<00:03,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  89% 151/170 [00:29<00:03,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  89% 152/170 [00:29<00:03,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  90% 153/170 [00:29<00:03,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  91% 154/170 [00:29<00:03,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  91% 155/170 [00:29<00:02,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  92% 156/170 [00:30<00:02,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  92% 157/170 [00:30<00:02,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  93% 158/170 [00:30<00:02,  5.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  94% 159/170 [00:30<00:02,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  94% 160/170 [00:30<00:01,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  95% 161/170 [00:31<00:01,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  95% 162/170 [00:31<00:01,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  96% 163/170 [00:31<00:01,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  96% 164/170 [00:31<00:01,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  97% 165/170 [00:31<00:00,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  98% 166/170 [00:32<00:00,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  98% 167/170 [00:32<00:00,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  99% 168/170 [00:32<00:00,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  99% 169/170 [00:32<00:00,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating: 100% 170/170 [00:32<00:00,  5.20it/s]\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","12/16/2021 06:03:36 - INFO - __main__ -   ***** Eval results on dev dataset *****\n","12/16/2021 06:03:36 - INFO - __main__ -     accuracy = 0.3573534832288979\n","12/16/2021 06:03:36 - INFO - __main__ -     loss = 0.1473802882958861\n","12/16/2021 06:03:36 - INFO - __main__ -     macro_f1 = 0.3965381585137937\n","12/16/2021 06:03:36 - INFO - __main__ -     macro_precision = 0.4172346128139031\n","12/16/2021 06:03:36 - INFO - __main__ -     macro_recall = 0.41689222824601757\n","12/16/2021 06:03:36 - INFO - __main__ -     micro_f1 = 0.48565253037191625\n","12/16/2021 06:03:36 - INFO - __main__ -     micro_precision = 0.46298138411254797\n","12/16/2021 06:03:36 - INFO - __main__ -     micro_recall = 0.5106583072100314\n","12/16/2021 06:03:36 - INFO - __main__ -     weighted_f1 = 0.48530047001413007\n","12/16/2021 06:03:36 - INFO - __main__ -     weighted_precision = 0.4735439964881216\n","12/16/2021 06:03:36 - INFO - __main__ -     weighted_recall = 0.5106583072100314\n","12/16/2021 06:03:36 - INFO - transformers.configuration_utils -   Configuration saved in drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-10000/config.json\n","12/16/2021 06:03:38 - INFO - transformers.modeling_utils -   Model weights saved in drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-10000/pytorch_model.bin\n","12/16/2021 06:03:38 - INFO - __main__ -   Saving model checkpoint to drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-10000\n","\n","Iteration:  37% 501/1357 [05:26<2:37:48, 11.06s/it]\u001b[A\n","Iteration:  37% 502/1357 [05:26<1:52:46,  7.91s/it]\u001b[A\n","Iteration:  37% 503/1357 [05:27<1:21:20,  5.72s/it]\u001b[A\n","Iteration:  37% 504/1357 [05:27<59:20,  4.17s/it]  \u001b[A\n","Iteration:  37% 505/1357 [05:28<43:59,  3.10s/it]\u001b[A\n","Iteration:  37% 506/1357 [05:29<33:14,  2.34s/it]\u001b[A\n","Iteration:  37% 507/1357 [05:29<25:42,  1.82s/it]\u001b[A\n","Iteration:  37% 508/1357 [05:30<20:26,  1.44s/it]\u001b[A\n","Iteration:  38% 509/1357 [05:30<16:43,  1.18s/it]\u001b[A\n","Iteration:  38% 510/1357 [05:31<14:10,  1.00s/it]\u001b[A\n","Iteration:  38% 511/1357 [05:31<12:22,  1.14it/s]\u001b[A\n","Iteration:  38% 512/1357 [05:32<11:06,  1.27it/s]\u001b[A\n","Iteration:  38% 513/1357 [05:33<10:14,  1.37it/s]\u001b[A\n","Iteration:  38% 514/1357 [05:33<09:38,  1.46it/s]\u001b[A\n","Iteration:  38% 515/1357 [05:34<09:10,  1.53it/s]\u001b[A\n","Iteration:  38% 516/1357 [05:34<08:50,  1.58it/s]\u001b[A\n","Iteration:  38% 517/1357 [05:35<08:46,  1.60it/s]\u001b[A\n","Iteration:  38% 518/1357 [05:36<08:33,  1.63it/s]\u001b[A\n","Iteration:  38% 519/1357 [05:36<08:31,  1.64it/s]\u001b[A\n","Iteration:  38% 520/1357 [05:37<08:24,  1.66it/s]\u001b[A\n","Iteration:  38% 521/1357 [05:37<08:20,  1.67it/s]\u001b[A\n","Iteration:  38% 522/1357 [05:38<08:19,  1.67it/s]\u001b[A\n","Iteration:  39% 523/1357 [05:39<08:15,  1.68it/s]\u001b[A\n","Iteration:  39% 524/1357 [05:39<08:13,  1.69it/s]\u001b[A\n","Iteration:  39% 525/1357 [05:40<08:12,  1.69it/s]\u001b[A\n","Iteration:  39% 526/1357 [05:40<08:15,  1.68it/s]\u001b[A\n","Iteration:  39% 527/1357 [05:41<08:08,  1.70it/s]\u001b[A\n","Iteration:  39% 528/1357 [05:41<08:06,  1.70it/s]\u001b[A\n","Iteration:  39% 529/1357 [05:42<08:05,  1.71it/s]\u001b[A\n","Iteration:  39% 530/1357 [05:43<08:04,  1.71it/s]\u001b[A\n","Iteration:  39% 531/1357 [05:43<08:04,  1.70it/s]\u001b[A\n","Iteration:  39% 532/1357 [05:44<08:03,  1.71it/s]\u001b[A\n","Iteration:  39% 533/1357 [05:44<08:03,  1.70it/s]\u001b[A\n","Iteration:  39% 534/1357 [05:45<08:02,  1.71it/s]\u001b[A\n","Iteration:  39% 535/1357 [05:46<07:58,  1.72it/s]\u001b[A\n","Iteration:  39% 536/1357 [05:46<07:55,  1.73it/s]\u001b[A\n","Iteration:  40% 537/1357 [05:47<07:57,  1.72it/s]\u001b[A\n","Iteration:  40% 538/1357 [05:47<07:59,  1.71it/s]\u001b[A\n","Iteration:  40% 539/1357 [05:48<07:57,  1.71it/s]\u001b[A\n","Iteration:  40% 540/1357 [05:48<08:00,  1.70it/s]\u001b[A\n","Iteration:  40% 541/1357 [05:49<07:57,  1.71it/s]\u001b[A\n","Iteration:  40% 542/1357 [05:50<07:57,  1.71it/s]\u001b[A\n","Iteration:  40% 543/1357 [05:50<07:56,  1.71it/s]\u001b[A\n","Iteration:  40% 544/1357 [05:51<07:57,  1.70it/s]\u001b[A\n","Iteration:  40% 545/1357 [05:51<07:56,  1.70it/s]\u001b[A\n","Iteration:  40% 546/1357 [05:52<07:56,  1.70it/s]\u001b[A\n","Iteration:  40% 547/1357 [05:53<07:53,  1.71it/s]\u001b[A\n","Iteration:  40% 548/1357 [05:53<07:55,  1.70it/s]\u001b[A\n","Iteration:  40% 549/1357 [05:54<07:51,  1.71it/s]\u001b[A\n","Iteration:  41% 550/1357 [05:54<07:48,  1.72it/s]\u001b[A\n","Iteration:  41% 551/1357 [05:55<07:47,  1.72it/s]\u001b[A\n","Iteration:  41% 552/1357 [05:55<07:48,  1.72it/s]\u001b[A\n","Iteration:  41% 553/1357 [05:56<07:46,  1.72it/s]\u001b[A\n","Iteration:  41% 554/1357 [05:57<07:45,  1.73it/s]\u001b[A\n","Iteration:  41% 555/1357 [05:57<07:47,  1.71it/s]\u001b[A\n","Iteration:  41% 556/1357 [05:58<07:45,  1.72it/s]\u001b[A\n","Iteration:  41% 557/1357 [05:58<07:46,  1.71it/s]\u001b[A\n","Iteration:  41% 558/1357 [05:59<07:45,  1.72it/s]\u001b[A\n","Iteration:  41% 559/1357 [06:00<07:44,  1.72it/s]\u001b[A\n","Iteration:  41% 560/1357 [06:00<07:46,  1.71it/s]\u001b[A\n","Iteration:  41% 561/1357 [06:01<07:45,  1.71it/s]\u001b[A\n","Iteration:  41% 562/1357 [06:01<07:46,  1.70it/s]\u001b[A\n","Iteration:  41% 563/1357 [06:02<07:43,  1.71it/s]\u001b[A\n","Iteration:  42% 564/1357 [06:02<07:42,  1.71it/s]\u001b[A\n","Iteration:  42% 565/1357 [06:03<07:43,  1.71it/s]\u001b[A\n","Iteration:  42% 566/1357 [06:04<07:41,  1.71it/s]\u001b[A\n","Iteration:  42% 567/1357 [06:04<07:41,  1.71it/s]\u001b[A\n","Iteration:  42% 568/1357 [06:05<07:41,  1.71it/s]\u001b[A\n","Iteration:  42% 569/1357 [06:05<07:43,  1.70it/s]\u001b[A\n","Iteration:  42% 570/1357 [06:06<07:41,  1.70it/s]\u001b[A\n","Iteration:  42% 571/1357 [06:07<07:41,  1.70it/s]\u001b[A\n","Iteration:  42% 572/1357 [06:07<07:40,  1.71it/s]\u001b[A\n","Iteration:  42% 573/1357 [06:08<07:38,  1.71it/s]\u001b[A\n","Iteration:  42% 574/1357 [06:08<07:37,  1.71it/s]\u001b[A\n","Iteration:  42% 575/1357 [06:09<07:36,  1.71it/s]\u001b[A\n","Iteration:  42% 576/1357 [06:09<07:35,  1.71it/s]\u001b[A\n","Iteration:  43% 577/1357 [06:10<07:31,  1.73it/s]\u001b[A\n","Iteration:  43% 578/1357 [06:11<07:32,  1.72it/s]\u001b[A\n","Iteration:  43% 579/1357 [06:11<07:36,  1.71it/s]\u001b[A\n","Iteration:  43% 580/1357 [06:12<07:33,  1.71it/s]\u001b[A\n","Iteration:  43% 581/1357 [06:12<07:34,  1.71it/s]\u001b[A\n","Iteration:  43% 582/1357 [06:13<07:31,  1.72it/s]\u001b[A\n","Iteration:  43% 583/1357 [06:14<07:28,  1.73it/s]\u001b[A\n","Iteration:  43% 584/1357 [06:14<07:27,  1.73it/s]\u001b[A\n","Iteration:  43% 585/1357 [06:15<07:27,  1.72it/s]\u001b[A\n","Iteration:  43% 586/1357 [06:15<07:30,  1.71it/s]\u001b[A\n","Iteration:  43% 587/1357 [06:16<07:28,  1.72it/s]\u001b[A\n","Iteration:  43% 588/1357 [06:16<07:28,  1.72it/s]\u001b[A\n","Iteration:  43% 589/1357 [06:17<07:25,  1.72it/s]\u001b[A\n","Iteration:  43% 590/1357 [06:18<07:24,  1.73it/s]\u001b[A\n","Iteration:  44% 591/1357 [06:18<07:24,  1.72it/s]\u001b[A\n","Iteration:  44% 592/1357 [06:19<07:24,  1.72it/s]\u001b[A\n","Iteration:  44% 593/1357 [06:19<07:23,  1.72it/s]\u001b[A\n","Iteration:  44% 594/1357 [06:20<07:24,  1.72it/s]\u001b[A\n","Iteration:  44% 595/1357 [06:21<07:22,  1.72it/s]\u001b[A\n","Iteration:  44% 596/1357 [06:21<07:20,  1.73it/s]\u001b[A\n","Iteration:  44% 597/1357 [06:22<07:20,  1.73it/s]\u001b[A\n","Iteration:  44% 598/1357 [06:22<07:20,  1.72it/s]\u001b[A\n","Iteration:  44% 599/1357 [06:23<07:20,  1.72it/s]\u001b[A\n","Iteration:  44% 600/1357 [06:23<07:19,  1.72it/s]\u001b[A\n","Iteration:  44% 601/1357 [06:24<07:21,  1.71it/s]\u001b[A\n","Iteration:  44% 602/1357 [06:25<07:19,  1.72it/s]\u001b[A\n","Iteration:  44% 603/1357 [06:25<07:20,  1.71it/s]\u001b[A\n","Iteration:  45% 604/1357 [06:26<07:21,  1.71it/s]\u001b[A\n","Iteration:  45% 605/1357 [06:26<07:17,  1.72it/s]\u001b[A\n","Iteration:  45% 606/1357 [06:27<07:17,  1.72it/s]\u001b[A\n","Iteration:  45% 607/1357 [06:28<07:17,  1.71it/s]\u001b[A\n","Iteration:  45% 608/1357 [06:28<07:15,  1.72it/s]\u001b[A\n","Iteration:  45% 609/1357 [06:29<07:17,  1.71it/s]\u001b[A\n","Iteration:  45% 610/1357 [06:29<07:14,  1.72it/s]\u001b[A\n","Iteration:  45% 611/1357 [06:30<07:12,  1.73it/s]\u001b[A\n","Iteration:  45% 612/1357 [06:30<07:12,  1.72it/s]\u001b[A\n","Iteration:  45% 613/1357 [06:31<07:14,  1.71it/s]\u001b[A\n","Iteration:  45% 614/1357 [06:32<07:11,  1.72it/s]\u001b[A\n","Iteration:  45% 615/1357 [06:32<07:10,  1.72it/s]\u001b[A\n","Iteration:  45% 616/1357 [06:33<07:10,  1.72it/s]\u001b[A\n","Iteration:  45% 617/1357 [06:33<07:08,  1.73it/s]\u001b[A\n","Iteration:  46% 618/1357 [06:34<07:08,  1.72it/s]\u001b[A\n","Iteration:  46% 619/1357 [06:34<07:08,  1.72it/s]\u001b[A\n","Iteration:  46% 620/1357 [06:35<07:08,  1.72it/s]\u001b[A\n","Iteration:  46% 621/1357 [06:36<07:08,  1.72it/s]\u001b[A\n","Iteration:  46% 622/1357 [06:36<07:09,  1.71it/s]\u001b[A\n","Iteration:  46% 623/1357 [06:37<07:07,  1.72it/s]\u001b[A\n","Iteration:  46% 624/1357 [06:37<07:07,  1.71it/s]\u001b[A\n","Iteration:  46% 625/1357 [06:38<07:06,  1.72it/s]\u001b[A\n","Iteration:  46% 626/1357 [06:39<07:06,  1.71it/s]\u001b[A\n","Iteration:  46% 627/1357 [06:39<07:05,  1.72it/s]\u001b[A\n","Iteration:  46% 628/1357 [06:40<07:05,  1.71it/s]\u001b[A\n","Iteration:  46% 629/1357 [06:40<07:03,  1.72it/s]\u001b[A\n","Iteration:  46% 630/1357 [06:41<07:02,  1.72it/s]\u001b[A\n","Iteration:  46% 631/1357 [06:41<07:02,  1.72it/s]\u001b[A\n","Iteration:  47% 632/1357 [06:42<07:03,  1.71it/s]\u001b[A\n","Iteration:  47% 633/1357 [06:43<07:04,  1.71it/s]\u001b[A\n","Iteration:  47% 634/1357 [06:43<07:03,  1.71it/s]\u001b[A\n","Iteration:  47% 635/1357 [06:44<07:01,  1.71it/s]\u001b[A\n","Iteration:  47% 636/1357 [06:44<07:00,  1.72it/s]\u001b[A\n","Iteration:  47% 637/1357 [06:45<06:59,  1.72it/s]\u001b[A\n","Iteration:  47% 638/1357 [06:46<06:59,  1.71it/s]\u001b[A\n","Iteration:  47% 639/1357 [06:46<06:56,  1.73it/s]\u001b[A\n","Iteration:  47% 640/1357 [06:47<06:57,  1.72it/s]\u001b[A\n","Iteration:  47% 641/1357 [06:47<06:56,  1.72it/s]\u001b[A\n","Iteration:  47% 642/1357 [06:48<06:56,  1.72it/s]\u001b[A\n","Iteration:  47% 643/1357 [06:48<06:56,  1.71it/s]\u001b[A\n","Iteration:  47% 644/1357 [06:49<06:54,  1.72it/s]\u001b[A\n","Iteration:  48% 645/1357 [06:50<06:52,  1.73it/s]\u001b[A\n","Iteration:  48% 646/1357 [06:50<06:52,  1.72it/s]\u001b[A\n","Iteration:  48% 647/1357 [06:51<06:52,  1.72it/s]\u001b[A\n","Iteration:  48% 648/1357 [06:51<06:53,  1.72it/s]\u001b[A\n","Iteration:  48% 649/1357 [06:52<06:51,  1.72it/s]\u001b[A\n","Iteration:  48% 650/1357 [06:53<06:51,  1.72it/s]\u001b[A\n","Iteration:  48% 651/1357 [06:53<06:48,  1.73it/s]\u001b[A\n","Iteration:  48% 652/1357 [06:54<06:50,  1.72it/s]\u001b[A\n","Iteration:  48% 653/1357 [06:54<06:51,  1.71it/s]\u001b[A\n","Iteration:  48% 654/1357 [06:55<06:50,  1.71it/s]\u001b[A\n","Iteration:  48% 655/1357 [06:55<06:49,  1.71it/s]\u001b[A\n","Iteration:  48% 656/1357 [06:56<06:47,  1.72it/s]\u001b[A\n","Iteration:  48% 657/1357 [06:57<06:47,  1.72it/s]\u001b[A\n","Iteration:  48% 658/1357 [06:57<06:47,  1.72it/s]\u001b[A\n","Iteration:  49% 659/1357 [06:58<06:46,  1.72it/s]\u001b[A\n","Iteration:  49% 660/1357 [06:58<06:45,  1.72it/s]\u001b[A\n","Iteration:  49% 661/1357 [06:59<06:44,  1.72it/s]\u001b[A\n","Iteration:  49% 662/1357 [07:00<06:44,  1.72it/s]\u001b[A\n","Iteration:  49% 663/1357 [07:00<06:42,  1.72it/s]\u001b[A\n","Iteration:  49% 664/1357 [07:01<06:42,  1.72it/s]\u001b[A\n","Iteration:  49% 665/1357 [07:01<06:41,  1.72it/s]\u001b[A\n","Iteration:  49% 666/1357 [07:02<06:40,  1.72it/s]\u001b[A\n","Iteration:  49% 667/1357 [07:02<06:41,  1.72it/s]\u001b[A\n","Iteration:  49% 668/1357 [07:03<06:41,  1.71it/s]\u001b[A\n","Iteration:  49% 669/1357 [07:04<06:39,  1.72it/s]\u001b[A\n","Iteration:  49% 670/1357 [07:04<06:39,  1.72it/s]\u001b[A\n","Iteration:  49% 671/1357 [07:05<06:39,  1.72it/s]\u001b[A\n","Iteration:  50% 672/1357 [07:05<06:39,  1.71it/s]\u001b[A\n","Iteration:  50% 673/1357 [07:06<06:39,  1.71it/s]\u001b[A\n","Iteration:  50% 674/1357 [07:07<06:40,  1.71it/s]\u001b[A\n","Iteration:  50% 675/1357 [07:07<06:38,  1.71it/s]\u001b[A\n","Iteration:  50% 676/1357 [07:08<06:36,  1.72it/s]\u001b[A\n","Iteration:  50% 677/1357 [07:08<06:36,  1.72it/s]\u001b[A\n","Iteration:  50% 678/1357 [07:09<06:35,  1.72it/s]\u001b[A\n","Iteration:  50% 679/1357 [07:09<06:34,  1.72it/s]\u001b[A\n","Iteration:  50% 680/1357 [07:10<06:33,  1.72it/s]\u001b[A\n","Iteration:  50% 681/1357 [07:11<06:34,  1.71it/s]\u001b[A\n","Iteration:  50% 682/1357 [07:11<06:32,  1.72it/s]\u001b[A\n","Iteration:  50% 683/1357 [07:12<06:33,  1.71it/s]\u001b[A\n","Iteration:  50% 684/1357 [07:12<06:30,  1.72it/s]\u001b[A\n","Iteration:  50% 685/1357 [07:13<06:28,  1.73it/s]\u001b[A\n","Iteration:  51% 686/1357 [07:14<06:29,  1.72it/s]\u001b[A\n","Iteration:  51% 687/1357 [07:14<06:30,  1.71it/s]\u001b[A\n","Iteration:  51% 688/1357 [07:15<06:29,  1.72it/s]\u001b[A\n","Iteration:  51% 689/1357 [07:15<06:31,  1.71it/s]\u001b[A\n","Iteration:  51% 690/1357 [07:16<06:30,  1.71it/s]\u001b[A\n","Iteration:  51% 691/1357 [07:16<06:28,  1.71it/s]\u001b[A\n","Iteration:  51% 692/1357 [07:17<06:27,  1.71it/s]\u001b[A\n","Iteration:  51% 693/1357 [07:18<06:27,  1.71it/s]\u001b[A\n","Iteration:  51% 694/1357 [07:18<06:27,  1.71it/s]\u001b[A\n","Iteration:  51% 695/1357 [07:19<06:27,  1.71it/s]\u001b[A\n","Iteration:  51% 696/1357 [07:19<06:26,  1.71it/s]\u001b[A\n","Iteration:  51% 697/1357 [07:20<06:24,  1.72it/s]\u001b[A\n","Iteration:  51% 698/1357 [07:21<06:24,  1.72it/s]\u001b[A\n","Iteration:  52% 699/1357 [07:21<06:22,  1.72it/s]\u001b[A\n","Iteration:  52% 700/1357 [07:22<06:19,  1.73it/s]\u001b[A\n","Iteration:  52% 701/1357 [07:22<06:21,  1.72it/s]\u001b[A\n","Iteration:  52% 702/1357 [07:23<06:22,  1.71it/s]\u001b[A\n","Iteration:  52% 703/1357 [07:23<06:21,  1.72it/s]\u001b[A\n","Iteration:  52% 704/1357 [07:24<06:21,  1.71it/s]\u001b[A\n","Iteration:  52% 705/1357 [07:25<06:19,  1.72it/s]\u001b[A\n","Iteration:  52% 706/1357 [07:25<06:19,  1.71it/s]\u001b[A\n","Iteration:  52% 707/1357 [07:26<06:18,  1.72it/s]\u001b[A\n","Iteration:  52% 708/1357 [07:26<06:21,  1.70it/s]\u001b[A\n","Iteration:  52% 709/1357 [07:27<06:18,  1.71it/s]\u001b[A\n","Iteration:  52% 710/1357 [07:28<06:16,  1.72it/s]\u001b[A\n","Iteration:  52% 711/1357 [07:28<06:17,  1.71it/s]\u001b[A\n","Iteration:  52% 712/1357 [07:29<06:14,  1.72it/s]\u001b[A\n","Iteration:  53% 713/1357 [07:29<06:16,  1.71it/s]\u001b[A\n","Iteration:  53% 714/1357 [07:30<06:17,  1.70it/s]\u001b[A\n","Iteration:  53% 715/1357 [07:30<06:15,  1.71it/s]\u001b[A\n","Iteration:  53% 716/1357 [07:31<06:15,  1.71it/s]\u001b[A\n","Iteration:  53% 717/1357 [07:32<06:13,  1.71it/s]\u001b[A\n","Iteration:  53% 718/1357 [07:32<06:12,  1.71it/s]\u001b[A\n","Iteration:  53% 719/1357 [07:33<06:12,  1.71it/s]\u001b[A\n","Iteration:  53% 720/1357 [07:33<06:13,  1.71it/s]\u001b[A\n","Iteration:  53% 721/1357 [07:34<06:11,  1.71it/s]\u001b[A\n","Iteration:  53% 722/1357 [07:35<06:10,  1.71it/s]\u001b[A\n","Iteration:  53% 723/1357 [07:35<06:08,  1.72it/s]\u001b[A\n","Iteration:  53% 724/1357 [07:36<06:06,  1.73it/s]\u001b[A\n","Iteration:  53% 725/1357 [07:36<06:07,  1.72it/s]\u001b[A\n","Iteration:  54% 726/1357 [07:37<06:06,  1.72it/s]\u001b[A\n","Iteration:  54% 727/1357 [07:37<06:04,  1.73it/s]\u001b[A\n","Iteration:  54% 728/1357 [07:38<06:03,  1.73it/s]\u001b[A\n","Iteration:  54% 729/1357 [07:39<06:05,  1.72it/s]\u001b[A\n","Iteration:  54% 730/1357 [07:39<06:03,  1.72it/s]\u001b[A\n","Iteration:  54% 731/1357 [07:40<06:02,  1.73it/s]\u001b[A\n","Iteration:  54% 732/1357 [07:40<06:02,  1.72it/s]\u001b[A\n","Iteration:  54% 733/1357 [07:41<06:01,  1.73it/s]\u001b[A\n","Iteration:  54% 734/1357 [07:41<06:00,  1.73it/s]\u001b[A\n","Iteration:  54% 735/1357 [07:42<06:00,  1.73it/s]\u001b[A\n","Iteration:  54% 736/1357 [07:43<06:00,  1.72it/s]\u001b[A\n","Iteration:  54% 737/1357 [07:43<05:59,  1.72it/s]\u001b[A\n","Iteration:  54% 738/1357 [07:44<06:01,  1.71it/s]\u001b[A\n","Iteration:  54% 739/1357 [07:44<05:59,  1.72it/s]\u001b[A\n","Iteration:  55% 740/1357 [07:45<05:57,  1.73it/s]\u001b[A\n","Iteration:  55% 741/1357 [07:46<05:57,  1.72it/s]\u001b[A\n","Iteration:  55% 742/1357 [07:46<05:58,  1.72it/s]\u001b[A\n","Iteration:  55% 743/1357 [07:47<05:57,  1.72it/s]\u001b[A\n","Iteration:  55% 744/1357 [07:47<05:56,  1.72it/s]\u001b[A\n","Iteration:  55% 745/1357 [07:48<05:56,  1.72it/s]\u001b[A\n","Iteration:  55% 746/1357 [07:48<05:55,  1.72it/s]\u001b[A\n","Iteration:  55% 747/1357 [07:49<05:56,  1.71it/s]\u001b[A\n","Iteration:  55% 748/1357 [07:50<05:55,  1.71it/s]\u001b[A\n","Iteration:  55% 749/1357 [07:50<05:54,  1.72it/s]\u001b[A\n","Iteration:  55% 750/1357 [07:51<05:53,  1.72it/s]\u001b[A\n","Iteration:  55% 751/1357 [07:51<05:52,  1.72it/s]\u001b[A\n","Iteration:  55% 752/1357 [07:52<05:51,  1.72it/s]\u001b[A\n","Iteration:  55% 753/1357 [07:53<05:51,  1.72it/s]\u001b[A\n","Iteration:  56% 754/1357 [07:53<05:49,  1.72it/s]\u001b[A\n","Iteration:  56% 755/1357 [07:54<05:47,  1.73it/s]\u001b[A\n","Iteration:  56% 756/1357 [07:54<05:47,  1.73it/s]\u001b[A\n","Iteration:  56% 757/1357 [07:55<05:49,  1.72it/s]\u001b[A\n","Iteration:  56% 758/1357 [07:55<05:47,  1.72it/s]\u001b[A\n","Iteration:  56% 759/1357 [07:56<05:47,  1.72it/s]\u001b[A\n","Iteration:  56% 760/1357 [07:57<05:46,  1.72it/s]\u001b[A\n","Iteration:  56% 761/1357 [07:57<05:44,  1.73it/s]\u001b[A\n","Iteration:  56% 762/1357 [07:58<05:44,  1.72it/s]\u001b[A\n","Iteration:  56% 763/1357 [07:58<05:44,  1.72it/s]\u001b[A\n","Iteration:  56% 764/1357 [07:59<05:44,  1.72it/s]\u001b[A\n","Iteration:  56% 765/1357 [07:59<05:43,  1.72it/s]\u001b[A\n","Iteration:  56% 766/1357 [08:00<05:43,  1.72it/s]\u001b[A\n","Iteration:  57% 767/1357 [08:01<05:41,  1.73it/s]\u001b[A\n","Iteration:  57% 768/1357 [08:01<05:39,  1.73it/s]\u001b[A\n","Iteration:  57% 769/1357 [08:02<05:42,  1.72it/s]\u001b[A\n","Iteration:  57% 770/1357 [08:02<05:42,  1.71it/s]\u001b[A\n","Iteration:  57% 771/1357 [08:03<05:41,  1.72it/s]\u001b[A\n","Iteration:  57% 772/1357 [08:04<05:41,  1.71it/s]\u001b[A\n","Iteration:  57% 773/1357 [08:04<05:39,  1.72it/s]\u001b[A\n","Iteration:  57% 774/1357 [08:05<05:37,  1.73it/s]\u001b[A\n","Iteration:  57% 775/1357 [08:05<05:38,  1.72it/s]\u001b[A\n","Iteration:  57% 776/1357 [08:06<05:38,  1.72it/s]\u001b[A\n","Iteration:  57% 777/1357 [08:06<05:37,  1.72it/s]\u001b[A\n","Iteration:  57% 778/1357 [08:07<05:36,  1.72it/s]\u001b[A\n","Iteration:  57% 779/1357 [08:08<05:35,  1.72it/s]\u001b[A\n","Iteration:  57% 780/1357 [08:08<05:35,  1.72it/s]\u001b[A\n","Iteration:  58% 781/1357 [08:09<05:35,  1.72it/s]\u001b[A\n","Iteration:  58% 782/1357 [08:09<05:36,  1.71it/s]\u001b[A\n","Iteration:  58% 783/1357 [08:10<05:35,  1.71it/s]\u001b[A\n","Iteration:  58% 784/1357 [08:11<05:33,  1.72it/s]\u001b[A\n","Iteration:  58% 785/1357 [08:11<05:33,  1.72it/s]\u001b[A\n","Iteration:  58% 786/1357 [08:12<05:31,  1.72it/s]\u001b[A\n","Iteration:  58% 787/1357 [08:12<05:30,  1.72it/s]\u001b[A\n","Iteration:  58% 788/1357 [08:13<05:30,  1.72it/s]\u001b[A\n","Iteration:  58% 789/1357 [08:13<05:28,  1.73it/s]\u001b[A\n","Iteration:  58% 790/1357 [08:14<05:28,  1.73it/s]\u001b[A\n","Iteration:  58% 791/1357 [08:15<05:29,  1.72it/s]\u001b[A\n","Iteration:  58% 792/1357 [08:15<05:27,  1.73it/s]\u001b[A\n","Iteration:  58% 793/1357 [08:16<05:26,  1.73it/s]\u001b[A\n","Iteration:  59% 794/1357 [08:16<05:26,  1.73it/s]\u001b[A\n","Iteration:  59% 795/1357 [08:17<05:24,  1.73it/s]\u001b[A\n","Iteration:  59% 796/1357 [08:17<05:23,  1.74it/s]\u001b[A\n","Iteration:  59% 797/1357 [08:18<05:23,  1.73it/s]\u001b[A\n","Iteration:  59% 798/1357 [08:19<05:24,  1.72it/s]\u001b[A\n","Iteration:  59% 799/1357 [08:19<05:24,  1.72it/s]\u001b[A\n","Iteration:  59% 800/1357 [08:20<05:24,  1.72it/s]\u001b[A\n","Iteration:  59% 801/1357 [08:20<05:22,  1.72it/s]\u001b[A\n","Iteration:  59% 802/1357 [08:21<05:21,  1.73it/s]\u001b[A\n","Iteration:  59% 803/1357 [08:22<05:22,  1.72it/s]\u001b[A\n","Iteration:  59% 804/1357 [08:22<05:22,  1.72it/s]\u001b[A\n","Iteration:  59% 805/1357 [08:23<05:21,  1.72it/s]\u001b[A\n","Iteration:  59% 806/1357 [08:23<05:20,  1.72it/s]\u001b[A\n","Iteration:  59% 807/1357 [08:24<05:19,  1.72it/s]\u001b[A\n","Iteration:  60% 808/1357 [08:24<05:17,  1.73it/s]\u001b[A\n","Iteration:  60% 809/1357 [08:25<05:19,  1.71it/s]\u001b[A\n","Iteration:  60% 810/1357 [08:26<05:18,  1.72it/s]\u001b[A\n","Iteration:  60% 811/1357 [08:26<05:18,  1.71it/s]\u001b[A\n","Iteration:  60% 812/1357 [08:27<05:19,  1.71it/s]\u001b[A\n","Iteration:  60% 813/1357 [08:27<05:19,  1.70it/s]\u001b[A\n","Iteration:  60% 814/1357 [08:28<05:17,  1.71it/s]\u001b[A\n","Iteration:  60% 815/1357 [08:29<05:16,  1.71it/s]\u001b[A\n","Iteration:  60% 816/1357 [08:29<05:14,  1.72it/s]\u001b[A\n","Iteration:  60% 817/1357 [08:30<05:13,  1.72it/s]\u001b[A\n","Iteration:  60% 818/1357 [08:30<05:12,  1.73it/s]\u001b[A\n","Iteration:  60% 819/1357 [08:31<05:14,  1.71it/s]\u001b[A\n","Iteration:  60% 820/1357 [08:31<05:11,  1.72it/s]\u001b[A\n","Iteration:  61% 821/1357 [08:32<05:11,  1.72it/s]\u001b[A\n","Iteration:  61% 822/1357 [08:33<05:12,  1.71it/s]\u001b[A\n","Iteration:  61% 823/1357 [08:33<05:10,  1.72it/s]\u001b[A\n","Iteration:  61% 824/1357 [08:34<05:11,  1.71it/s]\u001b[A\n","Iteration:  61% 825/1357 [08:34<05:11,  1.71it/s]\u001b[A\n","Iteration:  61% 826/1357 [08:35<05:09,  1.71it/s]\u001b[A\n","Iteration:  61% 827/1357 [08:36<05:07,  1.72it/s]\u001b[A\n","Iteration:  61% 828/1357 [08:36<05:07,  1.72it/s]\u001b[A\n","Iteration:  61% 829/1357 [08:37<05:06,  1.72it/s]\u001b[A\n","Iteration:  61% 830/1357 [08:37<05:05,  1.72it/s]\u001b[A\n","Iteration:  61% 831/1357 [08:38<05:04,  1.72it/s]\u001b[A\n","Iteration:  61% 832/1357 [08:38<05:04,  1.72it/s]\u001b[A\n","Iteration:  61% 833/1357 [08:39<05:04,  1.72it/s]\u001b[A\n","Iteration:  61% 834/1357 [08:40<05:04,  1.72it/s]\u001b[A\n","Iteration:  62% 835/1357 [08:40<05:02,  1.72it/s]\u001b[A\n","Iteration:  62% 836/1357 [08:41<05:02,  1.72it/s]\u001b[A\n","Iteration:  62% 837/1357 [08:41<05:01,  1.72it/s]\u001b[A\n","Iteration:  62% 838/1357 [08:42<05:04,  1.70it/s]\u001b[A\n","Iteration:  62% 839/1357 [08:43<05:02,  1.71it/s]\u001b[A\n","Iteration:  62% 840/1357 [08:43<05:01,  1.71it/s]\u001b[A\n","Iteration:  62% 841/1357 [08:44<05:00,  1.72it/s]\u001b[A\n","Iteration:  62% 842/1357 [08:44<04:59,  1.72it/s]\u001b[A\n","Iteration:  62% 843/1357 [08:45<04:59,  1.72it/s]\u001b[A\n","Iteration:  62% 844/1357 [08:45<04:58,  1.72it/s]\u001b[A\n","Iteration:  62% 845/1357 [08:46<04:57,  1.72it/s]\u001b[A\n","Iteration:  62% 846/1357 [08:47<04:56,  1.72it/s]\u001b[A\n","Iteration:  62% 847/1357 [08:47<04:57,  1.72it/s]\u001b[A\n","Iteration:  62% 848/1357 [08:48<04:56,  1.72it/s]\u001b[A\n","Iteration:  63% 849/1357 [08:48<04:55,  1.72it/s]\u001b[A\n","Iteration:  63% 850/1357 [08:49<04:54,  1.72it/s]\u001b[A\n","Iteration:  63% 851/1357 [08:49<04:52,  1.73it/s]\u001b[A\n","Iteration:  63% 852/1357 [08:50<04:52,  1.73it/s]\u001b[A\n","Iteration:  63% 853/1357 [08:51<04:54,  1.71it/s]\u001b[A\n","Iteration:  63% 854/1357 [08:51<04:53,  1.72it/s]\u001b[A\n","Iteration:  63% 855/1357 [08:52<04:52,  1.72it/s]\u001b[A\n","Iteration:  63% 856/1357 [08:52<04:52,  1.71it/s]\u001b[A\n","Iteration:  63% 857/1357 [08:53<04:50,  1.72it/s]\u001b[A\n","Iteration:  63% 858/1357 [08:54<04:50,  1.72it/s]\u001b[A\n","Iteration:  63% 859/1357 [08:54<04:49,  1.72it/s]\u001b[A\n","Iteration:  63% 860/1357 [08:55<04:48,  1.72it/s]\u001b[A\n","Iteration:  63% 861/1357 [08:55<04:49,  1.71it/s]\u001b[A\n","Iteration:  64% 862/1357 [08:56<04:48,  1.72it/s]\u001b[A\n","Iteration:  64% 863/1357 [08:56<04:47,  1.72it/s]\u001b[A\n","Iteration:  64% 864/1357 [08:57<04:47,  1.72it/s]\u001b[A\n","Iteration:  64% 865/1357 [08:58<04:47,  1.71it/s]\u001b[A\n","Iteration:  64% 866/1357 [08:58<04:46,  1.72it/s]\u001b[A\n","Iteration:  64% 867/1357 [08:59<04:46,  1.71it/s]\u001b[A\n","Iteration:  64% 868/1357 [08:59<04:45,  1.71it/s]\u001b[A\n","Iteration:  64% 869/1357 [09:00<04:44,  1.72it/s]\u001b[A\n","Iteration:  64% 870/1357 [09:01<04:43,  1.72it/s]\u001b[A\n","Iteration:  64% 871/1357 [09:01<04:43,  1.71it/s]\u001b[A\n","Iteration:  64% 872/1357 [09:02<04:41,  1.72it/s]\u001b[A\n","Iteration:  64% 873/1357 [09:02<04:40,  1.72it/s]\u001b[A\n","Iteration:  64% 874/1357 [09:03<04:41,  1.72it/s]\u001b[A\n","Iteration:  64% 875/1357 [09:03<04:39,  1.72it/s]\u001b[A\n","Iteration:  65% 876/1357 [09:04<04:39,  1.72it/s]\u001b[A\n","Iteration:  65% 877/1357 [09:05<04:39,  1.72it/s]\u001b[A\n","Iteration:  65% 878/1357 [09:05<04:38,  1.72it/s]\u001b[A\n","Iteration:  65% 879/1357 [09:06<04:37,  1.72it/s]\u001b[A\n","Iteration:  65% 880/1357 [09:06<04:36,  1.72it/s]\u001b[A\n","Iteration:  65% 881/1357 [09:07<04:37,  1.72it/s]\u001b[A\n","Iteration:  65% 882/1357 [09:08<04:36,  1.72it/s]\u001b[A\n","Iteration:  65% 883/1357 [09:08<04:36,  1.72it/s]\u001b[A\n","Iteration:  65% 884/1357 [09:09<04:34,  1.72it/s]\u001b[A\n","Iteration:  65% 885/1357 [09:09<04:32,  1.73it/s]\u001b[A\n","Iteration:  65% 886/1357 [09:10<04:32,  1.73it/s]\u001b[A\n","Iteration:  65% 887/1357 [09:10<04:33,  1.72it/s]\u001b[A\n","Iteration:  65% 888/1357 [09:11<04:31,  1.72it/s]\u001b[A\n","Iteration:  66% 889/1357 [09:12<04:32,  1.72it/s]\u001b[A\n","Iteration:  66% 890/1357 [09:12<04:31,  1.72it/s]\u001b[A\n","Iteration:  66% 891/1357 [09:13<04:29,  1.73it/s]\u001b[A\n","Iteration:  66% 892/1357 [09:13<04:29,  1.72it/s]\u001b[A\n","Iteration:  66% 893/1357 [09:14<04:30,  1.71it/s]\u001b[A\n","Iteration:  66% 894/1357 [09:15<04:28,  1.72it/s]\u001b[A\n","Iteration:  66% 895/1357 [09:15<04:29,  1.72it/s]\u001b[A\n","Iteration:  66% 896/1357 [09:16<04:28,  1.72it/s]\u001b[A\n","Iteration:  66% 897/1357 [09:16<04:27,  1.72it/s]\u001b[A\n","Iteration:  66% 898/1357 [09:17<04:27,  1.71it/s]\u001b[A\n","Iteration:  66% 899/1357 [09:17<04:27,  1.71it/s]\u001b[A\n","Iteration:  66% 900/1357 [09:18<04:27,  1.71it/s]\u001b[A\n","Iteration:  66% 901/1357 [09:19<04:26,  1.71it/s]\u001b[A\n","Iteration:  66% 902/1357 [09:19<04:25,  1.71it/s]\u001b[A\n","Iteration:  67% 903/1357 [09:20<04:24,  1.72it/s]\u001b[A\n","Iteration:  67% 904/1357 [09:20<04:23,  1.72it/s]\u001b[A\n","Iteration:  67% 905/1357 [09:21<04:22,  1.72it/s]\u001b[A\n","Iteration:  67% 906/1357 [09:22<04:20,  1.73it/s]\u001b[A\n","Iteration:  67% 907/1357 [09:22<04:20,  1.73it/s]\u001b[A\n","Iteration:  67% 908/1357 [09:23<04:21,  1.72it/s]\u001b[A\n","Iteration:  67% 909/1357 [09:23<04:20,  1.72it/s]\u001b[A\n","Iteration:  67% 910/1357 [09:24<04:19,  1.72it/s]\u001b[A\n","Iteration:  67% 911/1357 [09:24<04:19,  1.72it/s]\u001b[A\n","Iteration:  67% 912/1357 [09:25<04:18,  1.72it/s]\u001b[A\n","Iteration:  67% 913/1357 [09:26<04:17,  1.72it/s]\u001b[A\n","Iteration:  67% 914/1357 [09:26<04:17,  1.72it/s]\u001b[A\n","Iteration:  67% 915/1357 [09:27<04:17,  1.72it/s]\u001b[A\n","Iteration:  68% 916/1357 [09:27<04:16,  1.72it/s]\u001b[A\n","Iteration:  68% 917/1357 [09:28<04:16,  1.71it/s]\u001b[A\n","Iteration:  68% 918/1357 [09:28<04:16,  1.71it/s]\u001b[A\n","Iteration:  68% 919/1357 [09:29<04:15,  1.71it/s]\u001b[A\n","Iteration:  68% 920/1357 [09:30<04:16,  1.71it/s]\u001b[A\n","Iteration:  68% 921/1357 [09:30<04:15,  1.71it/s]\u001b[A\n","Iteration:  68% 922/1357 [09:31<04:14,  1.71it/s]\u001b[A\n","Iteration:  68% 923/1357 [09:31<04:13,  1.71it/s]\u001b[A\n","Iteration:  68% 924/1357 [09:32<04:11,  1.72it/s]\u001b[A\n","Iteration:  68% 925/1357 [09:33<04:10,  1.72it/s]\u001b[A\n","Iteration:  68% 926/1357 [09:33<04:09,  1.72it/s]\u001b[A\n","Iteration:  68% 927/1357 [09:34<04:10,  1.72it/s]\u001b[A\n","Iteration:  68% 928/1357 [09:34<04:10,  1.71it/s]\u001b[A\n","Iteration:  68% 929/1357 [09:35<04:09,  1.72it/s]\u001b[A\n","Iteration:  69% 930/1357 [09:35<04:07,  1.73it/s]\u001b[A\n","Iteration:  69% 931/1357 [09:36<04:06,  1.73it/s]\u001b[A\n","Iteration:  69% 932/1357 [09:37<04:07,  1.71it/s]\u001b[A\n","Iteration:  69% 933/1357 [09:37<04:06,  1.72it/s]\u001b[A\n","Iteration:  69% 934/1357 [09:38<04:04,  1.73it/s]\u001b[A\n","Iteration:  69% 935/1357 [09:38<04:04,  1.73it/s]\u001b[A\n","Iteration:  69% 936/1357 [09:39<04:05,  1.72it/s]\u001b[A\n","Iteration:  69% 937/1357 [09:40<04:04,  1.72it/s]\u001b[A\n","Iteration:  69% 938/1357 [09:40<04:03,  1.72it/s]\u001b[A\n","Iteration:  69% 939/1357 [09:41<04:02,  1.72it/s]\u001b[A\n","Iteration:  69% 940/1357 [09:41<04:01,  1.73it/s]\u001b[A\n","Iteration:  69% 941/1357 [09:42<04:01,  1.72it/s]\u001b[A\n","Iteration:  69% 942/1357 [09:42<04:01,  1.72it/s]\u001b[A\n","Iteration:  69% 943/1357 [09:43<04:01,  1.72it/s]\u001b[A\n","Iteration:  70% 944/1357 [09:44<04:01,  1.71it/s]\u001b[A\n","Iteration:  70% 945/1357 [09:44<04:00,  1.72it/s]\u001b[A\n","Iteration:  70% 946/1357 [09:45<03:58,  1.72it/s]\u001b[A\n","Iteration:  70% 947/1357 [09:45<03:57,  1.72it/s]\u001b[A\n","Iteration:  70% 948/1357 [09:46<03:57,  1.72it/s]\u001b[A\n","Iteration:  70% 949/1357 [09:47<03:57,  1.72it/s]\u001b[A\n","Iteration:  70% 950/1357 [09:47<03:56,  1.72it/s]\u001b[A\n","Iteration:  70% 951/1357 [09:48<03:56,  1.72it/s]\u001b[A\n","Iteration:  70% 952/1357 [09:48<03:55,  1.72it/s]\u001b[A\n","Iteration:  70% 953/1357 [09:49<03:54,  1.73it/s]\u001b[A\n","Iteration:  70% 954/1357 [09:49<03:54,  1.72it/s]\u001b[A\n","Iteration:  70% 955/1357 [09:50<03:54,  1.72it/s]\u001b[A\n","Iteration:  70% 956/1357 [09:51<03:53,  1.72it/s]\u001b[A\n","Iteration:  71% 957/1357 [09:51<03:53,  1.71it/s]\u001b[A\n","Iteration:  71% 958/1357 [09:52<03:51,  1.72it/s]\u001b[A\n","Iteration:  71% 959/1357 [09:52<03:51,  1.72it/s]\u001b[A\n","Iteration:  71% 960/1357 [09:53<03:51,  1.72it/s]\u001b[A\n","Iteration:  71% 961/1357 [09:54<03:50,  1.72it/s]\u001b[A\n","Iteration:  71% 962/1357 [09:54<03:49,  1.72it/s]\u001b[A\n","Iteration:  71% 963/1357 [09:55<03:49,  1.72it/s]\u001b[A\n","Iteration:  71% 964/1357 [09:55<03:48,  1.72it/s]\u001b[A\n","Iteration:  71% 965/1357 [09:56<03:48,  1.71it/s]\u001b[A\n","Iteration:  71% 966/1357 [09:56<03:48,  1.71it/s]\u001b[A\n","Iteration:  71% 967/1357 [09:57<03:47,  1.71it/s]\u001b[A\n","Iteration:  71% 968/1357 [09:58<03:46,  1.72it/s]\u001b[A\n","Iteration:  71% 969/1357 [09:58<03:46,  1.71it/s]\u001b[A\n","Iteration:  71% 970/1357 [09:59<03:45,  1.71it/s]\u001b[A\n","Iteration:  72% 971/1357 [09:59<03:45,  1.71it/s]\u001b[A\n","Iteration:  72% 972/1357 [10:00<03:44,  1.71it/s]\u001b[A\n","Iteration:  72% 973/1357 [10:01<03:44,  1.71it/s]\u001b[A\n","Iteration:  72% 974/1357 [10:01<03:42,  1.72it/s]\u001b[A\n","Iteration:  72% 975/1357 [10:02<03:41,  1.72it/s]\u001b[A\n","Iteration:  72% 976/1357 [10:02<03:41,  1.72it/s]\u001b[A\n","Iteration:  72% 977/1357 [10:03<03:40,  1.72it/s]\u001b[A\n","Iteration:  72% 978/1357 [10:03<03:39,  1.72it/s]\u001b[A\n","Iteration:  72% 979/1357 [10:04<03:39,  1.72it/s]\u001b[A\n","Iteration:  72% 980/1357 [10:05<03:37,  1.73it/s]\u001b[A\n","Iteration:  72% 981/1357 [10:05<03:37,  1.73it/s]\u001b[A\n","Iteration:  72% 982/1357 [10:06<03:37,  1.72it/s]\u001b[A\n","Iteration:  72% 983/1357 [10:06<03:38,  1.71it/s]\u001b[A\n","Iteration:  73% 984/1357 [10:07<03:37,  1.71it/s]\u001b[A\n","Iteration:  73% 985/1357 [10:07<03:36,  1.72it/s]\u001b[A\n","Iteration:  73% 986/1357 [10:08<03:35,  1.72it/s]\u001b[A\n","Iteration:  73% 987/1357 [10:09<03:34,  1.72it/s]\u001b[A\n","Iteration:  73% 988/1357 [10:09<03:35,  1.72it/s]\u001b[A\n","Iteration:  73% 989/1357 [10:10<03:34,  1.71it/s]\u001b[A\n","Iteration:  73% 990/1357 [10:10<03:33,  1.71it/s]\u001b[A\n","Iteration:  73% 991/1357 [10:11<03:33,  1.71it/s]\u001b[A\n","Iteration:  73% 992/1357 [10:12<03:32,  1.72it/s]\u001b[A\n","Iteration:  73% 993/1357 [10:12<03:31,  1.72it/s]\u001b[A\n","Iteration:  73% 994/1357 [10:13<03:30,  1.72it/s]\u001b[A\n","Iteration:  73% 995/1357 [10:13<03:29,  1.73it/s]\u001b[A\n","Iteration:  73% 996/1357 [10:14<03:28,  1.73it/s]\u001b[A\n","Iteration:  73% 997/1357 [10:14<03:28,  1.73it/s]\u001b[A\n","Iteration:  74% 998/1357 [10:15<03:28,  1.72it/s]\u001b[A\n","Iteration:  74% 999/1357 [10:16<03:27,  1.72it/s]\u001b[A\n","Iteration:  74% 1000/1357 [10:16<03:27,  1.72it/s]\u001b[A\n","Iteration:  74% 1001/1357 [10:17<03:26,  1.72it/s]\u001b[A\n","Iteration:  74% 1002/1357 [10:17<03:26,  1.72it/s]\u001b[A\n","Iteration:  74% 1003/1357 [10:18<03:25,  1.73it/s]\u001b[A\n","Iteration:  74% 1004/1357 [10:19<03:25,  1.72it/s]\u001b[A\n","Iteration:  74% 1005/1357 [10:19<03:25,  1.71it/s]\u001b[A\n","Iteration:  74% 1006/1357 [10:20<03:24,  1.72it/s]\u001b[A\n","Iteration:  74% 1007/1357 [10:20<03:23,  1.72it/s]\u001b[A\n","Iteration:  74% 1008/1357 [10:21<03:22,  1.72it/s]\u001b[A\n","Iteration:  74% 1009/1357 [10:21<03:22,  1.72it/s]\u001b[A\n","Iteration:  74% 1010/1357 [10:22<03:22,  1.71it/s]\u001b[A\n","Iteration:  75% 1011/1357 [10:23<03:21,  1.71it/s]\u001b[A\n","Iteration:  75% 1012/1357 [10:23<03:20,  1.72it/s]\u001b[A\n","Iteration:  75% 1013/1357 [10:24<03:20,  1.72it/s]\u001b[A\n","Iteration:  75% 1014/1357 [10:24<03:19,  1.72it/s]\u001b[A\n","Iteration:  75% 1015/1357 [10:25<03:19,  1.72it/s]\u001b[A\n","Iteration:  75% 1016/1357 [10:26<03:18,  1.72it/s]\u001b[A\n","Iteration:  75% 1017/1357 [10:26<03:17,  1.72it/s]\u001b[A\n","Iteration:  75% 1018/1357 [10:27<03:17,  1.72it/s]\u001b[A\n","Iteration:  75% 1019/1357 [10:27<03:17,  1.71it/s]\u001b[A\n","Iteration:  75% 1020/1357 [10:28<03:16,  1.71it/s]\u001b[A\n","Iteration:  75% 1021/1357 [10:28<03:16,  1.71it/s]\u001b[A\n","Iteration:  75% 1022/1357 [10:29<03:14,  1.72it/s]\u001b[A\n","Iteration:  75% 1023/1357 [10:30<03:13,  1.73it/s]\u001b[A\n","Iteration:  75% 1024/1357 [10:30<03:13,  1.72it/s]\u001b[A\n","Iteration:  76% 1025/1357 [10:31<03:13,  1.72it/s]\u001b[A\n","Iteration:  76% 1026/1357 [10:31<03:12,  1.72it/s]\u001b[A\n","Iteration:  76% 1027/1357 [10:32<03:11,  1.72it/s]\u001b[A\n","Iteration:  76% 1028/1357 [10:32<03:11,  1.72it/s]\u001b[A\n","Iteration:  76% 1029/1357 [10:33<03:10,  1.72it/s]\u001b[A\n","Iteration:  76% 1030/1357 [10:34<03:10,  1.72it/s]\u001b[A\n","Iteration:  76% 1031/1357 [10:34<03:09,  1.72it/s]\u001b[A\n","Iteration:  76% 1032/1357 [10:35<03:08,  1.72it/s]\u001b[A\n","Iteration:  76% 1033/1357 [10:35<03:08,  1.72it/s]\u001b[A\n","Iteration:  76% 1034/1357 [10:36<03:08,  1.71it/s]\u001b[A\n","Iteration:  76% 1035/1357 [10:37<03:07,  1.72it/s]\u001b[A\n","Iteration:  76% 1036/1357 [10:37<03:06,  1.72it/s]\u001b[A\n","Iteration:  76% 1037/1357 [10:38<03:05,  1.72it/s]\u001b[A\n","Iteration:  76% 1038/1357 [10:38<03:05,  1.72it/s]\u001b[A\n","Iteration:  77% 1039/1357 [10:39<03:05,  1.72it/s]\u001b[A\n","Iteration:  77% 1040/1357 [10:39<03:04,  1.72it/s]\u001b[A\n","Iteration:  77% 1041/1357 [10:40<03:03,  1.72it/s]\u001b[A\n","Iteration:  77% 1042/1357 [10:41<03:02,  1.72it/s]\u001b[A\n","Iteration:  77% 1043/1357 [10:41<03:02,  1.72it/s]\u001b[A\n","Iteration:  77% 1044/1357 [10:42<03:03,  1.71it/s]\u001b[A\n","Iteration:  77% 1045/1357 [10:42<03:01,  1.72it/s]\u001b[A\n","Iteration:  77% 1046/1357 [10:43<03:00,  1.72it/s]\u001b[A\n","Iteration:  77% 1047/1357 [10:44<03:00,  1.72it/s]\u001b[A\n","Iteration:  77% 1048/1357 [10:44<02:59,  1.72it/s]\u001b[A\n","Iteration:  77% 1049/1357 [10:45<02:59,  1.72it/s]\u001b[A\n","Iteration:  77% 1050/1357 [10:45<02:58,  1.72it/s]\u001b[A\n","Iteration:  77% 1051/1357 [10:46<02:57,  1.73it/s]\u001b[A\n","Iteration:  78% 1052/1357 [10:46<02:57,  1.72it/s]\u001b[A\n","Iteration:  78% 1053/1357 [10:47<02:57,  1.71it/s]\u001b[A\n","Iteration:  78% 1054/1357 [10:48<02:56,  1.72it/s]\u001b[A\n","Iteration:  78% 1055/1357 [10:48<02:55,  1.72it/s]\u001b[A\n","Iteration:  78% 1056/1357 [10:49<02:54,  1.72it/s]\u001b[A\n","Iteration:  78% 1057/1357 [10:49<02:53,  1.73it/s]\u001b[A\n","Iteration:  78% 1058/1357 [10:50<02:52,  1.73it/s]\u001b[A\n","Iteration:  78% 1059/1357 [10:51<02:52,  1.72it/s]\u001b[A\n","Iteration:  78% 1060/1357 [10:51<02:51,  1.73it/s]\u001b[A\n","Iteration:  78% 1061/1357 [10:52<02:51,  1.73it/s]\u001b[A\n","Iteration:  78% 1062/1357 [10:52<02:51,  1.72it/s]\u001b[A\n","Iteration:  78% 1063/1357 [10:53<02:49,  1.73it/s]\u001b[A\n","Iteration:  78% 1064/1357 [10:53<02:49,  1.73it/s]\u001b[A\n","Iteration:  78% 1065/1357 [10:54<02:50,  1.72it/s]\u001b[A\n","Iteration:  79% 1066/1357 [10:55<02:49,  1.71it/s]\u001b[A\n","Iteration:  79% 1067/1357 [10:55<02:48,  1.72it/s]\u001b[A\n","Iteration:  79% 1068/1357 [10:56<02:48,  1.72it/s]\u001b[A\n","Iteration:  79% 1069/1357 [10:56<02:46,  1.72it/s]\u001b[A\n","Iteration:  79% 1070/1357 [10:57<02:45,  1.73it/s]\u001b[A\n","Iteration:  79% 1071/1357 [10:57<02:45,  1.73it/s]\u001b[A\n","Iteration:  79% 1072/1357 [10:58<02:45,  1.73it/s]\u001b[A\n","Iteration:  79% 1073/1357 [10:59<02:44,  1.72it/s]\u001b[A\n","Iteration:  79% 1074/1357 [10:59<02:45,  1.71it/s]\u001b[A\n","Iteration:  79% 1075/1357 [11:00<02:44,  1.72it/s]\u001b[A\n","Iteration:  79% 1076/1357 [11:00<02:43,  1.72it/s]\u001b[A\n","Iteration:  79% 1077/1357 [11:01<02:43,  1.72it/s]\u001b[A\n","Iteration:  79% 1078/1357 [11:02<02:42,  1.72it/s]\u001b[A\n","Iteration:  80% 1079/1357 [11:02<02:41,  1.72it/s]\u001b[A\n","Iteration:  80% 1080/1357 [11:03<02:41,  1.72it/s]\u001b[A\n","Iteration:  80% 1081/1357 [11:03<02:40,  1.72it/s]\u001b[A\n","Iteration:  80% 1082/1357 [11:04<02:39,  1.72it/s]\u001b[A\n","Iteration:  80% 1083/1357 [11:04<02:39,  1.72it/s]\u001b[A\n","Iteration:  80% 1084/1357 [11:05<02:38,  1.72it/s]\u001b[A\n","Iteration:  80% 1085/1357 [11:06<02:37,  1.72it/s]\u001b[A\n","Iteration:  80% 1086/1357 [11:06<02:37,  1.72it/s]\u001b[A\n","Iteration:  80% 1087/1357 [11:07<02:37,  1.72it/s]\u001b[A\n","Iteration:  80% 1088/1357 [11:07<02:36,  1.72it/s]\u001b[A\n","Iteration:  80% 1089/1357 [11:08<02:35,  1.72it/s]\u001b[A\n","Iteration:  80% 1090/1357 [11:09<02:35,  1.72it/s]\u001b[A\n","Iteration:  80% 1091/1357 [11:09<02:33,  1.73it/s]\u001b[A\n","Iteration:  80% 1092/1357 [11:10<02:32,  1.74it/s]\u001b[A\n","Iteration:  81% 1093/1357 [11:10<02:32,  1.73it/s]\u001b[A\n","Iteration:  81% 1094/1357 [11:11<02:32,  1.72it/s]\u001b[A\n","Iteration:  81% 1095/1357 [11:11<02:32,  1.72it/s]\u001b[A\n","Iteration:  81% 1096/1357 [11:12<02:31,  1.72it/s]\u001b[A\n","Iteration:  81% 1097/1357 [11:13<02:30,  1.72it/s]\u001b[A\n","Iteration:  81% 1098/1357 [11:13<02:29,  1.73it/s]\u001b[A\n","Iteration:  81% 1099/1357 [11:14<02:29,  1.72it/s]\u001b[A\n","Iteration:  81% 1100/1357 [11:14<02:29,  1.72it/s]\u001b[A\n","Iteration:  81% 1101/1357 [11:15<02:28,  1.73it/s]\u001b[A\n","Iteration:  81% 1102/1357 [11:15<02:28,  1.71it/s]\u001b[A\n","Iteration:  81% 1103/1357 [11:16<02:28,  1.71it/s]\u001b[A\n","Iteration:  81% 1104/1357 [11:17<02:27,  1.71it/s]\u001b[A\n","Iteration:  81% 1105/1357 [11:17<02:26,  1.71it/s]\u001b[A\n","Iteration:  82% 1106/1357 [11:18<02:26,  1.71it/s]\u001b[A\n","Iteration:  82% 1107/1357 [11:18<02:26,  1.71it/s]\u001b[A\n","Iteration:  82% 1108/1357 [11:19<02:25,  1.72it/s]\u001b[A\n","Iteration:  82% 1109/1357 [11:20<02:24,  1.71it/s]\u001b[A\n","Iteration:  82% 1110/1357 [11:20<02:24,  1.71it/s]\u001b[A\n","Iteration:  82% 1111/1357 [11:21<02:23,  1.71it/s]\u001b[A\n","Iteration:  82% 1112/1357 [11:21<02:22,  1.72it/s]\u001b[A\n","Iteration:  82% 1113/1357 [11:22<02:21,  1.72it/s]\u001b[A\n","Iteration:  82% 1114/1357 [11:22<02:20,  1.73it/s]\u001b[A\n","Iteration:  82% 1115/1357 [11:23<02:20,  1.73it/s]\u001b[A\n","Iteration:  82% 1116/1357 [11:24<02:19,  1.73it/s]\u001b[A\n","Iteration:  82% 1117/1357 [11:24<02:18,  1.73it/s]\u001b[A\n","Iteration:  82% 1118/1357 [11:25<02:18,  1.73it/s]\u001b[A\n","Iteration:  82% 1119/1357 [11:25<02:17,  1.73it/s]\u001b[A\n","Iteration:  83% 1120/1357 [11:26<02:17,  1.73it/s]\u001b[A\n","Iteration:  83% 1121/1357 [11:27<02:16,  1.72it/s]\u001b[A\n","Iteration:  83% 1122/1357 [11:27<02:16,  1.72it/s]\u001b[A\n","Iteration:  83% 1123/1357 [11:28<02:15,  1.72it/s]\u001b[A\n","Iteration:  83% 1124/1357 [11:28<02:15,  1.72it/s]\u001b[A\n","Iteration:  83% 1125/1357 [11:29<02:14,  1.72it/s]\u001b[A\n","Iteration:  83% 1126/1357 [11:29<02:13,  1.73it/s]\u001b[A\n","Iteration:  83% 1127/1357 [11:30<02:13,  1.72it/s]\u001b[A\n","Iteration:  83% 1128/1357 [11:31<02:13,  1.72it/s]\u001b[A\n","Iteration:  83% 1129/1357 [11:31<02:12,  1.72it/s]\u001b[A\n","Iteration:  83% 1130/1357 [11:32<02:13,  1.71it/s]\u001b[A\n","Iteration:  83% 1131/1357 [11:32<02:11,  1.71it/s]\u001b[A\n","Iteration:  83% 1132/1357 [11:33<02:11,  1.71it/s]\u001b[A\n","Iteration:  83% 1133/1357 [11:34<02:10,  1.71it/s]\u001b[A\n","Iteration:  84% 1134/1357 [11:34<02:11,  1.70it/s]\u001b[A\n","Iteration:  84% 1135/1357 [11:35<02:09,  1.71it/s]\u001b[A\n","Iteration:  84% 1136/1357 [11:35<02:09,  1.71it/s]\u001b[A\n","Iteration:  84% 1137/1357 [11:36<02:08,  1.71it/s]\u001b[A\n","Iteration:  84% 1138/1357 [11:36<02:07,  1.72it/s]\u001b[A\n","Iteration:  84% 1139/1357 [11:37<02:07,  1.71it/s]\u001b[A\n","Iteration:  84% 1140/1357 [11:38<02:06,  1.72it/s]\u001b[A\n","Iteration:  84% 1141/1357 [11:38<02:04,  1.73it/s]\u001b[A\n","Iteration:  84% 1142/1357 [11:39<02:04,  1.73it/s]\u001b[A\n","Iteration:  84% 1143/1357 [11:39<02:04,  1.72it/s]\u001b[A\n","Iteration:  84% 1144/1357 [11:40<02:04,  1.72it/s]\u001b[A\n","Iteration:  84% 1145/1357 [11:41<02:03,  1.72it/s]\u001b[A\n","Iteration:  84% 1146/1357 [11:41<02:02,  1.72it/s]\u001b[A\n","Iteration:  85% 1147/1357 [11:42<02:01,  1.73it/s]\u001b[A\n","Iteration:  85% 1148/1357 [11:42<02:01,  1.72it/s]\u001b[A\n","Iteration:  85% 1149/1357 [11:43<02:01,  1.72it/s]\u001b[A\n","Iteration:  85% 1150/1357 [11:43<02:00,  1.72it/s]\u001b[A\n","Iteration:  85% 1151/1357 [11:44<01:59,  1.72it/s]\u001b[A\n","Iteration:  85% 1152/1357 [11:45<01:59,  1.72it/s]\u001b[A\n","Iteration:  85% 1153/1357 [11:45<01:58,  1.72it/s]\u001b[A\n","Iteration:  85% 1154/1357 [11:46<01:57,  1.72it/s]\u001b[A\n","Iteration:  85% 1155/1357 [11:46<01:57,  1.72it/s]\u001b[A\n","Iteration:  85% 1156/1357 [11:47<01:56,  1.72it/s]\u001b[A\n","Iteration:  85% 1157/1357 [11:47<01:56,  1.72it/s]\u001b[A\n","Iteration:  85% 1158/1357 [11:48<01:56,  1.71it/s]\u001b[A\n","Iteration:  85% 1159/1357 [11:49<01:54,  1.72it/s]\u001b[A\n","Iteration:  85% 1160/1357 [11:49<01:54,  1.73it/s]\u001b[A\n","Iteration:  86% 1161/1357 [11:50<01:53,  1.72it/s]\u001b[A\n","Iteration:  86% 1162/1357 [11:50<01:53,  1.72it/s]\u001b[A\n","Iteration:  86% 1163/1357 [11:51<01:52,  1.72it/s]\u001b[A\n","Iteration:  86% 1164/1357 [11:52<01:52,  1.72it/s]\u001b[A\n","Iteration:  86% 1165/1357 [11:52<01:51,  1.72it/s]\u001b[A\n","Iteration:  86% 1166/1357 [11:53<01:51,  1.72it/s]\u001b[A\n","Iteration:  86% 1167/1357 [11:53<01:50,  1.72it/s]\u001b[A\n","Iteration:  86% 1168/1357 [11:54<01:50,  1.71it/s]\u001b[A\n","Iteration:  86% 1169/1357 [11:54<01:49,  1.72it/s]\u001b[A\n","Iteration:  86% 1170/1357 [11:55<01:48,  1.72it/s]\u001b[A\n","Iteration:  86% 1171/1357 [11:56<01:48,  1.72it/s]\u001b[A\n","Iteration:  86% 1172/1357 [11:56<01:47,  1.73it/s]\u001b[A\n","Iteration:  86% 1173/1357 [11:57<01:46,  1.72it/s]\u001b[A\n","Iteration:  87% 1174/1357 [11:57<01:46,  1.73it/s]\u001b[A\n","Iteration:  87% 1175/1357 [11:58<01:45,  1.72it/s]\u001b[A\n","Iteration:  87% 1176/1357 [11:59<01:45,  1.72it/s]\u001b[A\n","Iteration:  87% 1177/1357 [11:59<01:44,  1.72it/s]\u001b[A\n","Iteration:  87% 1178/1357 [12:00<01:43,  1.72it/s]\u001b[A\n","Iteration:  87% 1179/1357 [12:00<01:43,  1.72it/s]\u001b[A\n","Iteration:  87% 1180/1357 [12:01<01:42,  1.72it/s]\u001b[A\n","Iteration:  87% 1181/1357 [12:01<01:41,  1.73it/s]\u001b[A\n","Iteration:  87% 1182/1357 [12:02<01:41,  1.72it/s]\u001b[A\n","Iteration:  87% 1183/1357 [12:03<01:41,  1.72it/s]\u001b[A\n","Iteration:  87% 1184/1357 [12:03<01:40,  1.72it/s]\u001b[A\n","Iteration:  87% 1185/1357 [12:04<01:39,  1.72it/s]\u001b[A\n","Iteration:  87% 1186/1357 [12:04<01:39,  1.72it/s]\u001b[A\n","Iteration:  87% 1187/1357 [12:05<01:38,  1.73it/s]\u001b[A\n","Iteration:  88% 1188/1357 [12:05<01:37,  1.73it/s]\u001b[A\n","Iteration:  88% 1189/1357 [12:06<01:37,  1.72it/s]\u001b[A\n","Iteration:  88% 1190/1357 [12:07<01:37,  1.72it/s]\u001b[A\n","Iteration:  88% 1191/1357 [12:07<01:37,  1.71it/s]\u001b[A\n","Iteration:  88% 1192/1357 [12:08<01:36,  1.71it/s]\u001b[A\n","Iteration:  88% 1193/1357 [12:08<01:35,  1.72it/s]\u001b[A\n","Iteration:  88% 1194/1357 [12:09<01:34,  1.72it/s]\u001b[A\n","Iteration:  88% 1195/1357 [12:10<01:34,  1.71it/s]\u001b[A\n","Iteration:  88% 1196/1357 [12:10<01:34,  1.71it/s]\u001b[A\n","Iteration:  88% 1197/1357 [12:11<01:33,  1.71it/s]\u001b[A\n","Iteration:  88% 1198/1357 [12:11<01:32,  1.71it/s]\u001b[A\n","Iteration:  88% 1199/1357 [12:12<01:31,  1.72it/s]\u001b[A\n","Iteration:  88% 1200/1357 [12:12<01:31,  1.72it/s]\u001b[A\n","Iteration:  89% 1201/1357 [12:13<01:30,  1.72it/s]\u001b[A\n","Iteration:  89% 1202/1357 [12:14<01:29,  1.73it/s]\u001b[A\n","Iteration:  89% 1203/1357 [12:14<01:29,  1.71it/s]\u001b[A\n","Iteration:  89% 1204/1357 [12:15<01:29,  1.71it/s]\u001b[A\n","Iteration:  89% 1205/1357 [12:15<01:28,  1.71it/s]\u001b[A\n","Iteration:  89% 1206/1357 [12:16<01:27,  1.72it/s]\u001b[A\n","Iteration:  89% 1207/1357 [12:17<01:27,  1.72it/s]\u001b[A\n","Iteration:  89% 1208/1357 [12:17<01:26,  1.72it/s]\u001b[A\n","Iteration:  89% 1209/1357 [12:18<01:25,  1.73it/s]\u001b[A\n","Iteration:  89% 1210/1357 [12:18<01:25,  1.72it/s]\u001b[A\n","Iteration:  89% 1211/1357 [12:19<01:25,  1.71it/s]\u001b[A\n","Iteration:  89% 1212/1357 [12:19<01:24,  1.72it/s]\u001b[A\n","Iteration:  89% 1213/1357 [12:20<01:23,  1.72it/s]\u001b[A\n","Iteration:  89% 1214/1357 [12:21<01:22,  1.72it/s]\u001b[A\n","Iteration:  90% 1215/1357 [12:21<01:21,  1.73it/s]\u001b[A\n","Iteration:  90% 1216/1357 [12:22<01:21,  1.73it/s]\u001b[A\n","Iteration:  90% 1217/1357 [12:22<01:20,  1.73it/s]\u001b[A\n","Iteration:  90% 1218/1357 [12:23<01:20,  1.73it/s]\u001b[A\n","Iteration:  90% 1219/1357 [12:24<01:20,  1.72it/s]\u001b[A\n","Iteration:  90% 1220/1357 [12:24<01:19,  1.72it/s]\u001b[A\n","Iteration:  90% 1221/1357 [12:25<01:18,  1.72it/s]\u001b[A\n","Iteration:  90% 1222/1357 [12:25<01:18,  1.72it/s]\u001b[A\n","Iteration:  90% 1223/1357 [12:26<01:18,  1.71it/s]\u001b[A\n","Iteration:  90% 1224/1357 [12:26<01:17,  1.71it/s]\u001b[A\n","Iteration:  90% 1225/1357 [12:27<01:17,  1.71it/s]\u001b[A\n","Iteration:  90% 1226/1357 [12:28<01:16,  1.70it/s]\u001b[A\n","Iteration:  90% 1227/1357 [12:28<01:15,  1.71it/s]\u001b[A\n","Iteration:  90% 1228/1357 [12:29<01:15,  1.72it/s]\u001b[A\n","Iteration:  91% 1229/1357 [12:29<01:14,  1.72it/s]\u001b[A\n","Iteration:  91% 1230/1357 [12:30<01:13,  1.72it/s]\u001b[A\n","Iteration:  91% 1231/1357 [12:31<01:12,  1.73it/s]\u001b[A\n","Iteration:  91% 1232/1357 [12:31<01:12,  1.73it/s]\u001b[A\n","Iteration:  91% 1233/1357 [12:32<01:12,  1.72it/s]\u001b[A\n","Iteration:  91% 1234/1357 [12:32<01:11,  1.72it/s]\u001b[A\n","Iteration:  91% 1235/1357 [12:33<01:11,  1.72it/s]\u001b[A\n","Iteration:  91% 1236/1357 [12:33<01:10,  1.72it/s]\u001b[A\n","Iteration:  91% 1237/1357 [12:34<01:09,  1.73it/s]\u001b[A\n","Iteration:  91% 1238/1357 [12:35<01:09,  1.72it/s]\u001b[A\n","Iteration:  91% 1239/1357 [12:35<01:08,  1.71it/s]\u001b[A\n","Iteration:  91% 1240/1357 [12:36<01:08,  1.71it/s]\u001b[A\n","Iteration:  91% 1241/1357 [12:36<01:07,  1.72it/s]\u001b[A\n","Iteration:  92% 1242/1357 [12:37<01:06,  1.72it/s]\u001b[A\n","Iteration:  92% 1243/1357 [12:37<01:05,  1.73it/s]\u001b[A\n","Iteration:  92% 1244/1357 [12:38<01:05,  1.72it/s]\u001b[A\n","Iteration:  92% 1245/1357 [12:39<01:05,  1.72it/s]\u001b[A\n","Iteration:  92% 1246/1357 [12:39<01:04,  1.72it/s]\u001b[A\n","Iteration:  92% 1247/1357 [12:40<01:04,  1.72it/s]\u001b[A\n","Iteration:  92% 1248/1357 [12:40<01:03,  1.72it/s]\u001b[A\n","Iteration:  92% 1249/1357 [12:41<01:02,  1.73it/s]\u001b[A\n","Iteration:  92% 1250/1357 [12:42<01:01,  1.73it/s]\u001b[A\n","Iteration:  92% 1251/1357 [12:42<01:01,  1.73it/s]\u001b[A\n","Iteration:  92% 1252/1357 [12:43<01:00,  1.72it/s]\u001b[A\n","Iteration:  92% 1253/1357 [12:43<01:00,  1.72it/s]\u001b[A\n","Iteration:  92% 1254/1357 [12:44<01:00,  1.71it/s]\u001b[A\n","Iteration:  92% 1255/1357 [12:44<00:59,  1.72it/s]\u001b[A\n","Iteration:  93% 1256/1357 [12:45<00:58,  1.72it/s]\u001b[A\n","Iteration:  93% 1257/1357 [12:46<00:58,  1.72it/s]\u001b[A\n","Iteration:  93% 1258/1357 [12:46<00:57,  1.71it/s]\u001b[A\n","Iteration:  93% 1259/1357 [12:47<00:57,  1.71it/s]\u001b[A\n","Iteration:  93% 1260/1357 [12:47<00:56,  1.71it/s]\u001b[A\n","Iteration:  93% 1261/1357 [12:48<00:55,  1.72it/s]\u001b[A\n","Iteration:  93% 1262/1357 [12:49<00:55,  1.72it/s]\u001b[A\n","Iteration:  93% 1263/1357 [12:49<00:54,  1.72it/s]\u001b[A\n","Iteration:  93% 1264/1357 [12:50<00:54,  1.72it/s]\u001b[A\n","Iteration:  93% 1265/1357 [12:50<00:53,  1.72it/s]\u001b[A\n","Iteration:  93% 1266/1357 [12:51<00:52,  1.72it/s]\u001b[A\n","Iteration:  93% 1267/1357 [12:51<00:52,  1.72it/s]\u001b[A\n","Iteration:  93% 1268/1357 [12:52<00:51,  1.72it/s]\u001b[A\n","Iteration:  94% 1269/1357 [12:53<00:51,  1.71it/s]\u001b[A\n","Iteration:  94% 1270/1357 [12:53<00:50,  1.72it/s]\u001b[A\n","Iteration:  94% 1271/1357 [12:54<00:49,  1.73it/s]\u001b[A\n","Iteration:  94% 1272/1357 [12:54<00:49,  1.72it/s]\u001b[A\n","Iteration:  94% 1273/1357 [12:55<00:48,  1.71it/s]\u001b[A\n","Iteration:  94% 1274/1357 [12:56<00:48,  1.72it/s]\u001b[A\n","Iteration:  94% 1275/1357 [12:56<00:47,  1.72it/s]\u001b[A\n","Iteration:  94% 1276/1357 [12:57<00:47,  1.72it/s]\u001b[A\n","Iteration:  94% 1277/1357 [12:57<00:46,  1.72it/s]\u001b[A\n","Iteration:  94% 1278/1357 [12:58<00:45,  1.72it/s]\u001b[A\n","Iteration:  94% 1279/1357 [12:58<00:45,  1.72it/s]\u001b[A\n","Iteration:  94% 1280/1357 [12:59<00:44,  1.72it/s]\u001b[A\n","Iteration:  94% 1281/1357 [13:00<00:44,  1.72it/s]\u001b[A\n","Iteration:  94% 1282/1357 [13:00<00:43,  1.72it/s]\u001b[A\n","Iteration:  95% 1283/1357 [13:01<00:42,  1.72it/s]\u001b[A\n","Iteration:  95% 1284/1357 [13:01<00:42,  1.72it/s]\u001b[A\n","Iteration:  95% 1285/1357 [13:02<00:42,  1.71it/s]\u001b[A\n","Iteration:  95% 1286/1357 [13:03<00:41,  1.71it/s]\u001b[A\n","Iteration:  95% 1287/1357 [13:03<00:41,  1.70it/s]\u001b[A\n","Iteration:  95% 1288/1357 [13:04<00:40,  1.70it/s]\u001b[A\n","Iteration:  95% 1289/1357 [13:04<00:39,  1.71it/s]\u001b[A\n","Iteration:  95% 1290/1357 [13:05<00:39,  1.71it/s]\u001b[A\n","Iteration:  95% 1291/1357 [13:05<00:38,  1.72it/s]\u001b[A\n","Iteration:  95% 1292/1357 [13:06<00:37,  1.73it/s]\u001b[A\n","Iteration:  95% 1293/1357 [13:07<00:37,  1.72it/s]\u001b[A\n","Iteration:  95% 1294/1357 [13:07<00:36,  1.72it/s]\u001b[A\n","Iteration:  95% 1295/1357 [13:08<00:35,  1.72it/s]\u001b[A\n","Iteration:  96% 1296/1357 [13:08<00:35,  1.73it/s]\u001b[A\n","Iteration:  96% 1297/1357 [13:09<00:34,  1.72it/s]\u001b[A\n","Iteration:  96% 1298/1357 [13:09<00:34,  1.72it/s]\u001b[A\n","Iteration:  96% 1299/1357 [13:10<00:33,  1.72it/s]\u001b[A\n","Iteration:  96% 1300/1357 [13:11<00:33,  1.72it/s]\u001b[A\n","Iteration:  96% 1301/1357 [13:11<00:32,  1.72it/s]\u001b[A\n","Iteration:  96% 1302/1357 [13:12<00:31,  1.73it/s]\u001b[A\n","Iteration:  96% 1303/1357 [13:12<00:31,  1.72it/s]\u001b[A\n","Iteration:  96% 1304/1357 [13:13<00:30,  1.73it/s]\u001b[A\n","Iteration:  96% 1305/1357 [13:14<00:30,  1.73it/s]\u001b[A\n","Iteration:  96% 1306/1357 [13:14<00:29,  1.72it/s]\u001b[A\n","Iteration:  96% 1307/1357 [13:15<00:29,  1.72it/s]\u001b[A\n","Iteration:  96% 1308/1357 [13:15<00:28,  1.73it/s]\u001b[A\n","Iteration:  96% 1309/1357 [13:16<00:27,  1.72it/s]\u001b[A\n","Iteration:  97% 1310/1357 [13:16<00:27,  1.71it/s]\u001b[A\n","Iteration:  97% 1311/1357 [13:17<00:26,  1.72it/s]\u001b[A\n","Iteration:  97% 1312/1357 [13:18<00:26,  1.71it/s]\u001b[A\n","Iteration:  97% 1313/1357 [13:18<00:25,  1.72it/s]\u001b[A\n","Iteration:  97% 1314/1357 [13:19<00:24,  1.72it/s]\u001b[A\n","Iteration:  97% 1315/1357 [13:19<00:24,  1.72it/s]\u001b[A\n","Iteration:  97% 1316/1357 [13:20<00:23,  1.72it/s]\u001b[A\n","Iteration:  97% 1317/1357 [13:21<00:23,  1.72it/s]\u001b[A\n","Iteration:  97% 1318/1357 [13:21<00:22,  1.70it/s]\u001b[A\n","Iteration:  97% 1319/1357 [13:22<00:22,  1.71it/s]\u001b[A\n","Iteration:  97% 1320/1357 [13:22<00:21,  1.72it/s]\u001b[A\n","Iteration:  97% 1321/1357 [13:23<00:20,  1.72it/s]\u001b[A\n","Iteration:  97% 1322/1357 [13:23<00:20,  1.72it/s]\u001b[A\n","Iteration:  97% 1323/1357 [13:24<00:19,  1.72it/s]\u001b[A\n","Iteration:  98% 1324/1357 [13:25<00:19,  1.72it/s]\u001b[A\n","Iteration:  98% 1325/1357 [13:25<00:18,  1.72it/s]\u001b[A\n","Iteration:  98% 1326/1357 [13:26<00:18,  1.72it/s]\u001b[A\n","Iteration:  98% 1327/1357 [13:26<00:17,  1.72it/s]\u001b[A\n","Iteration:  98% 1328/1357 [13:27<00:16,  1.72it/s]\u001b[A\n","Iteration:  98% 1329/1357 [13:28<00:16,  1.72it/s]\u001b[A\n","Iteration:  98% 1330/1357 [13:28<00:15,  1.72it/s]\u001b[A\n","Iteration:  98% 1331/1357 [13:29<00:15,  1.72it/s]\u001b[A\n","Iteration:  98% 1332/1357 [13:29<00:14,  1.73it/s]\u001b[A\n","Iteration:  98% 1333/1357 [13:30<00:13,  1.73it/s]\u001b[A\n","Iteration:  98% 1334/1357 [13:30<00:13,  1.73it/s]\u001b[A\n","Iteration:  98% 1335/1357 [13:31<00:12,  1.72it/s]\u001b[A\n","Iteration:  98% 1336/1357 [13:32<00:12,  1.73it/s]\u001b[A\n","Iteration:  99% 1337/1357 [13:32<00:11,  1.73it/s]\u001b[A\n","Iteration:  99% 1338/1357 [13:33<00:11,  1.72it/s]\u001b[A\n","Iteration:  99% 1339/1357 [13:33<00:10,  1.73it/s]\u001b[A\n","Iteration:  99% 1340/1357 [13:34<00:09,  1.72it/s]\u001b[A\n","Iteration:  99% 1341/1357 [13:34<00:09,  1.72it/s]\u001b[A\n","Iteration:  99% 1342/1357 [13:35<00:08,  1.72it/s]\u001b[A\n","Iteration:  99% 1343/1357 [13:36<00:08,  1.72it/s]\u001b[A\n","Iteration:  99% 1344/1357 [13:36<00:07,  1.72it/s]\u001b[A\n","Iteration:  99% 1345/1357 [13:37<00:06,  1.72it/s]\u001b[A\n","Iteration:  99% 1346/1357 [13:37<00:06,  1.72it/s]\u001b[A\n","Iteration:  99% 1347/1357 [13:38<00:05,  1.72it/s]\u001b[A\n","Iteration:  99% 1348/1357 [13:39<00:05,  1.73it/s]\u001b[A\n","Iteration:  99% 1349/1357 [13:39<00:04,  1.72it/s]\u001b[A\n","Iteration:  99% 1350/1357 [13:40<00:04,  1.71it/s]\u001b[A\n","Iteration: 100% 1351/1357 [13:40<00:03,  1.72it/s]\u001b[A\n","Iteration: 100% 1352/1357 [13:41<00:02,  1.72it/s]\u001b[A\n","Iteration: 100% 1353/1357 [13:41<00:02,  1.72it/s]\u001b[A\n","Iteration: 100% 1354/1357 [13:42<00:01,  1.71it/s]\u001b[A\n","Iteration: 100% 1355/1357 [13:43<00:01,  1.71it/s]\u001b[A\n","Iteration: 100% 1356/1357 [13:43<00:00,  1.71it/s]\u001b[A\n","Iteration: 100% 1357/1357 [13:44<00:00,  1.65it/s]\n","Epoch:  80% 8/10 [1:51:12<27:43, 831.98s/it]\n","Iteration:   0% 0/1357 [00:00<?, ?it/s]\u001b[A\n","Iteration:   0% 1/1357 [00:00<13:01,  1.73it/s]\u001b[A\n","Iteration:   0% 2/1357 [00:01<13:07,  1.72it/s]\u001b[A\n","Iteration:   0% 3/1357 [00:01<13:04,  1.73it/s]\u001b[A\n","Iteration:   0% 4/1357 [00:02<13:09,  1.71it/s]\u001b[A\n","Iteration:   0% 5/1357 [00:02<13:06,  1.72it/s]\u001b[A\n","Iteration:   0% 6/1357 [00:03<13:02,  1.73it/s]\u001b[A\n","Iteration:   1% 7/1357 [00:04<13:02,  1.72it/s]\u001b[A\n","Iteration:   1% 8/1357 [00:04<13:05,  1.72it/s]\u001b[A\n","Iteration:   1% 9/1357 [00:05<13:02,  1.72it/s]\u001b[A\n","Iteration:   1% 10/1357 [00:05<13:04,  1.72it/s]\u001b[A\n","Iteration:   1% 11/1357 [00:06<13:03,  1.72it/s]\u001b[A\n","Iteration:   1% 12/1357 [00:06<12:58,  1.73it/s]\u001b[A\n","Iteration:   1% 13/1357 [00:07<13:00,  1.72it/s]\u001b[A\n","Iteration:   1% 14/1357 [00:08<13:00,  1.72it/s]\u001b[A\n","Iteration:   1% 15/1357 [00:08<12:59,  1.72it/s]\u001b[A\n","Iteration:   1% 16/1357 [00:09<12:59,  1.72it/s]\u001b[A\n","Iteration:   1% 17/1357 [00:09<13:01,  1.71it/s]\u001b[A\n","Iteration:   1% 18/1357 [00:10<12:57,  1.72it/s]\u001b[A\n","Iteration:   1% 19/1357 [00:11<12:58,  1.72it/s]\u001b[A\n","Iteration:   1% 20/1357 [00:11<12:58,  1.72it/s]\u001b[A\n","Iteration:   2% 21/1357 [00:12<13:01,  1.71it/s]\u001b[A\n","Iteration:   2% 22/1357 [00:12<13:00,  1.71it/s]\u001b[A\n","Iteration:   2% 23/1357 [00:13<13:00,  1.71it/s]\u001b[A\n","Iteration:   2% 24/1357 [00:13<12:56,  1.72it/s]\u001b[A\n","Iteration:   2% 25/1357 [00:14<12:54,  1.72it/s]\u001b[A\n","Iteration:   2% 26/1357 [00:15<12:55,  1.72it/s]\u001b[A\n","Iteration:   2% 27/1357 [00:15<12:52,  1.72it/s]\u001b[A\n","Iteration:   2% 28/1357 [00:16<12:52,  1.72it/s]\u001b[A\n","Iteration:   2% 29/1357 [00:16<12:51,  1.72it/s]\u001b[A\n","Iteration:   2% 30/1357 [00:17<12:49,  1.72it/s]\u001b[A\n","Iteration:   2% 31/1357 [00:18<12:48,  1.72it/s]\u001b[A\n","Iteration:   2% 32/1357 [00:18<12:50,  1.72it/s]\u001b[A\n","Iteration:   2% 33/1357 [00:19<12:46,  1.73it/s]\u001b[A\n","Iteration:   3% 34/1357 [00:19<12:47,  1.72it/s]\u001b[A\n","Iteration:   3% 35/1357 [00:20<12:47,  1.72it/s]\u001b[A\n","Iteration:   3% 36/1357 [00:20<12:49,  1.72it/s]\u001b[A\n","Iteration:   3% 37/1357 [00:21<12:49,  1.72it/s]\u001b[A\n","Iteration:   3% 38/1357 [00:22<12:48,  1.72it/s]\u001b[A\n","Iteration:   3% 39/1357 [00:22<12:45,  1.72it/s]\u001b[A\n","Iteration:   3% 40/1357 [00:23<12:42,  1.73it/s]\u001b[A\n","Iteration:   3% 41/1357 [00:23<12:43,  1.72it/s]\u001b[A\n","Iteration:   3% 42/1357 [00:24<12:46,  1.72it/s]\u001b[A\n","Iteration:   3% 43/1357 [00:25<12:44,  1.72it/s]\u001b[A\n","Iteration:   3% 44/1357 [00:25<12:41,  1.72it/s]\u001b[A\n","Iteration:   3% 45/1357 [00:26<12:40,  1.73it/s]\u001b[A\n","Iteration:   3% 46/1357 [00:26<12:38,  1.73it/s]\u001b[A\n","Iteration:   3% 47/1357 [00:27<12:41,  1.72it/s]\u001b[A\n","Iteration:   4% 48/1357 [00:27<12:41,  1.72it/s]\u001b[A\n","Iteration:   4% 49/1357 [00:28<12:41,  1.72it/s]\u001b[A\n","Iteration:   4% 50/1357 [00:29<12:40,  1.72it/s]\u001b[A\n","Iteration:   4% 51/1357 [00:29<12:42,  1.71it/s]\u001b[A\n","Iteration:   4% 52/1357 [00:30<12:38,  1.72it/s]\u001b[A\n","Iteration:   4% 53/1357 [00:30<12:38,  1.72it/s]\u001b[A\n","Iteration:   4% 54/1357 [00:31<12:37,  1.72it/s]\u001b[A\n","Iteration:   4% 55/1357 [00:31<12:35,  1.72it/s]\u001b[A\n","Iteration:   4% 56/1357 [00:32<12:34,  1.72it/s]\u001b[A\n","Iteration:   4% 57/1357 [00:33<12:33,  1.72it/s]\u001b[A\n","Iteration:   4% 58/1357 [00:33<12:33,  1.72it/s]\u001b[A\n","Iteration:   4% 59/1357 [00:34<12:32,  1.73it/s]\u001b[A\n","Iteration:   4% 60/1357 [00:34<12:34,  1.72it/s]\u001b[A\n","Iteration:   4% 61/1357 [00:35<12:31,  1.73it/s]\u001b[A\n","Iteration:   5% 62/1357 [00:36<12:28,  1.73it/s]\u001b[A\n","Iteration:   5% 63/1357 [00:36<12:31,  1.72it/s]\u001b[A\n","Iteration:   5% 64/1357 [00:37<12:32,  1.72it/s]\u001b[A\n","Iteration:   5% 65/1357 [00:37<12:31,  1.72it/s]\u001b[A\n","Iteration:   5% 66/1357 [00:38<12:33,  1.71it/s]\u001b[A\n","Iteration:   5% 67/1357 [00:38<12:29,  1.72it/s]\u001b[A\n","Iteration:   5% 68/1357 [00:39<12:25,  1.73it/s]\u001b[A\n","Iteration:   5% 69/1357 [00:40<12:26,  1.72it/s]\u001b[A\n","Iteration:   5% 70/1357 [00:40<12:32,  1.71it/s]\u001b[A\n","Iteration:   5% 71/1357 [00:41<12:29,  1.72it/s]\u001b[A\n","Iteration:   5% 72/1357 [00:41<12:28,  1.72it/s]\u001b[A\n","Iteration:   5% 73/1357 [00:42<12:27,  1.72it/s]\u001b[A\n","Iteration:   5% 74/1357 [00:43<12:28,  1.71it/s]\u001b[A\n","Iteration:   6% 75/1357 [00:43<12:28,  1.71it/s]\u001b[A\n","Iteration:   6% 76/1357 [00:44<12:27,  1.71it/s]\u001b[A\n","Iteration:   6% 77/1357 [00:44<12:30,  1.71it/s]\u001b[A\n","Iteration:   6% 78/1357 [00:45<12:30,  1.70it/s]\u001b[A\n","Iteration:   6% 79/1357 [00:45<12:28,  1.71it/s]\u001b[A\n","Iteration:   6% 80/1357 [00:46<12:28,  1.71it/s]\u001b[A\n","Iteration:   6% 81/1357 [00:47<12:26,  1.71it/s]\u001b[A\n","Iteration:   6% 82/1357 [00:47<12:21,  1.72it/s]\u001b[A\n","Iteration:   6% 83/1357 [00:48<12:21,  1.72it/s]\u001b[A\n","Iteration:   6% 84/1357 [00:48<12:22,  1.71it/s]\u001b[A\n","Iteration:   6% 85/1357 [00:49<12:22,  1.71it/s]\u001b[A\n","Iteration:   6% 86/1357 [00:50<12:20,  1.72it/s]\u001b[A\n","Iteration:   6% 87/1357 [00:50<12:18,  1.72it/s]\u001b[A\n","Iteration:   6% 88/1357 [00:51<12:15,  1.72it/s]\u001b[A\n","Iteration:   7% 89/1357 [00:51<12:12,  1.73it/s]\u001b[A\n","Iteration:   7% 90/1357 [00:52<12:15,  1.72it/s]\u001b[A\n","Iteration:   7% 91/1357 [00:52<12:17,  1.72it/s]\u001b[A\n","Iteration:   7% 92/1357 [00:53<12:20,  1.71it/s]\u001b[A\n","Iteration:   7% 93/1357 [00:54<12:17,  1.71it/s]\u001b[A\n","Iteration:   7% 94/1357 [00:54<12:17,  1.71it/s]\u001b[A\n","Iteration:   7% 95/1357 [00:55<12:12,  1.72it/s]\u001b[A\n","Iteration:   7% 96/1357 [00:55<12:13,  1.72it/s]\u001b[A\n","Iteration:   7% 97/1357 [00:56<12:18,  1.71it/s]\u001b[A\n","Iteration:   7% 98/1357 [00:57<12:14,  1.71it/s]\u001b[A\n","Iteration:   7% 99/1357 [00:57<12:12,  1.72it/s]\u001b[A\n","Iteration:   7% 100/1357 [00:58<12:12,  1.72it/s]\u001b[A\n","Iteration:   7% 101/1357 [00:58<12:08,  1.72it/s]\u001b[A\n","Iteration:   8% 102/1357 [00:59<12:07,  1.73it/s]\u001b[A\n","Iteration:   8% 103/1357 [00:59<12:07,  1.72it/s]\u001b[A\n","Iteration:   8% 104/1357 [01:00<12:07,  1.72it/s]\u001b[A\n","Iteration:   8% 105/1357 [01:01<12:07,  1.72it/s]\u001b[A\n","Iteration:   8% 106/1357 [01:01<12:08,  1.72it/s]\u001b[A\n","Iteration:   8% 107/1357 [01:02<12:07,  1.72it/s]\u001b[A\n","Iteration:   8% 108/1357 [01:02<12:06,  1.72it/s]\u001b[A\n","Iteration:   8% 109/1357 [01:03<12:04,  1.72it/s]\u001b[A\n","Iteration:   8% 110/1357 [01:03<12:07,  1.71it/s]\u001b[A\n","Iteration:   8% 111/1357 [01:04<12:06,  1.71it/s]\u001b[A\n","Iteration:   8% 112/1357 [01:05<12:05,  1.72it/s]\u001b[A\n","Iteration:   8% 113/1357 [01:05<12:03,  1.72it/s]\u001b[A\n","Iteration:   8% 114/1357 [01:06<12:06,  1.71it/s]\u001b[A\n","Iteration:   8% 115/1357 [01:06<12:05,  1.71it/s]\u001b[A\n","Iteration:   9% 116/1357 [01:07<12:02,  1.72it/s]\u001b[A\n","Iteration:   9% 117/1357 [01:08<11:59,  1.72it/s]\u001b[A\n","Iteration:   9% 118/1357 [01:08<11:59,  1.72it/s]\u001b[A\n","Iteration:   9% 119/1357 [01:09<12:02,  1.71it/s]\u001b[A\n","Iteration:   9% 120/1357 [01:09<12:01,  1.71it/s]\u001b[A\n","Iteration:   9% 121/1357 [01:10<12:03,  1.71it/s]\u001b[A\n","Iteration:   9% 122/1357 [01:10<11:57,  1.72it/s]\u001b[A\n","Iteration:   9% 123/1357 [01:11<11:55,  1.73it/s]\u001b[A\n","Iteration:   9% 124/1357 [01:12<11:58,  1.72it/s]\u001b[A\n","Iteration:   9% 125/1357 [01:12<11:59,  1.71it/s]\u001b[A\n","Iteration:   9% 126/1357 [01:13<11:58,  1.71it/s]\u001b[A\n","Iteration:   9% 127/1357 [01:13<11:58,  1.71it/s]\u001b[A\n","Iteration:   9% 128/1357 [01:14<11:54,  1.72it/s]\u001b[A\n","Iteration:  10% 129/1357 [01:15<11:52,  1.72it/s]\u001b[A\n","Iteration:  10% 130/1357 [01:15<11:53,  1.72it/s]\u001b[A\n","Iteration:  10% 131/1357 [01:16<11:55,  1.71it/s]\u001b[A\n","Iteration:  10% 132/1357 [01:16<11:51,  1.72it/s]\u001b[A\n","Iteration:  10% 133/1357 [01:17<11:49,  1.73it/s]\u001b[A\n","Iteration:  10% 134/1357 [01:17<11:50,  1.72it/s]\u001b[A\n","Iteration:  10% 135/1357 [01:18<11:48,  1.72it/s]\u001b[A\n","Iteration:  10% 136/1357 [01:19<11:49,  1.72it/s]\u001b[A\n","Iteration:  10% 137/1357 [01:19<11:49,  1.72it/s]\u001b[A\n","Iteration:  10% 138/1357 [01:20<11:49,  1.72it/s]\u001b[A\n","Iteration:  10% 139/1357 [01:20<11:48,  1.72it/s]\u001b[A\n","Iteration:  10% 140/1357 [01:21<11:49,  1.72it/s]\u001b[A\n","Iteration:  10% 141/1357 [01:22<11:46,  1.72it/s]\u001b[A\n","Iteration:  10% 142/1357 [01:22<11:46,  1.72it/s]\u001b[A\n","Iteration:  11% 143/1357 [01:23<11:44,  1.72it/s]\u001b[A12/16/2021 06:13:20 - INFO - __main__ -   ***** Running evaluation on dev dataset (11000 step) *****\n","12/16/2021 06:13:20 - INFO - __main__ -     Num examples = 5426\n","12/16/2021 06:13:20 - INFO - __main__ -     Eval Batch size = 32\n","\n","\n","Evaluating:   0% 0/170 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluating:   1% 1/170 [00:00<00:32,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:   1% 2/170 [00:00<00:31,  5.35it/s]\u001b[A\u001b[A\n","\n","Evaluating:   2% 3/170 [00:00<00:31,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:   2% 4/170 [00:00<00:31,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:   3% 5/170 [00:00<00:31,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:   4% 6/170 [00:01<00:31,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:   4% 7/170 [00:01<00:31,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:   5% 8/170 [00:01<00:31,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:   5% 9/170 [00:01<00:30,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:   6% 10/170 [00:01<00:31,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:   6% 11/170 [00:02<00:30,  5.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:   7% 12/170 [00:02<00:30,  5.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:   8% 13/170 [00:02<00:30,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:   8% 14/170 [00:02<00:30,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:   9% 15/170 [00:02<00:29,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:   9% 16/170 [00:03<00:29,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  10% 17/170 [00:03<00:29,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  11% 18/170 [00:03<00:29,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  11% 19/170 [00:03<00:29,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  12% 20/170 [00:03<00:28,  5.23it/s]\u001b[A\u001b[A\n","\n","Evaluating:  12% 21/170 [00:04<00:28,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  13% 22/170 [00:04<00:28,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  14% 23/170 [00:04<00:28,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  14% 24/170 [00:04<00:28,  5.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  15% 25/170 [00:04<00:28,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  15% 26/170 [00:05<00:27,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  16% 27/170 [00:05<00:27,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  16% 28/170 [00:05<00:27,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  17% 29/170 [00:05<00:27,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  18% 30/170 [00:05<00:26,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  18% 31/170 [00:05<00:26,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  19% 32/170 [00:06<00:26,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  19% 33/170 [00:06<00:26,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  20% 34/170 [00:06<00:26,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  21% 35/170 [00:06<00:26,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  21% 36/170 [00:06<00:26,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  22% 37/170 [00:07<00:25,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  22% 38/170 [00:07<00:25,  5.23it/s]\u001b[A\u001b[A\n","\n","Evaluating:  23% 39/170 [00:07<00:25,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  24% 40/170 [00:07<00:25,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  24% 41/170 [00:07<00:24,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  25% 42/170 [00:08<00:24,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  25% 43/170 [00:08<00:24,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  26% 44/170 [00:08<00:24,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  26% 45/170 [00:08<00:24,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  27% 46/170 [00:08<00:23,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  28% 47/170 [00:09<00:23,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  28% 48/170 [00:09<00:23,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  29% 49/170 [00:09<00:23,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  29% 50/170 [00:09<00:23,  5.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  30% 51/170 [00:09<00:23,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  31% 52/170 [00:10<00:22,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  31% 53/170 [00:10<00:22,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  32% 54/170 [00:10<00:22,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  32% 55/170 [00:10<00:22,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  33% 56/170 [00:10<00:21,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  34% 57/170 [00:10<00:21,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  34% 58/170 [00:11<00:21,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  35% 59/170 [00:11<00:21,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  35% 60/170 [00:11<00:21,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  36% 61/170 [00:11<00:20,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  36% 62/170 [00:11<00:20,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  37% 63/170 [00:12<00:20,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  38% 64/170 [00:12<00:20,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  38% 65/170 [00:12<00:20,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  39% 66/170 [00:12<00:20,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  39% 67/170 [00:12<00:19,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  40% 68/170 [00:13<00:19,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  41% 69/170 [00:13<00:19,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  41% 70/170 [00:13<00:19,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  42% 71/170 [00:13<00:19,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  42% 72/170 [00:13<00:18,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  43% 73/170 [00:14<00:18,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  44% 74/170 [00:14<00:18,  5.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  44% 75/170 [00:14<00:18,  5.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  45% 76/170 [00:14<00:18,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  45% 77/170 [00:14<00:17,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  46% 78/170 [00:15<00:17,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  46% 79/170 [00:15<00:17,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  47% 80/170 [00:15<00:17,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  48% 81/170 [00:15<00:17,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  48% 82/170 [00:15<00:16,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  49% 83/170 [00:15<00:16,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  49% 84/170 [00:16<00:16,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  50% 85/170 [00:16<00:16,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  51% 86/170 [00:16<00:16,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  51% 87/170 [00:16<00:15,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  52% 88/170 [00:16<00:15,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  52% 89/170 [00:17<00:15,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  53% 90/170 [00:17<00:15,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  54% 91/170 [00:17<00:15,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  54% 92/170 [00:17<00:14,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  55% 93/170 [00:17<00:14,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  55% 94/170 [00:18<00:14,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  56% 95/170 [00:18<00:14,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  56% 96/170 [00:18<00:14,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  57% 97/170 [00:18<00:14,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  58% 98/170 [00:18<00:13,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  58% 99/170 [00:19<00:13,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  59% 100/170 [00:19<00:13,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  59% 101/170 [00:19<00:13,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  60% 102/170 [00:19<00:13,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  61% 103/170 [00:19<00:12,  5.23it/s]\u001b[A\u001b[A\n","\n","Evaluating:  61% 104/170 [00:20<00:12,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 105/170 [00:20<00:12,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 106/170 [00:20<00:12,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  63% 107/170 [00:20<00:12,  5.14it/s]\u001b[A\u001b[A\n","\n","Evaluating:  64% 108/170 [00:20<00:11,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  64% 109/170 [00:20<00:11,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  65% 110/170 [00:21<00:11,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  65% 111/170 [00:21<00:11,  5.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:  66% 112/170 [00:21<00:11,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  66% 113/170 [00:21<00:11,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  67% 114/170 [00:21<00:10,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  68% 115/170 [00:22<00:10,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  68% 116/170 [00:22<00:10,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  69% 117/170 [00:22<00:10,  5.23it/s]\u001b[A\u001b[A\n","\n","Evaluating:  69% 118/170 [00:22<00:09,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  70% 119/170 [00:22<00:09,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  71% 120/170 [00:23<00:09,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  71% 121/170 [00:23<00:09,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  72% 122/170 [00:23<00:09,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  72% 123/170 [00:23<00:09,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  73% 124/170 [00:23<00:08,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  74% 125/170 [00:24<00:08,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  74% 126/170 [00:24<00:08,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 127/170 [00:24<00:08,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 128/170 [00:24<00:08,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  76% 129/170 [00:24<00:07,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  76% 130/170 [00:25<00:07,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  77% 131/170 [00:25<00:07,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  78% 132/170 [00:25<00:07,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  78% 133/170 [00:25<00:07,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  79% 134/170 [00:25<00:06,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  79% 135/170 [00:25<00:06,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  80% 136/170 [00:26<00:06,  5.23it/s]\u001b[A\u001b[A\n","\n","Evaluating:  81% 137/170 [00:26<00:06,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  81% 138/170 [00:26<00:06,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  82% 139/170 [00:26<00:05,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  82% 140/170 [00:26<00:05,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  83% 141/170 [00:27<00:05,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  84% 142/170 [00:27<00:05,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  84% 143/170 [00:27<00:05,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  85% 144/170 [00:27<00:05,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  85% 145/170 [00:27<00:04,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  86% 146/170 [00:28<00:04,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  86% 147/170 [00:28<00:04,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  87% 148/170 [00:28<00:04,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 149/170 [00:28<00:04,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 150/170 [00:28<00:03,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  89% 151/170 [00:29<00:03,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  89% 152/170 [00:29<00:03,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  90% 153/170 [00:29<00:03,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  91% 154/170 [00:29<00:03,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  91% 155/170 [00:29<00:02,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  92% 156/170 [00:30<00:02,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  92% 157/170 [00:30<00:02,  5.16it/s]\u001b[A\u001b[A\n","\n","Evaluating:  93% 158/170 [00:30<00:02,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  94% 159/170 [00:30<00:02,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  94% 160/170 [00:30<00:01,  5.17it/s]\u001b[A\u001b[A\n","\n","Evaluating:  95% 161/170 [00:31<00:01,  5.15it/s]\u001b[A\u001b[A\n","\n","Evaluating:  95% 162/170 [00:31<00:01,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  96% 163/170 [00:31<00:01,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  96% 164/170 [00:31<00:01,  5.19it/s]\u001b[A\u001b[A\n","\n","Evaluating:  97% 165/170 [00:31<00:00,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  98% 166/170 [00:31<00:00,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  98% 167/170 [00:32<00:00,  5.18it/s]\u001b[A\u001b[A\n","\n","Evaluating:  99% 168/170 [00:32<00:00,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating:  99% 169/170 [00:32<00:00,  5.21it/s]\u001b[A\u001b[A\n","\n","Evaluating: 100% 170/170 [00:32<00:00,  5.20it/s]\n","12/16/2021 06:13:52 - INFO - __main__ -   ***** Eval results on dev dataset *****\n","12/16/2021 06:13:52 - INFO - __main__ -     accuracy = 0.3597493549576115\n","12/16/2021 06:13:52 - INFO - __main__ -     loss = 0.1504637247061028\n","12/16/2021 06:13:52 - INFO - __main__ -     macro_f1 = 0.39903610856810356\n","12/16/2021 06:13:52 - INFO - __main__ -     macro_precision = 0.38619541420040443\n","12/16/2021 06:13:52 - INFO - __main__ -     macro_recall = 0.4229142096518001\n","12/16/2021 06:13:52 - INFO - __main__ -     micro_f1 = 0.49793510324483775\n","12/16/2021 06:13:52 - INFO - __main__ -     micro_precision = 0.4701949860724234\n","12/16/2021 06:13:52 - INFO - __main__ -     micro_recall = 0.529153605015674\n","12/16/2021 06:13:52 - INFO - __main__ -     weighted_f1 = 0.49245445579186126\n","12/16/2021 06:13:52 - INFO - __main__ -     weighted_precision = 0.46485015137267116\n","12/16/2021 06:13:52 - INFO - __main__ -     weighted_recall = 0.529153605015674\n","12/16/2021 06:13:52 - INFO - transformers.configuration_utils -   Configuration saved in drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-11000/config.json\n","12/16/2021 06:13:54 - INFO - transformers.modeling_utils -   Model weights saved in drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-11000/pytorch_model.bin\n","12/16/2021 06:13:55 - INFO - __main__ -   Saving model checkpoint to drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-11000\n","\n","Iteration:  11% 144/1357 [01:59<3:47:11, 11.24s/it]\u001b[A\n","Iteration:  11% 145/1357 [01:59<2:42:56,  8.07s/it]\u001b[A\n","Iteration:  11% 146/1357 [02:00<1:57:27,  5.82s/it]\u001b[A\n","Iteration:  11% 147/1357 [02:01<1:25:40,  4.25s/it]\u001b[A\n","Iteration:  11% 148/1357 [02:01<1:03:27,  3.15s/it]\u001b[A\n","Iteration:  11% 149/1357 [02:02<47:50,  2.38s/it]  \u001b[A\n","Iteration:  11% 150/1357 [02:02<36:58,  1.84s/it]\u001b[A\n","Iteration:  11% 151/1357 [02:03<29:20,  1.46s/it]\u001b[A\n","Iteration:  11% 152/1357 [02:04<24:17,  1.21s/it]\u001b[A\n","Iteration:  11% 153/1357 [02:04<20:32,  1.02s/it]\u001b[A\n","Iteration:  11% 154/1357 [02:05<17:58,  1.12it/s]\u001b[A\n","Iteration:  11% 155/1357 [02:05<16:10,  1.24it/s]\u001b[A\n","Iteration:  11% 156/1357 [02:06<14:48,  1.35it/s]\u001b[A\n","Iteration:  12% 157/1357 [02:07<13:57,  1.43it/s]\u001b[A\n","Iteration:  12% 158/1357 [02:07<13:18,  1.50it/s]\u001b[A\n","Iteration:  12% 159/1357 [02:08<12:53,  1.55it/s]\u001b[A\n","Iteration:  12% 160/1357 [02:08<12:30,  1.60it/s]\u001b[A\n","Iteration:  12% 161/1357 [02:09<12:20,  1.62it/s]\u001b[A\n","Iteration:  12% 162/1357 [02:10<12:12,  1.63it/s]\u001b[A\n","Iteration:  12% 163/1357 [02:10<11:59,  1.66it/s]\u001b[A\n","Iteration:  12% 164/1357 [02:11<11:52,  1.68it/s]\u001b[A\n","Iteration:  12% 165/1357 [02:11<11:46,  1.69it/s]\u001b[A\n","Iteration:  12% 166/1357 [02:12<11:38,  1.71it/s]\u001b[A\n","Iteration:  12% 167/1357 [02:12<11:35,  1.71it/s]\u001b[A\n","Iteration:  12% 168/1357 [02:13<11:35,  1.71it/s]\u001b[A\n","Iteration:  12% 169/1357 [02:14<11:32,  1.72it/s]\u001b[A\n","Iteration:  13% 170/1357 [02:14<11:30,  1.72it/s]\u001b[A\n","Iteration:  13% 171/1357 [02:15<11:29,  1.72it/s]\u001b[A\n","Iteration:  13% 172/1357 [02:15<11:29,  1.72it/s]\u001b[A\n","Iteration:  13% 173/1357 [02:16<11:28,  1.72it/s]\u001b[A\n","Iteration:  13% 174/1357 [02:16<11:28,  1.72it/s]\u001b[A\n","Iteration:  13% 175/1357 [02:17<11:24,  1.73it/s]\u001b[A\n","Iteration:  13% 176/1357 [02:18<11:22,  1.73it/s]\u001b[A\n","Iteration:  13% 177/1357 [02:18<11:26,  1.72it/s]\u001b[A\n","Iteration:  13% 178/1357 [02:19<11:26,  1.72it/s]\u001b[A\n","Iteration:  13% 179/1357 [02:19<11:26,  1.72it/s]\u001b[A\n","Iteration:  13% 180/1357 [02:20<11:27,  1.71it/s]\u001b[A\n","Iteration:  13% 181/1357 [02:21<11:22,  1.72it/s]\u001b[A\n","Iteration:  13% 182/1357 [02:21<11:19,  1.73it/s]\u001b[A\n","Iteration:  13% 183/1357 [02:22<11:18,  1.73it/s]\u001b[A\n","Iteration:  14% 184/1357 [02:22<11:22,  1.72it/s]\u001b[A\n","Iteration:  14% 185/1357 [02:23<11:22,  1.72it/s]\u001b[A\n","Iteration:  14% 186/1357 [02:23<11:21,  1.72it/s]\u001b[A\n","Iteration:  14% 187/1357 [02:24<11:21,  1.72it/s]\u001b[A\n","Iteration:  14% 188/1357 [02:25<11:20,  1.72it/s]\u001b[A\n","Iteration:  14% 189/1357 [02:25<11:19,  1.72it/s]\u001b[A\n","Iteration:  14% 190/1357 [02:26<11:19,  1.72it/s]\u001b[A\n","Iteration:  14% 191/1357 [02:26<11:17,  1.72it/s]\u001b[A\n","Iteration:  14% 192/1357 [02:27<11:17,  1.72it/s]\u001b[A\n","Iteration:  14% 193/1357 [02:28<11:18,  1.72it/s]\u001b[A\n","Iteration:  14% 194/1357 [02:28<11:16,  1.72it/s]\u001b[A\n","Iteration:  14% 195/1357 [02:29<11:14,  1.72it/s]\u001b[A\n","Iteration:  14% 196/1357 [02:29<11:16,  1.72it/s]\u001b[A\n","Iteration:  15% 197/1357 [02:30<11:16,  1.72it/s]\u001b[A\n","Iteration:  15% 198/1357 [02:30<11:15,  1.72it/s]\u001b[A\n","Iteration:  15% 199/1357 [02:31<11:17,  1.71it/s]\u001b[A\n","Iteration:  15% 200/1357 [02:32<11:13,  1.72it/s]\u001b[A\n","Iteration:  15% 201/1357 [02:32<11:12,  1.72it/s]\u001b[A\n","Iteration:  15% 202/1357 [02:33<11:12,  1.72it/s]\u001b[A\n","Iteration:  15% 203/1357 [02:33<11:11,  1.72it/s]\u001b[A\n","Iteration:  15% 204/1357 [02:34<11:11,  1.72it/s]\u001b[A\n","Iteration:  15% 205/1357 [02:35<11:09,  1.72it/s]\u001b[A\n","Iteration:  15% 206/1357 [02:35<11:12,  1.71it/s]\u001b[A\n","Iteration:  15% 207/1357 [02:36<11:12,  1.71it/s]\u001b[A\n","Iteration:  15% 208/1357 [02:36<11:11,  1.71it/s]\u001b[A\n","Iteration:  15% 209/1357 [02:37<11:07,  1.72it/s]\u001b[A\n","Iteration:  15% 210/1357 [02:37<11:05,  1.72it/s]\u001b[A\n","Iteration:  16% 211/1357 [02:38<11:04,  1.72it/s]\u001b[A\n","Iteration:  16% 212/1357 [02:39<11:04,  1.72it/s]\u001b[A\n","Iteration:  16% 213/1357 [02:39<11:04,  1.72it/s]\u001b[A\n","Iteration:  16% 214/1357 [02:40<11:06,  1.71it/s]\u001b[A\n","Iteration:  16% 215/1357 [02:40<11:02,  1.72it/s]\u001b[A\n","Iteration:  16% 216/1357 [02:41<11:00,  1.73it/s]\u001b[A\n","Iteration:  16% 217/1357 [02:41<11:02,  1.72it/s]\u001b[A\n","Iteration:  16% 218/1357 [02:42<11:03,  1.72it/s]\u001b[A\n","Iteration:  16% 219/1357 [02:43<11:01,  1.72it/s]\u001b[A\n","Iteration:  16% 220/1357 [02:43<11:00,  1.72it/s]\u001b[A\n","Iteration:  16% 221/1357 [02:44<10:59,  1.72it/s]\u001b[A\n","Iteration:  16% 222/1357 [02:44<10:59,  1.72it/s]\u001b[A\n","Iteration:  16% 223/1357 [02:45<10:59,  1.72it/s]\u001b[A\n","Iteration:  17% 224/1357 [02:46<10:58,  1.72it/s]\u001b[A\n","Iteration:  17% 225/1357 [02:46<10:58,  1.72it/s]\u001b[A\n","Iteration:  17% 226/1357 [02:47<10:58,  1.72it/s]\u001b[A\n","Iteration:  17% 227/1357 [02:47<11:02,  1.71it/s]\u001b[A\n","Iteration:  17% 228/1357 [02:48<10:59,  1.71it/s]\u001b[A\n","Iteration:  17% 229/1357 [02:48<10:59,  1.71it/s]\u001b[A\n","Iteration:  17% 230/1357 [02:49<10:55,  1.72it/s]\u001b[A\n","Iteration:  17% 231/1357 [02:50<10:54,  1.72it/s]\u001b[A\n","Iteration:  17% 232/1357 [02:50<10:54,  1.72it/s]\u001b[A\n","Iteration:  17% 233/1357 [02:51<10:55,  1.72it/s]\u001b[A\n","Iteration:  17% 234/1357 [02:51<10:53,  1.72it/s]\u001b[A\n","Iteration:  17% 235/1357 [02:52<10:52,  1.72it/s]\u001b[A\n","Iteration:  17% 236/1357 [02:53<10:51,  1.72it/s]\u001b[A\n","Iteration:  17% 237/1357 [02:53<10:50,  1.72it/s]\u001b[A\n","Iteration:  18% 238/1357 [02:54<10:50,  1.72it/s]\u001b[A\n","Iteration:  18% 239/1357 [02:54<10:49,  1.72it/s]\u001b[A\n","Iteration:  18% 240/1357 [02:55<10:49,  1.72it/s]\u001b[A\n","Iteration:  18% 241/1357 [02:55<10:48,  1.72it/s]\u001b[A\n","Iteration:  18% 242/1357 [02:56<10:48,  1.72it/s]\u001b[A\n","Iteration:  18% 243/1357 [02:57<10:48,  1.72it/s]\u001b[A\n","Iteration:  18% 244/1357 [02:57<10:45,  1.73it/s]\u001b[A\n","Iteration:  18% 245/1357 [02:58<10:49,  1.71it/s]\u001b[A\n","Iteration:  18% 246/1357 [02:58<10:47,  1.71it/s]\u001b[A\n","Iteration:  18% 247/1357 [02:59<10:47,  1.71it/s]\u001b[A\n","Iteration:  18% 248/1357 [03:00<10:47,  1.71it/s]\u001b[A\n","Iteration:  18% 249/1357 [03:00<10:43,  1.72it/s]\u001b[A\n","Iteration:  18% 250/1357 [03:01<10:46,  1.71it/s]\u001b[A\n","Iteration:  18% 251/1357 [03:01<10:45,  1.71it/s]\u001b[A\n","Iteration:  19% 252/1357 [03:02<10:45,  1.71it/s]\u001b[A\n","Iteration:  19% 253/1357 [03:02<10:42,  1.72it/s]\u001b[A\n","Iteration:  19% 254/1357 [03:03<10:41,  1.72it/s]\u001b[A\n","Iteration:  19% 255/1357 [03:04<10:39,  1.72it/s]\u001b[A\n","Iteration:  19% 256/1357 [03:04<10:37,  1.73it/s]\u001b[A\n","Iteration:  19% 257/1357 [03:05<10:39,  1.72it/s]\u001b[A\n","Iteration:  19% 258/1357 [03:05<10:35,  1.73it/s]\u001b[A\n","Iteration:  19% 259/1357 [03:06<10:33,  1.73it/s]\u001b[A\n","Iteration:  19% 260/1357 [03:06<10:35,  1.73it/s]\u001b[A\n","Iteration:  19% 261/1357 [03:07<10:36,  1.72it/s]\u001b[A\n","Iteration:  19% 262/1357 [03:08<10:34,  1.73it/s]\u001b[A\n","Iteration:  19% 263/1357 [03:08<10:33,  1.73it/s]\u001b[A\n","Iteration:  19% 264/1357 [03:09<10:33,  1.72it/s]\u001b[A\n","Iteration:  20% 265/1357 [03:09<10:30,  1.73it/s]\u001b[A\n","Iteration:  20% 266/1357 [03:10<10:30,  1.73it/s]\u001b[A\n","Iteration:  20% 267/1357 [03:11<10:30,  1.73it/s]\u001b[A\n","Iteration:  20% 268/1357 [03:11<10:31,  1.72it/s]\u001b[A\n","Iteration:  20% 269/1357 [03:12<10:32,  1.72it/s]\u001b[A\n","Iteration:  20% 270/1357 [03:12<10:31,  1.72it/s]\u001b[A\n","Iteration:  20% 271/1357 [03:13<10:28,  1.73it/s]\u001b[A\n","Iteration:  20% 272/1357 [03:13<10:25,  1.73it/s]\u001b[A\n","Iteration:  20% 273/1357 [03:14<10:30,  1.72it/s]\u001b[A\n","Iteration:  20% 274/1357 [03:15<10:30,  1.72it/s]\u001b[A\n","Iteration:  20% 275/1357 [03:15<10:29,  1.72it/s]\u001b[A\n","Iteration:  20% 276/1357 [03:16<10:29,  1.72it/s]\u001b[A\n","Iteration:  20% 277/1357 [03:16<10:26,  1.72it/s]\u001b[A\n","Iteration:  20% 278/1357 [03:17<10:24,  1.73it/s]\u001b[A\n","Iteration:  21% 279/1357 [03:18<10:25,  1.72it/s]\u001b[A\n","Iteration:  21% 280/1357 [03:18<10:26,  1.72it/s]\u001b[A\n","Iteration:  21% 281/1357 [03:19<10:25,  1.72it/s]\u001b[A\n","Iteration:  21% 282/1357 [03:19<10:26,  1.72it/s]\u001b[A\n","Iteration:  21% 283/1357 [03:20<10:24,  1.72it/s]\u001b[A\n","Iteration:  21% 284/1357 [03:20<10:23,  1.72it/s]\u001b[A\n","Iteration:  21% 285/1357 [03:21<10:22,  1.72it/s]\u001b[A\n","Iteration:  21% 286/1357 [03:22<10:23,  1.72it/s]\u001b[A\n","Iteration:  21% 287/1357 [03:22<10:20,  1.72it/s]\u001b[A\n","Iteration:  21% 288/1357 [03:23<10:21,  1.72it/s]\u001b[A\n","Iteration:  21% 289/1357 [03:23<10:23,  1.71it/s]\u001b[A\n","Iteration:  21% 290/1357 [03:24<10:20,  1.72it/s]\u001b[A\n","Iteration:  21% 291/1357 [03:24<10:18,  1.72it/s]\u001b[A\n","Iteration:  22% 292/1357 [03:25<10:17,  1.72it/s]\u001b[A\n","Iteration:  22% 293/1357 [03:26<10:16,  1.73it/s]\u001b[A\n","Iteration:  22% 294/1357 [03:26<10:17,  1.72it/s]\u001b[A\n","Iteration:  22% 295/1357 [03:27<10:17,  1.72it/s]\u001b[A\n","Iteration:  22% 296/1357 [03:27<10:17,  1.72it/s]\u001b[A\n","Iteration:  22% 297/1357 [03:28<10:16,  1.72it/s]\u001b[A\n","Iteration:  22% 298/1357 [03:29<10:17,  1.72it/s]\u001b[A\n","Iteration:  22% 299/1357 [03:29<10:14,  1.72it/s]\u001b[A\n","Iteration:  22% 300/1357 [03:30<10:12,  1.73it/s]\u001b[A\n","Iteration:  22% 301/1357 [03:30<10:13,  1.72it/s]\u001b[A\n","Iteration:  22% 302/1357 [03:31<10:14,  1.72it/s]\u001b[A\n","Iteration:  22% 303/1357 [03:31<10:14,  1.71it/s]\u001b[A\n","Iteration:  22% 304/1357 [03:32<10:13,  1.72it/s]\u001b[A\n","Iteration:  22% 305/1357 [03:33<10:10,  1.72it/s]\u001b[A\n","Iteration:  23% 306/1357 [03:33<10:08,  1.73it/s]\u001b[A\n","Iteration:  23% 307/1357 [03:34<10:07,  1.73it/s]\u001b[A\n","Iteration:  23% 308/1357 [03:34<10:09,  1.72it/s]\u001b[A\n","Iteration:  23% 309/1357 [03:35<10:08,  1.72it/s]\u001b[A\n","Iteration:  23% 310/1357 [03:36<10:08,  1.72it/s]\u001b[A\n","Iteration:  23% 311/1357 [03:36<10:08,  1.72it/s]\u001b[A\n","Iteration:  23% 312/1357 [03:37<10:08,  1.72it/s]\u001b[A\n","Iteration:  23% 313/1357 [03:37<10:09,  1.71it/s]\u001b[A\n","Iteration:  23% 314/1357 [03:38<10:07,  1.72it/s]\u001b[A\n","Iteration:  23% 315/1357 [03:38<10:06,  1.72it/s]\u001b[A\n","Iteration:  23% 316/1357 [03:39<10:04,  1.72it/s]\u001b[A\n","Iteration:  23% 317/1357 [03:40<10:04,  1.72it/s]\u001b[A\n","Iteration:  23% 318/1357 [03:40<10:03,  1.72it/s]\u001b[A\n","Iteration:  24% 319/1357 [03:41<10:03,  1.72it/s]\u001b[A\n","Iteration:  24% 320/1357 [03:41<10:02,  1.72it/s]\u001b[A\n","Iteration:  24% 321/1357 [03:42<09:57,  1.73it/s]\u001b[A\n","Iteration:  24% 322/1357 [03:42<09:57,  1.73it/s]\u001b[A\n","Iteration:  24% 323/1357 [03:43<10:00,  1.72it/s]\u001b[A\n","Iteration:  24% 324/1357 [03:44<10:00,  1.72it/s]\u001b[A\n","Iteration:  24% 325/1357 [03:44<09:59,  1.72it/s]\u001b[A\n","Iteration:  24% 326/1357 [03:45<09:59,  1.72it/s]\u001b[A\n","Iteration:  24% 327/1357 [03:45<09:57,  1.73it/s]\u001b[A\n","Iteration:  24% 328/1357 [03:46<09:55,  1.73it/s]\u001b[A\n","Iteration:  24% 329/1357 [03:47<09:56,  1.72it/s]\u001b[A\n","Iteration:  24% 330/1357 [03:47<09:58,  1.72it/s]\u001b[A\n","Iteration:  24% 331/1357 [03:48<09:58,  1.72it/s]\u001b[A\n","Iteration:  24% 332/1357 [03:48<09:58,  1.71it/s]\u001b[A\n","Iteration:  25% 333/1357 [03:49<09:55,  1.72it/s]\u001b[A\n","Iteration:  25% 334/1357 [03:49<09:52,  1.73it/s]\u001b[A\n","Iteration:  25% 335/1357 [03:50<09:53,  1.72it/s]\u001b[A\n","Iteration:  25% 336/1357 [03:51<09:54,  1.72it/s]\u001b[A\n","Iteration:  25% 337/1357 [03:51<09:52,  1.72it/s]\u001b[A\n","Iteration:  25% 338/1357 [03:52<09:51,  1.72it/s]\u001b[A\n","Iteration:  25% 339/1357 [03:52<09:50,  1.73it/s]\u001b[A\n","Iteration:  25% 340/1357 [03:53<09:50,  1.72it/s]\u001b[A\n","Iteration:  25% 341/1357 [03:54<09:50,  1.72it/s]\u001b[A\n","Iteration:  25% 342/1357 [03:54<09:49,  1.72it/s]\u001b[A\n","Iteration:  25% 343/1357 [03:55<09:48,  1.72it/s]\u001b[A\n","Iteration:  25% 344/1357 [03:55<09:49,  1.72it/s]\u001b[A\n","Iteration:  25% 345/1357 [03:56<09:50,  1.72it/s]\u001b[A\n","Iteration:  25% 346/1357 [03:56<09:47,  1.72it/s]\u001b[A\n","Iteration:  26% 347/1357 [03:57<09:46,  1.72it/s]\u001b[A\n","Iteration:  26% 348/1357 [03:58<09:46,  1.72it/s]\u001b[A\n","Iteration:  26% 349/1357 [03:58<09:45,  1.72it/s]\u001b[A\n","Iteration:  26% 350/1357 [03:59<09:45,  1.72it/s]\u001b[A\n","Iteration:  26% 351/1357 [03:59<09:46,  1.71it/s]\u001b[A\n","Iteration:  26% 352/1357 [04:00<09:46,  1.71it/s]\u001b[A\n","Iteration:  26% 353/1357 [04:01<09:45,  1.72it/s]\u001b[A\n","Iteration:  26% 354/1357 [04:01<09:44,  1.71it/s]\u001b[A\n","Iteration:  26% 355/1357 [04:02<09:42,  1.72it/s]\u001b[A\n","Iteration:  26% 356/1357 [04:02<09:40,  1.72it/s]\u001b[A\n","Iteration:  26% 357/1357 [04:03<09:42,  1.72it/s]\u001b[A\n","Iteration:  26% 358/1357 [04:03<09:39,  1.72it/s]\u001b[A\n","Iteration:  26% 359/1357 [04:04<09:39,  1.72it/s]\u001b[A\n","Iteration:  27% 360/1357 [04:05<09:39,  1.72it/s]\u001b[A\n","Iteration:  27% 361/1357 [04:05<09:38,  1.72it/s]\u001b[A\n","Iteration:  27% 362/1357 [04:06<09:36,  1.73it/s]\u001b[A\n","Iteration:  27% 363/1357 [04:06<09:36,  1.72it/s]\u001b[A\n","Iteration:  27% 364/1357 [04:07<09:37,  1.72it/s]\u001b[A\n","Iteration:  27% 365/1357 [04:07<09:35,  1.72it/s]\u001b[A\n","Iteration:  27% 366/1357 [04:08<09:34,  1.72it/s]\u001b[A\n","Iteration:  27% 367/1357 [04:09<09:34,  1.72it/s]\u001b[A\n","Iteration:  27% 368/1357 [04:09<09:31,  1.73it/s]\u001b[A\n","Iteration:  27% 369/1357 [04:10<09:32,  1.73it/s]\u001b[A\n","Iteration:  27% 370/1357 [04:10<09:34,  1.72it/s]\u001b[A\n","Iteration:  27% 371/1357 [04:11<09:34,  1.72it/s]\u001b[A\n","Iteration:  27% 372/1357 [04:12<09:32,  1.72it/s]\u001b[A\n","Iteration:  27% 373/1357 [04:12<09:33,  1.71it/s]\u001b[A\n","Iteration:  28% 374/1357 [04:13<09:32,  1.72it/s]\u001b[A\n","Iteration:  28% 375/1357 [04:13<09:34,  1.71it/s]\u001b[A\n","Iteration:  28% 376/1357 [04:14<09:31,  1.72it/s]\u001b[A\n","Iteration:  28% 377/1357 [04:14<09:31,  1.71it/s]\u001b[A\n","Iteration:  28% 378/1357 [04:15<09:29,  1.72it/s]\u001b[A\n","Iteration:  28% 379/1357 [04:16<09:30,  1.72it/s]\u001b[A\n","Iteration:  28% 380/1357 [04:16<09:27,  1.72it/s]\u001b[A\n","Iteration:  28% 381/1357 [04:17<09:27,  1.72it/s]\u001b[A\n","Iteration:  28% 382/1357 [04:17<09:26,  1.72it/s]\u001b[A\n","Iteration:  28% 383/1357 [04:18<09:23,  1.73it/s]\u001b[A\n","Iteration:  28% 384/1357 [04:19<09:24,  1.72it/s]\u001b[A\n","Iteration:  28% 385/1357 [04:19<09:24,  1.72it/s]\u001b[A\n","Iteration:  28% 386/1357 [04:20<09:24,  1.72it/s]\u001b[A\n","Iteration:  29% 387/1357 [04:20<09:23,  1.72it/s]\u001b[A\n","Iteration:  29% 388/1357 [04:21<09:23,  1.72it/s]\u001b[A\n","Iteration:  29% 389/1357 [04:21<09:21,  1.72it/s]\u001b[A\n","Iteration:  29% 390/1357 [04:22<09:19,  1.73it/s]\u001b[A\n","Iteration:  29% 391/1357 [04:23<09:20,  1.72it/s]\u001b[A\n","Iteration:  29% 392/1357 [04:23<09:21,  1.72it/s]\u001b[A\n","Iteration:  29% 393/1357 [04:24<09:22,  1.71it/s]\u001b[A\n","Iteration:  29% 394/1357 [04:24<09:21,  1.71it/s]\u001b[A\n","Iteration:  29% 395/1357 [04:25<09:19,  1.72it/s]\u001b[A\n","Iteration:  29% 396/1357 [04:26<09:15,  1.73it/s]\u001b[A\n","Iteration:  29% 397/1357 [04:26<09:15,  1.73it/s]\u001b[A\n","Iteration:  29% 398/1357 [04:27<09:17,  1.72it/s]\u001b[A\n","Iteration:  29% 399/1357 [04:27<09:15,  1.72it/s]\u001b[A\n","Iteration:  29% 400/1357 [04:28<09:19,  1.71it/s]\u001b[A\n","Iteration:  30% 401/1357 [04:28<09:17,  1.72it/s]\u001b[A\n","Iteration:  30% 402/1357 [04:29<09:15,  1.72it/s]\u001b[A\n","Iteration:  30% 403/1357 [04:30<09:16,  1.71it/s]\u001b[A\n","Iteration:  30% 404/1357 [04:30<09:15,  1.71it/s]\u001b[A\n","Iteration:  30% 405/1357 [04:31<09:17,  1.71it/s]\u001b[A\n","Iteration:  30% 406/1357 [04:31<09:15,  1.71it/s]\u001b[A\n","Iteration:  30% 407/1357 [04:32<09:16,  1.71it/s]\u001b[A\n","Iteration:  30% 408/1357 [04:33<09:14,  1.71it/s]\u001b[A\n","Iteration:  30% 409/1357 [04:33<09:15,  1.71it/s]\u001b[A\n","Iteration:  30% 410/1357 [04:34<09:12,  1.72it/s]\u001b[A\n","Iteration:  30% 411/1357 [04:34<09:09,  1.72it/s]\u001b[A\n","Iteration:  30% 412/1357 [04:35<09:11,  1.72it/s]\u001b[A\n","Iteration:  30% 413/1357 [04:35<09:13,  1.70it/s]\u001b[A\n","Iteration:  31% 414/1357 [04:36<09:13,  1.70it/s]\u001b[A\n","Iteration:  31% 415/1357 [04:37<09:11,  1.71it/s]\u001b[A\n","Iteration:  31% 416/1357 [04:37<09:08,  1.72it/s]\u001b[A\n","Iteration:  31% 417/1357 [04:38<09:06,  1.72it/s]\u001b[A\n","Iteration:  31% 418/1357 [04:38<09:05,  1.72it/s]\u001b[A\n","Iteration:  31% 419/1357 [04:39<09:05,  1.72it/s]\u001b[A\n","Iteration:  31% 420/1357 [04:40<09:04,  1.72it/s]\u001b[A\n","Iteration:  31% 421/1357 [04:40<09:04,  1.72it/s]\u001b[A\n","Iteration:  31% 422/1357 [04:41<09:03,  1.72it/s]\u001b[A\n","Iteration:  31% 423/1357 [04:41<08:59,  1.73it/s]\u001b[A\n","Iteration:  31% 424/1357 [04:42<08:59,  1.73it/s]\u001b[A\n","Iteration:  31% 425/1357 [04:42<08:59,  1.73it/s]\u001b[A\n","Iteration:  31% 426/1357 [04:43<08:59,  1.73it/s]\u001b[A\n","Iteration:  31% 427/1357 [04:44<08:59,  1.73it/s]\u001b[A\n","Iteration:  32% 428/1357 [04:44<08:58,  1.73it/s]\u001b[A\n","Iteration:  32% 429/1357 [04:45<08:56,  1.73it/s]\u001b[A\n","Iteration:  32% 430/1357 [04:45<08:57,  1.72it/s]\u001b[A\n","Iteration:  32% 431/1357 [04:46<09:00,  1.71it/s]\u001b[A\n","Iteration:  32% 432/1357 [04:46<08:59,  1.71it/s]\u001b[A\n","Iteration:  32% 433/1357 [04:47<08:57,  1.72it/s]\u001b[A\n","Iteration:  32% 434/1357 [04:48<08:56,  1.72it/s]\u001b[A\n","Iteration:  32% 435/1357 [04:48<08:55,  1.72it/s]\u001b[A\n","Iteration:  32% 436/1357 [04:49<08:54,  1.72it/s]\u001b[A\n","Iteration:  32% 437/1357 [04:49<08:53,  1.73it/s]\u001b[A\n","Iteration:  32% 438/1357 [04:50<08:51,  1.73it/s]\u001b[A\n","Iteration:  32% 439/1357 [04:51<08:50,  1.73it/s]\u001b[A\n","Iteration:  32% 440/1357 [04:51<08:50,  1.73it/s]\u001b[A\n","Iteration:  32% 441/1357 [04:52<08:51,  1.72it/s]\u001b[A\n","Iteration:  33% 442/1357 [04:52<08:49,  1.73it/s]\u001b[A\n","Iteration:  33% 443/1357 [04:53<08:50,  1.72it/s]\u001b[A\n","Iteration:  33% 444/1357 [04:53<08:57,  1.70it/s]\u001b[A\n","Iteration:  33% 445/1357 [04:54<08:51,  1.72it/s]\u001b[A\n","Iteration:  33% 446/1357 [04:55<08:50,  1.72it/s]\u001b[A\n","Iteration:  33% 447/1357 [04:55<08:50,  1.71it/s]\u001b[A\n","Iteration:  33% 448/1357 [04:56<08:50,  1.71it/s]\u001b[A\n","Iteration:  33% 449/1357 [04:56<08:49,  1.72it/s]\u001b[A\n","Iteration:  33% 450/1357 [04:57<08:48,  1.72it/s]\u001b[A\n","Iteration:  33% 451/1357 [04:58<08:46,  1.72it/s]\u001b[A\n","Iteration:  33% 452/1357 [04:58<08:45,  1.72it/s]\u001b[A\n","Iteration:  33% 453/1357 [04:59<08:44,  1.72it/s]\u001b[A\n","Iteration:  33% 454/1357 [04:59<08:42,  1.73it/s]\u001b[A\n","Iteration:  34% 455/1357 [05:00<08:41,  1.73it/s]\u001b[A\n","Iteration:  34% 456/1357 [05:00<08:43,  1.72it/s]\u001b[A\n","Iteration:  34% 457/1357 [05:01<08:41,  1.73it/s]\u001b[A\n","Iteration:  34% 458/1357 [05:02<08:41,  1.72it/s]\u001b[A\n","Iteration:  34% 459/1357 [05:02<08:41,  1.72it/s]\u001b[A\n","Iteration:  34% 460/1357 [05:03<08:43,  1.71it/s]\u001b[A\n","Iteration:  34% 461/1357 [05:03<08:40,  1.72it/s]\u001b[A\n","Iteration:  34% 462/1357 [05:04<08:38,  1.72it/s]\u001b[A\n","Iteration:  34% 463/1357 [05:04<08:40,  1.72it/s]\u001b[A\n","Iteration:  34% 464/1357 [05:05<08:40,  1.72it/s]\u001b[A\n","Iteration:  34% 465/1357 [05:06<08:39,  1.72it/s]\u001b[A\n","Iteration:  34% 466/1357 [05:06<08:36,  1.73it/s]\u001b[A\n","Iteration:  34% 467/1357 [05:07<08:34,  1.73it/s]\u001b[A\n","Iteration:  34% 468/1357 [05:07<08:35,  1.73it/s]\u001b[A\n","Iteration:  35% 469/1357 [05:08<08:35,  1.72it/s]\u001b[A\n","Iteration:  35% 470/1357 [05:09<08:33,  1.73it/s]\u001b[A\n","Iteration:  35% 471/1357 [05:09<08:32,  1.73it/s]\u001b[A\n","Iteration:  35% 472/1357 [05:10<08:35,  1.72it/s]\u001b[A\n","Iteration:  35% 473/1357 [05:10<08:31,  1.73it/s]\u001b[A\n","Iteration:  35% 474/1357 [05:11<08:34,  1.72it/s]\u001b[A\n","Iteration:  35% 475/1357 [05:11<08:34,  1.71it/s]\u001b[A\n","Iteration:  35% 476/1357 [05:12<08:32,  1.72it/s]\u001b[A\n","Iteration:  35% 477/1357 [05:13<08:30,  1.72it/s]\u001b[A\n","Iteration:  35% 478/1357 [05:13<08:30,  1.72it/s]\u001b[A\n","Iteration:  35% 479/1357 [05:14<08:29,  1.72it/s]\u001b[A\n","Iteration:  35% 480/1357 [05:14<08:28,  1.72it/s]\u001b[A\n","Iteration:  35% 481/1357 [05:15<08:30,  1.72it/s]\u001b[A\n","Iteration:  36% 482/1357 [05:16<08:28,  1.72it/s]\u001b[A\n","Iteration:  36% 483/1357 [05:16<08:27,  1.72it/s]\u001b[A\n","Iteration:  36% 484/1357 [05:17<08:30,  1.71it/s]\u001b[A\n","Iteration:  36% 485/1357 [05:17<08:27,  1.72it/s]\u001b[A\n","Iteration:  36% 486/1357 [05:18<08:26,  1.72it/s]\u001b[A\n","Iteration:  36% 487/1357 [05:18<08:26,  1.72it/s]\u001b[A\n","Iteration:  36% 488/1357 [05:19<08:30,  1.70it/s]\u001b[A\n","Iteration:  36% 489/1357 [05:20<08:27,  1.71it/s]\u001b[A\n","Iteration:  36% 490/1357 [05:20<08:27,  1.71it/s]\u001b[A\n","Iteration:  36% 491/1357 [05:21<08:24,  1.72it/s]\u001b[A\n","Iteration:  36% 492/1357 [05:21<08:23,  1.72it/s]\u001b[A\n","Iteration:  36% 493/1357 [05:22<08:22,  1.72it/s]\u001b[A\n","Iteration:  36% 494/1357 [05:23<08:23,  1.71it/s]\u001b[A\n","Iteration:  36% 495/1357 [05:23<08:21,  1.72it/s]\u001b[A\n","Iteration:  37% 496/1357 [05:24<08:20,  1.72it/s]\u001b[A\n","Iteration:  37% 497/1357 [05:24<08:19,  1.72it/s]\u001b[A\n","Iteration:  37% 498/1357 [05:25<08:18,  1.72it/s]\u001b[A\n","Iteration:  37% 499/1357 [05:25<08:19,  1.72it/s]\u001b[A\n","Iteration:  37% 500/1357 [05:26<08:15,  1.73it/s]\u001b[A\n","Iteration:  37% 501/1357 [05:27<08:13,  1.73it/s]\u001b[A\n","Iteration:  37% 502/1357 [05:27<08:16,  1.72it/s]\u001b[A\n","Iteration:  37% 503/1357 [05:28<08:16,  1.72it/s]\u001b[A\n","Iteration:  37% 504/1357 [05:28<08:15,  1.72it/s]\u001b[A\n","Iteration:  37% 505/1357 [05:29<08:13,  1.72it/s]\u001b[A\n","Iteration:  37% 506/1357 [05:29<08:13,  1.72it/s]\u001b[A\n","Iteration:  37% 507/1357 [05:30<08:12,  1.73it/s]\u001b[A\n","Iteration:  37% 508/1357 [05:31<08:12,  1.73it/s]\u001b[A\n","Iteration:  38% 509/1357 [05:31<08:11,  1.72it/s]\u001b[A\n","Iteration:  38% 510/1357 [05:32<08:11,  1.72it/s]\u001b[A\n","Iteration:  38% 511/1357 [05:32<08:11,  1.72it/s]\u001b[A\n","Iteration:  38% 512/1357 [05:33<08:11,  1.72it/s]\u001b[A\n","Iteration:  38% 513/1357 [05:34<08:09,  1.72it/s]\u001b[A\n","Iteration:  38% 514/1357 [05:34<08:07,  1.73it/s]\u001b[A\n","Iteration:  38% 515/1357 [05:35<08:09,  1.72it/s]\u001b[A\n","Iteration:  38% 516/1357 [05:35<08:08,  1.72it/s]\u001b[A\n","Iteration:  38% 517/1357 [05:36<08:07,  1.72it/s]\u001b[A\n","Iteration:  38% 518/1357 [05:36<08:11,  1.71it/s]\u001b[A\n","Iteration:  38% 519/1357 [05:37<08:08,  1.71it/s]\u001b[A\n","Iteration:  38% 520/1357 [05:38<08:07,  1.72it/s]\u001b[A\n","Iteration:  38% 521/1357 [05:38<08:07,  1.72it/s]\u001b[A\n","Iteration:  38% 522/1357 [05:39<08:07,  1.71it/s]\u001b[A\n","Iteration:  39% 523/1357 [05:39<08:05,  1.72it/s]\u001b[A\n","Iteration:  39% 524/1357 [05:40<08:04,  1.72it/s]\u001b[A\n","Iteration:  39% 525/1357 [05:41<08:05,  1.71it/s]\u001b[A\n","Iteration:  39% 526/1357 [05:41<08:03,  1.72it/s]\u001b[A\n","Iteration:  39% 527/1357 [05:42<08:04,  1.71it/s]\u001b[A\n","Iteration:  39% 528/1357 [05:42<08:01,  1.72it/s]\u001b[A\n","Iteration:  39% 529/1357 [05:43<07:59,  1.73it/s]\u001b[A\n","Iteration:  39% 530/1357 [05:43<08:00,  1.72it/s]\u001b[A\n","Iteration:  39% 531/1357 [05:44<08:00,  1.72it/s]\u001b[A\n","Iteration:  39% 532/1357 [05:45<07:58,  1.72it/s]\u001b[A\n","Iteration:  39% 533/1357 [05:45<07:58,  1.72it/s]\u001b[A\n","Iteration:  39% 534/1357 [05:46<07:56,  1.73it/s]\u001b[A\n","Iteration:  39% 535/1357 [05:46<07:54,  1.73it/s]\u001b[A\n","Iteration:  39% 536/1357 [05:47<07:56,  1.72it/s]\u001b[A\n","Iteration:  40% 537/1357 [05:48<07:58,  1.71it/s]\u001b[A\n","Iteration:  40% 538/1357 [05:48<07:55,  1.72it/s]\u001b[A\n","Iteration:  40% 539/1357 [05:49<07:54,  1.72it/s]\u001b[A\n","Iteration:  40% 540/1357 [05:49<07:55,  1.72it/s]\u001b[A\n","Iteration:  40% 541/1357 [05:50<07:52,  1.73it/s]\u001b[A\n","Iteration:  40% 542/1357 [05:50<07:53,  1.72it/s]\u001b[A\n","Iteration:  40% 543/1357 [05:51<07:52,  1.72it/s]\u001b[A\n","Iteration:  40% 544/1357 [05:52<07:52,  1.72it/s]\u001b[A\n","Iteration:  40% 545/1357 [05:52<07:51,  1.72it/s]\u001b[A\n","Iteration:  40% 546/1357 [05:53<07:53,  1.71it/s]\u001b[A\n","Iteration:  40% 547/1357 [05:53<07:50,  1.72it/s]\u001b[A\n","Iteration:  40% 548/1357 [05:54<07:51,  1.72it/s]\u001b[A\n","Iteration:  40% 549/1357 [05:54<07:49,  1.72it/s]\u001b[A\n","Iteration:  41% 550/1357 [05:55<07:50,  1.71it/s]\u001b[A\n","Iteration:  41% 551/1357 [05:56<07:48,  1.72it/s]\u001b[A\n","Iteration:  41% 552/1357 [05:56<07:49,  1.71it/s]\u001b[A\n","Iteration:  41% 553/1357 [05:57<07:46,  1.72it/s]\u001b[A\n","Iteration:  41% 554/1357 [05:57<07:45,  1.72it/s]\u001b[A\n","Iteration:  41% 555/1357 [05:58<07:50,  1.71it/s]\u001b[A\n","Iteration:  41% 556/1357 [05:59<07:46,  1.72it/s]\u001b[A\n","Iteration:  41% 557/1357 [05:59<07:44,  1.72it/s]\u001b[A\n","Iteration:  41% 558/1357 [06:00<07:46,  1.71it/s]\u001b[A\n","Iteration:  41% 559/1357 [06:00<07:44,  1.72it/s]\u001b[A\n","Iteration:  41% 560/1357 [06:01<07:42,  1.72it/s]\u001b[A\n","Iteration:  41% 561/1357 [06:01<07:45,  1.71it/s]\u001b[A\n","Iteration:  41% 562/1357 [06:02<07:44,  1.71it/s]\u001b[A\n","Iteration:  41% 563/1357 [06:03<07:41,  1.72it/s]\u001b[A\n","Iteration:  42% 564/1357 [06:03<07:41,  1.72it/s]\u001b[A\n","Iteration:  42% 565/1357 [06:04<07:40,  1.72it/s]\u001b[A\n","Iteration:  42% 566/1357 [06:04<07:38,  1.73it/s]\u001b[A\n","Iteration:  42% 567/1357 [06:05<07:37,  1.73it/s]\u001b[A\n","Iteration:  42% 568/1357 [06:06<07:36,  1.73it/s]\u001b[A\n","Iteration:  42% 569/1357 [06:06<07:34,  1.73it/s]\u001b[A\n","Iteration:  42% 570/1357 [06:07<07:35,  1.73it/s]\u001b[A\n","Iteration:  42% 571/1357 [06:07<07:36,  1.72it/s]\u001b[A\n","Iteration:  42% 572/1357 [06:08<07:35,  1.72it/s]\u001b[A\n","Iteration:  42% 573/1357 [06:08<07:35,  1.72it/s]\u001b[A\n","Iteration:  42% 574/1357 [06:09<07:35,  1.72it/s]\u001b[A\n","Iteration:  42% 575/1357 [06:10<07:32,  1.73it/s]\u001b[A\n","Iteration:  42% 576/1357 [06:10<07:32,  1.73it/s]\u001b[A\n","Iteration:  43% 577/1357 [06:11<07:32,  1.73it/s]\u001b[A\n","Iteration:  43% 578/1357 [06:11<07:32,  1.72it/s]\u001b[A\n","Iteration:  43% 579/1357 [06:12<07:31,  1.72it/s]\u001b[A\n","Iteration:  43% 580/1357 [06:12<07:32,  1.72it/s]\u001b[A\n","Iteration:  43% 581/1357 [06:13<07:29,  1.73it/s]\u001b[A\n","Iteration:  43% 582/1357 [06:14<07:29,  1.73it/s]\u001b[A\n","Iteration:  43% 583/1357 [06:14<07:29,  1.72it/s]\u001b[A\n","Iteration:  43% 584/1357 [06:15<07:31,  1.71it/s]\u001b[A\n","Iteration:  43% 585/1357 [06:15<07:31,  1.71it/s]\u001b[A\n","Iteration:  43% 586/1357 [06:16<07:29,  1.71it/s]\u001b[A\n","Iteration:  43% 587/1357 [06:17<07:29,  1.71it/s]\u001b[A\n","Iteration:  43% 588/1357 [06:17<07:28,  1.72it/s]\u001b[A\n","Iteration:  43% 589/1357 [06:18<07:27,  1.72it/s]\u001b[A\n","Iteration:  43% 590/1357 [06:18<07:24,  1.72it/s]\u001b[A\n","Iteration:  44% 591/1357 [06:19<07:23,  1.73it/s]\u001b[A\n","Iteration:  44% 592/1357 [06:19<07:23,  1.72it/s]\u001b[A\n","Iteration:  44% 593/1357 [06:20<07:23,  1.72it/s]\u001b[A\n","Iteration:  44% 594/1357 [06:21<07:24,  1.72it/s]\u001b[A\n","Iteration:  44% 595/1357 [06:21<07:23,  1.72it/s]\u001b[A\n","Iteration:  44% 596/1357 [06:22<07:22,  1.72it/s]\u001b[A\n","Iteration:  44% 597/1357 [06:22<07:21,  1.72it/s]\u001b[A\n","Iteration:  44% 598/1357 [06:23<07:21,  1.72it/s]\u001b[A\n","Iteration:  44% 599/1357 [06:24<07:22,  1.71it/s]\u001b[A\n","Iteration:  44% 600/1357 [06:24<07:20,  1.72it/s]\u001b[A\n","Iteration:  44% 601/1357 [06:25<07:19,  1.72it/s]\u001b[A\n","Iteration:  44% 602/1357 [06:25<07:18,  1.72it/s]\u001b[A\n","Iteration:  44% 603/1357 [06:26<07:16,  1.73it/s]\u001b[A\n","Iteration:  45% 604/1357 [06:26<07:16,  1.73it/s]\u001b[A\n","Iteration:  45% 605/1357 [06:27<07:16,  1.72it/s]\u001b[A\n","Iteration:  45% 606/1357 [06:28<07:16,  1.72it/s]\u001b[A\n","Iteration:  45% 607/1357 [06:28<07:14,  1.73it/s]\u001b[A\n","Iteration:  45% 608/1357 [06:29<07:18,  1.71it/s]\u001b[A\n","Iteration:  45% 609/1357 [06:29<07:14,  1.72it/s]\u001b[A\n","Iteration:  45% 610/1357 [06:30<07:15,  1.72it/s]\u001b[A\n","Iteration:  45% 611/1357 [06:31<07:14,  1.72it/s]\u001b[A\n","Iteration:  45% 612/1357 [06:31<07:15,  1.71it/s]\u001b[A\n","Iteration:  45% 613/1357 [06:32<07:13,  1.71it/s]\u001b[A\n","Iteration:  45% 614/1357 [06:32<07:12,  1.72it/s]\u001b[A\n","Iteration:  45% 615/1357 [06:33<07:10,  1.72it/s]\u001b[A\n","Iteration:  45% 616/1357 [06:33<07:09,  1.72it/s]\u001b[A\n","Iteration:  45% 617/1357 [06:34<07:11,  1.71it/s]\u001b[A\n","Iteration:  46% 618/1357 [06:35<07:09,  1.72it/s]\u001b[A\n","Iteration:  46% 619/1357 [06:35<07:08,  1.72it/s]\u001b[A\n","Iteration:  46% 620/1357 [06:36<07:07,  1.72it/s]\u001b[A\n","Iteration:  46% 621/1357 [06:36<07:09,  1.71it/s]\u001b[A\n","Iteration:  46% 622/1357 [06:37<07:08,  1.72it/s]\u001b[A\n","Iteration:  46% 623/1357 [06:37<07:08,  1.71it/s]\u001b[A\n","Iteration:  46% 624/1357 [06:38<07:04,  1.73it/s]\u001b[A\n","Iteration:  46% 625/1357 [06:39<07:01,  1.74it/s]\u001b[A\n","Iteration:  46% 626/1357 [06:39<07:02,  1.73it/s]\u001b[A\n","Iteration:  46% 627/1357 [06:40<07:04,  1.72it/s]\u001b[A\n","Iteration:  46% 628/1357 [06:40<07:03,  1.72it/s]\u001b[A\n","Iteration:  46% 629/1357 [06:41<07:04,  1.72it/s]\u001b[A\n","Iteration:  46% 630/1357 [06:42<07:01,  1.72it/s]\u001b[A\n","Iteration:  46% 631/1357 [06:42<06:59,  1.73it/s]\u001b[A\n","Iteration:  47% 632/1357 [06:43<07:00,  1.72it/s]\u001b[A\n","Iteration:  47% 633/1357 [06:43<07:00,  1.72it/s]\u001b[A\n","Iteration:  47% 634/1357 [06:44<06:59,  1.73it/s]\u001b[A\n","Iteration:  47% 635/1357 [06:44<06:58,  1.72it/s]\u001b[A\n","Iteration:  47% 636/1357 [06:45<06:59,  1.72it/s]\u001b[A\n","Iteration:  47% 637/1357 [06:46<06:57,  1.73it/s]\u001b[A\n","Iteration:  47% 638/1357 [06:46<06:56,  1.73it/s]\u001b[A\n","Iteration:  47% 639/1357 [06:47<06:56,  1.72it/s]\u001b[A\n","Iteration:  47% 640/1357 [06:47<06:56,  1.72it/s]\u001b[A\n","Iteration:  47% 641/1357 [06:48<06:54,  1.73it/s]\u001b[A\n","Iteration:  47% 642/1357 [06:49<06:54,  1.73it/s]\u001b[A\n","Iteration:  47% 643/1357 [06:49<06:53,  1.73it/s]\u001b[A\n","Iteration:  47% 644/1357 [06:50<06:52,  1.73it/s]\u001b[A\n","Iteration:  48% 645/1357 [06:50<06:52,  1.72it/s]\u001b[A\n","Iteration:  48% 646/1357 [06:51<06:50,  1.73it/s]\u001b[A\n","Iteration:  48% 647/1357 [06:51<06:48,  1.74it/s]\u001b[A\n","Iteration:  48% 648/1357 [06:52<06:50,  1.73it/s]\u001b[A\n","Iteration:  48% 649/1357 [06:53<06:50,  1.72it/s]\u001b[A\n","Iteration:  48% 650/1357 [06:53<06:49,  1.73it/s]\u001b[A\n","Iteration:  48% 651/1357 [06:54<06:48,  1.73it/s]\u001b[A\n","Iteration:  48% 652/1357 [06:54<06:48,  1.73it/s]\u001b[A\n","Iteration:  48% 653/1357 [06:55<06:45,  1.74it/s]\u001b[A\n","Iteration:  48% 654/1357 [06:55<06:44,  1.74it/s]\u001b[A\n","Iteration:  48% 655/1357 [06:56<06:45,  1.73it/s]\u001b[A\n","Iteration:  48% 656/1357 [06:57<06:45,  1.73it/s]\u001b[A\n","Iteration:  48% 657/1357 [06:57<06:44,  1.73it/s]\u001b[A\n","Iteration:  48% 658/1357 [06:58<06:46,  1.72it/s]\u001b[A\n","Iteration:  49% 659/1357 [06:58<06:44,  1.72it/s]\u001b[A\n","Iteration:  49% 660/1357 [06:59<06:40,  1.74it/s]\u001b[A\n","Iteration:  49% 661/1357 [06:59<06:42,  1.73it/s]\u001b[A\n","Iteration:  49% 662/1357 [07:00<06:43,  1.72it/s]\u001b[A\n","Iteration:  49% 663/1357 [07:01<06:42,  1.73it/s]\u001b[A\n","Iteration:  49% 664/1357 [07:01<06:41,  1.73it/s]\u001b[A\n","Iteration:  49% 665/1357 [07:02<06:40,  1.73it/s]\u001b[A\n","Iteration:  49% 666/1357 [07:02<06:41,  1.72it/s]\u001b[A\n","Iteration:  49% 667/1357 [07:03<06:40,  1.72it/s]\u001b[A\n","Iteration:  49% 668/1357 [07:04<06:39,  1.72it/s]\u001b[A\n","Iteration:  49% 669/1357 [07:04<06:39,  1.72it/s]\u001b[A\n","Iteration:  49% 670/1357 [07:05<06:38,  1.73it/s]\u001b[A\n","Iteration:  49% 671/1357 [07:05<06:38,  1.72it/s]\u001b[A\n","Iteration:  50% 672/1357 [07:06<06:36,  1.73it/s]\u001b[A\n","Iteration:  50% 673/1357 [07:06<06:35,  1.73it/s]\u001b[A\n","Iteration:  50% 674/1357 [07:07<06:34,  1.73it/s]\u001b[A\n","Iteration:  50% 675/1357 [07:08<06:34,  1.73it/s]\u001b[A\n","Iteration:  50% 676/1357 [07:08<06:32,  1.74it/s]\u001b[A\n","Iteration:  50% 677/1357 [07:09<06:33,  1.73it/s]\u001b[A\n","Iteration:  50% 678/1357 [07:09<06:32,  1.73it/s]\u001b[A\n","Iteration:  50% 679/1357 [07:10<06:31,  1.73it/s]\u001b[A\n","Iteration:  50% 680/1357 [07:10<06:30,  1.73it/s]\u001b[A\n","Iteration:  50% 681/1357 [07:11<06:30,  1.73it/s]\u001b[A\n","Iteration:  50% 682/1357 [07:12<06:28,  1.74it/s]\u001b[A\n","Iteration:  50% 683/1357 [07:12<06:27,  1.74it/s]\u001b[A\n","Iteration:  50% 684/1357 [07:13<06:27,  1.74it/s]\u001b[A\n","Iteration:  50% 685/1357 [07:13<06:27,  1.73it/s]\u001b[A\n","Iteration:  51% 686/1357 [07:14<06:27,  1.73it/s]\u001b[A\n","Iteration:  51% 687/1357 [07:15<06:26,  1.73it/s]\u001b[A\n","Iteration:  51% 688/1357 [07:15<06:25,  1.74it/s]\u001b[A\n","Iteration:  51% 689/1357 [07:16<06:23,  1.74it/s]\u001b[A\n","Iteration:  51% 690/1357 [07:16<06:23,  1.74it/s]\u001b[A\n","Iteration:  51% 691/1357 [07:17<06:25,  1.73it/s]\u001b[A\n","Iteration:  51% 692/1357 [07:17<06:23,  1.73it/s]\u001b[A\n","Iteration:  51% 693/1357 [07:18<06:24,  1.73it/s]\u001b[A\n","Iteration:  51% 694/1357 [07:19<06:25,  1.72it/s]\u001b[A\n","Iteration:  51% 695/1357 [07:19<06:21,  1.73it/s]\u001b[A\n","Iteration:  51% 696/1357 [07:20<06:21,  1.73it/s]\u001b[A\n","Iteration:  51% 697/1357 [07:20<06:20,  1.74it/s]\u001b[A\n","Iteration:  51% 698/1357 [07:21<06:20,  1.73it/s]\u001b[A\n","Iteration:  52% 699/1357 [07:21<06:19,  1.73it/s]\u001b[A\n","Iteration:  52% 700/1357 [07:22<06:18,  1.74it/s]\u001b[A\n","Iteration:  52% 701/1357 [07:23<06:18,  1.73it/s]\u001b[A\n","Iteration:  52% 702/1357 [07:23<06:17,  1.73it/s]\u001b[A\n","Iteration:  52% 703/1357 [07:24<06:18,  1.73it/s]\u001b[A\n","Iteration:  52% 704/1357 [07:24<06:16,  1.73it/s]\u001b[A\n","Iteration:  52% 705/1357 [07:25<06:16,  1.73it/s]\u001b[A\n","Iteration:  52% 706/1357 [07:25<06:15,  1.73it/s]\u001b[A\n","Iteration:  52% 707/1357 [07:26<06:15,  1.73it/s]\u001b[A\n","Iteration:  52% 708/1357 [07:27<06:14,  1.73it/s]\u001b[A\n","Iteration:  52% 709/1357 [07:27<06:14,  1.73it/s]\u001b[A\n","Iteration:  52% 710/1357 [07:28<06:14,  1.73it/s]\u001b[A\n","Iteration:  52% 711/1357 [07:28<06:13,  1.73it/s]\u001b[A\n","Iteration:  52% 712/1357 [07:29<06:12,  1.73it/s]\u001b[A\n","Iteration:  53% 713/1357 [07:30<06:12,  1.73it/s]\u001b[A\n","Iteration:  53% 714/1357 [07:30<06:14,  1.72it/s]\u001b[A\n","Iteration:  53% 715/1357 [07:31<06:13,  1.72it/s]\u001b[A\n","Iteration:  53% 716/1357 [07:31<06:15,  1.71it/s]\u001b[A\n","Iteration:  53% 717/1357 [07:32<06:13,  1.71it/s]\u001b[A\n","Iteration:  53% 718/1357 [07:32<06:09,  1.73it/s]\u001b[A\n","Iteration:  53% 719/1357 [07:33<06:09,  1.73it/s]\u001b[A\n","Iteration:  53% 720/1357 [07:34<06:09,  1.72it/s]\u001b[A\n","Iteration:  53% 721/1357 [07:34<06:08,  1.73it/s]\u001b[A\n","Iteration:  53% 722/1357 [07:35<06:07,  1.73it/s]\u001b[A\n","Iteration:  53% 723/1357 [07:35<06:07,  1.73it/s]\u001b[A\n","Iteration:  53% 724/1357 [07:36<06:05,  1.73it/s]\u001b[A\n","Iteration:  53% 725/1357 [07:36<06:04,  1.73it/s]\u001b[A\n","Iteration:  54% 726/1357 [07:37<06:03,  1.73it/s]\u001b[A\n","Iteration:  54% 727/1357 [07:38<06:06,  1.72it/s]\u001b[A\n","Iteration:  54% 728/1357 [07:38<06:05,  1.72it/s]\u001b[A\n","Iteration:  54% 729/1357 [07:39<06:03,  1.73it/s]\u001b[A\n","Iteration:  54% 730/1357 [07:39<06:02,  1.73it/s]\u001b[A\n","Iteration:  54% 731/1357 [07:40<06:01,  1.73it/s]\u001b[A\n","Iteration:  54% 732/1357 [07:41<06:03,  1.72it/s]\u001b[A\n","Iteration:  54% 733/1357 [07:41<06:00,  1.73it/s]\u001b[A\n","Iteration:  54% 734/1357 [07:42<05:58,  1.74it/s]\u001b[A\n","Iteration:  54% 735/1357 [07:42<05:58,  1.73it/s]\u001b[A\n","Iteration:  54% 736/1357 [07:43<06:00,  1.72it/s]\u001b[A\n","Iteration:  54% 737/1357 [07:43<05:59,  1.73it/s]\u001b[A\n","Iteration:  54% 738/1357 [07:44<05:59,  1.72it/s]\u001b[A\n","Iteration:  54% 739/1357 [07:45<05:57,  1.73it/s]\u001b[A\n","Iteration:  55% 740/1357 [07:45<05:55,  1.74it/s]\u001b[A\n","Iteration:  55% 741/1357 [07:46<05:55,  1.73it/s]\u001b[A\n","Iteration:  55% 742/1357 [07:46<05:55,  1.73it/s]\u001b[A\n","Iteration:  55% 743/1357 [07:47<05:54,  1.73it/s]\u001b[A\n","Iteration:  55% 744/1357 [07:47<05:53,  1.73it/s]\u001b[A\n","Iteration:  55% 745/1357 [07:48<05:54,  1.73it/s]\u001b[A\n","Iteration:  55% 746/1357 [07:49<05:52,  1.73it/s]\u001b[A\n","Iteration:  55% 747/1357 [07:49<05:50,  1.74it/s]\u001b[A\n","Iteration:  55% 748/1357 [07:50<05:52,  1.73it/s]\u001b[A\n","Iteration:  55% 749/1357 [07:50<05:52,  1.72it/s]\u001b[A\n","Iteration:  55% 750/1357 [07:51<05:50,  1.73it/s]\u001b[A\n","Iteration:  55% 751/1357 [07:52<05:51,  1.73it/s]\u001b[A\n","Iteration:  55% 752/1357 [07:52<05:51,  1.72it/s]\u001b[A\n","Iteration:  55% 753/1357 [07:53<05:49,  1.73it/s]\u001b[A\n","Iteration:  56% 754/1357 [07:53<05:48,  1.73it/s]\u001b[A\n","Iteration:  56% 755/1357 [07:54<05:47,  1.73it/s]\u001b[A\n","Iteration:  56% 756/1357 [07:54<05:47,  1.73it/s]\u001b[A\n","Iteration:  56% 757/1357 [07:55<05:46,  1.73it/s]\u001b[A\n","Iteration:  56% 758/1357 [07:56<05:46,  1.73it/s]\u001b[A\n","Iteration:  56% 759/1357 [07:56<05:45,  1.73it/s]\u001b[A\n","Iteration:  56% 760/1357 [07:57<05:45,  1.73it/s]\u001b[A\n","Iteration:  56% 761/1357 [07:57<05:44,  1.73it/s]\u001b[A\n","Iteration:  56% 762/1357 [07:58<05:44,  1.73it/s]\u001b[A\n","Iteration:  56% 763/1357 [07:58<05:43,  1.73it/s]\u001b[A\n","Iteration:  56% 764/1357 [07:59<05:42,  1.73it/s]\u001b[A\n","Iteration:  56% 765/1357 [08:00<05:42,  1.73it/s]\u001b[A\n","Iteration:  56% 766/1357 [08:00<05:40,  1.73it/s]\u001b[A\n","Iteration:  57% 767/1357 [08:01<05:40,  1.73it/s]\u001b[A\n","Iteration:  57% 768/1357 [08:01<05:41,  1.72it/s]\u001b[A\n","Iteration:  57% 769/1357 [08:02<05:39,  1.73it/s]\u001b[A\n","Iteration:  57% 770/1357 [08:03<05:37,  1.74it/s]\u001b[A\n","Iteration:  57% 771/1357 [08:03<05:37,  1.74it/s]\u001b[A\n","Iteration:  57% 772/1357 [08:04<05:38,  1.73it/s]\u001b[A\n","Iteration:  57% 773/1357 [08:04<05:37,  1.73it/s]\u001b[A\n","Iteration:  57% 774/1357 [08:05<05:37,  1.73it/s]\u001b[A\n","Iteration:  57% 775/1357 [08:05<05:36,  1.73it/s]\u001b[A\n","Iteration:  57% 776/1357 [08:06<05:35,  1.73it/s]\u001b[A\n","Iteration:  57% 777/1357 [08:07<05:36,  1.72it/s]\u001b[A\n","Iteration:  57% 778/1357 [08:07<05:36,  1.72it/s]\u001b[A\n","Iteration:  57% 779/1357 [08:08<05:35,  1.72it/s]\u001b[A\n","Iteration:  57% 780/1357 [08:08<05:35,  1.72it/s]\u001b[A\n","Iteration:  58% 781/1357 [08:09<05:34,  1.72it/s]\u001b[A\n","Iteration:  58% 782/1357 [08:09<05:32,  1.73it/s]\u001b[A\n","Iteration:  58% 783/1357 [08:10<05:32,  1.72it/s]\u001b[A\n","Iteration:  58% 784/1357 [08:11<05:33,  1.72it/s]\u001b[A\n","Iteration:  58% 785/1357 [08:11<05:31,  1.72it/s]\u001b[A\n","Iteration:  58% 786/1357 [08:12<05:31,  1.72it/s]\u001b[A\n","Iteration:  58% 787/1357 [08:12<05:31,  1.72it/s]\u001b[A\n","Iteration:  58% 788/1357 [08:13<05:29,  1.72it/s]\u001b[A\n","Iteration:  58% 789/1357 [08:14<05:28,  1.73it/s]\u001b[A\n","Iteration:  58% 790/1357 [08:14<05:28,  1.72it/s]\u001b[A\n","Iteration:  58% 791/1357 [08:15<05:29,  1.72it/s]\u001b[A\n","Iteration:  58% 792/1357 [08:15<05:28,  1.72it/s]\u001b[A\n","Iteration:  58% 793/1357 [08:16<05:27,  1.72it/s]\u001b[A\n","Iteration:  59% 794/1357 [08:16<05:26,  1.72it/s]\u001b[A\n","Iteration:  59% 795/1357 [08:17<05:25,  1.73it/s]\u001b[A\n","Iteration:  59% 796/1357 [08:18<05:25,  1.72it/s]\u001b[A\n","Iteration:  59% 797/1357 [08:18<05:24,  1.73it/s]\u001b[A\n","Iteration:  59% 798/1357 [08:19<05:22,  1.73it/s]\u001b[A\n","Iteration:  59% 799/1357 [08:19<05:23,  1.73it/s]\u001b[A\n","Iteration:  59% 800/1357 [08:20<05:23,  1.72it/s]\u001b[A\n","Iteration:  59% 801/1357 [08:20<05:23,  1.72it/s]\u001b[A\n","Iteration:  59% 802/1357 [08:21<05:22,  1.72it/s]\u001b[A\n","Iteration:  59% 803/1357 [08:22<05:21,  1.72it/s]\u001b[A\n","Iteration:  59% 804/1357 [08:22<05:19,  1.73it/s]\u001b[A\n","Iteration:  59% 805/1357 [08:23<05:18,  1.73it/s]\u001b[A\n","Iteration:  59% 806/1357 [08:23<05:20,  1.72it/s]\u001b[A\n","Iteration:  59% 807/1357 [08:24<05:18,  1.72it/s]\u001b[A\n","Iteration:  60% 808/1357 [08:25<05:17,  1.73it/s]\u001b[A\n","Iteration:  60% 809/1357 [08:25<05:17,  1.73it/s]\u001b[A\n","Iteration:  60% 810/1357 [08:26<05:16,  1.73it/s]\u001b[A\n","Iteration:  60% 811/1357 [08:26<05:14,  1.74it/s]\u001b[A\n","Iteration:  60% 812/1357 [08:27<05:14,  1.73it/s]\u001b[A\n","Iteration:  60% 813/1357 [08:27<05:15,  1.72it/s]\u001b[A\n","Iteration:  60% 814/1357 [08:28<05:15,  1.72it/s]\u001b[A\n","Iteration:  60% 815/1357 [08:29<05:15,  1.72it/s]\u001b[A\n","Iteration:  60% 816/1357 [08:29<05:14,  1.72it/s]\u001b[A\n","Iteration:  60% 817/1357 [08:30<05:13,  1.72it/s]\u001b[A\n","Iteration:  60% 818/1357 [08:30<05:13,  1.72it/s]\u001b[A\n","Iteration:  60% 819/1357 [08:31<05:12,  1.72it/s]\u001b[A\n","Iteration:  60% 820/1357 [08:31<05:10,  1.73it/s]\u001b[A\n","Iteration:  61% 821/1357 [08:32<05:10,  1.73it/s]\u001b[A\n","Iteration:  61% 822/1357 [08:33<05:09,  1.73it/s]\u001b[A\n","Iteration:  61% 823/1357 [08:33<05:08,  1.73it/s]\u001b[A\n","Iteration:  61% 824/1357 [08:34<05:08,  1.73it/s]\u001b[A\n","Iteration:  61% 825/1357 [08:34<05:07,  1.73it/s]\u001b[A\n","Iteration:  61% 826/1357 [08:35<05:05,  1.74it/s]\u001b[A\n","Iteration:  61% 827/1357 [08:36<05:04,  1.74it/s]\u001b[A\n","Iteration:  61% 828/1357 [08:36<05:05,  1.73it/s]\u001b[A\n","Iteration:  61% 829/1357 [08:37<05:05,  1.73it/s]\u001b[A\n","Iteration:  61% 830/1357 [08:37<05:04,  1.73it/s]\u001b[A\n","Iteration:  61% 831/1357 [08:38<05:06,  1.72it/s]\u001b[A\n","Iteration:  61% 832/1357 [08:38<05:03,  1.73it/s]\u001b[A\n","Iteration:  61% 833/1357 [08:39<05:01,  1.74it/s]\u001b[A\n","Iteration:  61% 834/1357 [08:40<05:01,  1.73it/s]\u001b[A\n","Iteration:  62% 835/1357 [08:40<05:02,  1.73it/s]\u001b[A\n","Iteration:  62% 836/1357 [08:41<05:01,  1.73it/s]\u001b[A\n","Iteration:  62% 837/1357 [08:41<05:00,  1.73it/s]\u001b[A\n","Iteration:  62% 838/1357 [08:42<05:00,  1.73it/s]\u001b[A\n","Iteration:  62% 839/1357 [08:42<04:59,  1.73it/s]\u001b[A\n","Iteration:  62% 840/1357 [08:43<04:57,  1.74it/s]\u001b[A\n","Iteration:  62% 841/1357 [08:44<04:59,  1.72it/s]\u001b[A\n","Iteration:  62% 842/1357 [08:44<04:57,  1.73it/s]\u001b[A\n","Iteration:  62% 843/1357 [08:45<04:56,  1.73it/s]\u001b[A\n","Iteration:  62% 844/1357 [08:45<04:55,  1.73it/s]\u001b[A\n","Iteration:  62% 845/1357 [08:46<04:54,  1.74it/s]\u001b[A\n","Iteration:  62% 846/1357 [08:47<04:54,  1.73it/s]\u001b[A\n","Iteration:  62% 847/1357 [08:47<04:54,  1.73it/s]\u001b[A\n","Iteration:  62% 848/1357 [08:48<04:53,  1.73it/s]\u001b[A\n","Iteration:  63% 849/1357 [08:48<04:53,  1.73it/s]\u001b[A\n","Iteration:  63% 850/1357 [08:49<04:52,  1.73it/s]\u001b[A\n","Iteration:  63% 851/1357 [08:49<04:52,  1.73it/s]\u001b[A\n","Iteration:  63% 852/1357 [08:50<04:51,  1.73it/s]\u001b[A\n","Iteration:  63% 853/1357 [08:51<04:50,  1.73it/s]\u001b[A\n","Iteration:  63% 854/1357 [08:51<04:52,  1.72it/s]\u001b[A\n","Iteration:  63% 855/1357 [08:52<04:50,  1.73it/s]\u001b[A\n","Iteration:  63% 856/1357 [08:52<04:48,  1.74it/s]\u001b[A\n","Iteration:  63% 857/1357 [08:53<04:48,  1.73it/s]\u001b[A\n","Iteration:  63% 858/1357 [08:53<04:49,  1.73it/s]\u001b[A\n","Iteration:  63% 859/1357 [08:54<04:48,  1.73it/s]\u001b[A\n","Iteration:  63% 860/1357 [08:55<04:47,  1.73it/s]\u001b[A\n","Iteration:  63% 861/1357 [08:55<04:48,  1.72it/s]\u001b[A\n","Iteration:  64% 862/1357 [08:56<04:46,  1.73it/s]\u001b[A\n","Iteration:  64% 863/1357 [08:56<04:46,  1.73it/s]\u001b[A\n","Iteration:  64% 864/1357 [08:57<04:45,  1.73it/s]\u001b[A\n","Iteration:  64% 865/1357 [08:58<04:43,  1.73it/s]\u001b[A\n","Iteration:  64% 866/1357 [08:58<04:42,  1.74it/s]\u001b[A\n","Iteration:  64% 867/1357 [08:59<04:42,  1.73it/s]\u001b[A\n","Iteration:  64% 868/1357 [08:59<04:41,  1.74it/s]\u001b[A\n","Iteration:  64% 869/1357 [09:00<04:40,  1.74it/s]\u001b[A\n","Iteration:  64% 870/1357 [09:00<04:40,  1.74it/s]\u001b[A\n","Iteration:  64% 871/1357 [09:01<04:40,  1.73it/s]\u001b[A\n","Iteration:  64% 872/1357 [09:02<04:39,  1.73it/s]\u001b[A\n","Iteration:  64% 873/1357 [09:02<04:39,  1.73it/s]\u001b[A\n","Iteration:  64% 874/1357 [09:03<04:39,  1.73it/s]\u001b[A\n","Iteration:  64% 875/1357 [09:03<04:37,  1.74it/s]\u001b[A\n","Iteration:  65% 876/1357 [09:04<04:37,  1.73it/s]\u001b[A\n","Iteration:  65% 877/1357 [09:04<04:38,  1.73it/s]\u001b[A\n","Iteration:  65% 878/1357 [09:05<04:38,  1.72it/s]\u001b[A\n","Iteration:  65% 879/1357 [09:06<04:37,  1.72it/s]\u001b[A\n","Iteration:  65% 880/1357 [09:06<04:37,  1.72it/s]\u001b[A\n","Iteration:  65% 881/1357 [09:07<04:36,  1.72it/s]\u001b[A\n","Iteration:  65% 882/1357 [09:07<04:34,  1.73it/s]\u001b[A\n","Iteration:  65% 883/1357 [09:08<04:35,  1.72it/s]\u001b[A\n","Iteration:  65% 884/1357 [09:08<04:34,  1.73it/s]\u001b[A\n","Iteration:  65% 885/1357 [09:09<04:32,  1.73it/s]\u001b[A\n","Iteration:  65% 886/1357 [09:10<04:31,  1.73it/s]\u001b[A\n","Iteration:  65% 887/1357 [09:10<04:31,  1.73it/s]\u001b[A\n","Iteration:  65% 888/1357 [09:11<04:30,  1.74it/s]\u001b[A\n","Iteration:  66% 889/1357 [09:11<04:30,  1.73it/s]\u001b[A\n","Iteration:  66% 890/1357 [09:12<04:29,  1.73it/s]\u001b[A\n","Iteration:  66% 891/1357 [09:13<04:27,  1.74it/s]\u001b[A\n","Iteration:  66% 892/1357 [09:13<04:27,  1.74it/s]\u001b[A\n","Iteration:  66% 893/1357 [09:14<04:27,  1.74it/s]\u001b[A\n","Iteration:  66% 894/1357 [09:14<04:27,  1.73it/s]\u001b[A\n","Iteration:  66% 895/1357 [09:15<04:25,  1.74it/s]\u001b[A\n","Iteration:  66% 896/1357 [09:15<04:25,  1.74it/s]\u001b[A\n","Iteration:  66% 897/1357 [09:16<04:25,  1.74it/s]\u001b[A\n","Iteration:  66% 898/1357 [09:17<04:24,  1.74it/s]\u001b[A\n","Iteration:  66% 899/1357 [09:17<04:24,  1.73it/s]\u001b[A\n","Iteration:  66% 900/1357 [09:18<04:24,  1.73it/s]\u001b[A\n","Iteration:  66% 901/1357 [09:18<04:23,  1.73it/s]\u001b[A\n","Iteration:  66% 902/1357 [09:19<04:22,  1.74it/s]\u001b[A\n","Iteration:  67% 903/1357 [09:19<04:21,  1.74it/s]\u001b[A\n","Iteration:  67% 904/1357 [09:20<04:20,  1.74it/s]\u001b[A\n","Iteration:  67% 905/1357 [09:21<04:20,  1.73it/s]\u001b[A\n","Iteration:  67% 906/1357 [09:21<04:20,  1.73it/s]\u001b[A\n","Iteration:  67% 907/1357 [09:22<04:20,  1.72it/s]\u001b[A\n","Iteration:  67% 908/1357 [09:22<04:19,  1.73it/s]\u001b[A\n","Iteration:  67% 909/1357 [09:23<04:18,  1.74it/s]\u001b[A\n","Iteration:  67% 910/1357 [09:23<04:17,  1.73it/s]\u001b[A\n","Iteration:  67% 911/1357 [09:24<04:17,  1.73it/s]\u001b[A\n","Iteration:  67% 912/1357 [09:25<04:16,  1.73it/s]\u001b[A\n","Iteration:  67% 913/1357 [09:25<04:16,  1.73it/s]\u001b[A\n","Iteration:  67% 914/1357 [09:26<04:14,  1.74it/s]\u001b[A\n","Iteration:  67% 915/1357 [09:26<04:14,  1.74it/s]\u001b[A\n","Iteration:  68% 916/1357 [09:27<04:15,  1.73it/s]\u001b[A\n","Iteration:  68% 917/1357 [09:28<04:14,  1.73it/s]\u001b[A\n","Iteration:  68% 918/1357 [09:28<04:13,  1.73it/s]\u001b[A\n","Iteration:  68% 919/1357 [09:29<04:14,  1.72it/s]\u001b[A\n","Iteration:  68% 920/1357 [09:29<04:12,  1.73it/s]\u001b[A\n","Iteration:  68% 921/1357 [09:30<04:11,  1.74it/s]\u001b[A\n","Iteration:  68% 922/1357 [09:30<04:11,  1.73it/s]\u001b[A\n","Iteration:  68% 923/1357 [09:31<04:11,  1.73it/s]\u001b[A\n","Iteration:  68% 924/1357 [09:32<04:09,  1.73it/s]\u001b[A\n","Iteration:  68% 925/1357 [09:32<04:09,  1.73it/s]\u001b[A\n","Iteration:  68% 926/1357 [09:33<04:08,  1.73it/s]\u001b[A\n","Iteration:  68% 927/1357 [09:33<04:07,  1.74it/s]\u001b[A\n","Iteration:  68% 928/1357 [09:34<04:07,  1.73it/s]\u001b[A\n","Iteration:  68% 929/1357 [09:34<04:07,  1.73it/s]\u001b[A\n","Iteration:  69% 930/1357 [09:35<04:07,  1.73it/s]\u001b[A\n","Iteration:  69% 931/1357 [09:36<04:06,  1.73it/s]\u001b[A\n","Iteration:  69% 932/1357 [09:36<04:06,  1.72it/s]\u001b[A\n","Iteration:  69% 933/1357 [09:37<04:05,  1.73it/s]\u001b[A\n","Iteration:  69% 934/1357 [09:37<04:04,  1.73it/s]\u001b[A\n","Iteration:  69% 935/1357 [09:38<04:04,  1.73it/s]\u001b[A\n","Iteration:  69% 936/1357 [09:39<04:04,  1.72it/s]\u001b[A\n","Iteration:  69% 937/1357 [09:39<04:02,  1.73it/s]\u001b[A\n","Iteration:  69% 938/1357 [09:40<04:03,  1.72it/s]\u001b[A\n","Iteration:  69% 939/1357 [09:40<04:03,  1.72it/s]\u001b[A\n","Iteration:  69% 940/1357 [09:41<04:01,  1.72it/s]\u001b[A\n","Iteration:  69% 941/1357 [09:41<04:01,  1.72it/s]\u001b[A\n","Iteration:  69% 942/1357 [09:42<04:00,  1.73it/s]\u001b[A\n","Iteration:  69% 943/1357 [09:43<03:58,  1.73it/s]\u001b[A\n","Iteration:  70% 944/1357 [09:43<03:58,  1.73it/s]\u001b[A\n","Iteration:  70% 945/1357 [09:44<03:58,  1.72it/s]\u001b[A\n","Iteration:  70% 946/1357 [09:44<03:57,  1.73it/s]\u001b[A\n","Iteration:  70% 947/1357 [09:45<03:56,  1.73it/s]\u001b[A\n","Iteration:  70% 948/1357 [09:45<03:57,  1.73it/s]\u001b[A\n","Iteration:  70% 949/1357 [09:46<03:55,  1.73it/s]\u001b[A\n","Iteration:  70% 950/1357 [09:47<03:54,  1.74it/s]\u001b[A\n","Iteration:  70% 951/1357 [09:47<03:53,  1.74it/s]\u001b[A\n","Iteration:  70% 952/1357 [09:48<03:54,  1.73it/s]\u001b[A\n","Iteration:  70% 953/1357 [09:48<03:52,  1.73it/s]\u001b[A\n","Iteration:  70% 954/1357 [09:49<03:52,  1.74it/s]\u001b[A\n","Iteration:  70% 955/1357 [09:49<03:51,  1.73it/s]\u001b[A\n","Iteration:  70% 956/1357 [09:50<03:50,  1.74it/s]\u001b[A\n","Iteration:  71% 957/1357 [09:51<03:49,  1.75it/s]\u001b[A\n","Iteration:  71% 958/1357 [09:51<03:49,  1.74it/s]\u001b[A\n","Iteration:  71% 959/1357 [09:52<03:49,  1.73it/s]\u001b[A\n","Iteration:  71% 960/1357 [09:52<03:49,  1.73it/s]\u001b[A\n","Iteration:  71% 961/1357 [09:53<03:48,  1.73it/s]\u001b[A\n","Iteration:  71% 962/1357 [09:54<03:48,  1.73it/s]\u001b[A\n","Iteration:  71% 963/1357 [09:54<03:46,  1.74it/s]\u001b[A\n","Iteration:  71% 964/1357 [09:55<03:47,  1.73it/s]\u001b[A\n","Iteration:  71% 965/1357 [09:55<03:47,  1.73it/s]\u001b[A\n","Iteration:  71% 966/1357 [09:56<03:46,  1.73it/s]\u001b[A\n","Iteration:  71% 967/1357 [09:56<03:45,  1.73it/s]\u001b[A\n","Iteration:  71% 968/1357 [09:57<03:45,  1.73it/s]\u001b[A\n","Iteration:  71% 969/1357 [09:58<03:43,  1.73it/s]\u001b[A\n","Iteration:  71% 970/1357 [09:58<03:43,  1.73it/s]\u001b[A\n","Iteration:  72% 971/1357 [09:59<03:42,  1.74it/s]\u001b[A\n","Iteration:  72% 972/1357 [09:59<03:42,  1.73it/s]\u001b[A\n","Iteration:  72% 973/1357 [10:00<03:41,  1.73it/s]\u001b[A\n","Iteration:  72% 974/1357 [10:00<03:41,  1.73it/s]\u001b[A\n","Iteration:  72% 975/1357 [10:01<03:40,  1.73it/s]\u001b[A\n","Iteration:  72% 976/1357 [10:02<03:40,  1.73it/s]\u001b[A\n","Iteration:  72% 977/1357 [10:02<03:40,  1.73it/s]\u001b[A\n","Iteration:  72% 978/1357 [10:03<03:38,  1.73it/s]\u001b[A\n","Iteration:  72% 979/1357 [10:03<03:37,  1.74it/s]\u001b[A\n","Iteration:  72% 980/1357 [10:04<03:37,  1.73it/s]\u001b[A\n","Iteration:  72% 981/1357 [10:05<03:37,  1.73it/s]\u001b[A\n","Iteration:  72% 982/1357 [10:05<03:37,  1.72it/s]\u001b[A\n","Iteration:  72% 983/1357 [10:06<03:37,  1.72it/s]\u001b[A\n","Iteration:  73% 984/1357 [10:06<03:36,  1.72it/s]\u001b[A\n","Iteration:  73% 985/1357 [10:07<03:35,  1.73it/s]\u001b[A\n","Iteration:  73% 986/1357 [10:07<03:34,  1.73it/s]\u001b[A\n","Iteration:  73% 987/1357 [10:08<03:33,  1.73it/s]\u001b[A\n","Iteration:  73% 988/1357 [10:09<03:33,  1.73it/s]\u001b[A\n","Iteration:  73% 989/1357 [10:09<03:33,  1.73it/s]\u001b[A\n","Iteration:  73% 990/1357 [10:10<03:32,  1.73it/s]\u001b[A\n","Iteration:  73% 991/1357 [10:10<03:31,  1.73it/s]\u001b[A\n","Iteration:  73% 992/1357 [10:11<03:30,  1.74it/s]\u001b[A\n","Iteration:  73% 993/1357 [10:11<03:30,  1.73it/s]\u001b[A\n","Iteration:  73% 994/1357 [10:12<03:29,  1.73it/s]\u001b[A\n","Iteration:  73% 995/1357 [10:13<03:28,  1.73it/s]\u001b[A\n","Iteration:  73% 996/1357 [10:13<03:28,  1.73it/s]\u001b[A\n","Iteration:  73% 997/1357 [10:14<03:28,  1.73it/s]\u001b[A\n","Iteration:  74% 998/1357 [10:14<03:26,  1.73it/s]\u001b[A\n","Iteration:  74% 999/1357 [10:15<03:26,  1.73it/s]\u001b[A\n","Iteration:  74% 1000/1357 [10:15<03:26,  1.73it/s]\u001b[A\n","Iteration:  74% 1001/1357 [10:16<03:26,  1.73it/s]\u001b[A\n","Iteration:  74% 1002/1357 [10:17<03:25,  1.73it/s]\u001b[A\n","Iteration:  74% 1003/1357 [10:17<03:24,  1.73it/s]\u001b[A\n","Iteration:  74% 1004/1357 [10:18<03:24,  1.73it/s]\u001b[A\n","Iteration:  74% 1005/1357 [10:18<03:23,  1.73it/s]\u001b[A\n","Iteration:  74% 1006/1357 [10:19<03:22,  1.73it/s]\u001b[A\n","Iteration:  74% 1007/1357 [10:20<03:21,  1.73it/s]\u001b[A\n","Iteration:  74% 1008/1357 [10:20<03:20,  1.74it/s]\u001b[A\n","Iteration:  74% 1009/1357 [10:21<03:20,  1.73it/s]\u001b[A\n","Iteration:  74% 1010/1357 [10:21<03:20,  1.73it/s]\u001b[A\n","Iteration:  75% 1011/1357 [10:22<03:19,  1.73it/s]\u001b[A\n","Iteration:  75% 1012/1357 [10:22<03:18,  1.73it/s]\u001b[A\n","Iteration:  75% 1013/1357 [10:23<03:18,  1.73it/s]\u001b[A\n","Iteration:  75% 1014/1357 [10:24<03:17,  1.74it/s]\u001b[A\n","Iteration:  75% 1015/1357 [10:24<03:16,  1.74it/s]\u001b[A\n","Iteration:  75% 1016/1357 [10:25<03:17,  1.73it/s]\u001b[A\n","Iteration:  75% 1017/1357 [10:25<03:17,  1.72it/s]\u001b[A\n","Iteration:  75% 1018/1357 [10:26<03:16,  1.73it/s]\u001b[A\n","Iteration:  75% 1019/1357 [10:26<03:15,  1.73it/s]\u001b[A\n","Iteration:  75% 1020/1357 [10:27<03:14,  1.73it/s]\u001b[A\n","Iteration:  75% 1021/1357 [10:28<03:13,  1.73it/s]\u001b[A\n","Iteration:  75% 1022/1357 [10:28<03:13,  1.73it/s]\u001b[A\n","Iteration:  75% 1023/1357 [10:29<03:13,  1.73it/s]\u001b[A\n","Iteration:  75% 1024/1357 [10:29<03:13,  1.72it/s]\u001b[A\n","Iteration:  76% 1025/1357 [10:30<03:12,  1.72it/s]\u001b[A\n","Iteration:  76% 1026/1357 [10:31<03:13,  1.71it/s]\u001b[A\n","Iteration:  76% 1027/1357 [10:31<03:12,  1.72it/s]\u001b[A\n","Iteration:  76% 1028/1357 [10:32<03:11,  1.72it/s]\u001b[A\n","Iteration:  76% 1029/1357 [10:32<03:10,  1.72it/s]\u001b[A\n","Iteration:  76% 1030/1357 [10:33<03:09,  1.72it/s]\u001b[A\n","Iteration:  76% 1031/1357 [10:33<03:08,  1.73it/s]\u001b[A\n","Iteration:  76% 1032/1357 [10:34<03:07,  1.73it/s]\u001b[A\n","Iteration:  76% 1033/1357 [10:35<03:07,  1.73it/s]\u001b[A\n","Iteration:  76% 1034/1357 [10:35<03:06,  1.73it/s]\u001b[A\n","Iteration:  76% 1035/1357 [10:36<03:06,  1.73it/s]\u001b[A\n","Iteration:  76% 1036/1357 [10:36<03:05,  1.73it/s]\u001b[A\n","Iteration:  76% 1037/1357 [10:37<03:04,  1.74it/s]\u001b[A\n","Iteration:  76% 1038/1357 [10:37<03:03,  1.74it/s]\u001b[A\n","Iteration:  77% 1039/1357 [10:38<03:04,  1.73it/s]\u001b[A\n","Iteration:  77% 1040/1357 [10:39<03:03,  1.72it/s]\u001b[A\n","Iteration:  77% 1041/1357 [10:39<03:02,  1.73it/s]\u001b[A\n","Iteration:  77% 1042/1357 [10:40<03:02,  1.72it/s]\u001b[A\n","Iteration:  77% 1043/1357 [10:40<03:01,  1.73it/s]\u001b[A\n","Iteration:  77% 1044/1357 [10:41<03:00,  1.73it/s]\u001b[A\n","Iteration:  77% 1045/1357 [10:42<03:00,  1.73it/s]\u001b[A\n","Iteration:  77% 1046/1357 [10:42<03:00,  1.72it/s]\u001b[A\n","Iteration:  77% 1047/1357 [10:43<02:59,  1.73it/s]\u001b[A\n","Iteration:  77% 1048/1357 [10:43<02:58,  1.73it/s]\u001b[A\n","Iteration:  77% 1049/1357 [10:44<02:58,  1.73it/s]\u001b[A\n","Iteration:  77% 1050/1357 [10:44<02:56,  1.73it/s]\u001b[A\n","Iteration:  77% 1051/1357 [10:45<02:56,  1.73it/s]\u001b[A\n","Iteration:  78% 1052/1357 [10:46<02:56,  1.73it/s]\u001b[A\n","Iteration:  78% 1053/1357 [10:46<02:55,  1.73it/s]\u001b[A\n","Iteration:  78% 1054/1357 [10:47<02:55,  1.73it/s]\u001b[A\n","Iteration:  78% 1055/1357 [10:47<02:54,  1.73it/s]\u001b[A\n","Iteration:  78% 1056/1357 [10:48<02:53,  1.73it/s]\u001b[A\n","Iteration:  78% 1057/1357 [10:48<02:52,  1.74it/s]\u001b[A\n","Iteration:  78% 1058/1357 [10:49<02:52,  1.74it/s]\u001b[A\n","Iteration:  78% 1059/1357 [10:50<02:52,  1.73it/s]\u001b[A\n","Iteration:  78% 1060/1357 [10:50<02:51,  1.74it/s]\u001b[A\n","Iteration:  78% 1061/1357 [10:51<02:50,  1.74it/s]\u001b[A\n","Iteration:  78% 1062/1357 [10:51<02:50,  1.73it/s]\u001b[A\n","Iteration:  78% 1063/1357 [10:52<02:49,  1.73it/s]\u001b[A\n","Iteration:  78% 1064/1357 [10:52<02:49,  1.73it/s]\u001b[A\n","Iteration:  78% 1065/1357 [10:53<02:48,  1.73it/s]\u001b[A\n","Iteration:  79% 1066/1357 [10:54<02:47,  1.74it/s]\u001b[A\n","Iteration:  79% 1067/1357 [10:54<02:47,  1.73it/s]\u001b[A\n","Iteration:  79% 1068/1357 [10:55<02:46,  1.73it/s]\u001b[A\n","Iteration:  79% 1069/1357 [10:55<02:46,  1.73it/s]\u001b[A\n","Iteration:  79% 1070/1357 [10:56<02:45,  1.73it/s]\u001b[A\n","Iteration:  79% 1071/1357 [10:57<02:45,  1.73it/s]\u001b[A\n","Iteration:  79% 1072/1357 [10:57<02:44,  1.73it/s]\u001b[A\n","Iteration:  79% 1073/1357 [10:58<02:44,  1.73it/s]\u001b[A\n","Iteration:  79% 1074/1357 [10:58<02:44,  1.73it/s]\u001b[A\n","Iteration:  79% 1075/1357 [10:59<02:43,  1.72it/s]\u001b[A\n","Iteration:  79% 1076/1357 [10:59<02:42,  1.73it/s]\u001b[A\n","Iteration:  79% 1077/1357 [11:00<02:41,  1.73it/s]\u001b[A\n","Iteration:  79% 1078/1357 [11:01<02:41,  1.73it/s]\u001b[A\n","Iteration:  80% 1079/1357 [11:01<02:40,  1.74it/s]\u001b[A\n","Iteration:  80% 1080/1357 [11:02<02:40,  1.73it/s]\u001b[A\n","Iteration:  80% 1081/1357 [11:02<02:39,  1.73it/s]\u001b[A\n","Iteration:  80% 1082/1357 [11:03<02:39,  1.73it/s]\u001b[A\n","Iteration:  80% 1083/1357 [11:03<02:38,  1.73it/s]\u001b[A\n","Iteration:  80% 1084/1357 [11:04<02:37,  1.73it/s]\u001b[A\n","Iteration:  80% 1085/1357 [11:05<02:37,  1.73it/s]\u001b[A\n","Iteration:  80% 1086/1357 [11:05<02:37,  1.72it/s]\u001b[A\n","Iteration:  80% 1087/1357 [11:06<02:36,  1.72it/s]\u001b[A\n","Iteration:  80% 1088/1357 [11:06<02:36,  1.72it/s]\u001b[A\n","Iteration:  80% 1089/1357 [11:07<02:35,  1.73it/s]\u001b[A\n","Iteration:  80% 1090/1357 [11:08<02:34,  1.73it/s]\u001b[A\n","Iteration:  80% 1091/1357 [11:08<02:34,  1.72it/s]\u001b[A\n","Iteration:  80% 1092/1357 [11:09<02:33,  1.73it/s]\u001b[A\n","Iteration:  81% 1093/1357 [11:09<02:33,  1.73it/s]\u001b[A\n","Iteration:  81% 1094/1357 [11:10<02:31,  1.73it/s]\u001b[A\n","Iteration:  81% 1095/1357 [11:10<02:30,  1.74it/s]\u001b[A\n","Iteration:  81% 1096/1357 [11:11<02:30,  1.74it/s]\u001b[A\n","Iteration:  81% 1097/1357 [11:12<02:30,  1.73it/s]\u001b[A\n","Iteration:  81% 1098/1357 [11:12<02:29,  1.73it/s]\u001b[A\n","Iteration:  81% 1099/1357 [11:13<02:28,  1.73it/s]\u001b[A\n","Iteration:  81% 1100/1357 [11:13<02:28,  1.73it/s]\u001b[A\n","Iteration:  81% 1101/1357 [11:14<02:27,  1.74it/s]\u001b[A\n","Iteration:  81% 1102/1357 [11:14<02:26,  1.74it/s]\u001b[A\n","Iteration:  81% 1103/1357 [11:15<02:26,  1.74it/s]\u001b[A\n","Iteration:  81% 1104/1357 [11:16<02:26,  1.73it/s]\u001b[A\n","Iteration:  81% 1105/1357 [11:16<02:25,  1.73it/s]\u001b[A\n","Iteration:  82% 1106/1357 [11:17<02:24,  1.74it/s]\u001b[A\n","Iteration:  82% 1107/1357 [11:17<02:24,  1.73it/s]\u001b[A\n","Iteration:  82% 1108/1357 [11:18<02:23,  1.74it/s]\u001b[A\n","Iteration:  82% 1109/1357 [11:18<02:22,  1.74it/s]\u001b[A\n","Iteration:  82% 1110/1357 [11:19<02:22,  1.74it/s]\u001b[A\n","Iteration:  82% 1111/1357 [11:20<02:21,  1.74it/s]\u001b[A\n","Iteration:  82% 1112/1357 [11:20<02:21,  1.74it/s]\u001b[A\n","Iteration:  82% 1113/1357 [11:21<02:20,  1.73it/s]\u001b[A\n","Iteration:  82% 1114/1357 [11:21<02:20,  1.73it/s]\u001b[A\n","Iteration:  82% 1115/1357 [11:22<02:20,  1.72it/s]\u001b[A\n","Iteration:  82% 1116/1357 [11:23<02:19,  1.72it/s]\u001b[A\n","Iteration:  82% 1117/1357 [11:23<02:19,  1.72it/s]\u001b[A\n","Iteration:  82% 1118/1357 [11:24<02:18,  1.72it/s]\u001b[A\n","Iteration:  82% 1119/1357 [11:24<02:17,  1.73it/s]\u001b[A\n","Iteration:  83% 1120/1357 [11:25<02:17,  1.73it/s]\u001b[A\n","Iteration:  83% 1121/1357 [11:25<02:16,  1.73it/s]\u001b[A\n","Iteration:  83% 1122/1357 [11:26<02:15,  1.73it/s]\u001b[A\n","Iteration:  83% 1123/1357 [11:27<02:15,  1.73it/s]\u001b[A\n","Iteration:  83% 1124/1357 [11:27<02:14,  1.74it/s]\u001b[A\n","Iteration:  83% 1125/1357 [11:28<02:13,  1.74it/s]\u001b[A\n","Iteration:  83% 1126/1357 [11:28<02:13,  1.74it/s]\u001b[A\n","Iteration:  83% 1127/1357 [11:29<02:13,  1.73it/s]\u001b[A\n","Iteration:  83% 1128/1357 [11:29<02:12,  1.73it/s]\u001b[A\n","Iteration:  83% 1129/1357 [11:30<02:12,  1.72it/s]\u001b[A\n","Iteration:  83% 1130/1357 [11:31<02:11,  1.73it/s]\u001b[A\n","Iteration:  83% 1131/1357 [11:31<02:10,  1.74it/s]\u001b[A\n","Iteration:  83% 1132/1357 [11:32<02:09,  1.73it/s]\u001b[A\n","Iteration:  83% 1133/1357 [11:32<02:09,  1.73it/s]\u001b[A\n","Iteration:  84% 1134/1357 [11:33<02:08,  1.73it/s]\u001b[A\n","Iteration:  84% 1135/1357 [11:33<02:08,  1.73it/s]\u001b[A\n","Iteration:  84% 1136/1357 [11:34<02:07,  1.73it/s]\u001b[A\n","Iteration:  84% 1137/1357 [11:35<02:06,  1.74it/s]\u001b[A\n","Iteration:  84% 1138/1357 [11:35<02:05,  1.74it/s]\u001b[A\n","Iteration:  84% 1139/1357 [11:36<02:05,  1.73it/s]\u001b[A\n","Iteration:  84% 1140/1357 [11:36<02:06,  1.72it/s]\u001b[A\n","Iteration:  84% 1141/1357 [11:37<02:04,  1.73it/s]\u001b[A\n","Iteration:  84% 1142/1357 [11:38<02:04,  1.73it/s]\u001b[A\n","Iteration:  84% 1143/1357 [11:38<02:03,  1.73it/s]\u001b[A12/16/2021 06:23:35 - INFO - __main__ -   ***** Running evaluation on dev dataset (12000 step) *****\n","12/16/2021 06:23:35 - INFO - __main__ -     Num examples = 5426\n","12/16/2021 06:23:35 - INFO - __main__ -     Eval Batch size = 32\n","\n","\n","Evaluating:   0% 0/170 [00:00<?, ?it/s]\u001b[A\u001b[A\n","\n","Evaluating:   1% 1/170 [00:00<00:32,  5.13it/s]\u001b[A\u001b[A\n","\n","Evaluating:   1% 2/170 [00:00<00:32,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:   2% 3/170 [00:00<00:31,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:   2% 4/170 [00:00<00:31,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:   3% 5/170 [00:00<00:31,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:   4% 6/170 [00:01<00:31,  5.29it/s]\u001b[A\u001b[A\n","\n","Evaluating:   4% 7/170 [00:01<00:30,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:   5% 8/170 [00:01<00:30,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:   5% 9/170 [00:01<00:30,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:   6% 10/170 [00:01<00:30,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:   6% 11/170 [00:02<00:30,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:   7% 12/170 [00:02<00:29,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:   8% 13/170 [00:02<00:29,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:   8% 14/170 [00:02<00:29,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:   9% 15/170 [00:02<00:29,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:   9% 16/170 [00:03<00:29,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  10% 17/170 [00:03<00:29,  5.23it/s]\u001b[A\u001b[A\n","\n","Evaluating:  11% 18/170 [00:03<00:29,  5.20it/s]\u001b[A\u001b[A\n","\n","Evaluating:  11% 19/170 [00:03<00:28,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  12% 20/170 [00:03<00:28,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  12% 21/170 [00:04<00:28,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  13% 22/170 [00:04<00:28,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  14% 23/170 [00:04<00:27,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  14% 24/170 [00:04<00:27,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  15% 25/170 [00:04<00:27,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  15% 26/170 [00:04<00:27,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  16% 27/170 [00:05<00:26,  5.30it/s]\u001b[A\u001b[A\n","\n","Evaluating:  16% 28/170 [00:05<00:26,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  17% 29/170 [00:05<00:26,  5.29it/s]\u001b[A\u001b[A\n","\n","Evaluating:  18% 30/170 [00:05<00:26,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  18% 31/170 [00:05<00:26,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  19% 32/170 [00:06<00:26,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  19% 33/170 [00:06<00:26,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  20% 34/170 [00:06<00:25,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  21% 35/170 [00:06<00:25,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  21% 36/170 [00:06<00:25,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  22% 37/170 [00:07<00:25,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  22% 38/170 [00:07<00:25,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  23% 39/170 [00:07<00:24,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  24% 40/170 [00:07<00:24,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  24% 41/170 [00:07<00:24,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  25% 42/170 [00:07<00:24,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  25% 43/170 [00:08<00:24,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  26% 44/170 [00:08<00:23,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  26% 45/170 [00:08<00:23,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  27% 46/170 [00:08<00:23,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  28% 47/170 [00:08<00:23,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  28% 48/170 [00:09<00:23,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  29% 49/170 [00:09<00:23,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  29% 50/170 [00:09<00:22,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  30% 51/170 [00:09<00:22,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  31% 52/170 [00:09<00:22,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  31% 53/170 [00:10<00:22,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  32% 54/170 [00:10<00:21,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  32% 55/170 [00:10<00:21,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  33% 56/170 [00:10<00:21,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  34% 57/170 [00:10<00:21,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  34% 58/170 [00:11<00:21,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  35% 59/170 [00:11<00:21,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  35% 60/170 [00:11<00:20,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  36% 61/170 [00:11<00:20,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  36% 62/170 [00:11<00:20,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  37% 63/170 [00:11<00:20,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  38% 64/170 [00:12<00:20,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  38% 65/170 [00:12<00:19,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  39% 66/170 [00:12<00:19,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  39% 67/170 [00:12<00:19,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  40% 68/170 [00:12<00:19,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  41% 69/170 [00:13<00:19,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  41% 70/170 [00:13<00:18,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  42% 71/170 [00:13<00:18,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  42% 72/170 [00:13<00:18,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  43% 73/170 [00:13<00:18,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  44% 74/170 [00:14<00:18,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  44% 75/170 [00:14<00:18,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  45% 76/170 [00:14<00:17,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  45% 77/170 [00:14<00:17,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  46% 78/170 [00:14<00:17,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  46% 79/170 [00:15<00:17,  5.29it/s]\u001b[A\u001b[A\n","\n","Evaluating:  47% 80/170 [00:15<00:17,  5.29it/s]\u001b[A\u001b[A\n","\n","Evaluating:  48% 81/170 [00:15<00:16,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  48% 82/170 [00:15<00:16,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  49% 83/170 [00:15<00:16,  5.29it/s]\u001b[A\u001b[A\n","\n","Evaluating:  49% 84/170 [00:15<00:16,  5.29it/s]\u001b[A\u001b[A\n","\n","Evaluating:  50% 85/170 [00:16<00:16,  5.29it/s]\u001b[A\u001b[A\n","\n","Evaluating:  51% 86/170 [00:16<00:15,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  51% 87/170 [00:16<00:15,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  52% 88/170 [00:16<00:15,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  52% 89/170 [00:16<00:15,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  53% 90/170 [00:17<00:15,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  54% 91/170 [00:17<00:15,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  54% 92/170 [00:17<00:14,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  55% 93/170 [00:17<00:14,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  55% 94/170 [00:17<00:14,  5.23it/s]\u001b[A\u001b[A\n","\n","Evaluating:  56% 95/170 [00:18<00:14,  5.23it/s]\u001b[A\u001b[A\n","\n","Evaluating:  56% 96/170 [00:18<00:14,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  57% 97/170 [00:18<00:13,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  58% 98/170 [00:18<00:13,  5.22it/s]\u001b[A\u001b[A\n","\n","Evaluating:  58% 99/170 [00:18<00:13,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  59% 100/170 [00:19<00:13,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  59% 101/170 [00:19<00:13,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  60% 102/170 [00:19<00:12,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  61% 103/170 [00:19<00:12,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  61% 104/170 [00:19<00:12,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 105/170 [00:19<00:12,  5.23it/s]\u001b[A\u001b[A\n","\n","Evaluating:  62% 106/170 [00:20<00:12,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  63% 107/170 [00:20<00:11,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  64% 108/170 [00:20<00:11,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  64% 109/170 [00:20<00:11,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  65% 110/170 [00:20<00:11,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  65% 111/170 [00:21<00:11,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  66% 112/170 [00:21<00:11,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  66% 113/170 [00:21<00:10,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  67% 114/170 [00:21<00:10,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  68% 115/170 [00:21<00:10,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  68% 116/170 [00:22<00:10,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  69% 117/170 [00:22<00:10,  5.29it/s]\u001b[A\u001b[A\n","\n","Evaluating:  69% 118/170 [00:22<00:09,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  70% 119/170 [00:22<00:09,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  71% 120/170 [00:22<00:09,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  71% 121/170 [00:23<00:09,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  72% 122/170 [00:23<00:09,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  72% 123/170 [00:23<00:08,  5.29it/s]\u001b[A\u001b[A\n","\n","Evaluating:  73% 124/170 [00:23<00:08,  5.29it/s]\u001b[A\u001b[A\n","\n","Evaluating:  74% 125/170 [00:23<00:08,  5.29it/s]\u001b[A\u001b[A\n","\n","Evaluating:  74% 126/170 [00:23<00:08,  5.29it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 127/170 [00:24<00:08,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  75% 128/170 [00:24<00:07,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  76% 129/170 [00:24<00:07,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  76% 130/170 [00:24<00:07,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  77% 131/170 [00:24<00:07,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  78% 132/170 [00:25<00:07,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  78% 133/170 [00:25<00:06,  5.29it/s]\u001b[A\u001b[A\n","\n","Evaluating:  79% 134/170 [00:25<00:06,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  79% 135/170 [00:25<00:06,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  80% 136/170 [00:25<00:06,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  81% 137/170 [00:26<00:06,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  81% 138/170 [00:26<00:06,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  82% 139/170 [00:26<00:05,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  82% 140/170 [00:26<00:05,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  83% 141/170 [00:26<00:05,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  84% 142/170 [00:26<00:05,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  84% 143/170 [00:27<00:05,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  85% 144/170 [00:27<00:04,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  85% 145/170 [00:27<00:04,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  86% 146/170 [00:27<00:04,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  86% 147/170 [00:27<00:04,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  87% 148/170 [00:28<00:04,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 149/170 [00:28<00:03,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  88% 150/170 [00:28<00:03,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  89% 151/170 [00:28<00:03,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  89% 152/170 [00:28<00:03,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  90% 153/170 [00:29<00:03,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  91% 154/170 [00:29<00:03,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  91% 155/170 [00:29<00:02,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  92% 156/170 [00:29<00:02,  5.28it/s]\u001b[A\u001b[A\n","\n","Evaluating:  92% 157/170 [00:29<00:02,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  93% 158/170 [00:30<00:02,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  94% 159/170 [00:30<00:02,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  94% 160/170 [00:30<00:01,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  95% 161/170 [00:30<00:01,  5.23it/s]\u001b[A\u001b[A\n","\n","Evaluating:  95% 162/170 [00:30<00:01,  5.23it/s]\u001b[A\u001b[A\n","\n","Evaluating:  96% 163/170 [00:30<00:01,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating:  96% 164/170 [00:31<00:01,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  97% 165/170 [00:31<00:00,  5.27it/s]\u001b[A\u001b[A\n","\n","Evaluating:  98% 166/170 [00:31<00:00,  5.26it/s]\u001b[A\u001b[A\n","\n","Evaluating:  98% 167/170 [00:31<00:00,  5.25it/s]\u001b[A\u001b[A\n","\n","Evaluating:  99% 168/170 [00:31<00:00,  5.23it/s]\u001b[A\u001b[A\n","\n","Evaluating:  99% 169/170 [00:32<00:00,  5.24it/s]\u001b[A\u001b[A\n","\n","Evaluating: 100% 170/170 [00:32<00:00,  5.27it/s]\n","12/16/2021 06:24:07 - INFO - __main__ -   ***** Eval results on dev dataset *****\n","12/16/2021 06:24:07 - INFO - __main__ -     accuracy = 0.3569848875783266\n","12/16/2021 06:24:07 - INFO - __main__ -     loss = 0.15383316900800256\n","12/16/2021 06:24:07 - INFO - __main__ -     macro_f1 = 0.4013300395379002\n","12/16/2021 06:24:07 - INFO - __main__ -     macro_precision = 0.39831717102630476\n","12/16/2021 06:24:07 - INFO - __main__ -     macro_recall = 0.4248580740524538\n","12/16/2021 06:24:07 - INFO - __main__ -     micro_f1 = 0.49281524926686215\n","12/16/2021 06:24:07 - INFO - __main__ -     micro_precision = 0.46294765840220387\n","12/16/2021 06:24:07 - INFO - __main__ -     micro_recall = 0.5268025078369906\n","12/16/2021 06:24:07 - INFO - __main__ -     weighted_f1 = 0.4920969486798707\n","12/16/2021 06:24:07 - INFO - __main__ -     weighted_precision = 0.4655343332458724\n","12/16/2021 06:24:07 - INFO - __main__ -     weighted_recall = 0.5268025078369906\n","12/16/2021 06:24:07 - INFO - transformers.configuration_utils -   Configuration saved in drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-12000/config.json\n","12/16/2021 06:24:09 - INFO - transformers.modeling_utils -   Model weights saved in drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-12000/pytorch_model.bin\n","12/16/2021 06:24:09 - INFO - __main__ -   Saving model checkpoint to drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-12000\n","\n","Iteration:  84% 1144/1357 [12:13<38:46, 10.92s/it]\u001b[A\n","Iteration:  84% 1145/1357 [12:14<27:36,  7.82s/it]\u001b[A\n","Iteration:  84% 1146/1357 [12:14<19:51,  5.65s/it]\u001b[A\n","Iteration:  85% 1147/1357 [12:15<14:26,  4.13s/it]\u001b[A\n","Iteration:  85% 1148/1357 [12:15<10:39,  3.06s/it]\u001b[A\n","Iteration:  85% 1149/1357 [12:16<08:01,  2.32s/it]\u001b[A\n","Iteration:  85% 1150/1357 [12:17<06:11,  1.80s/it]\u001b[A\n","Iteration:  85% 1151/1357 [12:17<04:54,  1.43s/it]\u001b[A\n","Iteration:  85% 1152/1357 [12:18<04:00,  1.17s/it]\u001b[A\n","Iteration:  85% 1153/1357 [12:18<03:23,  1.00it/s]\u001b[A\n","Iteration:  85% 1154/1357 [12:19<02:56,  1.15it/s]\u001b[A\n","Iteration:  85% 1155/1357 [12:20<02:38,  1.27it/s]\u001b[A\n","Iteration:  85% 1156/1357 [12:20<02:27,  1.36it/s]\u001b[A\n","Iteration:  85% 1157/1357 [12:21<02:17,  1.45it/s]\u001b[A\n","Iteration:  85% 1158/1357 [12:21<02:10,  1.52it/s]\u001b[A\n","Iteration:  85% 1159/1357 [12:22<02:06,  1.57it/s]\u001b[A\n","Iteration:  85% 1160/1357 [12:22<02:02,  1.61it/s]\u001b[A\n","Iteration:  86% 1161/1357 [12:23<02:01,  1.62it/s]\u001b[A\n","Iteration:  86% 1162/1357 [12:24<01:58,  1.64it/s]\u001b[A\n","Iteration:  86% 1163/1357 [12:24<01:56,  1.67it/s]\u001b[A\n","Iteration:  86% 1164/1357 [12:25<01:54,  1.69it/s]\u001b[A\n","Iteration:  86% 1165/1357 [12:25<01:52,  1.70it/s]\u001b[A\n","Iteration:  86% 1166/1357 [12:26<01:51,  1.72it/s]\u001b[A\n","Iteration:  86% 1167/1357 [12:27<01:50,  1.72it/s]\u001b[A\n","Iteration:  86% 1168/1357 [12:27<01:50,  1.72it/s]\u001b[A\n","Iteration:  86% 1169/1357 [12:28<01:49,  1.72it/s]\u001b[A\n","Iteration:  86% 1170/1357 [12:28<01:48,  1.73it/s]\u001b[A\n","Iteration:  86% 1171/1357 [12:29<01:48,  1.72it/s]\u001b[A\n","Iteration:  86% 1172/1357 [12:29<01:47,  1.73it/s]\u001b[A\n","Iteration:  86% 1173/1357 [12:30<01:45,  1.74it/s]\u001b[A\n","Iteration:  87% 1174/1357 [12:31<01:46,  1.72it/s]\u001b[A\n","Iteration:  87% 1175/1357 [12:31<01:45,  1.72it/s]\u001b[A\n","Iteration:  87% 1176/1357 [12:32<01:45,  1.72it/s]\u001b[A\n","Iteration:  87% 1177/1357 [12:32<01:44,  1.72it/s]\u001b[A\n","Iteration:  87% 1178/1357 [12:33<01:43,  1.72it/s]\u001b[A\n","Iteration:  87% 1179/1357 [12:34<01:43,  1.73it/s]\u001b[A\n","Iteration:  87% 1180/1357 [12:34<01:43,  1.71it/s]\u001b[A\n","Iteration:  87% 1181/1357 [12:35<01:43,  1.70it/s]\u001b[A\n","Iteration:  87% 1182/1357 [12:35<01:42,  1.71it/s]\u001b[A\n","Iteration:  87% 1183/1357 [12:36<01:41,  1.72it/s]\u001b[A\n","Iteration:  87% 1184/1357 [12:36<01:40,  1.73it/s]\u001b[A\n","Iteration:  87% 1185/1357 [12:37<01:39,  1.73it/s]\u001b[A\n","Iteration:  87% 1186/1357 [12:38<01:38,  1.73it/s]\u001b[A\n","Iteration:  87% 1187/1357 [12:38<01:38,  1.73it/s]\u001b[A\n","Iteration:  88% 1188/1357 [12:39<01:37,  1.74it/s]\u001b[A\n","Iteration:  88% 1189/1357 [12:39<01:36,  1.73it/s]\u001b[A\n","Iteration:  88% 1190/1357 [12:40<01:36,  1.73it/s]\u001b[A\n","Iteration:  88% 1191/1357 [12:40<01:35,  1.73it/s]\u001b[A\n","Iteration:  88% 1192/1357 [12:41<01:35,  1.72it/s]\u001b[A\n","Iteration:  88% 1193/1357 [12:42<01:35,  1.72it/s]\u001b[A\n","Iteration:  88% 1194/1357 [12:42<01:34,  1.73it/s]\u001b[A\n","Iteration:  88% 1195/1357 [12:43<01:33,  1.74it/s]\u001b[A\n","Iteration:  88% 1196/1357 [12:43<01:32,  1.73it/s]\u001b[A\n","Iteration:  88% 1197/1357 [12:44<01:32,  1.74it/s]\u001b[A\n","Iteration:  88% 1198/1357 [12:45<01:31,  1.74it/s]\u001b[A\n","Iteration:  88% 1199/1357 [12:45<01:30,  1.74it/s]\u001b[A\n","Iteration:  88% 1200/1357 [12:46<01:30,  1.73it/s]\u001b[A\n","Iteration:  89% 1201/1357 [12:46<01:29,  1.74it/s]\u001b[A\n","Iteration:  89% 1202/1357 [12:47<01:29,  1.74it/s]\u001b[A\n","Iteration:  89% 1203/1357 [12:47<01:28,  1.73it/s]\u001b[A\n","Iteration:  89% 1204/1357 [12:48<01:28,  1.73it/s]\u001b[A\n","Iteration:  89% 1205/1357 [12:49<01:28,  1.73it/s]\u001b[A\n","Iteration:  89% 1206/1357 [12:49<01:27,  1.73it/s]\u001b[A\n","Iteration:  89% 1207/1357 [12:50<01:27,  1.72it/s]\u001b[A\n","Iteration:  89% 1208/1357 [12:50<01:26,  1.73it/s]\u001b[A\n","Iteration:  89% 1209/1357 [12:51<01:25,  1.72it/s]\u001b[A\n","Iteration:  89% 1210/1357 [12:51<01:25,  1.72it/s]\u001b[A\n","Iteration:  89% 1211/1357 [12:52<01:24,  1.72it/s]\u001b[A\n","Iteration:  89% 1212/1357 [12:53<01:23,  1.73it/s]\u001b[A\n","Iteration:  89% 1213/1357 [12:53<01:23,  1.72it/s]\u001b[A\n","Iteration:  89% 1214/1357 [12:54<01:22,  1.73it/s]\u001b[A\n","Iteration:  90% 1215/1357 [12:54<01:22,  1.73it/s]\u001b[A\n","Iteration:  90% 1216/1357 [12:55<01:21,  1.73it/s]\u001b[A\n","Iteration:  90% 1217/1357 [12:56<01:20,  1.74it/s]\u001b[A\n","Iteration:  90% 1218/1357 [12:56<01:19,  1.74it/s]\u001b[A\n","Iteration:  90% 1219/1357 [12:57<01:19,  1.73it/s]\u001b[A\n","Iteration:  90% 1220/1357 [12:57<01:19,  1.72it/s]\u001b[A\n","Iteration:  90% 1221/1357 [12:58<01:19,  1.72it/s]\u001b[A\n","Iteration:  90% 1222/1357 [12:58<01:18,  1.72it/s]\u001b[A\n","Iteration:  90% 1223/1357 [12:59<01:17,  1.73it/s]\u001b[A\n","Iteration:  90% 1224/1357 [13:00<01:17,  1.73it/s]\u001b[A\n","Iteration:  90% 1225/1357 [13:00<01:16,  1.73it/s]\u001b[A\n","Iteration:  90% 1226/1357 [13:01<01:15,  1.73it/s]\u001b[A\n","Iteration:  90% 1227/1357 [13:01<01:15,  1.73it/s]\u001b[A\n","Iteration:  90% 1228/1357 [13:02<01:14,  1.73it/s]\u001b[A\n","Iteration:  91% 1229/1357 [13:02<01:14,  1.72it/s]\u001b[A\n","Iteration:  91% 1230/1357 [13:03<01:13,  1.73it/s]\u001b[A\n","Iteration:  91% 1231/1357 [13:04<01:12,  1.73it/s]\u001b[A\n","Iteration:  91% 1232/1357 [13:04<01:12,  1.72it/s]\u001b[A\n","Iteration:  91% 1233/1357 [13:05<01:11,  1.73it/s]\u001b[A\n","Iteration:  91% 1234/1357 [13:05<01:11,  1.73it/s]\u001b[A\n","Iteration:  91% 1235/1357 [13:06<01:10,  1.73it/s]\u001b[A\n","Iteration:  91% 1236/1357 [13:07<01:09,  1.73it/s]\u001b[A\n","Iteration:  91% 1237/1357 [13:07<01:09,  1.73it/s]\u001b[A\n","Iteration:  91% 1238/1357 [13:08<01:08,  1.73it/s]\u001b[A\n","Iteration:  91% 1239/1357 [13:08<01:08,  1.73it/s]\u001b[A\n","Iteration:  91% 1240/1357 [13:09<01:07,  1.73it/s]\u001b[A\n","Iteration:  91% 1241/1357 [13:09<01:06,  1.73it/s]\u001b[A\n","Iteration:  92% 1242/1357 [13:10<01:06,  1.73it/s]\u001b[A\n","Iteration:  92% 1243/1357 [13:11<01:05,  1.73it/s]\u001b[A\n","Iteration:  92% 1244/1357 [13:11<01:05,  1.72it/s]\u001b[A\n","Iteration:  92% 1245/1357 [13:12<01:04,  1.73it/s]\u001b[A\n","Iteration:  92% 1246/1357 [13:12<01:03,  1.74it/s]\u001b[A\n","Iteration:  92% 1247/1357 [13:13<01:03,  1.73it/s]\u001b[A\n","Iteration:  92% 1248/1357 [13:13<01:03,  1.72it/s]\u001b[A\n","Iteration:  92% 1249/1357 [13:14<01:02,  1.73it/s]\u001b[A\n","Iteration:  92% 1250/1357 [13:15<01:02,  1.72it/s]\u001b[A\n","Iteration:  92% 1251/1357 [13:15<01:01,  1.72it/s]\u001b[A\n","Iteration:  92% 1252/1357 [13:16<01:00,  1.73it/s]\u001b[A\n","Iteration:  92% 1253/1357 [13:16<01:00,  1.73it/s]\u001b[A\n","Iteration:  92% 1254/1357 [13:17<00:59,  1.73it/s]\u001b[A\n","Iteration:  92% 1255/1357 [13:18<00:59,  1.72it/s]\u001b[A\n","Iteration:  93% 1256/1357 [13:18<00:58,  1.73it/s]\u001b[A\n","Iteration:  93% 1257/1357 [13:19<00:58,  1.72it/s]\u001b[A\n","Iteration:  93% 1258/1357 [13:19<00:57,  1.73it/s]\u001b[A\n","Iteration:  93% 1259/1357 [13:20<00:56,  1.74it/s]\u001b[A\n","Iteration:  93% 1260/1357 [13:20<00:55,  1.74it/s]\u001b[A\n","Iteration:  93% 1261/1357 [13:21<00:55,  1.74it/s]\u001b[A\n","Iteration:  93% 1262/1357 [13:22<00:54,  1.74it/s]\u001b[A\n","Iteration:  93% 1263/1357 [13:22<00:54,  1.74it/s]\u001b[A\n","Iteration:  93% 1264/1357 [13:23<00:53,  1.73it/s]\u001b[A\n","Iteration:  93% 1265/1357 [13:23<00:52,  1.74it/s]\u001b[A\n","Iteration:  93% 1266/1357 [13:24<00:52,  1.74it/s]\u001b[A\n","Iteration:  93% 1267/1357 [13:24<00:51,  1.73it/s]\u001b[A\n","Iteration:  93% 1268/1357 [13:25<00:51,  1.73it/s]\u001b[A\n","Iteration:  94% 1269/1357 [13:26<00:50,  1.73it/s]\u001b[A\n","Iteration:  94% 1270/1357 [13:26<00:50,  1.73it/s]\u001b[A\n","Iteration:  94% 1271/1357 [13:27<00:49,  1.73it/s]\u001b[A\n","Iteration:  94% 1272/1357 [13:27<00:49,  1.73it/s]\u001b[A\n","Iteration:  94% 1273/1357 [13:28<00:48,  1.72it/s]\u001b[A\n","Iteration:  94% 1274/1357 [13:28<00:47,  1.73it/s]\u001b[A\n","Iteration:  94% 1275/1357 [13:29<00:47,  1.74it/s]\u001b[A\n","Iteration:  94% 1276/1357 [13:30<00:46,  1.74it/s]\u001b[A\n","Iteration:  94% 1277/1357 [13:30<00:46,  1.73it/s]\u001b[A\n","Iteration:  94% 1278/1357 [13:31<00:45,  1.73it/s]\u001b[A\n","Iteration:  94% 1279/1357 [13:31<00:44,  1.73it/s]\u001b[A\n","Iteration:  94% 1280/1357 [13:32<00:44,  1.73it/s]\u001b[A\n","Iteration:  94% 1281/1357 [13:33<00:43,  1.74it/s]\u001b[A\n","Iteration:  94% 1282/1357 [13:33<00:43,  1.74it/s]\u001b[A\n","Iteration:  95% 1283/1357 [13:34<00:42,  1.74it/s]\u001b[A\n","Iteration:  95% 1284/1357 [13:34<00:42,  1.73it/s]\u001b[A\n","Iteration:  95% 1285/1357 [13:35<00:41,  1.73it/s]\u001b[A\n","Iteration:  95% 1286/1357 [13:35<00:40,  1.73it/s]\u001b[A\n","Iteration:  95% 1287/1357 [13:36<00:40,  1.73it/s]\u001b[A\n","Iteration:  95% 1288/1357 [13:37<00:39,  1.74it/s]\u001b[A\n","Iteration:  95% 1289/1357 [13:37<00:39,  1.74it/s]\u001b[A\n","Iteration:  95% 1290/1357 [13:38<00:38,  1.74it/s]\u001b[A\n","Iteration:  95% 1291/1357 [13:38<00:38,  1.73it/s]\u001b[A\n","Iteration:  95% 1292/1357 [13:39<00:37,  1.73it/s]\u001b[A\n","Iteration:  95% 1293/1357 [13:39<00:37,  1.73it/s]\u001b[A\n","Iteration:  95% 1294/1357 [13:40<00:36,  1.72it/s]\u001b[A\n","Iteration:  95% 1295/1357 [13:41<00:35,  1.73it/s]\u001b[A\n","Iteration:  96% 1296/1357 [13:41<00:35,  1.73it/s]\u001b[A\n","Iteration:  96% 1297/1357 [13:42<00:34,  1.73it/s]\u001b[A\n","Iteration:  96% 1298/1357 [13:42<00:34,  1.73it/s]\u001b[A\n","Iteration:  96% 1299/1357 [13:43<00:33,  1.73it/s]\u001b[A\n","Iteration:  96% 1300/1357 [13:43<00:33,  1.72it/s]\u001b[A\n","Iteration:  96% 1301/1357 [13:44<00:32,  1.73it/s]\u001b[A\n","Iteration:  96% 1302/1357 [13:45<00:31,  1.73it/s]\u001b[A\n","Iteration:  96% 1303/1357 [13:45<00:31,  1.72it/s]\u001b[A\n","Iteration:  96% 1304/1357 [13:46<00:30,  1.73it/s]\u001b[A\n","Iteration:  96% 1305/1357 [13:46<00:30,  1.72it/s]\u001b[A\n","Iteration:  96% 1306/1357 [13:47<00:29,  1.73it/s]\u001b[A\n","Iteration:  96% 1307/1357 [13:48<00:28,  1.73it/s]\u001b[A\n","Iteration:  96% 1308/1357 [13:48<00:28,  1.73it/s]\u001b[A\n","Iteration:  96% 1309/1357 [13:49<00:27,  1.73it/s]\u001b[A\n","Iteration:  97% 1310/1357 [13:49<00:27,  1.73it/s]\u001b[A\n","Iteration:  97% 1311/1357 [13:50<00:26,  1.74it/s]\u001b[A\n","Iteration:  97% 1312/1357 [13:50<00:25,  1.74it/s]\u001b[A\n","Iteration:  97% 1313/1357 [13:51<00:25,  1.73it/s]\u001b[A\n","Iteration:  97% 1314/1357 [13:52<00:24,  1.73it/s]\u001b[A\n","Iteration:  97% 1315/1357 [13:52<00:24,  1.73it/s]\u001b[A\n","Iteration:  97% 1316/1357 [13:53<00:23,  1.73it/s]\u001b[A\n","Iteration:  97% 1317/1357 [13:53<00:23,  1.74it/s]\u001b[A\n","Iteration:  97% 1318/1357 [13:54<00:22,  1.74it/s]\u001b[A\n","Iteration:  97% 1319/1357 [13:54<00:21,  1.74it/s]\u001b[A\n","Iteration:  97% 1320/1357 [13:55<00:21,  1.72it/s]\u001b[A\n","Iteration:  97% 1321/1357 [13:56<00:20,  1.73it/s]\u001b[A\n","Iteration:  97% 1322/1357 [13:56<00:20,  1.73it/s]\u001b[A\n","Iteration:  97% 1323/1357 [13:57<00:19,  1.73it/s]\u001b[A\n","Iteration:  98% 1324/1357 [13:57<00:19,  1.73it/s]\u001b[A\n","Iteration:  98% 1325/1357 [13:58<00:18,  1.73it/s]\u001b[A\n","Iteration:  98% 1326/1357 [13:59<00:17,  1.73it/s]\u001b[A\n","Iteration:  98% 1327/1357 [13:59<00:17,  1.73it/s]\u001b[A\n","Iteration:  98% 1328/1357 [14:00<00:16,  1.73it/s]\u001b[A\n","Iteration:  98% 1329/1357 [14:00<00:16,  1.72it/s]\u001b[A\n","Iteration:  98% 1330/1357 [14:01<00:15,  1.73it/s]\u001b[A\n","Iteration:  98% 1331/1357 [14:01<00:15,  1.72it/s]\u001b[A\n","Iteration:  98% 1332/1357 [14:02<00:14,  1.72it/s]\u001b[A\n","Iteration:  98% 1333/1357 [14:03<00:13,  1.73it/s]\u001b[A\n","Iteration:  98% 1334/1357 [14:03<00:13,  1.73it/s]\u001b[A\n","Iteration:  98% 1335/1357 [14:04<00:12,  1.73it/s]\u001b[A\n","Iteration:  98% 1336/1357 [14:04<00:12,  1.73it/s]\u001b[A\n","Iteration:  99% 1337/1357 [14:05<00:11,  1.73it/s]\u001b[A\n","Iteration:  99% 1338/1357 [14:05<00:11,  1.73it/s]\u001b[A\n","Iteration:  99% 1339/1357 [14:06<00:10,  1.73it/s]\u001b[A\n","Iteration:  99% 1340/1357 [14:07<00:09,  1.74it/s]\u001b[A\n","Iteration:  99% 1341/1357 [14:07<00:09,  1.73it/s]\u001b[A\n","Iteration:  99% 1342/1357 [14:08<00:08,  1.73it/s]\u001b[A\n","Iteration:  99% 1343/1357 [14:08<00:08,  1.73it/s]\u001b[A\n","Iteration:  99% 1344/1357 [14:09<00:07,  1.73it/s]\u001b[A\n","Iteration:  99% 1345/1357 [14:09<00:06,  1.73it/s]\u001b[A\n","Iteration:  99% 1346/1357 [14:10<00:06,  1.73it/s]\u001b[A\n","Iteration:  99% 1347/1357 [14:11<00:05,  1.74it/s]\u001b[A\n","Iteration:  99% 1348/1357 [14:11<00:05,  1.73it/s]\u001b[A\n","Iteration:  99% 1349/1357 [14:12<00:04,  1.72it/s]\u001b[A\n","Iteration:  99% 1350/1357 [14:12<00:04,  1.72it/s]\u001b[A\n","Iteration: 100% 1351/1357 [14:13<00:03,  1.72it/s]\u001b[A\n","Iteration: 100% 1352/1357 [14:14<00:02,  1.72it/s]\u001b[A\n","Iteration: 100% 1353/1357 [14:14<00:02,  1.74it/s]\u001b[A\n","Iteration: 100% 1354/1357 [14:15<00:01,  1.73it/s]\u001b[A\n","Iteration: 100% 1355/1357 [14:15<00:01,  1.73it/s]\u001b[A\n","Iteration: 100% 1356/1357 [14:16<00:00,  1.73it/s]\u001b[A\n","Iteration: 100% 1357/1357 [14:16<00:00,  1.58it/s]\n","Epoch:  90% 9/10 [2:05:29<13:59, 839.72s/it]\n","Iteration:   0% 0/1357 [00:00<?, ?it/s]\u001b[A\n","Iteration:   0% 1/1357 [00:00<13:02,  1.73it/s]\u001b[A\n","Iteration:   0% 2/1357 [00:01<13:04,  1.73it/s]\u001b[A\n","Iteration:   0% 3/1357 [00:01<13:02,  1.73it/s]\u001b[A\n","Iteration:   0% 4/1357 [00:02<13:00,  1.73it/s]\u001b[A\n","Iteration:   0% 5/1357 [00:02<13:00,  1.73it/s]\u001b[A\n","Iteration:   0% 6/1357 [00:03<13:00,  1.73it/s]\u001b[A\n","Iteration:   1% 7/1357 [00:04<12:58,  1.73it/s]\u001b[A\n","Iteration:   1% 8/1357 [00:04<12:55,  1.74it/s]\u001b[A\n","Iteration:   1% 9/1357 [00:05<12:55,  1.74it/s]\u001b[A\n","Iteration:   1% 10/1357 [00:05<12:59,  1.73it/s]\u001b[A\n","Iteration:   1% 11/1357 [00:06<12:58,  1.73it/s]\u001b[A\n","Iteration:   1% 12/1357 [00:06<12:56,  1.73it/s]\u001b[A\n","Iteration:   1% 13/1357 [00:07<13:01,  1.72it/s]\u001b[A\n","Iteration:   1% 14/1357 [00:08<12:58,  1.73it/s]\u001b[A\n","Iteration:   1% 15/1357 [00:08<12:55,  1.73it/s]\u001b[A\n","Iteration:   1% 16/1357 [00:09<12:57,  1.73it/s]\u001b[A\n","Iteration:   1% 17/1357 [00:09<12:59,  1.72it/s]\u001b[A\n","Iteration:   1% 18/1357 [00:10<12:57,  1.72it/s]\u001b[A\n","Iteration:   1% 19/1357 [00:10<12:58,  1.72it/s]\u001b[A\n","Iteration:   1% 20/1357 [00:11<12:55,  1.72it/s]\u001b[A\n","Iteration:   2% 21/1357 [00:12<12:52,  1.73it/s]\u001b[A\n","Iteration:   2% 22/1357 [00:12<12:53,  1.72it/s]\u001b[A\n","Iteration:   2% 23/1357 [00:13<12:55,  1.72it/s]\u001b[A\n","Iteration:   2% 24/1357 [00:13<12:53,  1.72it/s]\u001b[A\n","Iteration:   2% 25/1357 [00:14<12:52,  1.72it/s]\u001b[A\n","Iteration:   2% 26/1357 [00:15<12:51,  1.73it/s]\u001b[A\n","Iteration:   2% 27/1357 [00:15<12:50,  1.73it/s]\u001b[A\n","Iteration:   2% 28/1357 [00:16<12:53,  1.72it/s]\u001b[A\n","Iteration:   2% 29/1357 [00:16<12:52,  1.72it/s]\u001b[A\n","Iteration:   2% 30/1357 [00:17<12:51,  1.72it/s]\u001b[A\n","Iteration:   2% 31/1357 [00:17<12:50,  1.72it/s]\u001b[A\n","Iteration:   2% 32/1357 [00:18<12:50,  1.72it/s]\u001b[A\n","Iteration:   2% 33/1357 [00:19<12:49,  1.72it/s]\u001b[A\n","Iteration:   3% 34/1357 [00:19<12:49,  1.72it/s]\u001b[A\n","Iteration:   3% 35/1357 [00:20<12:48,  1.72it/s]\u001b[A\n","Iteration:   3% 36/1357 [00:20<12:46,  1.72it/s]\u001b[A\n","Iteration:   3% 37/1357 [00:21<12:46,  1.72it/s]\u001b[A\n","Iteration:   3% 38/1357 [00:22<12:49,  1.71it/s]\u001b[A\n","Iteration:   3% 39/1357 [00:22<12:47,  1.72it/s]\u001b[A\n","Iteration:   3% 40/1357 [00:23<12:48,  1.71it/s]\u001b[A\n","Iteration:   3% 41/1357 [00:23<12:45,  1.72it/s]\u001b[A\n","Iteration:   3% 42/1357 [00:24<12:43,  1.72it/s]\u001b[A\n","Iteration:   3% 43/1357 [00:24<12:40,  1.73it/s]\u001b[A\n","Iteration:   3% 44/1357 [00:25<12:41,  1.72it/s]\u001b[A\n","Iteration:   3% 45/1357 [00:26<12:40,  1.73it/s]\u001b[A\n","Iteration:   3% 46/1357 [00:26<12:39,  1.73it/s]\u001b[A\n","Iteration:   3% 47/1357 [00:27<12:40,  1.72it/s]\u001b[A\n","Iteration:   4% 48/1357 [00:27<12:36,  1.73it/s]\u001b[A\n","Iteration:   4% 49/1357 [00:28<12:33,  1.74it/s]\u001b[A\n","Iteration:   4% 50/1357 [00:28<12:36,  1.73it/s]\u001b[A\n","Iteration:   4% 51/1357 [00:29<12:37,  1.72it/s]\u001b[A\n","Iteration:   4% 52/1357 [00:30<12:34,  1.73it/s]\u001b[A\n","Iteration:   4% 53/1357 [00:30<12:35,  1.73it/s]\u001b[A\n","Iteration:   4% 54/1357 [00:31<12:35,  1.72it/s]\u001b[A\n","Iteration:   4% 55/1357 [00:31<12:34,  1.73it/s]\u001b[A\n","Iteration:   4% 56/1357 [00:32<12:34,  1.73it/s]\u001b[A\n","Iteration:   4% 57/1357 [00:33<12:34,  1.72it/s]\u001b[A\n","Iteration:   4% 58/1357 [00:33<12:32,  1.73it/s]\u001b[A\n","Iteration:   4% 59/1357 [00:34<12:32,  1.72it/s]\u001b[A\n","Iteration:   4% 60/1357 [00:34<12:34,  1.72it/s]\u001b[A\n","Iteration:   4% 61/1357 [00:35<12:32,  1.72it/s]\u001b[A\n","Iteration:   5% 62/1357 [00:35<12:31,  1.72it/s]\u001b[A\n","Iteration:   5% 63/1357 [00:36<12:36,  1.71it/s]\u001b[A\n","Iteration:   5% 64/1357 [00:37<12:37,  1.71it/s]\u001b[A\n","Iteration:   5% 65/1357 [00:37<12:34,  1.71it/s]\u001b[A\n","Iteration:   5% 66/1357 [00:38<12:36,  1.71it/s]\u001b[A\n","Iteration:   5% 67/1357 [00:38<12:31,  1.72it/s]\u001b[A\n","Iteration:   5% 68/1357 [00:39<12:31,  1.71it/s]\u001b[A\n","Iteration:   5% 69/1357 [00:40<12:30,  1.72it/s]\u001b[A\n","Iteration:   5% 70/1357 [00:40<12:30,  1.72it/s]\u001b[A\n","Iteration:   5% 71/1357 [00:41<12:28,  1.72it/s]\u001b[A\n","Iteration:   5% 72/1357 [00:41<12:27,  1.72it/s]\u001b[A\n","Iteration:   5% 73/1357 [00:42<12:26,  1.72it/s]\u001b[A\n","Iteration:   5% 74/1357 [00:42<12:24,  1.72it/s]\u001b[A\n","Iteration:   6% 75/1357 [00:43<12:23,  1.72it/s]\u001b[A\n","Iteration:   6% 76/1357 [00:44<12:19,  1.73it/s]\u001b[A\n","Iteration:   6% 77/1357 [00:44<12:19,  1.73it/s]\u001b[A\n","Iteration:   6% 78/1357 [00:45<12:19,  1.73it/s]\u001b[A\n","Iteration:   6% 79/1357 [00:45<12:21,  1.72it/s]\u001b[A\n","Iteration:   6% 80/1357 [00:46<12:21,  1.72it/s]\u001b[A\n","Iteration:   6% 81/1357 [00:47<12:21,  1.72it/s]\u001b[A\n","Iteration:   6% 82/1357 [00:47<12:22,  1.72it/s]\u001b[A\n","Iteration:   6% 83/1357 [00:48<12:18,  1.72it/s]\u001b[A\n","Iteration:   6% 84/1357 [00:48<12:20,  1.72it/s]\u001b[A\n","Iteration:   6% 85/1357 [00:49<12:19,  1.72it/s]\u001b[A\n","Iteration:   6% 86/1357 [00:49<12:17,  1.72it/s]\u001b[A\n","Iteration:   6% 87/1357 [00:50<12:16,  1.73it/s]\u001b[A\n","Iteration:   6% 88/1357 [00:51<12:16,  1.72it/s]\u001b[A\n","Iteration:   7% 89/1357 [00:51<12:14,  1.73it/s]\u001b[A\n","Iteration:   7% 90/1357 [00:52<12:13,  1.73it/s]\u001b[A\n","Iteration:   7% 91/1357 [00:52<12:15,  1.72it/s]\u001b[A\n","Iteration:   7% 92/1357 [00:53<12:15,  1.72it/s]\u001b[A\n","Iteration:   7% 93/1357 [00:53<12:14,  1.72it/s]\u001b[A\n","Iteration:   7% 94/1357 [00:54<12:15,  1.72it/s]\u001b[A\n","Iteration:   7% 95/1357 [00:55<12:12,  1.72it/s]\u001b[A\n","Iteration:   7% 96/1357 [00:55<12:10,  1.73it/s]\u001b[A\n","Iteration:   7% 97/1357 [00:56<12:11,  1.72it/s]\u001b[A\n","Iteration:   7% 98/1357 [00:56<12:07,  1.73it/s]\u001b[A\n","Iteration:   7% 99/1357 [00:57<12:06,  1.73it/s]\u001b[A\n","Iteration:   7% 100/1357 [00:58<12:11,  1.72it/s]\u001b[A\n","Iteration:   7% 101/1357 [00:58<12:11,  1.72it/s]\u001b[A\n","Iteration:   8% 102/1357 [00:59<12:08,  1.72it/s]\u001b[A\n","Iteration:   8% 103/1357 [00:59<12:07,  1.72it/s]\u001b[A\n","Iteration:   8% 104/1357 [01:00<12:06,  1.72it/s]\u001b[A\n","Iteration:   8% 105/1357 [01:00<12:04,  1.73it/s]\u001b[A\n","Iteration:   8% 106/1357 [01:01<12:08,  1.72it/s]\u001b[A\n","Iteration:   8% 107/1357 [01:02<12:08,  1.72it/s]\u001b[A\n","Iteration:   8% 108/1357 [01:02<12:06,  1.72it/s]\u001b[A\n","Iteration:   8% 109/1357 [01:03<12:04,  1.72it/s]\u001b[A\n","Iteration:   8% 110/1357 [01:03<12:03,  1.72it/s]\u001b[A\n","Iteration:   8% 111/1357 [01:04<12:02,  1.73it/s]\u001b[A\n","Iteration:   8% 112/1357 [01:04<12:02,  1.72it/s]\u001b[A\n","Iteration:   8% 113/1357 [01:05<12:02,  1.72it/s]\u001b[A\n","Iteration:   8% 114/1357 [01:06<12:03,  1.72it/s]\u001b[A\n","Iteration:   8% 115/1357 [01:06<12:04,  1.71it/s]\u001b[A\n","Iteration:   9% 116/1357 [01:07<12:05,  1.71it/s]\u001b[A\n","Iteration:   9% 117/1357 [01:07<12:01,  1.72it/s]\u001b[A\n","Iteration:   9% 118/1357 [01:08<12:04,  1.71it/s]\u001b[A\n","Iteration:   9% 119/1357 [01:09<12:01,  1.72it/s]\u001b[A\n","Iteration:   9% 120/1357 [01:09<11:59,  1.72it/s]\u001b[A\n","Iteration:   9% 121/1357 [01:10<11:59,  1.72it/s]\u001b[A\n","Iteration:   9% 122/1357 [01:10<12:03,  1.71it/s]\u001b[A\n","Iteration:   9% 123/1357 [01:11<11:59,  1.72it/s]\u001b[A\n","Iteration:   9% 124/1357 [01:11<11:57,  1.72it/s]\u001b[A\n","Iteration:   9% 125/1357 [01:12<11:56,  1.72it/s]\u001b[A\n","Iteration:   9% 126/1357 [01:13<11:53,  1.72it/s]\u001b[A\n","Iteration:   9% 127/1357 [01:13<11:51,  1.73it/s]\u001b[A\n","Iteration:   9% 128/1357 [01:14<11:51,  1.73it/s]\u001b[A\n","Iteration:  10% 129/1357 [01:14<11:51,  1.72it/s]\u001b[A\n","Iteration:  10% 130/1357 [01:15<11:53,  1.72it/s]\u001b[A\n","Iteration:  10% 131/1357 [01:16<11:54,  1.72it/s]\u001b[A\n","Iteration:  10% 132/1357 [01:16<11:51,  1.72it/s]\u001b[A\n","Iteration:  10% 133/1357 [01:17<11:49,  1.73it/s]\u001b[A\n","Iteration:  10% 134/1357 [01:17<11:49,  1.72it/s]\u001b[A\n","Iteration:  10% 135/1357 [01:18<11:50,  1.72it/s]\u001b[A\n","Iteration:  10% 136/1357 [01:18<11:48,  1.72it/s]\u001b[A\n","Iteration:  10% 137/1357 [01:19<11:50,  1.72it/s]\u001b[A\n","Iteration:  10% 138/1357 [01:20<11:50,  1.71it/s]\u001b[A\n","Iteration:  10% 139/1357 [01:20<11:46,  1.72it/s]\u001b[A\n","Iteration:  10% 140/1357 [01:21<11:47,  1.72it/s]\u001b[A\n","Iteration:  10% 141/1357 [01:21<11:49,  1.71it/s]\u001b[A\n","Iteration:  10% 142/1357 [01:22<11:48,  1.72it/s]\u001b[A\n","Iteration:  11% 143/1357 [01:23<11:45,  1.72it/s]\u001b[A\n","Iteration:  11% 144/1357 [01:23<11:46,  1.72it/s]\u001b[A\n","Iteration:  11% 145/1357 [01:24<11:41,  1.73it/s]\u001b[A\n","Iteration:  11% 146/1357 [01:24<11:42,  1.72it/s]\u001b[A\n","Iteration:  11% 147/1357 [01:25<11:42,  1.72it/s]\u001b[A\n","Iteration:  11% 148/1357 [01:25<11:41,  1.72it/s]\u001b[A\n","Iteration:  11% 149/1357 [01:26<11:41,  1.72it/s]\u001b[A\n","Iteration:  11% 150/1357 [01:27<11:43,  1.72it/s]\u001b[A\n","Iteration:  11% 151/1357 [01:27<11:40,  1.72it/s]\u001b[A\n","Iteration:  11% 152/1357 [01:28<11:40,  1.72it/s]\u001b[A\n","Iteration:  11% 153/1357 [01:28<11:39,  1.72it/s]\u001b[A\n","Iteration:  11% 154/1357 [01:29<11:35,  1.73it/s]\u001b[A\n","Iteration:  11% 155/1357 [01:29<11:35,  1.73it/s]\u001b[A\n","Iteration:  11% 156/1357 [01:30<11:35,  1.73it/s]\u001b[A\n","Iteration:  12% 157/1357 [01:31<11:36,  1.72it/s]\u001b[A\n","Iteration:  12% 158/1357 [01:31<11:36,  1.72it/s]\u001b[A\n","Iteration:  12% 159/1357 [01:32<11:37,  1.72it/s]\u001b[A\n","Iteration:  12% 160/1357 [01:32<11:34,  1.72it/s]\u001b[A\n","Iteration:  12% 161/1357 [01:33<11:31,  1.73it/s]\u001b[A\n","Iteration:  12% 162/1357 [01:34<11:33,  1.72it/s]\u001b[A\n","Iteration:  12% 163/1357 [01:34<11:35,  1.72it/s]\u001b[A\n","Iteration:  12% 164/1357 [01:35<11:33,  1.72it/s]\u001b[A\n","Iteration:  12% 165/1357 [01:35<11:32,  1.72it/s]\u001b[A\n","Iteration:  12% 166/1357 [01:36<11:30,  1.72it/s]\u001b[A\n","Iteration:  12% 167/1357 [01:36<11:30,  1.72it/s]\u001b[A\n","Iteration:  12% 168/1357 [01:37<11:33,  1.71it/s]\u001b[A\n","Iteration:  12% 169/1357 [01:38<11:35,  1.71it/s]\u001b[A\n","Iteration:  13% 170/1357 [01:38<11:31,  1.72it/s]\u001b[A\n","Iteration:  13% 171/1357 [01:39<11:32,  1.71it/s]\u001b[A\n","Iteration:  13% 172/1357 [01:39<11:31,  1.71it/s]\u001b[A\n","Iteration:  13% 173/1357 [01:40<11:27,  1.72it/s]\u001b[A\n","Iteration:  13% 174/1357 [01:41<11:27,  1.72it/s]\u001b[A\n","Iteration:  13% 175/1357 [01:41<11:27,  1.72it/s]\u001b[A\n","Iteration:  13% 176/1357 [01:42<11:28,  1.71it/s]\u001b[A\n","Iteration:  13% 177/1357 [01:42<11:27,  1.72it/s]\u001b[A\n","Iteration:  13% 178/1357 [01:43<11:27,  1.71it/s]\u001b[A\n","Iteration:  13% 179/1357 [01:43<11:25,  1.72it/s]\u001b[A\n","Iteration:  13% 180/1357 [01:44<11:24,  1.72it/s]\u001b[A\n","Iteration:  13% 181/1357 [01:45<11:24,  1.72it/s]\u001b[A\n","Iteration:  13% 182/1357 [01:45<11:26,  1.71it/s]\u001b[A\n","Iteration:  13% 183/1357 [01:46<11:24,  1.72it/s]\u001b[A\n","Iteration:  14% 184/1357 [01:46<11:25,  1.71it/s]\u001b[A\n","Iteration:  14% 185/1357 [01:47<11:22,  1.72it/s]\u001b[A\n","Iteration:  14% 186/1357 [01:48<11:23,  1.71it/s]\u001b[A\n","Iteration:  14% 187/1357 [01:48<11:20,  1.72it/s]\u001b[A\n","Iteration:  14% 188/1357 [01:49<11:18,  1.72it/s]\u001b[A\n","Iteration:  14% 189/1357 [01:49<11:19,  1.72it/s]\u001b[A\n","Iteration:  14% 190/1357 [01:50<11:17,  1.72it/s]\u001b[A\n","Iteration:  14% 191/1357 [01:50<11:16,  1.72it/s]\u001b[A\n","Iteration:  14% 192/1357 [01:51<11:17,  1.72it/s]\u001b[A\n","Iteration:  14% 193/1357 [01:52<11:19,  1.71it/s]\u001b[A\n","Iteration:  14% 194/1357 [01:52<11:15,  1.72it/s]\u001b[A\n","Iteration:  14% 195/1357 [01:53<11:12,  1.73it/s]\u001b[A\n","Iteration:  14% 196/1357 [01:53<11:14,  1.72it/s]\u001b[A\n","Iteration:  15% 197/1357 [01:54<11:15,  1.72it/s]\u001b[A\n","Iteration:  15% 198/1357 [01:55<11:13,  1.72it/s]\u001b[A\n","Iteration:  15% 199/1357 [01:55<11:13,  1.72it/s]\u001b[A\n","Iteration:  15% 200/1357 [01:56<11:11,  1.72it/s]\u001b[A\n","Iteration:  15% 201/1357 [01:56<11:08,  1.73it/s]\u001b[A\n","Iteration:  15% 202/1357 [01:57<11:11,  1.72it/s]\u001b[A\n","Iteration:  15% 203/1357 [01:57<11:13,  1.71it/s]\u001b[A\n","Iteration:  15% 204/1357 [01:58<11:13,  1.71it/s]\u001b[A\n","Iteration:  15% 205/1357 [01:59<11:11,  1.72it/s]\u001b[A\n","Iteration:  15% 206/1357 [01:59<11:09,  1.72it/s]\u001b[A\n","Iteration:  15% 207/1357 [02:00<11:08,  1.72it/s]\u001b[A\n","Iteration:  15% 208/1357 [02:00<11:08,  1.72it/s]\u001b[A\n","Iteration:  15% 209/1357 [02:01<11:08,  1.72it/s]\u001b[A\n","Iteration:  15% 210/1357 [02:01<11:07,  1.72it/s]\u001b[A\n","Iteration:  16% 211/1357 [02:02<11:09,  1.71it/s]\u001b[A\n","Iteration:  16% 212/1357 [02:03<11:09,  1.71it/s]\u001b[A\n","Iteration:  16% 213/1357 [02:03<11:07,  1.71it/s]\u001b[A\n","Iteration:  16% 214/1357 [02:04<11:06,  1.71it/s]\u001b[A\n","Iteration:  16% 215/1357 [02:04<11:03,  1.72it/s]\u001b[A\n","Iteration:  16% 216/1357 [02:05<11:01,  1.73it/s]\u001b[A\n","Iteration:  16% 217/1357 [02:06<11:02,  1.72it/s]\u001b[A\n","Iteration:  16% 218/1357 [02:06<11:06,  1.71it/s]\u001b[A\n","Iteration:  16% 219/1357 [02:07<11:03,  1.72it/s]\u001b[A\n","Iteration:  16% 220/1357 [02:07<11:01,  1.72it/s]\u001b[A\n","Iteration:  16% 221/1357 [02:08<11:00,  1.72it/s]\u001b[A\n","Iteration:  16% 222/1357 [02:08<10:58,  1.72it/s]\u001b[A\n","Iteration:  16% 223/1357 [02:09<10:59,  1.72it/s]\u001b[A\n","Iteration:  17% 224/1357 [02:10<10:57,  1.72it/s]\u001b[A\n","Iteration:  17% 225/1357 [02:10<10:57,  1.72it/s]\u001b[A\n","Iteration:  17% 226/1357 [02:11<10:57,  1.72it/s]\u001b[A\n","Iteration:  17% 227/1357 [02:11<10:56,  1.72it/s]\u001b[A\n","Iteration:  17% 228/1357 [02:12<10:54,  1.73it/s]\u001b[A\n","Iteration:  17% 229/1357 [02:13<10:52,  1.73it/s]\u001b[A\n","Iteration:  17% 230/1357 [02:13<10:58,  1.71it/s]\u001b[A\n","Iteration:  17% 231/1357 [02:14<10:58,  1.71it/s]\u001b[A\n","Iteration:  17% 232/1357 [02:14<10:56,  1.71it/s]\u001b[A\n","Iteration:  17% 233/1357 [02:15<10:55,  1.71it/s]\u001b[A\n","Iteration:  17% 234/1357 [02:15<10:52,  1.72it/s]\u001b[A\n","Iteration:  17% 235/1357 [02:16<10:54,  1.72it/s]\u001b[A\n","Iteration:  17% 236/1357 [02:17<10:53,  1.72it/s]\u001b[A\n","Iteration:  17% 237/1357 [02:17<10:53,  1.71it/s]\u001b[A\n","Iteration:  18% 238/1357 [02:18<10:51,  1.72it/s]\u001b[A\n","Iteration:  18% 239/1357 [02:18<10:50,  1.72it/s]\u001b[A\n","Iteration:  18% 240/1357 [02:19<10:49,  1.72it/s]\u001b[A\n","Iteration:  18% 241/1357 [02:20<10:49,  1.72it/s]\u001b[A\n","Iteration:  18% 242/1357 [02:20<10:48,  1.72it/s]\u001b[A\n","Iteration:  18% 243/1357 [02:21<10:50,  1.71it/s]\u001b[A\n","Iteration:  18% 244/1357 [02:21<10:48,  1.72it/s]\u001b[A\n","Iteration:  18% 245/1357 [02:22<10:46,  1.72it/s]\u001b[A\n","Iteration:  18% 246/1357 [02:22<10:49,  1.71it/s]\u001b[A\n","Iteration:  18% 247/1357 [02:23<10:47,  1.72it/s]\u001b[A\n","Iteration:  18% 248/1357 [02:24<10:47,  1.71it/s]\u001b[A\n","Iteration:  18% 249/1357 [02:24<10:43,  1.72it/s]\u001b[A\n","Iteration:  18% 250/1357 [02:25<10:40,  1.73it/s]\u001b[A\n","Iteration:  18% 251/1357 [02:25<10:41,  1.72it/s]\u001b[A\n","Iteration:  19% 252/1357 [02:26<10:43,  1.72it/s]\u001b[A\n","Iteration:  19% 253/1357 [02:27<10:41,  1.72it/s]\u001b[A\n","Iteration:  19% 254/1357 [02:27<10:41,  1.72it/s]\u001b[A\n","Iteration:  19% 255/1357 [02:28<10:42,  1.72it/s]\u001b[A\n","Iteration:  19% 256/1357 [02:28<10:38,  1.72it/s]\u001b[A\n","Iteration:  19% 257/1357 [02:29<10:37,  1.73it/s]\u001b[A\n","Iteration:  19% 258/1357 [02:29<10:37,  1.72it/s]\u001b[A\n","Iteration:  19% 259/1357 [02:30<10:37,  1.72it/s]\u001b[A\n","Iteration:  19% 260/1357 [02:31<10:36,  1.72it/s]\u001b[A\n","Iteration:  19% 261/1357 [02:31<10:36,  1.72it/s]\u001b[A\n","Iteration:  19% 262/1357 [02:32<10:35,  1.72it/s]\u001b[A\n","Iteration:  19% 263/1357 [02:32<10:31,  1.73it/s]\u001b[A\n","Iteration:  19% 264/1357 [02:33<10:32,  1.73it/s]\u001b[A\n","Iteration:  20% 265/1357 [02:33<10:34,  1.72it/s]\u001b[A\n","Iteration:  20% 266/1357 [02:34<10:33,  1.72it/s]\u001b[A\n","Iteration:  20% 267/1357 [02:35<10:34,  1.72it/s]\u001b[A\n","Iteration:  20% 268/1357 [02:35<10:32,  1.72it/s]\u001b[A\n","Iteration:  20% 269/1357 [02:36<10:31,  1.72it/s]\u001b[A\n","Iteration:  20% 270/1357 [02:36<10:32,  1.72it/s]\u001b[A\n","Iteration:  20% 271/1357 [02:37<10:34,  1.71it/s]\u001b[A\n","Iteration:  20% 272/1357 [02:38<10:32,  1.72it/s]\u001b[A\n","Iteration:  20% 273/1357 [02:38<10:30,  1.72it/s]\u001b[A\n","Iteration:  20% 274/1357 [02:39<10:29,  1.72it/s]\u001b[A\n","Iteration:  20% 275/1357 [02:39<10:27,  1.72it/s]\u001b[A\n","Iteration:  20% 276/1357 [02:40<10:27,  1.72it/s]\u001b[A\n","Iteration:  20% 277/1357 [02:40<10:24,  1.73it/s]\u001b[A\n","Iteration:  20% 278/1357 [02:41<10:22,  1.73it/s]\u001b[A\n","Iteration:  21% 279/1357 [02:42<10:25,  1.72it/s]\u001b[A\n","Iteration:  21% 280/1357 [02:42<10:27,  1.72it/s]\u001b[A\n","Iteration:  21% 281/1357 [02:43<10:25,  1.72it/s]\u001b[A\n","Iteration:  21% 282/1357 [02:43<10:24,  1.72it/s]\u001b[A\n","Iteration:  21% 283/1357 [02:44<10:28,  1.71it/s]\u001b[A\n","Iteration:  21% 284/1357 [02:45<10:23,  1.72it/s]\u001b[A\n","Iteration:  21% 285/1357 [02:45<10:24,  1.72it/s]\u001b[A\n","Iteration:  21% 286/1357 [02:46<10:22,  1.72it/s]\u001b[A\n","Iteration:  21% 287/1357 [02:46<10:21,  1.72it/s]\u001b[A\n","Iteration:  21% 288/1357 [02:47<10:20,  1.72it/s]\u001b[A\n","Iteration:  21% 289/1357 [02:47<10:21,  1.72it/s]\u001b[A\n","Iteration:  21% 290/1357 [02:48<10:19,  1.72it/s]\u001b[A\n","Iteration:  21% 291/1357 [02:49<10:17,  1.73it/s]\u001b[A\n","Iteration:  22% 292/1357 [02:49<10:19,  1.72it/s]\u001b[A\n","Iteration:  22% 293/1357 [02:50<10:18,  1.72it/s]\u001b[A\n","Iteration:  22% 294/1357 [02:50<10:20,  1.71it/s]\u001b[A\n","Iteration:  22% 295/1357 [02:51<10:20,  1.71it/s]\u001b[A\n","Iteration:  22% 296/1357 [02:52<10:17,  1.72it/s]\u001b[A\n","Iteration:  22% 297/1357 [02:52<10:17,  1.72it/s]\u001b[A\n","Iteration:  22% 298/1357 [02:53<10:15,  1.72it/s]\u001b[A\n","Iteration:  22% 299/1357 [02:53<10:16,  1.72it/s]\u001b[A\n","Iteration:  22% 300/1357 [02:54<10:14,  1.72it/s]\u001b[A\n","Iteration:  22% 301/1357 [02:54<10:14,  1.72it/s]\u001b[A\n","Iteration:  22% 302/1357 [02:55<10:13,  1.72it/s]\u001b[A\n","Iteration:  22% 303/1357 [02:56<10:12,  1.72it/s]\u001b[A\n","Iteration:  22% 304/1357 [02:56<10:14,  1.71it/s]\u001b[A\n","Iteration:  22% 305/1357 [02:57<10:09,  1.73it/s]\u001b[A\n","Iteration:  23% 306/1357 [02:57<10:06,  1.73it/s]\u001b[A\n","Iteration:  23% 307/1357 [02:58<10:07,  1.73it/s]\u001b[A\n","Iteration:  23% 308/1357 [02:58<10:09,  1.72it/s]\u001b[A\n","Iteration:  23% 309/1357 [02:59<10:08,  1.72it/s]\u001b[A\n","Iteration:  23% 310/1357 [03:00<10:07,  1.72it/s]\u001b[A\n","Iteration:  23% 311/1357 [03:00<10:05,  1.73it/s]\u001b[A\n","Iteration:  23% 312/1357 [03:01<10:06,  1.72it/s]\u001b[A\n","Iteration:  23% 313/1357 [03:01<10:05,  1.72it/s]\u001b[A\n","Iteration:  23% 314/1357 [03:02<10:05,  1.72it/s]\u001b[A\n","Iteration:  23% 315/1357 [03:03<10:04,  1.72it/s]\u001b[A\n","Iteration:  23% 316/1357 [03:03<10:04,  1.72it/s]\u001b[A\n","Iteration:  23% 317/1357 [03:04<10:04,  1.72it/s]\u001b[A\n","Iteration:  23% 318/1357 [03:04<10:01,  1.73it/s]\u001b[A\n","Iteration:  24% 319/1357 [03:05<10:00,  1.73it/s]\u001b[A\n","Iteration:  24% 320/1357 [03:05<10:01,  1.72it/s]\u001b[A\n","Iteration:  24% 321/1357 [03:06<10:01,  1.72it/s]\u001b[A\n","Iteration:  24% 322/1357 [03:07<10:00,  1.72it/s]\u001b[A\n","Iteration:  24% 323/1357 [03:07<10:00,  1.72it/s]\u001b[A\n","Iteration:  24% 324/1357 [03:08<09:58,  1.73it/s]\u001b[A\n","Iteration:  24% 325/1357 [03:08<09:58,  1.72it/s]\u001b[A\n","Iteration:  24% 326/1357 [03:09<09:59,  1.72it/s]\u001b[A\n","Iteration:  24% 327/1357 [03:10<09:59,  1.72it/s]\u001b[A\n","Iteration:  24% 328/1357 [03:10<09:57,  1.72it/s]\u001b[A\n","Iteration:  24% 329/1357 [03:11<09:59,  1.71it/s]\u001b[A\n","Iteration:  24% 330/1357 [03:11<09:57,  1.72it/s]\u001b[A\n","Iteration:  24% 331/1357 [03:12<09:56,  1.72it/s]\u001b[A\n","Iteration:  24% 332/1357 [03:12<09:57,  1.72it/s]\u001b[A\n","Iteration:  25% 333/1357 [03:13<09:54,  1.72it/s]\u001b[A\n","Iteration:  25% 334/1357 [03:14<09:51,  1.73it/s]\u001b[A\n","Iteration:  25% 335/1357 [03:14<09:52,  1.73it/s]\u001b[A\n","Iteration:  25% 336/1357 [03:15<09:52,  1.72it/s]\u001b[A\n","Iteration:  25% 337/1357 [03:15<09:51,  1.72it/s]\u001b[A\n","Iteration:  25% 338/1357 [03:16<09:50,  1.73it/s]\u001b[A\n","Iteration:  25% 339/1357 [03:16<09:50,  1.72it/s]\u001b[A\n","Iteration:  25% 340/1357 [03:17<09:49,  1.73it/s]\u001b[A\n","Iteration:  25% 341/1357 [03:18<09:49,  1.72it/s]\u001b[A\n","Iteration:  25% 342/1357 [03:18<09:49,  1.72it/s]\u001b[A\n","Iteration:  25% 343/1357 [03:19<09:48,  1.72it/s]\u001b[A\n","Iteration:  25% 344/1357 [03:19<09:47,  1.72it/s]\u001b[A\n","Iteration:  25% 345/1357 [03:20<09:48,  1.72it/s]\u001b[A\n","Iteration:  25% 346/1357 [03:21<09:44,  1.73it/s]\u001b[A\n","Iteration:  26% 347/1357 [03:21<09:43,  1.73it/s]\u001b[A\n","Iteration:  26% 348/1357 [03:22<09:45,  1.72it/s]\u001b[A\n","Iteration:  26% 349/1357 [03:22<09:45,  1.72it/s]\u001b[A\n","Iteration:  26% 350/1357 [03:23<09:45,  1.72it/s]\u001b[A\n","Iteration:  26% 351/1357 [03:23<09:45,  1.72it/s]\u001b[A\n","Iteration:  26% 352/1357 [03:24<09:44,  1.72it/s]\u001b[A\n","Iteration:  26% 353/1357 [03:25<09:40,  1.73it/s]\u001b[A\n","Iteration:  26% 354/1357 [03:25<09:41,  1.72it/s]\u001b[A\n","Iteration:  26% 355/1357 [03:26<09:43,  1.72it/s]\u001b[A\n","Iteration:  26% 356/1357 [03:26<09:41,  1.72it/s]\u001b[A\n","Iteration:  26% 357/1357 [03:27<09:40,  1.72it/s]\u001b[A\n","Iteration:  26% 358/1357 [03:28<09:41,  1.72it/s]\u001b[A\n","Iteration:  26% 359/1357 [03:28<09:40,  1.72it/s]\u001b[A\n","Iteration:  27% 360/1357 [03:29<09:40,  1.72it/s]\u001b[A\n","Iteration:  27% 361/1357 [03:29<09:39,  1.72it/s]\u001b[A\n","Iteration:  27% 362/1357 [03:30<09:40,  1.71it/s]\u001b[A\n","Iteration:  27% 363/1357 [03:30<09:39,  1.71it/s]\u001b[A\n","Iteration:  27% 364/1357 [03:31<09:39,  1.71it/s]\u001b[A\n","Iteration:  27% 365/1357 [03:32<09:38,  1.71it/s]\u001b[A\n","Iteration:  27% 366/1357 [03:32<09:39,  1.71it/s]\u001b[A\n","Iteration:  27% 367/1357 [03:33<09:36,  1.72it/s]\u001b[A\n","Iteration:  27% 368/1357 [03:33<09:33,  1.73it/s]\u001b[A\n","Iteration:  27% 369/1357 [03:34<09:33,  1.72it/s]\u001b[A\n","Iteration:  27% 370/1357 [03:34<09:33,  1.72it/s]\u001b[A\n","Iteration:  27% 371/1357 [03:35<09:32,  1.72it/s]\u001b[A\n","Iteration:  27% 372/1357 [03:36<09:33,  1.72it/s]\u001b[A\n","Iteration:  27% 373/1357 [03:36<09:34,  1.71it/s]\u001b[A\n","Iteration:  28% 374/1357 [03:37<09:30,  1.72it/s]\u001b[A\n","Iteration:  28% 375/1357 [03:37<09:28,  1.73it/s]\u001b[A\n","Iteration:  28% 376/1357 [03:38<09:28,  1.72it/s]\u001b[A\n","Iteration:  28% 377/1357 [03:39<09:29,  1.72it/s]\u001b[A\n","Iteration:  28% 378/1357 [03:39<09:28,  1.72it/s]\u001b[A\n","Iteration:  28% 379/1357 [03:40<09:29,  1.72it/s]\u001b[A\n","Iteration:  28% 380/1357 [03:40<09:26,  1.72it/s]\u001b[A\n","Iteration:  28% 381/1357 [03:41<09:25,  1.73it/s]\u001b[A\n","Iteration:  28% 382/1357 [03:41<09:24,  1.73it/s]\u001b[A\n","Iteration:  28% 383/1357 [03:42<09:27,  1.72it/s]\u001b[A\n","Iteration:  28% 384/1357 [03:43<09:25,  1.72it/s]\u001b[A\n","Iteration:  28% 385/1357 [03:43<09:24,  1.72it/s]\u001b[A\n","Iteration:  28% 386/1357 [03:44<09:24,  1.72it/s]\u001b[A\n","Iteration:  29% 387/1357 [03:44<09:22,  1.72it/s]\u001b[A\n","Iteration:  29% 388/1357 [03:45<09:26,  1.71it/s]\u001b[A\n","Iteration:  29% 389/1357 [03:46<09:25,  1.71it/s]\u001b[A\n","Iteration:  29% 390/1357 [03:46<09:25,  1.71it/s]\u001b[A\n","Iteration:  29% 391/1357 [03:47<09:24,  1.71it/s]\u001b[A\n","Iteration:  29% 392/1357 [03:47<09:23,  1.71it/s]\u001b[A\n","Iteration:  29% 393/1357 [03:48<09:20,  1.72it/s]\u001b[A\n","Iteration:  29% 394/1357 [03:48<09:19,  1.72it/s]\u001b[A\n","Iteration:  29% 395/1357 [03:49<09:18,  1.72it/s]\u001b[A\n","Iteration:  29% 396/1357 [03:50<09:16,  1.73it/s]\u001b[A\n","Iteration:  29% 397/1357 [03:50<09:14,  1.73it/s]\u001b[A\n","Iteration:  29% 398/1357 [03:51<09:16,  1.72it/s]\u001b[A\n","Iteration:  29% 399/1357 [03:51<09:15,  1.73it/s]\u001b[A\n","Iteration:  29% 400/1357 [03:52<09:15,  1.72it/s]\u001b[A\n","Iteration:  30% 401/1357 [03:53<09:16,  1.72it/s]\u001b[A\n","Iteration:  30% 402/1357 [03:53<09:16,  1.72it/s]\u001b[A\n","Iteration:  30% 403/1357 [03:54<09:16,  1.71it/s]\u001b[A\n","Iteration:  30% 404/1357 [03:54<09:15,  1.72it/s]\u001b[A\n","Iteration:  30% 405/1357 [03:55<09:14,  1.72it/s]\u001b[A\n","Iteration:  30% 406/1357 [03:55<09:13,  1.72it/s]\u001b[A\n","Iteration:  30% 407/1357 [03:56<09:11,  1.72it/s]\u001b[A\n","Iteration:  30% 408/1357 [03:57<09:09,  1.73it/s]\u001b[A\n","Iteration:  30% 409/1357 [03:57<09:08,  1.73it/s]\u001b[A\n","Iteration:  30% 410/1357 [03:58<09:09,  1.72it/s]\u001b[A\n","Iteration:  30% 411/1357 [03:58<09:11,  1.71it/s]\u001b[A\n","Iteration:  30% 412/1357 [03:59<09:11,  1.71it/s]\u001b[A\n","Iteration:  30% 413/1357 [03:59<09:11,  1.71it/s]\u001b[A\n","Iteration:  31% 414/1357 [04:00<09:08,  1.72it/s]\u001b[A\n","Iteration:  31% 415/1357 [04:01<09:07,  1.72it/s]\u001b[A\n","Iteration:  31% 416/1357 [04:01<09:07,  1.72it/s]\u001b[A\n","Iteration:  31% 417/1357 [04:02<09:07,  1.72it/s]\u001b[A\n","Iteration:  31% 418/1357 [04:02<09:06,  1.72it/s]\u001b[A\n","Iteration:  31% 419/1357 [04:03<09:08,  1.71it/s]\u001b[A\n","Iteration:  31% 420/1357 [04:04<09:06,  1.72it/s]\u001b[A\n","Iteration:  31% 421/1357 [04:04<09:05,  1.72it/s]\u001b[A\n","Iteration:  31% 422/1357 [04:05<09:04,  1.72it/s]\u001b[A\n","Iteration:  31% 423/1357 [04:05<09:01,  1.73it/s]\u001b[A\n","Iteration:  31% 424/1357 [04:06<08:59,  1.73it/s]\u001b[A\n","Iteration:  31% 425/1357 [04:06<09:00,  1.73it/s]\u001b[A\n","Iteration:  31% 426/1357 [04:07<09:04,  1.71it/s]\u001b[A\n","Iteration:  31% 427/1357 [04:08<09:02,  1.72it/s]\u001b[A\n","Iteration:  32% 428/1357 [04:08<09:01,  1.72it/s]\u001b[A\n","Iteration:  32% 429/1357 [04:09<08:58,  1.72it/s]\u001b[A\n","Iteration:  32% 430/1357 [04:09<08:56,  1.73it/s]\u001b[A\n","Iteration:  32% 431/1357 [04:10<08:56,  1.73it/s]\u001b[A\n","Iteration:  32% 432/1357 [04:11<08:56,  1.72it/s]\u001b[A\n","Iteration:  32% 433/1357 [04:11<08:56,  1.72it/s]\u001b[A\n","Iteration:  32% 434/1357 [04:12<08:55,  1.72it/s]\u001b[A\n","Iteration:  32% 435/1357 [04:12<08:56,  1.72it/s]\u001b[A\n","Iteration:  32% 436/1357 [04:13<08:52,  1.73it/s]\u001b[A\n","Iteration:  32% 437/1357 [04:13<08:49,  1.74it/s]\u001b[A\n","Iteration:  32% 438/1357 [04:14<08:51,  1.73it/s]\u001b[A\n","Iteration:  32% 439/1357 [04:15<08:52,  1.72it/s]\u001b[A\n","Iteration:  32% 440/1357 [04:15<08:53,  1.72it/s]\u001b[A\n","Iteration:  32% 441/1357 [04:16<08:54,  1.71it/s]\u001b[A\n","Iteration:  33% 442/1357 [04:16<08:51,  1.72it/s]\u001b[A\n","Iteration:  33% 443/1357 [04:17<08:48,  1.73it/s]\u001b[A\n","Iteration:  33% 444/1357 [04:17<08:50,  1.72it/s]\u001b[A\n","Iteration:  33% 445/1357 [04:18<08:52,  1.71it/s]\u001b[A\n","Iteration:  33% 446/1357 [04:19<08:50,  1.72it/s]\u001b[A\n","Iteration:  33% 447/1357 [04:19<08:49,  1.72it/s]\u001b[A\n","Iteration:  33% 448/1357 [04:20<08:47,  1.72it/s]\u001b[A\n","Iteration:  33% 449/1357 [04:20<08:46,  1.72it/s]\u001b[A\n","Iteration:  33% 450/1357 [04:21<08:47,  1.72it/s]\u001b[A\n","Iteration:  33% 451/1357 [04:22<08:46,  1.72it/s]\u001b[A\n","Iteration:  33% 452/1357 [04:22<08:43,  1.73it/s]\u001b[A\n","Iteration:  33% 453/1357 [04:23<08:42,  1.73it/s]\u001b[A\n","Iteration:  33% 454/1357 [04:23<08:44,  1.72it/s]\u001b[A\n","Iteration:  34% 455/1357 [04:24<08:43,  1.72it/s]\u001b[A\n","Iteration:  34% 456/1357 [04:24<08:42,  1.72it/s]\u001b[A\n","Iteration:  34% 457/1357 [04:25<08:42,  1.72it/s]\u001b[A\n","Iteration:  34% 458/1357 [04:26<08:39,  1.73it/s]\u001b[A\n","Iteration:  34% 459/1357 [04:26<08:39,  1.73it/s]\u001b[A\n","Iteration:  34% 460/1357 [04:27<08:39,  1.73it/s]\u001b[A\n","Iteration:  34% 461/1357 [04:27<08:40,  1.72it/s]\u001b[A\n","Iteration:  34% 462/1357 [04:28<08:40,  1.72it/s]\u001b[A\n","Iteration:  34% 463/1357 [04:29<08:40,  1.72it/s]\u001b[A\n","Iteration:  34% 464/1357 [04:29<08:38,  1.72it/s]\u001b[A\n","Iteration:  34% 465/1357 [04:30<08:36,  1.73it/s]\u001b[A\n","Iteration:  34% 466/1357 [04:30<08:36,  1.72it/s]\u001b[A\n","Iteration:  34% 467/1357 [04:31<08:38,  1.72it/s]\u001b[A\n","Iteration:  34% 468/1357 [04:31<08:36,  1.72it/s]\u001b[A\n","Iteration:  35% 469/1357 [04:32<08:36,  1.72it/s]\u001b[A\n","Iteration:  35% 470/1357 [04:33<08:36,  1.72it/s]\u001b[A\n","Iteration:  35% 471/1357 [04:33<08:33,  1.73it/s]\u001b[A\n","Iteration:  35% 472/1357 [04:34<08:34,  1.72it/s]\u001b[A\n","Iteration:  35% 473/1357 [04:34<08:34,  1.72it/s]\u001b[A\n","Iteration:  35% 474/1357 [04:35<08:33,  1.72it/s]\u001b[A\n","Iteration:  35% 475/1357 [04:36<08:32,  1.72it/s]\u001b[A\n","Iteration:  35% 476/1357 [04:36<08:32,  1.72it/s]\u001b[A\n","Iteration:  35% 477/1357 [04:37<08:32,  1.72it/s]\u001b[A\n","Iteration:  35% 478/1357 [04:37<08:31,  1.72it/s]\u001b[A\n","Iteration:  35% 479/1357 [04:38<08:31,  1.72it/s]\u001b[A\n","Iteration:  35% 480/1357 [04:38<08:31,  1.71it/s]\u001b[A\n","Iteration:  35% 481/1357 [04:39<08:30,  1.71it/s]\u001b[A\n","Iteration:  36% 482/1357 [04:40<08:32,  1.71it/s]\u001b[A\n","Iteration:  36% 483/1357 [04:40<08:29,  1.72it/s]\u001b[A\n","Iteration:  36% 484/1357 [04:41<08:28,  1.72it/s]\u001b[A\n","Iteration:  36% 485/1357 [04:41<08:26,  1.72it/s]\u001b[A\n","Iteration:  36% 486/1357 [04:42<08:24,  1.73it/s]\u001b[A\n","Iteration:  36% 487/1357 [04:42<08:23,  1.73it/s]\u001b[A\n","Iteration:  36% 488/1357 [04:43<08:23,  1.72it/s]\u001b[A\n","Iteration:  36% 489/1357 [04:44<08:22,  1.73it/s]\u001b[A\n","Iteration:  36% 490/1357 [04:44<08:22,  1.73it/s]\u001b[A\n","Iteration:  36% 491/1357 [04:45<08:23,  1.72it/s]\u001b[A\n","Iteration:  36% 492/1357 [04:45<08:22,  1.72it/s]\u001b[A\n","Iteration:  36% 493/1357 [04:46<08:20,  1.73it/s]\u001b[A\n","Iteration:  36% 494/1357 [04:47<08:21,  1.72it/s]\u001b[A\n","Iteration:  36% 495/1357 [04:47<08:22,  1.72it/s]\u001b[A\n","Iteration:  37% 496/1357 [04:48<08:21,  1.72it/s]\u001b[A\n","Iteration:  37% 497/1357 [04:48<08:22,  1.71it/s]\u001b[A\n","Iteration:  37% 498/1357 [04:49<08:19,  1.72it/s]\u001b[A\n","Iteration:  37% 499/1357 [04:49<08:17,  1.73it/s]\u001b[A\n","Iteration:  37% 500/1357 [04:50<08:17,  1.72it/s]\u001b[A\n","Iteration:  37% 501/1357 [04:51<08:18,  1.72it/s]\u001b[A\n","Iteration:  37% 502/1357 [04:51<08:16,  1.72it/s]\u001b[A\n","Iteration:  37% 503/1357 [04:52<08:15,  1.72it/s]\u001b[A\n","Iteration:  37% 504/1357 [04:52<08:18,  1.71it/s]\u001b[A\n","Iteration:  37% 505/1357 [04:53<08:15,  1.72it/s]\u001b[A\n","Iteration:  37% 506/1357 [04:54<08:15,  1.72it/s]\n","Epoch:  90% 9/10 [2:10:23<14:29, 869.33s/it]\n","Traceback (most recent call last):\n","  File \"run_goemotions.py\", line 392, in <module>\n","    main(cli_args)\n","  File \"run_goemotions.py\", line 350, in main\n","    global_step, tr_loss = train(args, model, tokenizer, train_dataset, dev_dataset, test_dataset)\n","  File \"run_goemotions.py\", line 127, in train\n","    loss.backward()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 195, in backward\n","    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 99, in backward\n","    allow_unreachable=True)  # allow_unreachable flag\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["!rm -rf data/original/cached_goemotions_checkpoint-2000_50_train"],"metadata":{"id":"34Ly5EZzZO6R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python3 run_goemotions.py --taxonomy original-roberta ## test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q_0tJXLXLbqF","executionInfo":{"status":"ok","timestamp":1639700031759,"user_tz":300,"elapsed":596591,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"}},"outputId":"3f5ce25f-ff73-424b-9d15-2b7ddcf03706"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["12/17/2021 00:04:03 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-9000/config.json\n","12/17/2021 00:04:03 - INFO - transformers.configuration_utils -   Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMultiLabelClassification\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 2,\n","  \"finetuning_task\": \"goemotions\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"admiration\",\n","    \"1\": \"amusement\",\n","    \"10\": \"disapproval\",\n","    \"11\": \"disgust\",\n","    \"12\": \"embarrassment\",\n","    \"13\": \"excitement\",\n","    \"14\": \"fear\",\n","    \"15\": \"gratitude\",\n","    \"16\": \"grief\",\n","    \"17\": \"joy\",\n","    \"18\": \"love\",\n","    \"19\": \"nervousness\",\n","    \"2\": \"anger\",\n","    \"20\": \"optimism\",\n","    \"21\": \"pride\",\n","    \"22\": \"realization\",\n","    \"23\": \"relief\",\n","    \"24\": \"remorse\",\n","    \"25\": \"sadness\",\n","    \"26\": \"surprise\",\n","    \"27\": \"neutral\",\n","    \"3\": \"annoyance\",\n","    \"4\": \"approval\",\n","    \"5\": \"caring\",\n","    \"6\": \"confusion\",\n","    \"7\": \"curiosity\",\n","    \"8\": \"desire\",\n","    \"9\": \"disappointment\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"admiration\": 0,\n","    \"amusement\": 1,\n","    \"anger\": 2,\n","    \"annoyance\": 3,\n","    \"approval\": 4,\n","    \"caring\": 5,\n","    \"confusion\": 6,\n","    \"curiosity\": 7,\n","    \"desire\": 8,\n","    \"disappointment\": 9,\n","    \"disapproval\": 10,\n","    \"disgust\": 11,\n","    \"embarrassment\": 12,\n","    \"excitement\": 13,\n","    \"fear\": 14,\n","    \"gratitude\": 15,\n","    \"grief\": 16,\n","    \"joy\": 17,\n","    \"love\": 18,\n","    \"nervousness\": 19,\n","    \"neutral\": 27,\n","    \"optimism\": 20,\n","    \"pride\": 21,\n","    \"realization\": 22,\n","    \"relief\": 23,\n","    \"remorse\": 24,\n","    \"sadness\": 25,\n","    \"surprise\": 26\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","helllo i am done\n","12/17/2021 00:04:03 - INFO - transformers.modeling_utils -   loading weights file /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-9000/pytorch_model.bin\n","12/17/2021 00:04:13 - INFO - transformers.tokenization_utils -   Model name '/content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-9000/' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming '/content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-9000/' is a path, a model identifier, or url to a directory containing tokenizer files.\n","12/17/2021 00:04:13 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-9000/added_tokens.json. We won't load it.\n","12/17/2021 00:04:13 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-9000/vocab.json\n","12/17/2021 00:04:13 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-9000/merges.txt\n","12/17/2021 00:04:13 - INFO - transformers.tokenization_utils -   loading file None\n","12/17/2021 00:04:13 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-9000/special_tokens_map.json\n","12/17/2021 00:04:13 - INFO - transformers.tokenization_utils -   loading file /content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-9000/tokenizer_config.json\n","12/17/2021 00:04:16 - INFO - data_loader -   Creating features from dataset file at data/original\n","12/17/2021 00:04:16 - INFO - data_loader -   LOOKING AT data/original/train.tsv\n","12/17/2021 00:04:16 - INFO - data_loader -   My favourite food is anything I didn't have to cook myself.\t27\teebbqej\n","12/17/2021 00:04:16 - INFO - data_loader -   What’s that extra B for?\t6,7\tedo4lm1\n","12/17/2021 00:04:16 - INFO - data_loader -   Quick... there's a boot somewhere that you haven't licked today yet!\t27\tedoblwt\n","12/17/2021 00:04:16 - INFO - data_loader -   I'm so gay I can't even drive straight - a bumper sticker older than most redditors\t19\tedfval6\n","12/17/2021 00:04:16 - INFO - data_loader -   I don't know\t27\ted98qh1\n","12/17/2021 00:04:16 - INFO - data_loader -   Broom him fast.\t27\tedket23\n","12/17/2021 00:04:16 - INFO - data_loader -   The balance above the base fee gets put somewhere else. Education, healthcare, etc. Voila, police aren't biased, people are proportionally fined. \t27\teepn62z\n","12/17/2021 00:04:16 - INFO - data_loader -   Hi [NAME], I love you, that is all. Can't wait to see you in Worcester in February!\t17,18\tee8wndy\n","12/17/2021 00:04:16 - INFO - data_loader -   I mean it sucks but that man looks deaded\t11,22\ted917ws\n","12/17/2021 00:04:26 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:26 - INFO - data_loader -   guid: train-0\n","12/17/2021 00:04:26 - INFO - data_loader -   sentence: My favourite food is anything I didn't have to cook myself.\n","12/17/2021 00:04:26 - INFO - data_loader -   tokens: My Ġfavourite Ġfood Ġis Ġanything ĠI Ġdidn 't Ġhave Ġto Ġcook Ġmyself .\n","12/17/2021 00:04:26 - INFO - data_loader -   input_ids: 0 1308 5548 689 16 932 38 399 75 33 7 7142 2185 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:26 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:26 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/17/2021 00:04:26 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:26 - INFO - data_loader -   guid: train-1\n","12/17/2021 00:04:26 - INFO - data_loader -   sentence: Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead\n","12/17/2021 00:04:26 - INFO - data_loader -   tokens: Now Ġif Ġhe Ġdoes Ġoff Ġhimself , Ġeveryone Ġwill Ġthink Ġhes Ġhaving Ġa Ġlaugh Ġscrew ing Ġwith Ġpeople Ġinstead Ġof Ġactually Ġdead\n","12/17/2021 00:04:26 - INFO - data_loader -   input_ids: 0 978 114 37 473 160 1003 6 961 40 206 36279 519 10 7923 21927 154 19 82 1386 9 888 1462 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:26 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:26 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/17/2021 00:04:26 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:26 - INFO - data_loader -   guid: train-2\n","12/17/2021 00:04:26 - INFO - data_loader -   sentence: WHY THE FUCK IS BAYLESS ISOING\n","12/17/2021 00:04:26 - INFO - data_loader -   tokens: WH Y ĠTHE ĠFUCK ĠIS ĠB AY LESS ĠISO ING\n","12/17/2021 00:04:26 - INFO - data_loader -   input_ids: 0 34912 1941 46997 3703 163 2547 43023 26553 1862 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:26 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:26 - INFO - data_loader -   label: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:26 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:26 - INFO - data_loader -   guid: train-3\n","12/17/2021 00:04:26 - INFO - data_loader -   sentence: To make her feel threatened\n","12/17/2021 00:04:26 - INFO - data_loader -   tokens: To Ġmake Ġher Ġfeel Ġthreatened\n","12/17/2021 00:04:26 - INFO - data_loader -   input_ids: 0 598 146 69 619 3711 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:26 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:26 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:26 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:26 - INFO - data_loader -   guid: train-4\n","12/17/2021 00:04:26 - INFO - data_loader -   sentence: Dirty Southern Wankers\n","12/17/2021 00:04:26 - INFO - data_loader -   tokens: D irty ĠSouthern ĠW ank ers\n","12/17/2021 00:04:26 - INFO - data_loader -   input_ids: 0 30375 2944 305 3153 268 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:26 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:26 - INFO - data_loader -   label: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:26 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:26 - INFO - data_loader -   guid: train-5\n","12/17/2021 00:04:26 - INFO - data_loader -   sentence: OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe PlAyOfFs! Dumbass Broncos fans circa December 2015.\n","12/17/2021 00:04:26 - INFO - data_loader -   tokens: O m G Ġp Ey To N Ġi Sn ' T Ġg O o D Ġe No U g H Ġt O Ġh El P Ġu S Ġi N Ġt He ĠPl Ay Of Fs ! ĠDumb ass ĠBroncos Ġfans Ġcirca ĠDecember Ġ2015 .\n","12/17/2021 00:04:26 - INFO - data_loader -   input_ids: 0 13292 534 181 43431 3972 487 939 37790 108 565 821 673 139 495 364 3084 791 571 725 326 673 1368 9682 510 1717 104 939 487 326 894 3037 41585 10643 34417 328 37098 2401 7609 841 33570 719 570 4 2 1 1 1 1 1\n","12/17/2021 00:04:26 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n","12/17/2021 00:04:26 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n","12/17/2021 00:04:26 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:26 - INFO - data_loader -   guid: train-6\n","12/17/2021 00:04:26 - INFO - data_loader -   sentence: Yes I heard abt the f bombs! That has to be why. Thanks for your reply:) until then hubby and I will anxiously wait 😝\n","12/17/2021 00:04:26 - INFO - data_loader -   tokens: Yes ĠI Ġheard Ġab t Ġthe Ġf Ġbombs ! ĠThat Ġhas Ġto Ġbe Ġwhy . ĠThanks Ġfor Ġyour Ġreply : ) Ġuntil Ġthen Ġhub by Ġand ĠI Ġwill Ġanx iously Ġwait ĠðŁĺ Ŀ\n","12/17/2021 00:04:26 - INFO - data_loader -   input_ids: 0 3216 38 1317 4091 90 5 856 10834 328 280 34 7 28 596 4 4557 13 110 10418 35 43 454 172 6756 1409 8 38 40 27442 9997 2067 17841 46 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:26 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:26 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:26 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:26 - INFO - data_loader -   guid: train-7\n","12/17/2021 00:04:26 - INFO - data_loader -   sentence: We need more boards and to create a bit more space for [NAME]. Then we’ll be good.\n","12/17/2021 00:04:26 - INFO - data_loader -   tokens: We Ġneed Ġmore Ġboards Ġand Ġto Ġcreate Ġa Ġbit Ġmore Ġspace Ġfor Ġ[ NAME ]. ĠThen Ġwe âĢ Ļ ll Ġbe Ġgood .\n","12/17/2021 00:04:26 - INFO - data_loader -   input_ids: 0 166 240 55 6904 8 7 1045 10 828 55 980 13 646 48307 8174 1892 52 17 27 890 28 205 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:26 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:26 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n","12/17/2021 00:04:26 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:26 - INFO - data_loader -   guid: train-8\n","12/17/2021 00:04:26 - INFO - data_loader -   sentence: Damn youtube and outrage drama is super lucrative for reddit\n","12/17/2021 00:04:26 - INFO - data_loader -   tokens: Damn Ġyoutube Ġand Ġoutrage Ġdrama Ġis Ġsuper Ġlucrative Ġfor Ġreddit\n","12/17/2021 00:04:26 - INFO - data_loader -   input_ids: 0 41163 44736 8 10618 4149 16 2422 11874 13 44014 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:26 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:26 - INFO - data_loader -   label: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:26 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:26 - INFO - data_loader -   guid: train-9\n","12/17/2021 00:04:26 - INFO - data_loader -   sentence: It might be linked to the trust factor of your friend.\n","12/17/2021 00:04:26 - INFO - data_loader -   tokens: It Ġmight Ġbe Ġlinked Ġto Ġthe Ġtrust Ġfactor Ġof Ġyour Ġfriend .\n","12/17/2021 00:04:26 - INFO - data_loader -   input_ids: 0 85 429 28 3307 7 5 2416 3724 9 110 1441 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:26 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:26 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/17/2021 00:04:26 - INFO - data_loader -   Saving features into cached file data/original/cached_goemotions_checkpoint-9000_50_train\n","12/17/2021 00:04:30 - INFO - data_loader -   Creating features from dataset file at data/original\n","12/17/2021 00:04:30 - INFO - data_loader -   LOOKING AT data/original/dev.tsv\n","12/17/2021 00:04:30 - INFO - data_loader -   Is this in New Orleans?? I really feel like this is New Orleans.\t27\tedgurhb\n","12/17/2021 00:04:30 - INFO - data_loader -   [NAME] is vastly overrated. Much bette4 [RELIGION] delis in the outer Burroughs\t4\tedc0amo\n","12/17/2021 00:04:31 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:31 - INFO - data_loader -   guid: dev-0\n","12/17/2021 00:04:31 - INFO - data_loader -   sentence: Is this in New Orleans?? I really feel like this is New Orleans.\n","12/17/2021 00:04:31 - INFO - data_loader -   tokens: Is Ġthis Ġin ĠNew ĠOrleans ?? ĠI Ġreally Ġfeel Ġlike Ġthis Ġis ĠNew ĠOrleans .\n","12/17/2021 00:04:31 - INFO - data_loader -   input_ids: 0 1534 42 11 188 4942 28749 38 269 619 101 42 16 188 4942 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:31 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:31 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/17/2021 00:04:31 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:31 - INFO - data_loader -   guid: dev-1\n","12/17/2021 00:04:31 - INFO - data_loader -   sentence: You know the answer man, you are programmed to capture those codes they send you, don’t avoid them!\n","12/17/2021 00:04:31 - INFO - data_loader -   tokens: You Ġknow Ġthe Ġanswer Ġman , Ġyou Ġare Ġprogrammed Ġto Ġcapture Ġthose Ġcodes Ġthey Ġsend Ġyou , Ġdon âĢ Ļ t Ġavoid Ġthem !\n","12/17/2021 00:04:31 - INFO - data_loader -   input_ids: 0 370 216 5 1948 313 6 47 32 30825 7 5604 167 14284 51 2142 47 6 218 17 27 90 1877 106 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:31 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:31 - INFO - data_loader -   label: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/17/2021 00:04:31 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:31 - INFO - data_loader -   guid: dev-2\n","12/17/2021 00:04:31 - INFO - data_loader -   sentence: I've never been this sad in my life!\n","12/17/2021 00:04:31 - INFO - data_loader -   tokens: I 've Ġnever Ġbeen Ġthis Ġsad Ġin Ġmy Ġlife !\n","12/17/2021 00:04:31 - INFO - data_loader -   input_ids: 0 38 348 393 57 42 5074 11 127 301 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:31 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:31 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n","12/17/2021 00:04:31 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:31 - INFO - data_loader -   guid: dev-3\n","12/17/2021 00:04:31 - INFO - data_loader -   sentence: The economy is heavily controlled and subsidized by the government. In any case, I was poking at the lack of nuance in US politics today\n","12/17/2021 00:04:31 - INFO - data_loader -   tokens: The Ġeconomy Ġis Ġheavily Ġcontrolled Ġand Ġsubsidized Ġby Ġthe Ġgovernment . ĠIn Ġany Ġcase , ĠI Ġwas Ġpoking Ġat Ġthe Ġlack Ġof Ġnuance Ġin ĠUS Ġpolitics Ġtoday\n","12/17/2021 00:04:31 - INFO - data_loader -   input_ids: 0 20 866 16 4008 4875 8 28397 30 5 168 4 96 143 403 6 38 21 34552 23 5 1762 9 37784 11 382 2302 452 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:31 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:31 - INFO - data_loader -   label: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/17/2021 00:04:31 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:31 - INFO - data_loader -   guid: dev-4\n","12/17/2021 00:04:31 - INFO - data_loader -   sentence: He could have easily taken a real camera from a legitimate source and change the price in Word/Photoshop and then print it out.\n","12/17/2021 00:04:31 - INFO - data_loader -   tokens: He Ġcould Ġhave Ġeasily Ġtaken Ġa Ġreal Ġcamera Ġfrom Ġa Ġlegitimate Ġsource Ġand Ġchange Ġthe Ġprice Ġin ĠWord / Phot oshop Ġand Ġthen Ġprint Ġit Ġout .\n","12/17/2021 00:04:31 - INFO - data_loader -   input_ids: 0 91 115 33 2773 551 10 588 2280 31 10 8134 1300 8 464 5 425 11 15690 73 41612 46491 8 172 5780 24 66 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:31 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:31 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n","12/17/2021 00:04:31 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:31 - INFO - data_loader -   guid: dev-5\n","12/17/2021 00:04:31 - INFO - data_loader -   sentence: Thank you for your vote of confidence, but we statistically can't get to 10 wins.\n","12/17/2021 00:04:31 - INFO - data_loader -   tokens: Thank Ġyou Ġfor Ġyour Ġvote Ġof Ġconfidence , Ġbut Ġwe Ġstatistically Ġcan 't Ġget Ġto Ġ10 Ġwins .\n","12/17/2021 00:04:31 - INFO - data_loader -   input_ids: 0 3837 47 13 110 900 9 2123 6 53 52 27697 64 75 120 7 158 2693 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:31 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:31 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:31 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:31 - INFO - data_loader -   guid: dev-6\n","12/17/2021 00:04:31 - INFO - data_loader -   sentence: Wah Mum other people call me on my bullshit and I can't ban them , Go out side son.\n","12/17/2021 00:04:31 - INFO - data_loader -   tokens: W ah ĠMum Ġother Ġpeople Ġcall Ġme Ġon Ġmy Ġbullshit Ġand ĠI Ġcan 't Ġban Ġthem Ġ, ĠGo Ġout Ġside Ġson .\n","12/17/2021 00:04:31 - INFO - data_loader -   input_ids: 0 19478 20675 97 82 486 162 15 127 37568 8 38 64 75 2020 106 2156 2381 66 526 979 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:31 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:31 - INFO - data_loader -   label: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:31 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:31 - INFO - data_loader -   guid: dev-7\n","12/17/2021 00:04:31 - INFO - data_loader -   sentence: There it is!\n","12/17/2021 00:04:31 - INFO - data_loader -   tokens: There Ġit Ġis !\n","12/17/2021 00:04:31 - INFO - data_loader -   input_ids: 0 345 24 16 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:31 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:31 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/17/2021 00:04:31 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:31 - INFO - data_loader -   guid: dev-8\n","12/17/2021 00:04:31 - INFO - data_loader -   sentence: At least now [NAME] has more time to gain his confidence\n","12/17/2021 00:04:31 - INFO - data_loader -   tokens: At Ġleast Ġnow Ġ[ NAME ] Ġhas Ġmore Ġtime Ġto Ġgain Ġhis Ġconfidence\n","12/17/2021 00:04:31 - INFO - data_loader -   input_ids: 0 497 513 122 646 48307 742 34 55 86 7 2364 39 2123 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:31 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:31 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n","12/17/2021 00:04:31 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:31 - INFO - data_loader -   guid: dev-9\n","12/17/2021 00:04:31 - INFO - data_loader -   sentence: Good. We don't want more thrash liberal offspring in this world.\n","12/17/2021 00:04:31 - INFO - data_loader -   tokens: Good . ĠWe Ġdon 't Ġwant Ġmore Ġthr ash Ġliberal Ġoffspring Ġin Ġthis Ġworld .\n","12/17/2021 00:04:31 - INFO - data_loader -   input_ids: 0 2497 4 166 218 75 236 55 10161 1671 6176 28491 11 42 232 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:31 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:31 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:31 - INFO - data_loader -   Saving features into cached file data/original/cached_goemotions_checkpoint-9000_50_dev\n","12/17/2021 00:04:32 - INFO - data_loader -   Creating features from dataset file at data/original\n","12/17/2021 00:04:32 - INFO - data_loader -   LOOKING AT data/original/test.tsv\n","12/17/2021 00:04:32 - INFO - data_loader -   I’m really sorry about your situation :( Although I love the names Sapphira, Cirilla, and Scarlett!\t25\teecwqtt\n","12/17/2021 00:04:32 - INFO - data_loader -   Well I am a lady, so that would probably just freak them out. Oh, Reddit. Everyone is a man haha. \t1\teez3kgr\n","12/17/2021 00:04:33 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:33 - INFO - data_loader -   guid: test-0\n","12/17/2021 00:04:33 - INFO - data_loader -   sentence: I’m really sorry about your situation :( Although I love the names Sapphira, Cirilla, and Scarlett!\n","12/17/2021 00:04:33 - INFO - data_loader -   tokens: I âĢ Ļ m Ġreally Ġsorry Ġabout Ġyour Ġsituation Ġ:( ĠAlthough ĠI Ġlove Ġthe Ġnames ĠSapp h ira , ĠCir illa , Ġand ĠScarlett !\n","12/17/2021 00:04:33 - INFO - data_loader -   input_ids: 0 38 17 27 119 269 6661 59 110 1068 46225 2223 38 657 5 2523 37151 298 3578 6 24223 4699 6 8 27473 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:33 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:33 - INFO - data_loader -   guid: test-1\n","12/17/2021 00:04:33 - INFO - data_loader -   sentence: It's wonderful because it's awful. At not with.\n","12/17/2021 00:04:33 - INFO - data_loader -   tokens: It 's Ġwonderful Ġbecause Ġit 's Ġawful . ĠAt Ġnot Ġwith .\n","12/17/2021 00:04:33 - INFO - data_loader -   input_ids: 0 85 18 4613 142 24 18 11522 4 497 45 19 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:33 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   label: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:33 - INFO - data_loader -   guid: test-2\n","12/17/2021 00:04:33 - INFO - data_loader -   sentence: Kings fan here, good luck to you guys! Will be an interesting game to watch! \n","12/17/2021 00:04:33 - INFO - data_loader -   tokens: Kings Ġfan Ġhere , Ġgood Ġluck Ġto Ġyou Ġguys ! ĠWill Ġbe Ġan Ġinteresting Ġgame Ġto Ġwatch !\n","12/17/2021 00:04:33 - INFO - data_loader -   input_ids: 0 5414 2378 259 6 205 6620 7 47 1669 328 2290 28 41 2679 177 7 1183 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:33 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:33 - INFO - data_loader -   guid: test-3\n","12/17/2021 00:04:33 - INFO - data_loader -   sentence: I didn't know that, thank you for teaching me something today!\n","12/17/2021 00:04:33 - INFO - data_loader -   tokens: I Ġdidn 't Ġknow Ġthat , Ġthank Ġyou Ġfor Ġteaching Ġme Ġsomething Ġtoday !\n","12/17/2021 00:04:33 - INFO - data_loader -   input_ids: 0 38 399 75 216 14 6 3392 47 13 5307 162 402 452 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:33 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:33 - INFO - data_loader -   guid: test-4\n","12/17/2021 00:04:33 - INFO - data_loader -   sentence: They got bored from haunting earth for thousands of years and ultimately moved on to the afterlife.\n","12/17/2021 00:04:33 - INFO - data_loader -   tokens: They Ġgot Ġbored Ġfrom Ġhaunting Ġearth Ġfor Ġthousands Ġof Ġyears Ġand Ġultimately Ġmoved Ġon Ġto Ġthe Ġafterlife .\n","12/17/2021 00:04:33 - INFO - data_loader -   input_ids: 0 252 300 23809 31 29475 6872 13 1583 9 107 8 3284 1410 15 7 5 42873 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:33 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/17/2021 00:04:33 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:33 - INFO - data_loader -   guid: test-5\n","12/17/2021 00:04:33 - INFO - data_loader -   sentence: Thank you for asking questions and recognizing that there may be things that you don’t know or understand about police tactics. Seriously. Thank you.\n","12/17/2021 00:04:33 - INFO - data_loader -   tokens: Thank Ġyou Ġfor Ġasking Ġquestions Ġand Ġrecognizing Ġthat Ġthere Ġmay Ġbe Ġthings Ġthat Ġyou Ġdon âĢ Ļ t Ġknow Ġor Ġunderstand Ġabout Ġpolice Ġtactics . ĠSeriously . ĠThank Ġyou .\n","12/17/2021 00:04:33 - INFO - data_loader -   input_ids: 0 3837 47 13 1996 1142 8 16257 14 89 189 28 383 14 47 218 17 27 90 216 50 1346 59 249 8893 4 29945 4 3837 47 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:33 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:33 - INFO - data_loader -   guid: test-6\n","12/17/2021 00:04:33 - INFO - data_loader -   sentence: You’re welcome\n","12/17/2021 00:04:33 - INFO - data_loader -   tokens: You âĢ Ļ re Ġwelcome\n","12/17/2021 00:04:33 - INFO - data_loader -   input_ids: 0 370 17 27 241 2814 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:33 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:33 - INFO - data_loader -   guid: test-7\n","12/17/2021 00:04:33 - INFO - data_loader -   sentence: 100%! Congrats on your job too!\n","12/17/2021 00:04:33 - INFO - data_loader -   tokens: 100 % ! ĠCong rats Ġon Ġyour Ġjob Ġtoo !\n","12/17/2021 00:04:33 - INFO - data_loader -   input_ids: 0 727 207 328 12249 28814 15 110 633 350 328 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:33 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:33 - INFO - data_loader -   guid: test-8\n","12/17/2021 00:04:33 - INFO - data_loader -   sentence: I’m sorry to hear that friend :(. It’s for the best most likely if she didn’t accept you for who you are\n","12/17/2021 00:04:33 - INFO - data_loader -   tokens: I âĢ Ļ m Ġsorry Ġto Ġhear Ġthat Ġfriend Ġ:( . ĠIt âĢ Ļ s Ġfor Ġthe Ġbest Ġmost Ġlikely Ġif Ġshe Ġdidn âĢ Ļ t Ġaccept Ġyou Ġfor Ġwho Ġyou Ġare\n","12/17/2021 00:04:33 - INFO - data_loader -   input_ids: 0 38 17 27 119 6661 7 1798 14 1441 46225 4 85 17 27 29 13 5 275 144 533 114 79 399 17 27 90 3264 47 13 54 47 32 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:33 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   *** Example ***\n","12/17/2021 00:04:33 - INFO - data_loader -   guid: test-9\n","12/17/2021 00:04:33 - INFO - data_loader -   sentence: Girlfriend weak as well, that jump was pathetic.\n","12/17/2021 00:04:33 - INFO - data_loader -   tokens: G irlfriend Ġweak Ġas Ġwell , Ġthat Ġjump Ġwas Ġpathetic .\n","12/17/2021 00:04:33 - INFO - data_loader -   input_ids: 0 272 38883 3953 25 157 6 14 3704 21 31790 4 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/17/2021 00:04:33 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n","12/17/2021 00:04:33 - INFO - data_loader -   Saving features into cached file data/original/cached_goemotions_checkpoint-9000_50_test\n","12/17/2021 00:04:34 - INFO - __main__ -   Evaluate the following checkpoints: ['drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-1000', 'drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-10000', 'drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-11000', 'drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-12000', 'drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-2000', 'drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-3000', 'drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-4000', 'drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-5000', 'drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-6000', 'drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-7000', 'drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-8000', 'drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-9000']\n","12/17/2021 00:04:45 - INFO - __main__ -   ***** Running evaluation on test dataset (1000 step) *****\n","12/17/2021 00:04:45 - INFO - __main__ -     Num examples = 5427\n","12/17/2021 00:04:45 - INFO - __main__ -     Eval Batch size = 32\n","Evaluating: 100% 170/170 [00:33<00:00,  5.10it/s]\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","12/17/2021 00:05:18 - INFO - __main__ -   ***** Eval results on test dataset *****\n","12/17/2021 00:05:18 - INFO - __main__ -     accuracy = 0.4011424359683066\n","12/17/2021 00:05:18 - INFO - __main__ -     loss = 0.10310842377298018\n","12/17/2021 00:05:18 - INFO - __main__ -     macro_f1 = 0.34498118660183347\n","12/17/2021 00:05:18 - INFO - __main__ -     macro_precision = 0.43303507532556973\n","12/17/2021 00:05:18 - INFO - __main__ -     macro_recall = 0.33843911214234573\n","12/17/2021 00:05:18 - INFO - __main__ -     micro_f1 = 0.5305692768645235\n","12/17/2021 00:05:18 - INFO - __main__ -     micro_precision = 0.5441860465116279\n","12/17/2021 00:05:18 - INFO - __main__ -     micro_recall = 0.517617317111708\n","12/17/2021 00:05:18 - INFO - __main__ -     weighted_f1 = 0.49525264623627857\n","12/17/2021 00:05:18 - INFO - __main__ -     weighted_precision = 0.535787551527261\n","12/17/2021 00:05:18 - INFO - __main__ -     weighted_recall = 0.517617317111708\n","12/17/2021 00:05:34 - INFO - __main__ -   ***** Running evaluation on test dataset (10000 step) *****\n","12/17/2021 00:05:34 - INFO - __main__ -     Num examples = 5427\n","12/17/2021 00:05:34 - INFO - __main__ -     Eval Batch size = 32\n","Evaluating: 100% 170/170 [00:33<00:00,  5.11it/s]\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","12/17/2021 00:06:07 - INFO - __main__ -   ***** Eval results on test dataset *****\n","12/17/2021 00:06:07 - INFO - __main__ -     accuracy = 0.3375714022480192\n","12/17/2021 00:06:07 - INFO - __main__ -     loss = 0.14917851097005255\n","12/17/2021 00:06:07 - INFO - __main__ -     macro_f1 = 0.3775423407677999\n","12/17/2021 00:06:07 - INFO - __main__ -     macro_precision = 0.3749210544175095\n","12/17/2021 00:06:07 - INFO - __main__ -     macro_recall = 0.40647853340846407\n","12/17/2021 00:06:07 - INFO - __main__ -     micro_f1 = 0.4788878977103777\n","12/17/2021 00:06:07 - INFO - __main__ -     micro_precision = 0.4521971079601292\n","12/17/2021 00:06:07 - INFO - __main__ -     micro_recall = 0.5089271606888924\n","12/17/2021 00:06:07 - INFO - __main__ -     weighted_f1 = 0.4810278793060826\n","12/17/2021 00:06:07 - INFO - __main__ -     weighted_precision = 0.4667780512488134\n","12/17/2021 00:06:07 - INFO - __main__ -     weighted_recall = 0.5089271606888924\n","12/17/2021 00:06:20 - INFO - __main__ -   ***** Running evaluation on test dataset (11000 step) *****\n","12/17/2021 00:06:20 - INFO - __main__ -     Num examples = 5427\n","12/17/2021 00:06:20 - INFO - __main__ -     Eval Batch size = 32\n","Evaluating: 100% 170/170 [00:33<00:00,  5.12it/s]\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","12/17/2021 00:06:54 - INFO - __main__ -   ***** Eval results on test dataset *****\n","12/17/2021 00:06:54 - INFO - __main__ -     accuracy = 0.3449419568822554\n","12/17/2021 00:06:54 - INFO - __main__ -     loss = 0.152031889119569\n","12/17/2021 00:06:54 - INFO - __main__ -     macro_f1 = 0.3862113927314662\n","12/17/2021 00:06:54 - INFO - __main__ -     macro_precision = 0.3716065543773697\n","12/17/2021 00:06:54 - INFO - __main__ -     macro_recall = 0.4145049939660447\n","12/17/2021 00:06:54 - INFO - __main__ -     micro_f1 = 0.48838409912235414\n","12/17/2021 00:06:54 - INFO - __main__ -     micro_precision = 0.45795297372060856\n","12/17/2021 00:06:54 - INFO - __main__ -     micro_recall = 0.5231474166534997\n","12/17/2021 00:06:54 - INFO - __main__ -     weighted_f1 = 0.48594294241833763\n","12/17/2021 00:06:54 - INFO - __main__ -     weighted_precision = 0.458093413752213\n","12/17/2021 00:06:54 - INFO - __main__ -     weighted_recall = 0.5231474166534997\n","12/17/2021 00:07:06 - INFO - __main__ -   ***** Running evaluation on test dataset (12000 step) *****\n","12/17/2021 00:07:06 - INFO - __main__ -     Num examples = 5427\n","12/17/2021 00:07:06 - INFO - __main__ -     Eval Batch size = 32\n","Evaluating: 100% 170/170 [00:33<00:00,  5.13it/s]\n","12/17/2021 00:07:40 - INFO - __main__ -   ***** Eval results on test dataset *****\n","12/17/2021 00:07:40 - INFO - __main__ -     accuracy = 0.3331490694674774\n","12/17/2021 00:07:40 - INFO - __main__ -     loss = 0.15511109828948974\n","12/17/2021 00:07:40 - INFO - __main__ -     macro_f1 = 0.39371686800922573\n","12/17/2021 00:07:40 - INFO - __main__ -     macro_precision = 0.41836806982213565\n","12/17/2021 00:07:40 - INFO - __main__ -     macro_recall = 0.4146691531032755\n","12/17/2021 00:07:40 - INFO - __main__ -     micro_f1 = 0.4822757111597374\n","12/17/2021 00:07:40 - INFO - __main__ -     micro_precision = 0.4479067876981439\n","12/17/2021 00:07:40 - INFO - __main__ -     micro_recall = 0.5223574024332438\n","12/17/2021 00:07:40 - INFO - __main__ -     weighted_f1 = 0.4842298962480291\n","12/17/2021 00:07:40 - INFO - __main__ -     weighted_precision = 0.45551727924227803\n","12/17/2021 00:07:40 - INFO - __main__ -     weighted_recall = 0.5223574024332438\n","12/17/2021 00:07:56 - INFO - __main__ -   ***** Running evaluation on test dataset (2000 step) *****\n","12/17/2021 00:07:56 - INFO - __main__ -     Num examples = 5427\n","12/17/2021 00:07:56 - INFO - __main__ -     Eval Batch size = 32\n","Evaluating: 100% 170/170 [00:33<00:00,  5.12it/s]\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","12/17/2021 00:08:29 - INFO - __main__ -   ***** Eval results on test dataset *****\n","12/17/2021 00:08:29 - INFO - __main__ -     accuracy = 0.35784042749216877\n","12/17/2021 00:08:29 - INFO - __main__ -     loss = 0.10646961445317549\n","12/17/2021 00:08:29 - INFO - __main__ -     macro_f1 = 0.37468041655397905\n","12/17/2021 00:08:29 - INFO - __main__ -     macro_precision = 0.38999774108979196\n","12/17/2021 00:08:29 - INFO - __main__ -     macro_recall = 0.39107233761323246\n","12/17/2021 00:08:29 - INFO - __main__ -     micro_f1 = 0.5144336963972884\n","12/17/2021 00:08:29 - INFO - __main__ -     micro_precision = 0.49661764705882355\n","12/17/2021 00:08:29 - INFO - __main__ -     micro_recall = 0.5335756043608785\n","12/17/2021 00:08:29 - INFO - __main__ -     weighted_f1 = 0.499457128231102\n","12/17/2021 00:08:29 - INFO - __main__ -     weighted_precision = 0.4854594913549845\n","12/17/2021 00:08:29 - INFO - __main__ -     weighted_recall = 0.5335756043608785\n","12/17/2021 00:08:44 - INFO - __main__ -   ***** Running evaluation on test dataset (3000 step) *****\n","12/17/2021 00:08:44 - INFO - __main__ -     Num examples = 5427\n","12/17/2021 00:08:44 - INFO - __main__ -     Eval Batch size = 32\n","Evaluating: 100% 170/170 [00:33<00:00,  5.12it/s]\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","12/17/2021 00:09:17 - INFO - __main__ -   ***** Eval results on test dataset *****\n","12/17/2021 00:09:17 - INFO - __main__ -     accuracy = 0.38603279896812237\n","12/17/2021 00:09:17 - INFO - __main__ -     loss = 0.11082169216345339\n","12/17/2021 00:09:17 - INFO - __main__ -     macro_f1 = 0.3760004609434823\n","12/17/2021 00:09:17 - INFO - __main__ -     macro_precision = 0.4085595249562654\n","12/17/2021 00:09:17 - INFO - __main__ -     macro_recall = 0.38594403356215057\n","12/17/2021 00:09:17 - INFO - __main__ -     micro_f1 = 0.5178008821676119\n","12/17/2021 00:09:17 - INFO - __main__ -     micro_precision = 0.5162556934191928\n","12/17/2021 00:09:17 - INFO - __main__ -     micro_recall = 0.5193553483962712\n","12/17/2021 00:09:17 - INFO - __main__ -     weighted_f1 = 0.5024576769570704\n","12/17/2021 00:09:17 - INFO - __main__ -     weighted_precision = 0.5053481125133334\n","12/17/2021 00:09:17 - INFO - __main__ -     weighted_recall = 0.5193553483962712\n","12/17/2021 00:09:31 - INFO - __main__ -   ***** Running evaluation on test dataset (4000 step) *****\n","12/17/2021 00:09:31 - INFO - __main__ -     Num examples = 5427\n","12/17/2021 00:09:31 - INFO - __main__ -     Eval Batch size = 32\n","Evaluating: 100% 170/170 [00:33<00:00,  5.12it/s]\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","12/17/2021 00:10:04 - INFO - __main__ -   ***** Eval results on test dataset *****\n","12/17/2021 00:10:04 - INFO - __main__ -     accuracy = 0.3810576745900129\n","12/17/2021 00:10:04 - INFO - __main__ -     loss = 0.11083525620839176\n","12/17/2021 00:10:04 - INFO - __main__ -     macro_f1 = 0.36970697620046883\n","12/17/2021 00:10:04 - INFO - __main__ -     macro_precision = 0.40792183321097214\n","12/17/2021 00:10:04 - INFO - __main__ -     macro_recall = 0.3889201315770743\n","12/17/2021 00:10:04 - INFO - __main__ -     micro_f1 = 0.5065159365677501\n","12/17/2021 00:10:04 - INFO - __main__ -     micro_precision = 0.5033546575128726\n","12/17/2021 00:10:04 - INFO - __main__ -     micro_recall = 0.5097171749091484\n","12/17/2021 00:10:04 - INFO - __main__ -     weighted_f1 = 0.4910654825586225\n","12/17/2021 00:10:04 - INFO - __main__ -     weighted_precision = 0.5076620928672816\n","12/17/2021 00:10:04 - INFO - __main__ -     weighted_recall = 0.5097171749091484\n","12/17/2021 00:10:16 - INFO - __main__ -   ***** Running evaluation on test dataset (5000 step) *****\n","12/17/2021 00:10:16 - INFO - __main__ -     Num examples = 5427\n","12/17/2021 00:10:16 - INFO - __main__ -     Eval Batch size = 32\n","Evaluating: 100% 170/170 [00:33<00:00,  5.13it/s]\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","12/17/2021 00:10:49 - INFO - __main__ -   ***** Eval results on test dataset *****\n","12/17/2021 00:10:49 - INFO - __main__ -     accuracy = 0.39616731159019714\n","12/17/2021 00:10:49 - INFO - __main__ -     loss = 0.11763020453645903\n","12/17/2021 00:10:49 - INFO - __main__ -     macro_f1 = 0.38610020865495687\n","12/17/2021 00:10:49 - INFO - __main__ -     macro_precision = 0.4067294168546417\n","12/17/2021 00:10:49 - INFO - __main__ -     macro_recall = 0.3905668680430012\n","12/17/2021 00:10:49 - INFO - __main__ -     micro_f1 = 0.5159181131781739\n","12/17/2021 00:10:49 - INFO - __main__ -     micro_precision = 0.508438171218165\n","12/17/2021 00:10:49 - INFO - __main__ -     micro_recall = 0.5236214251856534\n","12/17/2021 00:10:49 - INFO - __main__ -     weighted_f1 = 0.4983527789449374\n","12/17/2021 00:10:49 - INFO - __main__ -     weighted_precision = 0.4964223391127006\n","12/17/2021 00:10:49 - INFO - __main__ -     weighted_recall = 0.5236214251856534\n","12/17/2021 00:11:00 - INFO - __main__ -   ***** Running evaluation on test dataset (6000 step) *****\n","12/17/2021 00:11:00 - INFO - __main__ -     Num examples = 5427\n","12/17/2021 00:11:00 - INFO - __main__ -     Eval Batch size = 32\n","Evaluating: 100% 170/170 [00:33<00:00,  5.13it/s]\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","12/17/2021 00:11:33 - INFO - __main__ -   ***** Eval results on test dataset *****\n","12/17/2021 00:11:33 - INFO - __main__ -     accuracy = 0.3548922056384743\n","12/17/2021 00:11:33 - INFO - __main__ -     loss = 0.12407021404189222\n","12/17/2021 00:11:33 - INFO - __main__ -     macro_f1 = 0.3742853182147314\n","12/17/2021 00:11:33 - INFO - __main__ -     macro_precision = 0.3949099842791401\n","12/17/2021 00:11:33 - INFO - __main__ -     macro_recall = 0.3768897399532106\n","12/17/2021 00:11:33 - INFO - __main__ -     micro_f1 = 0.4983513189448441\n","12/17/2021 00:11:33 - INFO - __main__ -     micro_precision = 0.47398431931575197\n","12/17/2021 00:11:33 - INFO - __main__ -     micro_recall = 0.5253594564702164\n","12/17/2021 00:11:33 - INFO - __main__ -     weighted_f1 = 0.4951223530898302\n","12/17/2021 00:11:33 - INFO - __main__ -     weighted_precision = 0.4800434080353639\n","12/17/2021 00:11:33 - INFO - __main__ -     weighted_recall = 0.5253594564702164\n","12/17/2021 00:11:47 - INFO - __main__ -   ***** Running evaluation on test dataset (7000 step) *****\n","12/17/2021 00:11:47 - INFO - __main__ -     Num examples = 5427\n","12/17/2021 00:11:47 - INFO - __main__ -     Eval Batch size = 32\n","Evaluating: 100% 170/170 [00:33<00:00,  5.12it/s]\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","12/17/2021 00:12:20 - INFO - __main__ -   ***** Eval results on test dataset *****\n","12/17/2021 00:12:20 - INFO - __main__ -     accuracy = 0.34899576193108534\n","12/17/2021 00:12:20 - INFO - __main__ -     loss = 0.13235356733202935\n","12/17/2021 00:12:20 - INFO - __main__ -     macro_f1 = 0.3737346112370125\n","12/17/2021 00:12:20 - INFO - __main__ -     macro_precision = 0.3609003832746777\n","12/17/2021 00:12:20 - INFO - __main__ -     macro_recall = 0.4034181562408384\n","12/17/2021 00:12:20 - INFO - __main__ -     micro_f1 = 0.481528854111805\n","12/17/2021 00:12:20 - INFO - __main__ -     micro_precision = 0.4596380350474002\n","12/17/2021 00:12:20 - INFO - __main__ -     micro_recall = 0.5056091009638174\n","12/17/2021 00:12:20 - INFO - __main__ -     weighted_f1 = 0.47737414248425514\n","12/17/2021 00:12:20 - INFO - __main__ -     weighted_precision = 0.4636875964782634\n","12/17/2021 00:12:20 - INFO - __main__ -     weighted_recall = 0.5056091009638174\n","12/17/2021 00:12:36 - INFO - __main__ -   ***** Running evaluation on test dataset (8000 step) *****\n","12/17/2021 00:12:36 - INFO - __main__ -     Num examples = 5427\n","12/17/2021 00:12:36 - INFO - __main__ -     Eval Batch size = 32\n","Evaluating: 100% 170/170 [00:33<00:00,  5.11it/s]\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","12/17/2021 00:13:09 - INFO - __main__ -   ***** Eval results on test dataset *****\n","12/17/2021 00:13:09 - INFO - __main__ -     accuracy = 0.36686935691910816\n","12/17/2021 00:13:09 - INFO - __main__ -     loss = 0.13437500048209639\n","12/17/2021 00:13:09 - INFO - __main__ -     macro_f1 = 0.38662709011430313\n","12/17/2021 00:13:09 - INFO - __main__ -     macro_precision = 0.4170969309724089\n","12/17/2021 00:13:09 - INFO - __main__ -     macro_recall = 0.40116005171623464\n","12/17/2021 00:13:09 - INFO - __main__ -     micro_f1 = 0.4981005926151041\n","12/17/2021 00:13:09 - INFO - __main__ -     micro_precision = 0.4797307185716376\n","12/17/2021 00:13:09 - INFO - __main__ -     micro_recall = 0.5179333227998104\n","12/17/2021 00:13:09 - INFO - __main__ -     weighted_f1 = 0.4924594177943951\n","12/17/2021 00:13:09 - INFO - __main__ -     weighted_precision = 0.47940783053585184\n","12/17/2021 00:13:09 - INFO - __main__ -     weighted_recall = 0.5179333227998104\n","12/17/2021 00:13:16 - INFO - __main__ -   ***** Running evaluation on test dataset (9000 step) *****\n","12/17/2021 00:13:16 - INFO - __main__ -     Num examples = 5427\n","12/17/2021 00:13:16 - INFO - __main__ -     Eval Batch size = 32\n","Evaluating: 100% 170/170 [00:33<00:00,  5.12it/s]\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","12/17/2021 00:13:49 - INFO - __main__ -   ***** Eval results on test dataset *****\n","12/17/2021 00:13:49 - INFO - __main__ -     accuracy = 0.36336834346784597\n","12/17/2021 00:13:49 - INFO - __main__ -     loss = 0.14320239678901783\n","12/17/2021 00:13:49 - INFO - __main__ -     macro_f1 = 0.3900970938416831\n","12/17/2021 00:13:49 - INFO - __main__ -     macro_precision = 0.39995215873149237\n","12/17/2021 00:13:49 - INFO - __main__ -     macro_recall = 0.4000445870033314\n","12/17/2021 00:13:49 - INFO - __main__ -     micro_f1 = 0.5017556966753829\n","12/17/2021 00:13:49 - INFO - __main__ -     micro_precision = 0.47590702947845803\n","12/17/2021 00:13:49 - INFO - __main__ -     micro_recall = 0.5305735503239059\n","12/17/2021 00:13:49 - INFO - __main__ -     weighted_f1 = 0.4924417100536545\n","12/17/2021 00:13:49 - INFO - __main__ -     weighted_precision = 0.46907790444933956\n","12/17/2021 00:13:49 - INFO - __main__ -     weighted_recall = 0.5305735503239059\n"]}]},{"cell_type":"code","source":["!touch \"drive/MyDrive/EECS595 Final Project/roberta/test\""],"metadata":{"id":"6EV63QDNh771"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import transformers\n","\n","t1 = transformers.AutoTokenizer.from_pretrained(\"roberta-base\")\n","t2 =  transformers.AutoTokenizer.from_pretrained(\"bert-base-cased\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["4f646ae860ea44d9b9e79dc6ed1e6c15","b9cf18222f694aa38c94590702f1e23e","3e891269b055446988ec3fc1615178ee","dd4d4de30d954fb59192d20341041498","fd3f8f90abdb40f6a82868f9b49ce196","1a853d58799c436ab8a5db3b775f9f01","cecce3f305e54059891625f7f8e824f0","8de3b4fc6db5430f93ed22206af337f1","c69dbd011549416092f02338517a5090","9f7165dc2a414c839bc330717f4dc706","abe61baa3ef04998b90795f300b78729","47cc7c93968142babcb27a237c7b6e3c","fa2ee3e1b22a4ea896ffcd3767775363","c74020d77e1f4fdc83c6da6d1690b8ad","7a7216f874f04e78862c1178f6c5210a","efcd6952eb8a408293ae6b76d73b9b0e","c80edcd12cbd4f09b17b00144cb332b7","66f254bc51034680afce2d10eb114c1d","1432dff21c8a4630a7227b887ef44b99","99bb9f07e91c4bbea7b48e8e7d240956","bebcdae1422845c6a752c3c5d27b0ea0","e1dc429f25fb4c8093075e18a6853703","911584865dad49859b03d7532b72dbeb","6e55628812ea41fd8ad8668b331826ea","8f4d31ed00314b5a8d9342b003259b03","3ddfeab59ab34259bfb6c427eab421bd","1b5ff11f8d2044a79ac20c32b323d6b0","b138b17fbc024117afd057a3a45983f0","7413a01b7df2471c949e75308d15bbdb","dbfdf5d8647c4ecd8f396d1f326ea5bc","022c661555534494a8612546645adfc5","30e01abb9fb24f1aa3a9361010b70a84","ed59518c922d4f368e2ac839335ec4f2","40073a8ccf91401a9d7e6c798e88126f","54cfbb7513264f0bb28d9b77f0d644bb","22ead6bcd2ca4a39b91ecde3589edc84","22d61ed900b94f9484549d843054c8b9","89b057040be0419fadde9ca8f406609e","a5baee23842c4501bcc7d4b4f7973243","5bc23bec087c4aefa711ccf435498545","2bb9f980fba24cc5bf3a03c521bf3296","9759927df77642beb88ac60f51e8ec00","2de5005115df49ecab9a6ddd198b24bb","da3f14ec6aa44c43961859a7ce30e93b","d583eb7dd72e49f9809336be3a24e12e","e9455342dfa045f1b99c19740e9a937b","2d49833d93ed40939dcd62f704aecc8b","3b453fe885c945e5a6ee086f46cfcb93","34d0f64b5cef41b590514f340e99a5bd","6553daaf6be54cc8af39f64a84d3416a","bb3d730a8b174e1385b7d7d67b8f97c4","d4f096d8c93c4191806bb910f630ef17","545deceee5ec45c396ddc86bd4f1ff6e","19ca7778cb4e4c4c88c51a7b85c52cb5","04cb7a9aa5c04a7587b68d82f082b8a2"]},"id":"awoSPuoZ4JN8","executionInfo":{"status":"ok","timestamp":1639623869230,"user_tz":300,"elapsed":10624,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"}},"outputId":"d120c7c6-61ff-4f51-a914-4af6787f3ef6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4f646ae860ea44d9b9e79dc6ed1e6c15","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47cc7c93968142babcb27a237c7b6e3c","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"911584865dad49859b03d7532b72dbeb","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40073a8ccf91401a9d7e6c798e88126f","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d583eb7dd72e49f9809336be3a24e12e","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","source":["!ls \"drive/MyDrive/EECS595 Final Project/roberta\""],"metadata":{"id":"IWaMLork8Nx6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized1 = t1.encode_plus(\"I ate a clock yesterday.\", \"It was very time consuming.\")\n","tokenized1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rX8DsGBG4ZzR","executionInfo":{"status":"ok","timestamp":1639501127327,"user_tz":300,"elapsed":113,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"}},"outputId":"de0b62d0-22c0-46ce-ab50-866bdf3476ea"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [0, 38, 14964, 10, 6700, 2350, 4, 2, 2, 85, 21, 182, 86, 16997, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["tokenized2 = t2.encode_plus(\"I ate a clock yesterday.\", \"It was very time consuming.\")\n","tokenized2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ShihUHC4e1q","executionInfo":{"status":"ok","timestamp":1639501146156,"user_tz":300,"elapsed":260,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"}},"outputId":"789456d1-1710-4452-f913-e6aff67191d1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [101, 146, 8756, 170, 4705, 8128, 119, 102, 1135, 1108, 1304, 1159, 16114, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["t2."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gG6sRSel4mkd","executionInfo":{"status":"ok","timestamp":1639501164375,"user_tz":300,"elapsed":279,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"}},"outputId":"cfb70d85-e123-4b56-8cfa-52a9b94d793b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<transformers.tokenization_roberta.RobertaTokenizer at 0x7f7bf744ba10>"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52098,"status":"ok","timestamp":1639499905307,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"},"user_tz":300},"id":"71Ra2z6TYdIP","outputId":"841d424b-f3a7-4a55-8c04-63b7a69a5030"},"outputs":[{"output_type":"stream","name":"stdout","text":["12/14/2021 16:37:37 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpvp16fzhw\n","\rDownloading:   0% 0.00/433 [00:00<?, ?B/s]\rDownloading: 100% 433/433 [00:00<00:00, 308kB/s]\n","12/14/2021 16:37:37 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json in cache at /root/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n","12/14/2021 16:37:37 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n","12/14/2021 16:37:37 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /root/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n","12/14/2021 16:37:37 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"goemotions\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"admiration\",\n","    \"1\": \"amusement\",\n","    \"10\": \"disapproval\",\n","    \"11\": \"disgust\",\n","    \"12\": \"embarrassment\",\n","    \"13\": \"excitement\",\n","    \"14\": \"fear\",\n","    \"15\": \"gratitude\",\n","    \"16\": \"grief\",\n","    \"17\": \"joy\",\n","    \"18\": \"love\",\n","    \"19\": \"nervousness\",\n","    \"2\": \"anger\",\n","    \"20\": \"optimism\",\n","    \"21\": \"pride\",\n","    \"22\": \"realization\",\n","    \"23\": \"relief\",\n","    \"24\": \"remorse\",\n","    \"25\": \"sadness\",\n","    \"26\": \"surprise\",\n","    \"27\": \"neutral\",\n","    \"3\": \"annoyance\",\n","    \"4\": \"approval\",\n","    \"5\": \"caring\",\n","    \"6\": \"confusion\",\n","    \"7\": \"curiosity\",\n","    \"8\": \"desire\",\n","    \"9\": \"disappointment\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"admiration\": 0,\n","    \"amusement\": 1,\n","    \"anger\": 2,\n","    \"annoyance\": 3,\n","    \"approval\": 4,\n","    \"caring\": 5,\n","    \"confusion\": 6,\n","    \"curiosity\": 7,\n","    \"desire\": 8,\n","    \"disappointment\": 9,\n","    \"disapproval\": 10,\n","    \"disgust\": 11,\n","    \"embarrassment\": 12,\n","    \"excitement\": 13,\n","    \"fear\": 14,\n","    \"gratitude\": 15,\n","    \"grief\": 16,\n","    \"joy\": 17,\n","    \"love\": 18,\n","    \"nervousness\": 19,\n","    \"neutral\": 27,\n","    \"optimism\": 20,\n","    \"pride\": 21,\n","    \"realization\": 22,\n","    \"relief\": 23,\n","    \"remorse\": 24,\n","    \"sadness\": 25,\n","    \"surprise\": 26\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 28996\n","}\n","\n","12/14/2021 16:37:37 - INFO - transformers.tokenization_utils -   Model name 'monologg/bert-base-cased-goemotions-original' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'monologg/bert-base-cased-goemotions-original' is a path, a model identifier, or url to a directory containing tokenizer files.\n","12/14/2021 16:37:37 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/monologg/bert-base-cased-goemotions-original/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpq8fpaejh\n","Downloading: 100% 242k/242k [00:00<00:00, 2.38MB/s]\n","12/14/2021 16:37:38 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/monologg/bert-base-cased-goemotions-original/vocab.txt in cache at /root/.cache/torch/transformers/b74290920f7089fe634c13c663a80f8fe036cbc92886af6769d52dc5571903ae.8cc3984a9fa06874c3f4e5857332d1064e27106f4506f8a3f7343b64145f9c47\n","12/14/2021 16:37:38 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/b74290920f7089fe634c13c663a80f8fe036cbc92886af6769d52dc5571903ae.8cc3984a9fa06874c3f4e5857332d1064e27106f4506f8a3f7343b64145f9c47\n","12/14/2021 16:37:38 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/monologg/bert-base-cased-goemotions-original/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpl_d4usdl\n","Downloading: 100% 188/188 [00:00<00:00, 116kB/s]\n","12/14/2021 16:37:38 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/monologg/bert-base-cased-goemotions-original/special_tokens_map.json in cache at /root/.cache/torch/transformers/5484d3a56df815af65d85528521e364f44acd4619a41d3d3875f479bff7435bb.9ca88b9d315598fd4997e027f473cb03cb429915e3256c4a6458a60bd1004770\n","12/14/2021 16:37:38 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/5484d3a56df815af65d85528521e364f44acd4619a41d3d3875f479bff7435bb.9ca88b9d315598fd4997e027f473cb03cb429915e3256c4a6458a60bd1004770\n","12/14/2021 16:37:38 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/monologg/bert-base-cased-goemotions-original/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpqblnw8_c\n","Downloading: 100% 243/243 [00:00<00:00, 157kB/s]\n","12/14/2021 16:37:39 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/monologg/bert-base-cased-goemotions-original/tokenizer_config.json in cache at /root/.cache/torch/transformers/dc67e42be728e2e6bfbe18ca1434b1202e7fd1a913d5237ec14ee7ca6c993c88.e3b885d5cb183bdd9b977fd690abb6edf1cd2083f7e30d30a49d0972edd77642\n","12/14/2021 16:37:39 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/dc67e42be728e2e6bfbe18ca1434b1202e7fd1a913d5237ec14ee7ca6c993c88.e3b885d5cb183bdd9b977fd690abb6edf1cd2083f7e30d30a49d0972edd77642\n","12/14/2021 16:37:39 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/monologg/bert-base-cased-goemotions-original/vocab.txt from cache at /root/.cache/torch/transformers/b74290920f7089fe634c13c663a80f8fe036cbc92886af6769d52dc5571903ae.8cc3984a9fa06874c3f4e5857332d1064e27106f4506f8a3f7343b64145f9c47\n","12/14/2021 16:37:39 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/monologg/bert-base-cased-goemotions-original/added_tokens.json from cache at None\n","12/14/2021 16:37:39 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/monologg/bert-base-cased-goemotions-original/special_tokens_map.json from cache at /root/.cache/torch/transformers/5484d3a56df815af65d85528521e364f44acd4619a41d3d3875f479bff7435bb.9ca88b9d315598fd4997e027f473cb03cb429915e3256c4a6458a60bd1004770\n","12/14/2021 16:37:39 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/monologg/bert-base-cased-goemotions-original/tokenizer_config.json from cache at /root/.cache/torch/transformers/dc67e42be728e2e6bfbe18ca1434b1202e7fd1a913d5237ec14ee7ca6c993c88.e3b885d5cb183bdd9b977fd690abb6edf1cd2083f7e30d30a49d0972edd77642\n","12/14/2021 16:37:39 - INFO - transformers.file_utils -   https://cdn.huggingface.co/bert-base-cased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpvqmyheor\n","Downloading: 100% 436M/436M [00:10<00:00, 43.0MB/s]\n","12/14/2021 16:37:49 - INFO - transformers.file_utils -   storing https://cdn.huggingface.co/bert-base-cased-pytorch_model.bin in cache at /root/.cache/torch/transformers/d8f11f061e407be64c4d5d7867ee61d1465263e24085cfa26abf183fdc830569.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n","12/14/2021 16:37:49 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/d8f11f061e407be64c4d5d7867ee61d1465263e24085cfa26abf183fdc830569.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n","12/14/2021 16:37:49 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/bert-base-cased-pytorch_model.bin from cache at /root/.cache/torch/transformers/d8f11f061e407be64c4d5d7867ee61d1465263e24085cfa26abf183fdc830569.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n","12/14/2021 16:37:53 - INFO - transformers.modeling_utils -   Weights of BertForMultiLabelClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n","12/14/2021 16:37:53 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMultiLabelClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","12/14/2021 16:37:53 - INFO - data_loader -   Creating features from dataset file at data/original\n","12/14/2021 16:37:53 - INFO - data_loader -   LOOKING AT data/original/train.tsv\n","12/14/2021 16:37:53 - INFO - data_loader -   My favourite food is anything I didn't have to cook myself.\t27\teebbqej\n","12/14/2021 16:37:53 - INFO - data_loader -   What’s that extra B for?\t6,7\tedo4lm1\n","12/14/2021 16:37:53 - INFO - data_loader -   Quick... there's a boot somewhere that you haven't licked today yet!\t27\tedoblwt\n","12/14/2021 16:37:53 - INFO - data_loader -   I'm so gay I can't even drive straight - a bumper sticker older than most redditors\t19\tedfval6\n","12/14/2021 16:37:53 - INFO - data_loader -   I don't know\t27\ted98qh1\n","12/14/2021 16:37:53 - INFO - data_loader -   Broom him fast.\t27\tedket23\n","12/14/2021 16:37:53 - INFO - data_loader -   The balance above the base fee gets put somewhere else. Education, healthcare, etc. Voila, police aren't biased, people are proportionally fined. \t27\teepn62z\n","12/14/2021 16:37:53 - INFO - data_loader -   Hi [NAME], I love you, that is all. Can't wait to see you in Worcester in February!\t17,18\tee8wndy\n","12/14/2021 16:37:53 - INFO - data_loader -   I mean it sucks but that man looks deaded\t11,22\ted917ws\n","12/14/2021 16:38:07 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:07 - INFO - data_loader -   guid: train-0\n","12/14/2021 16:38:07 - INFO - data_loader -   sentence: My favourite food is anything I didn't have to cook myself.\n","12/14/2021 16:38:07 - INFO - data_loader -   tokens: My favourite food is anything I didn ' t have to cook myself .\n","12/14/2021 16:38:07 - INFO - data_loader -   input_ids: 101 1422 9122 2094 1110 1625 146 1238 112 189 1138 1106 9834 1991 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/14/2021 16:38:07 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:07 - INFO - data_loader -   guid: train-1\n","12/14/2021 16:38:07 - INFO - data_loader -   sentence: Now if he does off himself, everyone will think hes having a laugh screwing with people instead of actually dead\n","12/14/2021 16:38:07 - INFO - data_loader -   tokens: Now if he does off himself , everyone will think he ##s having a laugh screw ##ing with people instead of actually dead\n","12/14/2021 16:38:07 - INFO - data_loader -   input_ids: 101 1986 1191 1119 1674 1228 1471 117 2490 1209 1341 1119 1116 1515 170 4046 13084 1158 1114 1234 1939 1104 2140 2044 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/14/2021 16:38:07 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:07 - INFO - data_loader -   guid: train-2\n","12/14/2021 16:38:07 - INFO - data_loader -   sentence: WHY THE FUCK IS BAYLESS ISOING\n","12/14/2021 16:38:07 - INFO - data_loader -   tokens: W ##H ##Y THE F ##UC ##K IS BA ##Y ##LE ##SS ISO ##ING\n","12/14/2021 16:38:07 - INFO - data_loader -   input_ids: 101 160 3048 3663 7462 143 21986 2428 19432 12465 3663 17516 12480 11533 15740 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   label: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:07 - INFO - data_loader -   guid: train-3\n","12/14/2021 16:38:07 - INFO - data_loader -   sentence: To make her feel threatened\n","12/14/2021 16:38:07 - INFO - data_loader -   tokens: To make her feel threatened\n","12/14/2021 16:38:07 - INFO - data_loader -   input_ids: 101 1706 1294 1123 1631 4963 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:07 - INFO - data_loader -   guid: train-4\n","12/14/2021 16:38:07 - INFO - data_loader -   sentence: Dirty Southern Wankers\n","12/14/2021 16:38:07 - INFO - data_loader -   tokens: Dirty Southern Wan ##kers\n","12/14/2021 16:38:07 - INFO - data_loader -   input_ids: 101 14853 2685 17878 8811 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   label: 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:07 - INFO - data_loader -   guid: train-5\n","12/14/2021 16:38:07 - INFO - data_loader -   sentence: OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe PlAyOfFs! Dumbass Broncos fans circa December 2015.\n","12/14/2021 16:38:07 - INFO - data_loader -   tokens: O ##m ##G p ##E ##y ##T ##o ##N i ##S ##n ' T g ##O ##o ##D e ##N ##o ##U ##g ##H t ##O h ##E ##l ##P u ##S i ##N t ##H ##e P ##l ##A ##y ##O ##f ##F ##s ! Du ##mba ##ss Broncos fans circa December 2015 .\n","12/14/2021 16:38:07 - INFO - data_loader -   input_ids: 101 152 1306 2349 185 2036 1183 1942 1186 2249 178 1708 1179 112 157 176 2346 1186 2137 174 2249 1186 2591 1403 3048 189 2346 177 2036 1233 2101 190 1708 178 2249 189 3048 1162 153 1233 1592 1183 2346 2087 2271 1116 106 12786 10806 102\n","12/14/2021 16:38:07 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n","12/14/2021 16:38:07 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n","12/14/2021 16:38:07 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:07 - INFO - data_loader -   guid: train-6\n","12/14/2021 16:38:07 - INFO - data_loader -   sentence: Yes I heard abt the f bombs! That has to be why. Thanks for your reply:) until then hubby and I will anxiously wait 😝\n","12/14/2021 16:38:07 - INFO - data_loader -   tokens: Yes I heard a ##bt the f bombs ! That has to be why . Thanks for your reply : ) until then hub ##by and I will anxiously wait [UNK]\n","12/14/2021 16:38:07 - INFO - data_loader -   input_ids: 101 2160 146 1767 170 21238 1103 175 10095 106 1337 1144 1106 1129 1725 119 5749 1111 1240 7163 131 114 1235 1173 10960 2665 1105 146 1209 26433 3074 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:07 - INFO - data_loader -   guid: train-7\n","12/14/2021 16:38:07 - INFO - data_loader -   sentence: We need more boards and to create a bit more space for [NAME]. Then we’ll be good.\n","12/14/2021 16:38:07 - INFO - data_loader -   tokens: We need more boards and to create a bit more space for [NAME] . Then we ’ ll be good .\n","12/14/2021 16:38:07 - INFO - data_loader -   input_ids: 101 1284 1444 1167 8190 1105 1106 2561 170 2113 1167 2000 1111 1 119 1599 1195 787 1325 1129 1363 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:07 - INFO - data_loader -   guid: train-8\n","12/14/2021 16:38:07 - INFO - data_loader -   sentence: Damn youtube and outrage drama is super lucrative for reddit\n","12/14/2021 16:38:07 - INFO - data_loader -   tokens: Damn you ##tub ##e and outrage drama is super lucrative for red ##dit\n","12/14/2021 16:38:07 - INFO - data_loader -   input_ids: 101 8441 1128 25098 1162 1105 22052 3362 1110 7688 23284 1111 1894 17903 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   label: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:07 - INFO - data_loader -   guid: train-9\n","12/14/2021 16:38:07 - INFO - data_loader -   sentence: It might be linked to the trust factor of your friend.\n","12/14/2021 16:38:07 - INFO - data_loader -   tokens: It might be linked to the trust factor of your friend .\n","12/14/2021 16:38:07 - INFO - data_loader -   input_ids: 101 1135 1547 1129 5128 1106 1103 3496 5318 1104 1240 1910 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:07 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/14/2021 16:38:07 - INFO - data_loader -   Saving features into cached file data/original/cached_goemotions_bert-base-cased_50_train\n","12/14/2021 16:38:11 - INFO - data_loader -   Creating features from dataset file at data/original\n","12/14/2021 16:38:11 - INFO - data_loader -   LOOKING AT data/original/dev.tsv\n","12/14/2021 16:38:11 - INFO - data_loader -   Is this in New Orleans?? I really feel like this is New Orleans.\t27\tedgurhb\n","12/14/2021 16:38:11 - INFO - data_loader -   [NAME] is vastly overrated. Much bette4 [RELIGION] delis in the outer Burroughs\t4\tedc0amo\n","12/14/2021 16:38:13 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:13 - INFO - data_loader -   guid: dev-0\n","12/14/2021 16:38:13 - INFO - data_loader -   sentence: Is this in New Orleans?? I really feel like this is New Orleans.\n","12/14/2021 16:38:13 - INFO - data_loader -   tokens: Is this in New Orleans ? ? I really feel like this is New Orleans .\n","12/14/2021 16:38:13 - INFO - data_loader -   input_ids: 101 2181 1142 1107 1203 5705 136 136 146 1541 1631 1176 1142 1110 1203 5705 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/14/2021 16:38:13 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:13 - INFO - data_loader -   guid: dev-1\n","12/14/2021 16:38:13 - INFO - data_loader -   sentence: You know the answer man, you are programmed to capture those codes they send you, don’t avoid them!\n","12/14/2021 16:38:13 - INFO - data_loader -   tokens: You know the answer man , you are programmed to capture those codes they send you , don ’ t avoid them !\n","12/14/2021 16:38:13 - INFO - data_loader -   input_ids: 101 1192 1221 1103 2590 1299 117 1128 1132 18693 1106 4821 1343 9812 1152 3952 1128 117 1274 787 189 3644 1172 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   label: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/14/2021 16:38:13 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:13 - INFO - data_loader -   guid: dev-2\n","12/14/2021 16:38:13 - INFO - data_loader -   sentence: I've never been this sad in my life!\n","12/14/2021 16:38:13 - INFO - data_loader -   tokens: I ' ve never been this sad in my life !\n","12/14/2021 16:38:13 - INFO - data_loader -   input_ids: 101 146 112 1396 1309 1151 1142 6782 1107 1139 1297 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:13 - INFO - data_loader -   guid: dev-3\n","12/14/2021 16:38:13 - INFO - data_loader -   sentence: The economy is heavily controlled and subsidized by the government. In any case, I was poking at the lack of nuance in US politics today\n","12/14/2021 16:38:13 - INFO - data_loader -   tokens: The economy is heavily controlled and sub ##si ##dized by the government . In any case , I was poking at the lack of n ##uan ##ce in US politics today\n","12/14/2021 16:38:13 - INFO - data_loader -   input_ids: 101 1109 4190 1110 3777 4013 1105 4841 5053 26332 1118 1103 1433 119 1130 1251 1692 117 146 1108 24337 1120 1103 2960 1104 183 8734 2093 1107 1646 4039 2052 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   label: 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/14/2021 16:38:13 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:13 - INFO - data_loader -   guid: dev-4\n","12/14/2021 16:38:13 - INFO - data_loader -   sentence: He could have easily taken a real camera from a legitimate source and change the price in Word/Photoshop and then print it out.\n","12/14/2021 16:38:13 - INFO - data_loader -   tokens: He could have easily taken a real camera from a legitimate source and change the price in Word / Photo ##sh ##op and then print it out .\n","12/14/2021 16:38:13 - INFO - data_loader -   input_ids: 101 1124 1180 1138 3253 1678 170 1842 4504 1121 170 11582 2674 1105 1849 1103 3945 1107 10683 120 21906 2737 4184 1105 1173 5911 1122 1149 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:13 - INFO - data_loader -   guid: dev-5\n","12/14/2021 16:38:13 - INFO - data_loader -   sentence: Thank you for your vote of confidence, but we statistically can't get to 10 wins.\n","12/14/2021 16:38:13 - INFO - data_loader -   tokens: Thank you for your vote of confidence , but we statistical ##ly can ' t get to 10 wins .\n","12/14/2021 16:38:13 - INFO - data_loader -   input_ids: 101 4514 1128 1111 1240 2992 1104 6595 117 1133 1195 11435 1193 1169 112 189 1243 1106 1275 4646 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:13 - INFO - data_loader -   guid: dev-6\n","12/14/2021 16:38:13 - INFO - data_loader -   sentence: Wah Mum other people call me on my bullshit and I can't ban them , Go out side son.\n","12/14/2021 16:38:13 - INFO - data_loader -   tokens: W ##ah Mum other people call me on my bullshit and I can ' t ban them , Go out side son .\n","12/14/2021 16:38:13 - INFO - data_loader -   input_ids: 101 160 3354 20409 1168 1234 1840 1143 1113 1139 17480 1105 146 1169 112 189 8214 1172 117 3414 1149 1334 1488 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   label: 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:13 - INFO - data_loader -   guid: dev-7\n","12/14/2021 16:38:13 - INFO - data_loader -   sentence: There it is!\n","12/14/2021 16:38:13 - INFO - data_loader -   tokens: There it is !\n","12/14/2021 16:38:13 - INFO - data_loader -   input_ids: 101 1247 1122 1110 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/14/2021 16:38:13 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:13 - INFO - data_loader -   guid: dev-8\n","12/14/2021 16:38:13 - INFO - data_loader -   sentence: At least now [NAME] has more time to gain his confidence\n","12/14/2021 16:38:13 - INFO - data_loader -   tokens: At least now [NAME] has more time to gain his confidence\n","12/14/2021 16:38:13 - INFO - data_loader -   input_ids: 101 1335 1655 1208 1 1144 1167 1159 1106 4361 1117 6595 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:13 - INFO - data_loader -   guid: dev-9\n","12/14/2021 16:38:13 - INFO - data_loader -   sentence: Good. We don't want more thrash liberal offspring in this world.\n","12/14/2021 16:38:13 - INFO - data_loader -   tokens: Good . We don ' t want more th ##rash liberal offspring in this world .\n","12/14/2021 16:38:13 - INFO - data_loader -   input_ids: 101 2750 119 1284 1274 112 189 1328 1167 24438 16543 7691 14416 1107 1142 1362 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:13 - INFO - data_loader -   Saving features into cached file data/original/cached_goemotions_bert-base-cased_50_dev\n","12/14/2021 16:38:13 - INFO - data_loader -   Creating features from dataset file at data/original\n","12/14/2021 16:38:13 - INFO - data_loader -   LOOKING AT data/original/test.tsv\n","12/14/2021 16:38:13 - INFO - data_loader -   I’m really sorry about your situation :( Although I love the names Sapphira, Cirilla, and Scarlett!\t25\teecwqtt\n","12/14/2021 16:38:13 - INFO - data_loader -   Well I am a lady, so that would probably just freak them out. Oh, Reddit. Everyone is a man haha. \t1\teez3kgr\n","12/14/2021 16:38:15 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:15 - INFO - data_loader -   guid: test-0\n","12/14/2021 16:38:15 - INFO - data_loader -   sentence: I’m really sorry about your situation :( Although I love the names Sapphira, Cirilla, and Scarlett!\n","12/14/2021 16:38:15 - INFO - data_loader -   tokens: I ’ m really sorry about your situation : ( Although I love the names Sa ##pp ##hir ##a , C ##iri ##lla , and Scarlett !\n","12/14/2021 16:38:15 - INFO - data_loader -   input_ids: 101 146 787 182 1541 2959 1164 1240 2820 131 113 1966 146 1567 1103 2666 17784 8661 14518 1161 117 140 17262 3848 117 1105 22991 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:15 - INFO - data_loader -   guid: test-1\n","12/14/2021 16:38:15 - INFO - data_loader -   sentence: It's wonderful because it's awful. At not with.\n","12/14/2021 16:38:15 - INFO - data_loader -   tokens: It ' s wonderful because it ' s awful . At not with .\n","12/14/2021 16:38:15 - INFO - data_loader -   input_ids: 101 1135 112 188 7310 1272 1122 112 188 9684 119 1335 1136 1114 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   label: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:15 - INFO - data_loader -   guid: test-2\n","12/14/2021 16:38:15 - INFO - data_loader -   sentence: Kings fan here, good luck to you guys! Will be an interesting game to watch! \n","12/14/2021 16:38:15 - INFO - data_loader -   tokens: Kings fan here , good luck to you guys ! Will be an interesting game to watch !\n","12/14/2021 16:38:15 - INFO - data_loader -   input_ids: 101 6560 5442 1303 117 1363 6920 1106 1128 3713 106 3100 1129 1126 5426 1342 1106 2824 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:15 - INFO - data_loader -   guid: test-3\n","12/14/2021 16:38:15 - INFO - data_loader -   sentence: I didn't know that, thank you for teaching me something today!\n","12/14/2021 16:38:15 - INFO - data_loader -   tokens: I didn ' t know that , thank you for teaching me something today !\n","12/14/2021 16:38:15 - INFO - data_loader -   input_ids: 101 146 1238 112 189 1221 1115 117 6243 1128 1111 3679 1143 1380 2052 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:15 - INFO - data_loader -   guid: test-4\n","12/14/2021 16:38:15 - INFO - data_loader -   sentence: They got bored from haunting earth for thousands of years and ultimately moved on to the afterlife.\n","12/14/2021 16:38:15 - INFO - data_loader -   tokens: They got bored from haunting earth for thousands of years and ultimately moved on to the after ##life .\n","12/14/2021 16:38:15 - INFO - data_loader -   input_ids: 101 1220 1400 11920 1121 24844 4033 1111 4674 1104 1201 1105 4444 1427 1113 1106 1103 1170 14430 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n","12/14/2021 16:38:15 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:15 - INFO - data_loader -   guid: test-5\n","12/14/2021 16:38:15 - INFO - data_loader -   sentence: Thank you for asking questions and recognizing that there may be things that you don’t know or understand about police tactics. Seriously. Thank you.\n","12/14/2021 16:38:15 - INFO - data_loader -   tokens: Thank you for asking questions and recognizing that there may be things that you don ’ t know or understand about police tactics . Seriously . Thank you .\n","12/14/2021 16:38:15 - INFO - data_loader -   input_ids: 101 4514 1128 1111 4107 3243 1105 17344 1115 1175 1336 1129 1614 1115 1128 1274 787 189 1221 1137 2437 1164 2021 10524 119 18725 119 4514 1128 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:15 - INFO - data_loader -   guid: test-6\n","12/14/2021 16:38:15 - INFO - data_loader -   sentence: You’re welcome\n","12/14/2021 16:38:15 - INFO - data_loader -   tokens: You ’ re welcome\n","12/14/2021 16:38:15 - INFO - data_loader -   input_ids: 101 1192 787 1231 7236 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:15 - INFO - data_loader -   guid: test-7\n","12/14/2021 16:38:15 - INFO - data_loader -   sentence: 100%! Congrats on your job too!\n","12/14/2021 16:38:15 - INFO - data_loader -   tokens: 100 % ! Con ##gra ##ts on your job too !\n","12/14/2021 16:38:15 - INFO - data_loader -   input_ids: 101 1620 110 106 16752 14867 2145 1113 1240 2261 1315 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:15 - INFO - data_loader -   guid: test-8\n","12/14/2021 16:38:15 - INFO - data_loader -   sentence: I’m sorry to hear that friend :(. It’s for the best most likely if she didn’t accept you for who you are\n","12/14/2021 16:38:15 - INFO - data_loader -   tokens: I ’ m sorry to hear that friend : ( . It ’ s for the best most likely if she didn ’ t accept you for who you are\n","12/14/2021 16:38:15 - INFO - data_loader -   input_ids: 101 146 787 182 2959 1106 2100 1115 1910 131 113 119 1135 787 188 1111 1103 1436 1211 2620 1191 1131 1238 787 189 4392 1128 1111 1150 1128 1132 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   *** Example ***\n","12/14/2021 16:38:15 - INFO - data_loader -   guid: test-9\n","12/14/2021 16:38:15 - INFO - data_loader -   sentence: Girlfriend weak as well, that jump was pathetic.\n","12/14/2021 16:38:15 - INFO - data_loader -   tokens: Girl ##friend weak as well , that jump was pathetic .\n","12/14/2021 16:38:15 - INFO - data_loader -   input_ids: 101 4537 23630 4780 1112 1218 117 1115 5152 1108 18970 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   label: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n","12/14/2021 16:38:15 - INFO - data_loader -   Saving features into cached file data/original/cached_goemotions_bert-base-cased_50_test\n","12/14/2021 16:38:16 - INFO - __main__ -   ***** Running training *****\n","12/14/2021 16:38:16 - INFO - __main__ -     Num examples = 43410\n","12/14/2021 16:38:16 - INFO - __main__ -     Num Epochs = 10\n","12/14/2021 16:38:16 - INFO - __main__ -     Total train batch size = 16\n","12/14/2021 16:38:16 - INFO - __main__ -     Gradient Accumulation steps = 1\n","12/14/2021 16:38:16 - INFO - __main__ -     Total optimization steps = 27140\n","12/14/2021 16:38:16 - INFO - __main__ -     Logging steps = 1000\n","12/14/2021 16:38:16 - INFO - __main__ -     Save steps = 1000\n","Epoch:   0% 0/10 [00:00<?, ?it/s]\n","Iteration:   0% 0/2714 [00:00<?, ?it/s]\u001b[Aoutputs:\n","(tensor([[[ 0.5541,  0.3008,  0.1197,  ..., -0.1305,  0.2319, -0.0146],\n","         [ 0.6313,  0.1041,  0.4044,  ...,  0.2453,  0.1449, -0.0485],\n","         [ 0.3041,  0.3971,  0.4691,  ..., -0.0015,  0.0403,  0.0253],\n","         ...,\n","         [ 0.1480,  0.4686,  0.1373,  ..., -0.1663,  0.1705, -0.6376],\n","         [ 0.2065,  0.3440,  0.0724,  ...,  0.0725,  0.2336, -0.6801],\n","         [ 0.2496,  0.2246,  0.1651,  ...,  0.0146,  0.2792, -0.4015]],\n","\n","        [[ 0.5012,  0.3955,  0.2344,  ..., -0.1845,  0.1827, -0.2004],\n","         [ 0.3505, -0.1328,  0.2699,  ...,  0.1859,  0.0022, -0.0736],\n","         [ 0.0774,  0.2003,  0.1863,  ...,  0.2926, -0.1665, -0.2270],\n","         ...,\n","         [ 0.1942,  0.2819,  0.0525,  ...,  0.2650, -0.1911,  0.1216],\n","         [ 0.2768,  0.0853, -0.2105,  ...,  0.4413,  0.5000, -0.1787],\n","         [ 0.0315,  0.3287,  0.0992,  ..., -0.0042, -0.2903,  0.0145]],\n","\n","        [[ 0.5834,  0.0819,  0.2374,  ..., -0.4533,  0.3146,  0.1580],\n","         [ 0.6678, -0.3953,  0.5142,  ...,  0.0213,  0.1752,  0.1255],\n","         [ 0.9656,  0.1976,  0.0999,  ...,  0.6374,  0.2502,  0.3203],\n","         ...,\n","         [ 0.4370, -0.1542, -0.0036,  ...,  0.0944, -0.0083, -0.0083],\n","         [ 0.2863, -0.0666,  0.0028,  ...,  0.0843,  0.1815, -0.0649],\n","         [ 0.3710, -0.0145,  0.2834,  ...,  0.0800, -0.0304, -0.1244]],\n","\n","        ...,\n","\n","        [[ 0.5519,  0.3870,  0.1202,  ..., -0.0405,  0.2192, -0.0670],\n","         [ 0.1216, -0.0205,  0.0138,  ...,  0.3931,  0.0906, -0.0798],\n","         [ 0.4923,  0.8025, -0.1194,  ..., -0.3324, -0.1924, -0.1402],\n","         ...,\n","         [ 0.0047,  0.3537, -0.2225,  ..., -0.2163, -0.2541, -0.0672],\n","         [ 0.0674,  0.5757, -0.2236,  ..., -0.3602, -0.1701, -0.2884],\n","         [ 0.0118,  0.3286, -0.3112,  ..., -0.2471, -0.3953, -0.1240]],\n","\n","        [[ 0.5818,  0.1614,  0.0573,  ..., -0.1739,  0.3680, -0.2610],\n","         [ 0.4635, -0.3933,  0.2123,  ..., -0.0771,  0.0739,  0.0968],\n","         [ 1.4651,  0.0220, -0.0891,  ...,  0.5264,  0.0028,  0.5170],\n","         ...,\n","         [ 0.1235,  0.4858, -0.0185,  ...,  0.1404, -0.0541, -0.1694],\n","         [ 0.0096,  0.1609, -0.0565,  ...,  0.1240,  0.3971, -0.3028],\n","         [ 0.1804,  0.2452,  0.0818,  ...,  0.2691,  0.3127, -0.3106]],\n","\n","        [[ 0.4829,  0.4267, -0.0642,  ..., -0.4599,  0.2443,  0.0179],\n","         [ 0.5676, -0.3533,  0.4827,  ..., -0.1235,  0.1572, -0.0663],\n","         [-0.4475, -0.2185, -0.3939,  ..., -0.3042, -0.5257,  0.8772],\n","         ...,\n","         [ 0.2072,  0.1552, -0.1042,  ...,  0.0683,  0.2713,  0.0432],\n","         [ 0.2152,  0.4463,  0.0606,  ..., -0.0091,  0.2699, -0.3665],\n","         [-0.1838,  0.1157,  0.0150,  ...,  0.1781, -0.2417,  0.0194]]],\n","       grad_fn=<NativeLayerNormBackward>), tensor([[-0.6567,  0.4963,  0.9999,  ...,  1.0000, -0.8038,  0.9921],\n","        [-0.5589,  0.4362,  0.9996,  ...,  0.9998, -0.9285,  0.9910],\n","        [-0.7437,  0.3701,  0.9999,  ...,  1.0000, -0.8407,  0.9934],\n","        ...,\n","        [-0.6231,  0.4746,  0.9998,  ...,  0.9999, -0.8590,  0.9917],\n","        [-0.7066,  0.3874,  0.9997,  ...,  0.9999, -0.8983,  0.9853],\n","        [-0.7311,  0.4630,  0.9999,  ...,  1.0000, -0.7234,  0.9931]],\n","       grad_fn=<TanhBackward>))\n","pooled_output\n","tensor([[-0.6567,  0.4963,  0.9999,  ...,  1.0000, -0.8038,  0.9921],\n","        [-0.5589,  0.4362,  0.9996,  ...,  0.9998, -0.9285,  0.9910],\n","        [-0.7437,  0.3701,  0.9999,  ...,  1.0000, -0.8407,  0.9934],\n","        ...,\n","        [-0.6231,  0.4746,  0.9998,  ...,  0.9999, -0.8590,  0.9917],\n","        [-0.7066,  0.3874,  0.9997,  ...,  0.9999, -0.8983,  0.9853],\n","        [-0.7311,  0.4630,  0.9999,  ...,  1.0000, -0.7234,  0.9931]],\n","       grad_fn=<TanhBackward>)\n","pooled_output.shape torch.Size([16, 768])\n","logits: tensor([[-0.7276, -0.7398,  0.0331, -0.3895,  0.3348,  0.5714, -1.0015,  0.8095,\n","         -0.3737, -0.5253, -0.2369,  0.7458,  0.1519,  0.3888,  0.3222,  0.1552,\n","         -0.2803,  0.6367, -0.2515, -0.7745, -1.4876,  0.3475,  0.3455, -0.0464,\n","          0.2996,  0.8550,  0.2806,  0.5032],\n","        [-0.8004, -0.7229,  0.0797, -0.1354,  0.3119,  0.4911, -0.9072,  0.8146,\n","         -0.1950, -0.6896,  0.0045,  0.6129, -0.0371,  0.4763,  0.3648,  0.4554,\n","         -0.2204,  1.0087,  0.0269, -0.8700, -1.5020,  0.3197,  0.2624, -0.0357,\n","          0.2074,  0.9088,  0.2373,  0.5774],\n","        [-0.8805, -0.5598,  0.0392, -0.2006,  0.1286,  0.5356, -0.9698,  0.9192,\n","         -0.4544, -0.3099, -0.0689,  0.6014, -0.2376,  0.4843,  0.0191,  0.2989,\n","         -0.4546,  0.8293, -0.0954, -0.9486, -1.4503,  0.1820,  0.3379, -0.3020,\n","          0.0310,  1.0462, -0.1813,  0.3718],\n","        [-0.9608, -0.7678,  0.3154, -0.2443,  0.3995,  0.4827, -0.4277,  0.6067,\n","         -0.4487, -0.4589,  0.0788,  0.3395, -0.0582,  0.3212, -0.0038,  0.6340,\n","          0.0197,  0.7690, -0.1567, -0.9500, -1.3866, -0.1799,  0.2605,  0.1967,\n","          0.0272,  0.8371,  0.3100,  0.2944],\n","        [-0.6439, -0.5802,  0.1066, -0.1792,  0.3215,  0.7222, -0.9280,  0.8943,\n","         -0.4784, -0.6962,  0.1140,  0.6305, -0.3684,  0.3102,  0.1001,  0.3301,\n","          0.0036,  0.9512,  0.0962, -1.0483, -1.5947,  0.2597,  0.3526, -0.4246,\n","          0.1762,  0.8005,  0.4542,  0.3821],\n","        [-0.8360, -0.6943,  0.3608, -0.1852,  0.3274,  0.7855, -0.7484,  0.8490,\n","         -0.5427, -0.7681,  0.1580,  0.5947,  0.0500,  0.5107, -0.1155,  0.4401,\n","         -0.5047,  0.8477,  0.0964, -0.3644, -1.3410,  0.2681,  0.5607, -0.2034,\n","          0.2219,  1.0324,  0.2509,  0.4223],\n","        [-0.9866, -0.7121,  0.4214, -0.0944,  0.4594,  0.3998, -1.2365,  0.5804,\n","         -0.4918, -0.6192, -0.1426,  0.7049, -0.2763,  0.2482,  0.1670,  0.1496,\n","         -0.1210,  1.0683, -0.0737, -0.6315, -1.5286,  0.3435,  0.3085, -0.1509,\n","          0.4931,  0.8682,  0.4199,  0.5432],\n","        [-1.0200, -0.4085,  0.0545, -0.4952,  0.4705,  0.8153, -0.7930,  0.9893,\n","         -0.4231, -0.5318, -0.1752,  0.3324,  0.0705,  0.3387, -0.1213,  0.3603,\n","         -0.2046,  0.8583,  0.0662, -0.6827, -1.3903,  0.2077,  0.0549,  0.1105,\n","          0.1465,  1.0070,  0.4798,  0.6453],\n","        [-0.8641, -0.8351,  0.2299, -0.3140,  0.4048,  0.6098, -1.2790,  0.7952,\n","         -0.2895, -0.9574,  0.0515,  0.6774,  0.0490,  0.2870,  0.1230,  0.3948,\n","         -0.2674,  1.1261, -0.0525, -0.5006, -1.4735,  0.2524,  0.1886, -0.3648,\n","          0.0445,  1.1025,  0.1389,  0.7582],\n","        [-0.4702, -0.6188,  0.0301, -0.5862,  0.4321,  0.4628, -1.2212,  0.7508,\n","          0.0048, -0.5393, -0.1727,  0.5888, -0.3706,  0.4886, -0.0889,  0.1717,\n","         -0.1179,  0.8232, -0.1118, -0.6743, -1.2247,  0.0996,  0.4635,  0.1270,\n","          0.1684,  0.9893,  0.1958,  0.3936],\n","        [-0.9969, -0.6961, -0.2479, -0.0668,  0.6148,  0.7896, -1.0140,  0.5305,\n","         -0.3161, -0.5245, -0.2832,  0.5718,  0.0022,  0.7086, -0.0624,  0.2282,\n","         -0.3991,  1.0124,  0.0180, -0.7541, -1.2518,  0.3557,  0.2913, -0.3280,\n","          0.3282,  0.6352,  0.1897,  0.6500],\n","        [-0.7352, -0.6692,  0.1587, -0.3674,  0.5014,  0.3871, -1.2693,  0.4818,\n","         -0.2284, -0.6244,  0.2746,  0.7214, -0.1466,  0.3314,  0.1949,  0.3334,\n","         -0.1031,  0.9869, -0.2045, -0.8543, -1.5569,  0.1570,  0.1431, -0.2883,\n","          0.0909,  0.9288,  0.2466,  0.6612],\n","        [-0.6429, -0.3869,  0.0228,  0.0241,  0.4016,  0.5619, -1.0348,  0.7501,\n","         -0.4064, -0.6821,  0.1802,  0.4531, -0.4099,  0.6792, -0.0076,  0.4212,\n","         -0.2081,  0.9218,  0.0135, -0.3714, -1.4430,  0.0721,  0.0922, -0.3675,\n","          0.2191,  1.2217,  0.2014,  0.4920],\n","        [-0.7383, -0.6615, -0.0409, -0.6061,  0.5210,  0.4382, -1.1859,  1.0023,\n","         -0.2032, -0.4315,  0.0435,  0.7039,  0.0597,  0.4283, -0.1825,  0.3193,\n","         -0.3086,  0.7412,  0.0660, -0.5194, -1.6583,  0.3173,  0.3351, -0.0291,\n","          0.4169,  0.9874,  0.3094,  0.4166],\n","        [-0.8894, -0.6823,  0.1742, -0.1757,  0.6612,  0.5977, -0.8021,  0.6774,\n","         -0.2364, -0.3764,  0.1365,  0.9139, -0.2732,  0.5898, -0.0597,  0.3236,\n","         -0.2380,  0.9206, -0.0134, -0.3823, -1.5112,  0.3085,  0.2576, -0.1912,\n","          0.5290,  0.7621,  0.0957,  0.4360],\n","        [-0.9152, -0.5931,  0.0434, -0.3380,  0.0959,  0.7400, -1.0471,  0.7803,\n","         -0.1442, -0.3791, -0.3491,  0.6315, -0.3728,  0.5323, -0.1531,  0.2375,\n","         -0.2266,  0.8727, -0.0320, -0.7105, -1.6198,  0.1956,  0.3853, -0.2424,\n","          0.2820,  0.7658,  0.3243,  0.3633]], grad_fn=<AddmmBackward>)\n","logits.shape\n","torch.Size([16, 28])\n","Iteration:   0% 0/2714 [00:08<?, ?it/s]\n","Epoch:   0% 0/10 [00:08<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"run_goemotions.py\", line 336, in <module>\n","    main(cli_args)\n","  File \"run_goemotions.py\", line 301, in main\n","    global_step, tr_loss = train(args, model, tokenizer, train_dataset, dev_dataset, test_dataset)\n","  File \"run_goemotions.py\", line 109, in train\n","    loss.backward()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/tensor.py\", line 195, in backward\n","    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 99, in backward\n","    allow_unreachable=True)  # allow_unreachable flag\n","KeyboardInterrupt\n"]}],"source":["!python3 run_goemotions.py --taxonomy original"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O2Bv26jw7uM9"},"outputs":[],"source":["label2id = {\n","    \"admiration\": 0,\n","    \"amusement\": 1,\n","    \"anger\": 2,\n","    \"annoyance\": 3,\n","    \"approval\": 4,\n","    \"caring\": 5,\n","    \"confusion\": 6,\n","    \"curiosity\": 7,\n","    \"desire\": 8,\n","    \"disappointment\": 9,\n","    \"disapproval\": 10,\n","    \"disgust\": 11,\n","    \"embarrassment\": 12,\n","    \"excitement\": 13,\n","    \"fear\": 14,\n","    \"gratitude\": 15,\n","    \"grief\": 16,\n","    \"joy\": 17,\n","    \"love\": 18,\n","    \"nervousness\": 19,\n","    \"neutral\": 27,\n","    \"optimism\": 20,\n","    \"pride\": 21,\n","    \"realization\": 22,\n","    \"relief\": 23,\n","    \"remorse\": 24,\n","    \"sadness\": 25,\n","    \"surprise\": 26\n","}\n","\n","id2label =  {\n","    \"0\": \"admiration\",\n","    \"1\": \"amusement\",\n","    \"10\": \"disapproval\",\n","    \"11\": \"disgust\",\n","    \"12\": \"embarrassment\",\n","    \"13\": \"excitement\",\n","    \"14\": \"fear\",\n","    \"15\": \"gratitude\",\n","    \"16\": \"grief\",\n","    \"17\": \"joy\",\n","    \"18\": \"love\",\n","    \"19\": \"nervousness\",\n","    \"2\": \"anger\",\n","    \"20\": \"optimism\",\n","    \"21\": \"pride\",\n","    \"22\": \"realization\",\n","    \"23\": \"relief\",\n","    \"24\": \"remorse\",\n","    \"25\": \"sadness\",\n","    \"26\": \"surprise\",\n","    \"27\": \"neutral\",\n","    \"3\": \"annoyance\",\n","    \"4\": \"approval\",\n","    \"5\": \"caring\",\n","    \"6\": \"confusion\",\n","    \"7\": \"curiosity\",\n","    \"8\": \"desire\",\n","    \"9\": \"disappointment\"\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_jeOKVq33A_"},"outputs":[],"source":["import torch.nn as nn\n","from transformers import BertPreTrainedModel, BertModel\n","from transformers import RobertaModel\n","from transformers import XLNetPreTrainedModel, XLNetModel\n","\n","class XLNetForMultiLabelClassification(XLNetPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","\n","        self.xlnet = XLNetModel(config)\n","        # self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n","        self.loss_fct = nn.BCEWithLogitsLoss()\n","        self.init_weights()\n","        \n","\n","    def forward(\n","            self,\n","            input_ids=None,\n","            attention_mask=None,\n","            token_type_ids=None,\n","            position_ids=None,\n","            head_mask=None,\n","            inputs_embeds=None,\n","            labels=None,\n","    ):\n","        outputs = self.xlnet(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            # position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","        )\n","        pooled_output = outputs[1]\n","\n","        # pooled_output = self.dropout(pooled_output)\n","        logits = self.classifier(pooled_output)\n","\n","        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n","\n","        if labels is not None:\n","            loss = self.loss_fct(logits, labels)\n","            outputs = (loss,) + outputs\n","\n","        return outputs  # (loss), logits, (hidden_states), (attentions)\n","\n","\n","class RobertaForMultiLabelClassification(BertPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","\n","        self.bert = RobertaModel(config)\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n","        self.loss_fct = nn.BCEWithLogitsLoss()\n","\n","        self.init_weights()\n","\n","    def forward(\n","            self,\n","            input_ids=None,\n","            attention_mask=None,\n","            token_type_ids=None,\n","            position_ids=None,\n","            head_mask=None,\n","            inputs_embeds=None,\n","            labels=None,\n","    ):\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","        )\n","        # print(\"outputs:\")\n","        # print(outputs)\n","\n","        pooled_output = outputs[1]\n","        # print(\"pooled_output\")\n","        # print(pooled_output)\n","\n","        # print(\"pooled_output.shape\", pooled_output.shape)\n","\n","        pooled_output = self.dropout(pooled_output)\n","\n","        logits = self.classifier(pooled_output)\n","\n","        # print(\"logits:\", logits)\n","        # print(\"logits.shape\")\n","        # print(logits.shape)\n","\n","        # add hidden states and attention if they are here\n","        outputs = (logits,) + outputs[2:]\n","\n","        if labels is not None:\n","            loss = self.loss_fct(logits, labels)\n","            outputs = (loss,) + outputs\n","\n","        return outputs  # (loss), logits, (hidden_states), (attentions)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"uV9_e3Q1Q0sX"},"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"37rJAPda7Nju"},"outputs":[],"source":["from transformers import (\n","    BertConfig,\n","    BertTokenizer,\n","    XLNetConfig,\n","    XLNetTokenizer,\n","      RobertaConfig,\n","    RobertaTokenizer,\n","    AdamW,\n","    get_linear_schedule_with_warmup\n",")\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pTt3bGDV7dBy"},"outputs":[],"source":["from attrdict import AttrDict\n","import json\n","import argparse\n","import json\n","import logging\n","import os\n","import glob\n","\n","import numpy as np\n","import torch\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from tqdm import tqdm, trange\n","from attrdict import AttrDict"]},{"cell_type":"code","source":["config_filename = \"{}.json\".format(\"original-roberta\")\n","with open(os.path.join(\"config\", config_filename)) as f:\n","    args = AttrDict(json.load(f))\n","\n","config = RobertaConfig.from_pretrained(\n","            \"/content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-2000/\",\n","            num_labels=len(id2label),\n","            finetuning_task=args.task,\n","            id2label=id2label,\n","            label2id=label2id\n","        )\n","        \n","model = RobertaForMultiLabelClassification.from_pretrained(\n","    \"/content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-2000/\",\n","    config=config,\n","    # encoding='latin1'\n",")\n","\n","# TODO: Move the model to the colab to see if it's a path problem or what???\n"],"metadata":{"id":"KPw364OeJpUp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["args.model_name_or_path"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"4dPKYoa9Lsu7","executionInfo":{"status":"ok","timestamp":1639623893068,"user_tz":300,"elapsed":139,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"}},"outputId":"1e4113e5-c9e4-4ba8-9890-49036a5cccd6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-2000/pytorch_model.bin'"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/EECS595 Final Project/roberta/ckpt/checkpoint-2000/\" ."],"metadata":{"id":"B4jB4uZnM1FF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_aWPSj2KNCmB","executionInfo":{"status":"ok","timestamp":1639623962962,"user_tz":300,"elapsed":128,"user":{"displayName":"Khuwaja Faryab","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg61PbkdIRDYcLcmPBpks3lhhfJANTS1Jcf-ZnkJKA=s64","userId":"15446774190644314074"}},"outputId":"2c238f49-dca3-4927-8411-dbac21695fa5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["config\t\tGoEmotions-pytorch\tpytorch_model.bin  utils.py\n","data\t\tLICENSE\t\t\tREADME.md\n","data_loader.py\tmodel.py\t\trequirements.txt\n","drive\t\tmultilabel_pipeline.py\trun_goemotions.py\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["5fbd1aedd27a4254af4dad03bd12e10a","f332f0f71dfa4244bb50ab77aca5d45c","a186232a832547328db7c573d02c9f89","7265c8dff1ab42a1ae538fe7d5cab156","1ca18ba0473848299dab9e74af3c1f44","0d5397bd72b34faab18129ecbbc270fe","daeed3ea163747f49c50c2af9bbbdf4f","4bf3d5a3a0274e6dbbb4285206c75c96","001df28cd4d64c878a38d5a938a6aea6","69dfd5c67b834f97910ab3c2280289b0","795d4a17c3e1477a8955d3ef9cce0b59","ca1117b0c731451bae8e6bf63832025f","d054809768a14852b4211dc320945036","963455a597554969a45c3b74014c6b39","c97955e8bcd94b84a5bfbddd4c275c43","5db3c5d61d5c430aa0e6a6b60ab1ac19","15a1ea079ee34654a9c0ce75e55e8566","213f287bda6b4f66b00fffb1b343ccc1","28106956373d441eb2b4b7c4df59ac14","1bce2d8adc3242ada6736747d72e305d","d3b06bd6a93e470ea0e6ada21915babb","266286d7b9a44fb987ed276d4ac39dbe","324442b6e4434a288888284697d3e571","46b4bd34b8a04c4eb5b5f1622bd743b2","9346f5e8d0d649c583502dbb6202bbc3","f92e41c237df4557b4b80bd4bdf396a8","f2be9051b4d24d2cbd91e662d647b469","e40c00d495e542b5971a168aaa141253","52dca1db9cb348119afeff0d081e979a","df4c5688410b47308e798c24e15124a4","5d844e263894462d8ac162a447562e02","ea1f0142522c427b8a39b03957437078","d9f70aff04c941f5a33b557c3134defe"]},"executionInfo":{"elapsed":18210,"status":"ok","timestamp":1639490004640,"user":{"displayName":"Faryab Haye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16087714056557341269"},"user_tz":300},"id":"Wz2ZDU7c68nY","outputId":"5aee0848-a825-44d6-e2c8-f6a1bf115c47"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5fbd1aedd27a4254af4dad03bd12e10a","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/760 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca1117b0c731451bae8e6bf63832025f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/798k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"324442b6e4434a288888284697d3e571","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/467M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["\n","\n","\n","\n","\n","config_filename = \"{}.json\".format(\"original-xlnet\")\n","with open(os.path.join(\"config\", config_filename)) as f:\n","    args = AttrDict(json.load(f))\n","\n","config = XLNetConfig.from_pretrained(\n","            args.model_name_or_path,\n","            num_labels=27,\n","            finetuning_task=args.task,\n","            id2label=id2label,\n","            label2id=label2id\n",")\n","tokenizer = XLNetTokenizer.from_pretrained(\n","    args.tokenizer_name_or_path,\n",")\n","model = XLNetForMultiLabelClassification.from_pretrained(\n","    args.model_name_or_path,\n","    config=config\n",")"]},{"cell_type":"code","source":["goemotions = MultiLabelPipeline(\n","    model=model,\n","    tokenizer=tokenizer,\n","    threshold=0.3\n",")\n","\n","texts = [\n","    \"Hey that's a thought! Maybe we need [NAME] to be the celebrity vaccine endorsement!\",\n","    \"it’s happened before?! love my hometown of beautiful new ken 😂😂\",\n","    \"I love you, brother.\",\n","    \"Troll, bro. They know they're saying stupid shit. The motherfucker does nothing but stink up libertarian subs talking shit\",\n","]\n","\n","pprint(goemotions(texts))\n","\n","\n"],"metadata":{"id":"5GZpsd9SOI7U"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pqx-HvXa7Kmf"},"outputs":[],"source":["from torchinfo import summary\n","summary(model, (3, 28, 28))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddHdVxhA_XF0"},"outputs":[],"source":["summary(model, (3, 28, 28))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lwaSt0XrAeRc"},"outputs":[],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4588,"status":"ok","timestamp":1639347404285,"user":{"displayName":"Faryab Haye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16087714056557341269"},"user_tz":300},"id":"2kcsboVkt4Be","outputId":"0b7c25c3-4ab0-4f26-f511-cf51f06d535f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torchinfo\n","  Downloading torchinfo-1.5.4-py3-none-any.whl (19 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.5.4\n"]}],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UUawBvQnuCtR"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":434},"executionInfo":{"elapsed":152,"status":"error","timestamp":1639347495585,"user":{"displayName":"Faryab Haye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16087714056557341269"},"user_tz":300},"id":"pUq3fnjvuG7v","outputId":"aabcf7db-c39f-4b92-b891-89dfbe5e6fd2"},"outputs":[{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-4db4230654d6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'position_ids'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-870a80c6b1c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     )\n\u001b[1;32m    194\u001b[0m     summary_list = forward_pass(\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_forward_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     )\n\u001b[1;32m    197\u001b[0m     \u001b[0mformatting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFormattingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;34m\"Failed to run torchinfo. See above stack traces for more details. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;34mf\"Executed layers up to: {executed_layers}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         ) from e\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhooks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"]}],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yx2D97fFuIFG"},"outputs":[],"source":["t = torch.tensor([[1., -1.], [1., -1.]])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1639490468576,"user":{"displayName":"Faryab Haye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16087714056557341269"},"user_tz":300},"id":"1f8IBJQSPy-h","outputId":"51c9e2a0-616d-4dcb-af9b-4752250a8244"},"outputs":[{"data":{"text/plain":["torch.Size([2, 2])"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["t.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":251,"status":"ok","timestamp":1639490474657,"user":{"displayName":"Faryab Haye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16087714056557341269"},"user_tz":300},"id":"y3nTc3AHPzeN","outputId":"619ddaec-c24c-42da-8873-5b81418fb2be"},"outputs":[{"data":{"text/plain":["tensor([[ 1., -1.],\n","        [ 1., -1.]])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["t"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":231,"status":"ok","timestamp":1639490505778,"user":{"displayName":"Faryab Haye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16087714056557341269"},"user_tz":300},"id":"04DFvagtP1Bf","outputId":"89abee8b-13be-42de-8743-836571a6bca4"},"outputs":[{"data":{"text/plain":["XLNetForMultiLabelClassification(\n","  (xlnet): XLNetModel(\n","    (word_embedding): Embedding(32000, 768)\n","    (layer): ModuleList(\n","      (0): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (6): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (7): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (8): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (9): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (10): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (11): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (classifier): Linear(in_features=768, out_features=28, bias=True)\n","  (loss_fct): BCEWithLogitsLoss()\n",")"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Xskmi4qP8nX"},"outputs":[],"source":["class BertForMultiLabelClassification(BertPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.num_labels = config.num_labels\n","\n","        self.bert = BertModel(config)\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.classifier = nn.Linear(config.hidden_size, self.config.num_labels)\n","        self.loss_fct = nn.BCEWithLogitsLoss()\n","\n","        self.init_weights()\n","\n","    def forward(\n","            self,\n","            input_ids=None,\n","            attention_mask=None,\n","            token_type_ids=None,\n","            position_ids=None,\n","            head_mask=None,\n","            inputs_embeds=None,\n","            labels=None,\n","    ):\n","        outputs = self.bert(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            token_type_ids=token_type_ids,\n","            position_ids=position_ids,\n","            head_mask=head_mask,\n","            inputs_embeds=inputs_embeds,\n","        )\n","        pooled_output = outputs[1]\n","\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.classifier(pooled_output)\n","\n","        outputs = (logits,) + outputs[2:]  # add hidden states and attention if they are here\n","\n","        if labels is not None:\n","            loss = self.loss_fct(logits, labels)\n","            outputs = (loss,) + outputs\n","\n","        return outputs  # (loss), logits, (hidden_states), (attentions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["fa0c7f0b8f0f47c18756dae1d5919abc","94f2bb2fd2304fc795b8f924db35c8fd","4b32dfd0517b44458928ff22c8ab6dea","6def8847f5a146cdbe3d6b43a78083c9","8e0639d3ea41441abbbeccfa6632c31f","aa981e79ce2d42f1af631e08924555f2","05349e963ae6484f8d8c9d0234caf146","e1842d82d43b4465be3e8937a7f4f5f0","1f1955db0e474b0e9ff41078f56cd026","153b9ade9d084c75ad824781010bccbd","71fca287feb2480fa74e633c4e8b094a","21276c305e514f818c0edbc95ac2144e","618db510379d4e63a8c5504857a716df","dc143698ed504b0f9f0eaeb5634f4f70","efa143e2cd7a4ae09edcfb48233a9489","a4f85c81a0514fed94e023c3782c5926","709f3a52b7e047fa8e1d22a630d82ef1","f9bd5130682e45c4ba76b1bef887577c","906386f98d8f4fd3927f49a2d2f405ff","66be450a7c854b1b8eabd376df42c3c6","450b23d0b2de4e098cda2d815b376d9f","b629d933b9c841aa88708396ea6d08e7"]},"executionInfo":{"elapsed":14849,"status":"ok","timestamp":1639492352208,"user":{"displayName":"Faryab Haye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16087714056557341269"},"user_tz":300},"id":"VmgYvjuaWm7f","outputId":"b9a31901-9921-4749-c6d0-8910e6e7b692"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa0c7f0b8f0f47c18756dae1d5919abc","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21276c305e514f818c0edbc95ac2144e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/436M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["config_filename = \"{}.json\".format(\"original\")\n","with open(os.path.join(\"config\", config_filename)) as f:\n","    args = AttrDict(json.load(f))\n","\n","config = BertConfig.from_pretrained(\n","            args.model_name_or_path,\n","            num_labels=27,\n","            finetuning_task=args.task,\n","            id2label=id2label,\n","            label2id=label2id\n",")\n","\n","bertmodel = BertForMultiLabelClassification.from_pretrained(\n","    args.model_name_or_path,\n","    config=config\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":204,"status":"ok","timestamp":1639492357086,"user":{"displayName":"Faryab Haye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16087714056557341269"},"user_tz":300},"id":"SqXUxj7-Wovw","outputId":"19164a7e-490d-4da5-89ac-99a10964c7ee"},"outputs":[{"data":{"text/plain":["BertForMultiLabelClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=28, bias=True)\n","  (loss_fct): BCEWithLogitsLoss()\n",")"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["bertmodel"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":208,"status":"ok","timestamp":1639492378082,"user":{"displayName":"Faryab Haye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16087714056557341269"},"user_tz":300},"id":"KdWXP7h5XAn2","outputId":"e30dfd07-c0ce-47e4-a55e-cd8d9da8bfcb"},"outputs":[{"data":{"text/plain":["XLNetForMultiLabelClassification(\n","  (xlnet): XLNetModel(\n","    (word_embedding): Embedding(32000, 768)\n","    (layer): ModuleList(\n","      (0): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (1): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (2): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (3): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (4): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (5): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (6): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (7): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (8): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (9): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (10): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (11): XLNetLayer(\n","        (rel_attn): XLNetRelativeAttention(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ff): XLNetFeedForward(\n","          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n","          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (classifier): Linear(in_features=768, out_features=28, bias=True)\n","  (loss_fct): BCEWithLogitsLoss()\n",")"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":177,"referenced_widgets":["504ce6e672cb41ce936fb5aa00cdee1a","a8621e8880cd4535b833b2459ae01558","48b90e7dd340484aa904d62032864f4c","7173a7469c5147feba23e3ecc4ae871f","56405a2dd3fa465c9dc61e0f822afc62","fd38abe72f534c4bbc05def71e195460","373a3d02f804424d9f29499a0273c1dc","f94dd538cc7f4ba29dd888416c40fe4f","cbccfdaa773c426aabc5342c8a204eab","304bc80569a3457dae1703afabb418dd","8575776662c74510af913e0d50e55afc","42fab95ddcb6474e84584b36da934567","11f7214f41a2439fb4ee6a5f4c551f14","ded4b4a3b35a4ac586b9bde01ae53d86","a40b3a7a209c4a5497326b11bea3a4ff","5f4e652d0abb4718a3da7d301462205f","a68128e7c5d14c67bf0a247ca31338cf","25666ac241f545ee84e4299be150590e","b4bef094940644e0b6276feaabad3cc0","2609e55b32894cfb91e7378f87473bb4","0b98bc3148e04395889c22d17bd2f6b8","d173dc9019e742318b8fb53e49f77b7b","365cc6f248884f19ac1d35fd97e48d25","fd59172c7d814475bd53470d589c8f21","1505b960c3724b7a81d042be7f816dc0","0892b94df50d4cd58a368ff59bb54ee8","c3a021aedc334d5db31e3d115749baa6","2ff0d37922e34f7885c8d3abb50e88dc","f3eb7e5660c64640a36f212dc3637dbe","47645a3344c641e788304cd673536839","b020e87c20e64c42b9b6283edaf4295c","581cafcd25d74e85b769e63aca3e6a3b","acfd16db66074312a13ad94a9dfbabb2","57e1fb49004e4afd8c4296e3be80a49c","8d9df52b493a4a09ab89da5aa42693e2","2edcf09038864d609126809d3607b336","24a770e994d846299edbd5e863782974","0eb9b69a28a44ee3a55b8a03c68117e0","8ef248669c2c47119e11ec5da0d54ab3","f25c31e8895049c183f2eaf2756a5c91","0e311d0060134b1fa1fa8b347774e200","6eb05b57ff794c668f4a42aa22b6624f","a81720172d0e467aa938fb1a5890ce21","b2f180f8499443a78178035ef1902c2d","3b5107d5c754420e97c060faa8a51f82","8ccc2745b03c4b118213bcad070f631a","b572c51524134b4390dad767024a3b2e","1d73ea98b2694738b5d78adb335af812","a73662d822a44c91a6a78efd9f8818ba","912c7f7ca4244673aa85943597d63a54","211f58dff523491794a85852410834c4","fa3ec1f008ed416ca61add380c601e33","fdc9c55991814ab188388dd348bfe042","f2c2f686317f4130aea52043f7d23a46","3e3b6c410a1948f586e90f52b45a561d"]},"executionInfo":{"elapsed":20149,"status":"ok","timestamp":1639492502875,"user":{"displayName":"Faryab Haye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16087714056557341269"},"user_tz":300},"id":"dntOcsezXFrj","outputId":"3679ed90-3433-413f-8ee4-c2bb75c93b91"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"504ce6e672cb41ce936fb5aa00cdee1a","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/242k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42fab95ddcb6474e84584b36da934567","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/188 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"365cc6f248884f19ac1d35fd97e48d25","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/243 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"57e1fb49004e4afd8c4296e3be80a49c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/716 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b5107d5c754420e97c060faa8a51f82","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/433M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = BertTokenizer.from_pretrained(\"monologg/bert-base-cased-goemotions-group\")\n","model = BertForMultiLabelClassification.from_pretrained(\"monologg/bert-base-cased-goemotions-group\")\n","\n","goemotions_bert = MultiLabelPipeline(\n","    model=model,\n","    tokenizer=tokenizer,\n","    threshold=0.3\n",")\n","\n","texts = [\n","    \"Hey that's a thought! Maybe we need [NAME] to be the celebrity vaccine endorsement!\",\n","    \"it’s happened before?! love my hometown of beautiful new ken 😂😂\",\n","    \"I love you, brother.\",\n","    \"Troll, bro. They know they're saying stupid shit. The motherfucker does nothing but stink up libertarian subs talking shit\",\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":167},"executionInfo":{"elapsed":205,"status":"error","timestamp":1639492505493,"user":{"displayName":"Faryab Haye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16087714056557341269"},"user_tz":300},"id":"JMLTxOwmXUma","outputId":"db259024-1aed-426f-f8c1-0258476f014f"},"outputs":[{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-56-cd5777e0083e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: 'BertTokenizer' object is not callable"]}],"source":["tokenizer(texts)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PUlJBn8eXk3K"},"outputs":[],"source":["ff = nn.Linear(786, 28)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":238,"status":"ok","timestamp":1639493708253,"user":{"displayName":"Faryab Haye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16087714056557341269"},"user_tz":300},"id":"_lTIL6TIb8Vr","outputId":"5faf02ee-226f-4fff-81d2-c56ca9919638"},"outputs":[{"data":{"text/plain":["torch.Size([16, 50, 28])"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["ff(torch.rand(16, 50, 786)).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VQ7Lk4FvcJUu"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"name":"roberta-pytorch-go-emotions.ipynb","provenance":[],"collapsed_sections":["QPX7peAaRCM5"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"001df28cd4d64c878a38d5a938a6aea6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"05349e963ae6484f8d8c9d0234caf146":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0892b94df50d4cd58a368ff59bb54ee8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_581cafcd25d74e85b769e63aca3e6a3b","placeholder":"​","style":"IPY_MODEL_acfd16db66074312a13ad94a9dfbabb2","value":" 243/243 [00:00&lt;00:00, 7.07kB/s]"}},"0b98bc3148e04395889c22d17bd2f6b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d5397bd72b34faab18129ecbbc270fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e311d0060134b1fa1fa8b347774e200":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0eb9b69a28a44ee3a55b8a03c68117e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11f7214f41a2439fb4ee6a5f4c551f14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a68128e7c5d14c67bf0a247ca31338cf","placeholder":"​","style":"IPY_MODEL_25666ac241f545ee84e4299be150590e","value":"Downloading: 100%"}},"1505b960c3724b7a81d042be7f816dc0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_47645a3344c641e788304cd673536839","max":243,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b020e87c20e64c42b9b6283edaf4295c","value":243}},"153b9ade9d084c75ad824781010bccbd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15a1ea079ee34654a9c0ce75e55e8566":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bce2d8adc3242ada6736747d72e305d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ca18ba0473848299dab9e74af3c1f44":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d73ea98b2694738b5d78adb335af812":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2c2f686317f4130aea52043f7d23a46","placeholder":"​","style":"IPY_MODEL_3e3b6c410a1948f586e90f52b45a561d","value":" 433M/433M [00:11&lt;00:00, 38.9MB/s]"}},"1f1955db0e474b0e9ff41078f56cd026":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"211f58dff523491794a85852410834c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21276c305e514f818c0edbc95ac2144e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_618db510379d4e63a8c5504857a716df","IPY_MODEL_dc143698ed504b0f9f0eaeb5634f4f70","IPY_MODEL_efa143e2cd7a4ae09edcfb48233a9489"],"layout":"IPY_MODEL_a4f85c81a0514fed94e023c3782c5926"}},"213f287bda6b4f66b00fffb1b343ccc1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24a770e994d846299edbd5e863782974":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a81720172d0e467aa938fb1a5890ce21","placeholder":"​","style":"IPY_MODEL_b2f180f8499443a78178035ef1902c2d","value":" 716/716 [00:00&lt;00:00, 16.3kB/s]"}},"25666ac241f545ee84e4299be150590e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2609e55b32894cfb91e7378f87473bb4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"266286d7b9a44fb987ed276d4ac39dbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28106956373d441eb2b4b7c4df59ac14":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2edcf09038864d609126809d3607b336":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e311d0060134b1fa1fa8b347774e200","max":716,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6eb05b57ff794c668f4a42aa22b6624f","value":716}},"2ff0d37922e34f7885c8d3abb50e88dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"304bc80569a3457dae1703afabb418dd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"324442b6e4434a288888284697d3e571":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46b4bd34b8a04c4eb5b5f1622bd743b2","IPY_MODEL_9346f5e8d0d649c583502dbb6202bbc3","IPY_MODEL_f92e41c237df4557b4b80bd4bdf396a8"],"layout":"IPY_MODEL_f2be9051b4d24d2cbd91e662d647b469"}},"365cc6f248884f19ac1d35fd97e48d25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd59172c7d814475bd53470d589c8f21","IPY_MODEL_1505b960c3724b7a81d042be7f816dc0","IPY_MODEL_0892b94df50d4cd58a368ff59bb54ee8"],"layout":"IPY_MODEL_c3a021aedc334d5db31e3d115749baa6"}},"373a3d02f804424d9f29499a0273c1dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b5107d5c754420e97c060faa8a51f82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ccc2745b03c4b118213bcad070f631a","IPY_MODEL_b572c51524134b4390dad767024a3b2e","IPY_MODEL_1d73ea98b2694738b5d78adb335af812"],"layout":"IPY_MODEL_a73662d822a44c91a6a78efd9f8818ba"}},"3e3b6c410a1948f586e90f52b45a561d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42fab95ddcb6474e84584b36da934567":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_11f7214f41a2439fb4ee6a5f4c551f14","IPY_MODEL_ded4b4a3b35a4ac586b9bde01ae53d86","IPY_MODEL_a40b3a7a209c4a5497326b11bea3a4ff"],"layout":"IPY_MODEL_5f4e652d0abb4718a3da7d301462205f"}},"450b23d0b2de4e098cda2d815b376d9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46b4bd34b8a04c4eb5b5f1622bd743b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e40c00d495e542b5971a168aaa141253","placeholder":"​","style":"IPY_MODEL_52dca1db9cb348119afeff0d081e979a","value":"Downloading: 100%"}},"47645a3344c641e788304cd673536839":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48b90e7dd340484aa904d62032864f4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f94dd538cc7f4ba29dd888416c40fe4f","max":242444,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cbccfdaa773c426aabc5342c8a204eab","value":242444}},"4b32dfd0517b44458928ff22c8ab6dea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1842d82d43b4465be3e8937a7f4f5f0","max":433,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f1955db0e474b0e9ff41078f56cd026","value":433}},"4bf3d5a3a0274e6dbbb4285206c75c96":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"504ce6e672cb41ce936fb5aa00cdee1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a8621e8880cd4535b833b2459ae01558","IPY_MODEL_48b90e7dd340484aa904d62032864f4c","IPY_MODEL_7173a7469c5147feba23e3ecc4ae871f"],"layout":"IPY_MODEL_56405a2dd3fa465c9dc61e0f822afc62"}},"52dca1db9cb348119afeff0d081e979a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"56405a2dd3fa465c9dc61e0f822afc62":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57e1fb49004e4afd8c4296e3be80a49c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d9df52b493a4a09ab89da5aa42693e2","IPY_MODEL_2edcf09038864d609126809d3607b336","IPY_MODEL_24a770e994d846299edbd5e863782974"],"layout":"IPY_MODEL_0eb9b69a28a44ee3a55b8a03c68117e0"}},"581cafcd25d74e85b769e63aca3e6a3b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d844e263894462d8ac162a447562e02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5db3c5d61d5c430aa0e6a6b60ab1ac19":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f4e652d0abb4718a3da7d301462205f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fbd1aedd27a4254af4dad03bd12e10a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f332f0f71dfa4244bb50ab77aca5d45c","IPY_MODEL_a186232a832547328db7c573d02c9f89","IPY_MODEL_7265c8dff1ab42a1ae538fe7d5cab156"],"layout":"IPY_MODEL_1ca18ba0473848299dab9e74af3c1f44"}},"618db510379d4e63a8c5504857a716df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_709f3a52b7e047fa8e1d22a630d82ef1","placeholder":"​","style":"IPY_MODEL_f9bd5130682e45c4ba76b1bef887577c","value":"Downloading: 100%"}},"66be450a7c854b1b8eabd376df42c3c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"69dfd5c67b834f97910ab3c2280289b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6def8847f5a146cdbe3d6b43a78083c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_153b9ade9d084c75ad824781010bccbd","placeholder":"​","style":"IPY_MODEL_71fca287feb2480fa74e633c4e8b094a","value":" 433/433 [00:00&lt;00:00, 11.1kB/s]"}},"6eb05b57ff794c668f4a42aa22b6624f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"709f3a52b7e047fa8e1d22a630d82ef1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7173a7469c5147feba23e3ecc4ae871f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_304bc80569a3457dae1703afabb418dd","placeholder":"​","style":"IPY_MODEL_8575776662c74510af913e0d50e55afc","value":" 242k/242k [00:00&lt;00:00, 769kB/s]"}},"71fca287feb2480fa74e633c4e8b094a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7265c8dff1ab42a1ae538fe7d5cab156":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69dfd5c67b834f97910ab3c2280289b0","placeholder":"​","style":"IPY_MODEL_795d4a17c3e1477a8955d3ef9cce0b59","value":" 760/760 [00:00&lt;00:00, 18.0kB/s]"}},"795d4a17c3e1477a8955d3ef9cce0b59":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8575776662c74510af913e0d50e55afc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ccc2745b03c4b118213bcad070f631a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_912c7f7ca4244673aa85943597d63a54","placeholder":"​","style":"IPY_MODEL_211f58dff523491794a85852410834c4","value":"Downloading: 100%"}},"8d9df52b493a4a09ab89da5aa42693e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ef248669c2c47119e11ec5da0d54ab3","placeholder":"​","style":"IPY_MODEL_f25c31e8895049c183f2eaf2756a5c91","value":"Downloading: 100%"}},"8e0639d3ea41441abbbeccfa6632c31f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ef248669c2c47119e11ec5da0d54ab3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"906386f98d8f4fd3927f49a2d2f405ff":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"912c7f7ca4244673aa85943597d63a54":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9346f5e8d0d649c583502dbb6202bbc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_df4c5688410b47308e798c24e15124a4","max":467042463,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d844e263894462d8ac162a447562e02","value":467042463}},"94f2bb2fd2304fc795b8f924db35c8fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa981e79ce2d42f1af631e08924555f2","placeholder":"​","style":"IPY_MODEL_05349e963ae6484f8d8c9d0234caf146","value":"Downloading: 100%"}},"963455a597554969a45c3b74014c6b39":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_28106956373d441eb2b4b7c4df59ac14","max":798011,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1bce2d8adc3242ada6736747d72e305d","value":798011}},"a186232a832547328db7c573d02c9f89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bf3d5a3a0274e6dbbb4285206c75c96","max":760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_001df28cd4d64c878a38d5a938a6aea6","value":760}},"a40b3a7a209c4a5497326b11bea3a4ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b98bc3148e04395889c22d17bd2f6b8","placeholder":"​","style":"IPY_MODEL_d173dc9019e742318b8fb53e49f77b7b","value":" 188/188 [00:00&lt;00:00, 3.50kB/s]"}},"a4f85c81a0514fed94e023c3782c5926":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a68128e7c5d14c67bf0a247ca31338cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a73662d822a44c91a6a78efd9f8818ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a81720172d0e467aa938fb1a5890ce21":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8621e8880cd4535b833b2459ae01558":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd38abe72f534c4bbc05def71e195460","placeholder":"​","style":"IPY_MODEL_373a3d02f804424d9f29499a0273c1dc","value":"Downloading: 100%"}},"aa981e79ce2d42f1af631e08924555f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acfd16db66074312a13ad94a9dfbabb2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b020e87c20e64c42b9b6283edaf4295c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b2f180f8499443a78178035ef1902c2d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4bef094940644e0b6276feaabad3cc0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b572c51524134b4390dad767024a3b2e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa3ec1f008ed416ca61add380c601e33","max":433303297,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fdc9c55991814ab188388dd348bfe042","value":433303297}},"b629d933b9c841aa88708396ea6d08e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3a021aedc334d5db31e3d115749baa6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c97955e8bcd94b84a5bfbddd4c275c43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3b06bd6a93e470ea0e6ada21915babb","placeholder":"​","style":"IPY_MODEL_266286d7b9a44fb987ed276d4ac39dbe","value":" 798k/798k [00:00&lt;00:00, 1.75MB/s]"}},"ca1117b0c731451bae8e6bf63832025f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d054809768a14852b4211dc320945036","IPY_MODEL_963455a597554969a45c3b74014c6b39","IPY_MODEL_c97955e8bcd94b84a5bfbddd4c275c43"],"layout":"IPY_MODEL_5db3c5d61d5c430aa0e6a6b60ab1ac19"}},"cbccfdaa773c426aabc5342c8a204eab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d054809768a14852b4211dc320945036":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15a1ea079ee34654a9c0ce75e55e8566","placeholder":"​","style":"IPY_MODEL_213f287bda6b4f66b00fffb1b343ccc1","value":"Downloading: 100%"}},"d173dc9019e742318b8fb53e49f77b7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3b06bd6a93e470ea0e6ada21915babb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9f70aff04c941f5a33b557c3134defe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"daeed3ea163747f49c50c2af9bbbdf4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc143698ed504b0f9f0eaeb5634f4f70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_906386f98d8f4fd3927f49a2d2f405ff","max":435779157,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66be450a7c854b1b8eabd376df42c3c6","value":435779157}},"ded4b4a3b35a4ac586b9bde01ae53d86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4bef094940644e0b6276feaabad3cc0","max":188,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2609e55b32894cfb91e7378f87473bb4","value":188}},"df4c5688410b47308e798c24e15124a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1842d82d43b4465be3e8937a7f4f5f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e40c00d495e542b5971a168aaa141253":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea1f0142522c427b8a39b03957437078":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efa143e2cd7a4ae09edcfb48233a9489":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_450b23d0b2de4e098cda2d815b376d9f","placeholder":"​","style":"IPY_MODEL_b629d933b9c841aa88708396ea6d08e7","value":" 436M/436M [00:10&lt;00:00, 41.2MB/s]"}},"f25c31e8895049c183f2eaf2756a5c91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2be9051b4d24d2cbd91e662d647b469":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2c2f686317f4130aea52043f7d23a46":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f332f0f71dfa4244bb50ab77aca5d45c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d5397bd72b34faab18129ecbbc270fe","placeholder":"​","style":"IPY_MODEL_daeed3ea163747f49c50c2af9bbbdf4f","value":"Downloading: 100%"}},"f3eb7e5660c64640a36f212dc3637dbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f92e41c237df4557b4b80bd4bdf396a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea1f0142522c427b8a39b03957437078","placeholder":"​","style":"IPY_MODEL_d9f70aff04c941f5a33b557c3134defe","value":" 467M/467M [00:12&lt;00:00, 40.8MB/s]"}},"f94dd538cc7f4ba29dd888416c40fe4f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9bd5130682e45c4ba76b1bef887577c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa0c7f0b8f0f47c18756dae1d5919abc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94f2bb2fd2304fc795b8f924db35c8fd","IPY_MODEL_4b32dfd0517b44458928ff22c8ab6dea","IPY_MODEL_6def8847f5a146cdbe3d6b43a78083c9"],"layout":"IPY_MODEL_8e0639d3ea41441abbbeccfa6632c31f"}},"fa3ec1f008ed416ca61add380c601e33":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd38abe72f534c4bbc05def71e195460":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd59172c7d814475bd53470d589c8f21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ff0d37922e34f7885c8d3abb50e88dc","placeholder":"​","style":"IPY_MODEL_f3eb7e5660c64640a36f212dc3637dbe","value":"Downloading: 100%"}},"fdc9c55991814ab188388dd348bfe042":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4f646ae860ea44d9b9e79dc6ed1e6c15":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b9cf18222f694aa38c94590702f1e23e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3e891269b055446988ec3fc1615178ee","IPY_MODEL_dd4d4de30d954fb59192d20341041498","IPY_MODEL_fd3f8f90abdb40f6a82868f9b49ce196"]}},"b9cf18222f694aa38c94590702f1e23e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3e891269b055446988ec3fc1615178ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1a853d58799c436ab8a5db3b775f9f01","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cecce3f305e54059891625f7f8e824f0"}},"dd4d4de30d954fb59192d20341041498":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8de3b4fc6db5430f93ed22206af337f1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":481,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":481,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c69dbd011549416092f02338517a5090"}},"fd3f8f90abdb40f6a82868f9b49ce196":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9f7165dc2a414c839bc330717f4dc706","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 481/481 [00:00&lt;00:00, 10.2kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_abe61baa3ef04998b90795f300b78729"}},"1a853d58799c436ab8a5db3b775f9f01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cecce3f305e54059891625f7f8e824f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8de3b4fc6db5430f93ed22206af337f1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c69dbd011549416092f02338517a5090":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9f7165dc2a414c839bc330717f4dc706":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"abe61baa3ef04998b90795f300b78729":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"47cc7c93968142babcb27a237c7b6e3c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fa2ee3e1b22a4ea896ffcd3767775363","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c74020d77e1f4fdc83c6da6d1690b8ad","IPY_MODEL_7a7216f874f04e78862c1178f6c5210a","IPY_MODEL_efcd6952eb8a408293ae6b76d73b9b0e"]}},"fa2ee3e1b22a4ea896ffcd3767775363":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c74020d77e1f4fdc83c6da6d1690b8ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c80edcd12cbd4f09b17b00144cb332b7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_66f254bc51034680afce2d10eb114c1d"}},"7a7216f874f04e78862c1178f6c5210a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1432dff21c8a4630a7227b887ef44b99","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_99bb9f07e91c4bbea7b48e8e7d240956"}},"efcd6952eb8a408293ae6b76d73b9b0e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bebcdae1422845c6a752c3c5d27b0ea0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:00&lt;00:00, 2.15MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e1dc429f25fb4c8093075e18a6853703"}},"c80edcd12cbd4f09b17b00144cb332b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"66f254bc51034680afce2d10eb114c1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1432dff21c8a4630a7227b887ef44b99":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"99bb9f07e91c4bbea7b48e8e7d240956":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bebcdae1422845c6a752c3c5d27b0ea0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e1dc429f25fb4c8093075e18a6853703":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"911584865dad49859b03d7532b72dbeb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6e55628812ea41fd8ad8668b331826ea","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8f4d31ed00314b5a8d9342b003259b03","IPY_MODEL_3ddfeab59ab34259bfb6c427eab421bd","IPY_MODEL_1b5ff11f8d2044a79ac20c32b323d6b0"]}},"6e55628812ea41fd8ad8668b331826ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8f4d31ed00314b5a8d9342b003259b03":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b138b17fbc024117afd057a3a45983f0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7413a01b7df2471c949e75308d15bbdb"}},"3ddfeab59ab34259bfb6c427eab421bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dbfdf5d8647c4ecd8f396d1f326ea5bc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_022c661555534494a8612546645adfc5"}},"1b5ff11f8d2044a79ac20c32b323d6b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_30e01abb9fb24f1aa3a9361010b70a84","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:00&lt;00:00, 2.08MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ed59518c922d4f368e2ac839335ec4f2"}},"b138b17fbc024117afd057a3a45983f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7413a01b7df2471c949e75308d15bbdb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dbfdf5d8647c4ecd8f396d1f326ea5bc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"022c661555534494a8612546645adfc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30e01abb9fb24f1aa3a9361010b70a84":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ed59518c922d4f368e2ac839335ec4f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"40073a8ccf91401a9d7e6c798e88126f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_54cfbb7513264f0bb28d9b77f0d644bb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_22ead6bcd2ca4a39b91ecde3589edc84","IPY_MODEL_22d61ed900b94f9484549d843054c8b9","IPY_MODEL_89b057040be0419fadde9ca8f406609e"]}},"54cfbb7513264f0bb28d9b77f0d644bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"22ead6bcd2ca4a39b91ecde3589edc84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a5baee23842c4501bcc7d4b4f7973243","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5bc23bec087c4aefa711ccf435498545"}},"22d61ed900b94f9484549d843054c8b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2bb9f980fba24cc5bf3a03c521bf3296","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9759927df77642beb88ac60f51e8ec00"}},"89b057040be0419fadde9ca8f406609e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2de5005115df49ecab9a6ddd198b24bb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 9.91kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_da3f14ec6aa44c43961859a7ce30e93b"}},"a5baee23842c4501bcc7d4b4f7973243":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5bc23bec087c4aefa711ccf435498545":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2bb9f980fba24cc5bf3a03c521bf3296":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9759927df77642beb88ac60f51e8ec00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2de5005115df49ecab9a6ddd198b24bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"da3f14ec6aa44c43961859a7ce30e93b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d583eb7dd72e49f9809336be3a24e12e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e9455342dfa045f1b99c19740e9a937b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2d49833d93ed40939dcd62f704aecc8b","IPY_MODEL_3b453fe885c945e5a6ee086f46cfcb93","IPY_MODEL_34d0f64b5cef41b590514f340e99a5bd"]}},"e9455342dfa045f1b99c19740e9a937b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2d49833d93ed40939dcd62f704aecc8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6553daaf6be54cc8af39f64a84d3416a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bb3d730a8b174e1385b7d7d67b8f97c4"}},"3b453fe885c945e5a6ee086f46cfcb93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d4f096d8c93c4191806bb910f630ef17","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_545deceee5ec45c396ddc86bd4f1ff6e"}},"34d0f64b5cef41b590514f340e99a5bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_19ca7778cb4e4c4c88c51a7b85c52cb5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 213k/213k [00:00&lt;00:00, 2.32MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_04cb7a9aa5c04a7587b68d82f082b8a2"}},"6553daaf6be54cc8af39f64a84d3416a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bb3d730a8b174e1385b7d7d67b8f97c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d4f096d8c93c4191806bb910f630ef17":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"545deceee5ec45c396ddc86bd4f1ff6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19ca7778cb4e4c4c88c51a7b85c52cb5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"04cb7a9aa5c04a7587b68d82f082b8a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":0}